# Kafka / ì¹´í”„ì¹´

> ì¹´í…Œê³ ë¦¬: ë©”ì‹œì§• ì‹œìŠ¤í…œ
> [â† ë©´ì ‘ ì§ˆë¬¸ ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°€ê¸°](../interview.md)

---

## ğŸ“Œ Kafka ê¸°ë³¸ ì•„í‚¤í…ì²˜

### KAFKA-001
Kafkaì˜ ê¸°ë³¸ ì•„í‚¤í…ì²˜ì™€ ì£¼ìš” ì»´í¬ë„ŒíŠ¸(Producer, Broker, Consumer, Topic ë“±)ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

KafkaëŠ” ë¶„ì‚° ìŠ¤íŠ¸ë¦¬ë° í”Œë«í¼ìœ¼ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ì»´í¬ë„ŒíŠ¸ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

- **Producer**: ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ì—¬ Topicì— ë°œí–‰í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸
- **Broker**: ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” Kafka ì„œë²„. í´ëŸ¬ìŠ¤í„°ëŠ” ì—¬ëŸ¬ Brokerë¡œ êµ¬ì„±ë¨
- **Consumer**: Topicì—ì„œ ë©”ì‹œì§€ë¥¼ ì½ì–´ ì²˜ë¦¬í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸
- **Topic**: ë©”ì‹œì§€ê°€ ì €ì¥ë˜ëŠ” ë…¼ë¦¬ì  ì±„ë„. ì¹´í…Œê³ ë¦¬ ë˜ëŠ” í”¼ë“œ ì´ë¦„ê³¼ ìœ ì‚¬
- **Partition**: Topicì„ ë¬¼ë¦¬ì ìœ¼ë¡œ ë¶„í• í•œ ë‹¨ìœ„. ë³‘ë ¬ ì²˜ë¦¬ì™€ í™•ì¥ì„±ì„ ì œê³µ
- **ZooKeeper/KRaft**: í´ëŸ¬ìŠ¤í„° ë©”íƒ€ë°ì´í„° ê´€ë¦¬ ë° ë¦¬ë” ì„ ì¶œ ë‹´ë‹¹

ë©”ì‹œì§€ íë¦„: Producer â†’ Broker(Topic/Partition) â†’ Consumer

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/#gettingStarted)[^1]

</details>

[^1]: Kafka ê³µì‹ ë¬¸ì„œ - Getting Started ì„¹ì…˜

### KAFKA-002
Kafka Brokerì˜ ì—­í• ê³¼ ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

Kafka BrokerëŠ” Kafka í´ëŸ¬ìŠ¤í„°ì˜ í•µì‹¬ ì„œë²„ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

- **ë©”ì‹œì§€ ì €ì¥**: Producerë¡œë¶€í„° ë°›ì€ ë©”ì‹œì§€ë¥¼ ë””ìŠ¤í¬ì— ì˜êµ¬ ì €ì¥
- **ë©”ì‹œì§€ ì „ë‹¬**: Consumer ìš”ì²­ ì‹œ ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ ì „ë‹¬
- **íŒŒí‹°ì…˜ ê´€ë¦¬**: ê° íŒŒí‹°ì…˜ì˜ ë¦¬ë” ë˜ëŠ” íŒ”ë¡œì›Œ ì—­í•  ìˆ˜í–‰
- **ë³µì œ ê´€ë¦¬**: ë°ì´í„° ë³µì œë¥¼ í†µí•œ ë‚´ê²°í•¨ì„± ë³´ì¥
- **í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ ì²˜ë¦¬**: Producer/Consumerì˜ ë©”íƒ€ë°ì´í„° ìš”ì²­ ì²˜ë¦¬

BrokerëŠ” Controllerë¡œ ì„ ì¶œë˜ì–´ íŒŒí‹°ì…˜ ë¦¬ë” ì„ ì¶œ, ë¸Œë¡œì»¤ ì¥ì•  ê°ì§€ ë“± í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Design](https://kafka.apache.org/documentation/#design)[^2]

</details>

[^2]: Kafka ê³µì‹ ë¬¸ì„œ - Design ì„¹ì…˜

### KAFKA-003
Producerì™€ Consumerì˜ ì°¨ì´ì  ë° ì—­í• ì— ëŒ€í•´ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**Producer (ìƒì‚°ì)**
- ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ì—¬ Kafka Topicì— ë°œí–‰
- íŒŒí‹°ì…˜ ì„ íƒ ì „ëµ ê²°ì • (ë¼ìš´ë“œ ë¡œë¹ˆ, í‚¤ ê¸°ë°˜ í•´ì‹± ë“±)
- ë°°ì¹˜ ì „ì†¡, ì••ì¶•, ì¬ì‹œë„ ë“± ì„¤ì • ê°€ëŠ¥
- ACK ì„¤ì •ìœ¼ë¡œ ì „ì†¡ ì‹ ë¢°ì„± ì¡°ì ˆ

**Consumer (ì†Œë¹„ì)**
- Topicì—ì„œ ë©”ì‹œì§€ë¥¼ êµ¬ë…í•˜ê³  ì²˜ë¦¬
- Offsetì„ ê´€ë¦¬í•˜ì—¬ ì²˜ë¦¬ ìœ„ì¹˜ ì¶”ì 
- Consumer Groupì— ì†í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
- Pull ë°©ì‹ìœ¼ë¡œ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜´ (Consumerê°€ ëŠ¥ë™ì ìœ¼ë¡œ ìš”ì²­)

**í•µì‹¬ ì°¨ì´ì **: ProducerëŠ” ë°ì´í„°ë¥¼ ë°€ì–´ë„£ê³ (push), ConsumerëŠ” ë°ì´í„°ë¥¼ ë‹¹ê²¨ì˜´(pull)

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Producers](https://kafka.apache.org/documentation/#theproducer)[^3]

</details>

[^3]: Kafka ê³µì‹ ë¬¸ì„œ - Producer/Consumer API

### KAFKA-004
Kafkaì—ì„œ Partitionê³¼ Offsetì˜ ê°œë… ë° í™œìš© ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**Partition (íŒŒí‹°ì…˜)**
- Topicì„ ë¬¼ë¦¬ì ìœ¼ë¡œ ë¶„í• í•œ ë‹¨ìœ„
- ê° íŒŒí‹°ì…˜ì€ ìˆœì„œê°€ ë³´ì¥ëœ ë¶ˆë³€ì˜ ë©”ì‹œì§€ ì‹œí€€ìŠ¤
- ë³‘ë ¬ ì²˜ë¦¬ì˜ ê¸°ë³¸ ë‹¨ìœ„ (íŒŒí‹°ì…˜ ìˆ˜ = ìµœëŒ€ Consumer ë³‘ë ¬ì„±)
- íŒŒí‹°ì…˜ í‚¤ë¥¼ í†µí•´ ê´€ë ¨ ë©”ì‹œì§€ë¥¼ ê°™ì€ íŒŒí‹°ì…˜ì— ì €ì¥ ê°€ëŠ¥

**Offset (ì˜¤í”„ì…‹)**
- íŒŒí‹°ì…˜ ë‚´ ê° ë©”ì‹œì§€ì˜ ê³ ìœ  ì‹ë³„ì (ìˆœì°¨ ì¦ê°€í•˜ëŠ” ì •ìˆ˜)
- Consumerê°€ ì–´ë””ê¹Œì§€ ì½ì—ˆëŠ”ì§€ ì¶”ì í•˜ëŠ” ìœ„ì¹˜ í‘œì‹œ
- ìë™/ìˆ˜ë™ ì»¤ë°‹ì„ í†µí•´ ê´€ë¦¬
- `__consumer_offsets` í† í”½ì— ì €ì¥ë¨

**í™œìš©**: íŒŒí‹°ì…˜ ìˆ˜ë¥¼ ëŠ˜ë ¤ ì²˜ë¦¬ëŸ‰ í™•ì¥, Offsetì„ ì¡°ì ˆí•˜ì—¬ ë©”ì‹œì§€ ì¬ì²˜ë¦¬ ê°€ëŠ¥

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Topics and Logs](https://kafka.apache.org/documentation/#intro_topics)[^4]

</details>

[^4]: Kafka ê³µì‹ ë¬¸ì„œ - Topics and Logs

---

## ğŸ“Œ Kafka ë©”ì‹œì§€ ë³´ì¡´ê³¼ ì²˜ë¦¬

### KAFKA-005
Kafkaì˜ ë©”ì‹œì§€ ë³´ì¡´ ì •ì±…(retention policy)ì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?

<details>
<summary>ë‹µë³€</summary>

KafkaëŠ” ë‘ ê°€ì§€ ë©”ì‹œì§€ ë³´ì¡´ ì •ì±…ì„ ì œê³µí•©ë‹ˆë‹¤:

**ì‹œê°„ ê¸°ë°˜ ë³´ì¡´ (Time-based)**
- `log.retention.hours/minutes/ms`: ë©”ì‹œì§€ ë³´ì¡´ ê¸°ê°„ ì„¤ì •
- ê¸°ë³¸ê°’: 7ì¼ (168ì‹œê°„)
- ì„¤ì •ëœ ì‹œê°„ì´ ì§€ë‚˜ë©´ ìë™ ì‚­ì œ

**í¬ê¸° ê¸°ë°˜ ë³´ì¡´ (Size-based)**
- `log.retention.bytes`: íŒŒí‹°ì…˜ë‹¹ ìµœëŒ€ ë¡œê·¸ í¬ê¸°
- í¬ê¸° ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ ì„¸ê·¸ë¨¼íŠ¸ë¶€í„° ì‚­ì œ

**ì„¸ê·¸ë¨¼íŠ¸ ê´€ë¦¬**
- `log.segment.bytes`: ì„¸ê·¸ë¨¼íŠ¸ íŒŒì¼ í¬ê¸° (ê¸°ë³¸ 1GB)
- `log.segment.ms`: ì„¸ê·¸ë¨¼íŠ¸ ë¡¤ë§ ì£¼ê¸°
- ì‚­ì œëŠ” ì„¸ê·¸ë¨¼íŠ¸ ë‹¨ìœ„ë¡œ ìˆ˜í–‰ë¨

ë‘ ì •ì±… ëª¨ë‘ ì„¤ì • ì‹œ, ë¨¼ì € ë„ë‹¬í•˜ëŠ” ì¡°ê±´ì— ë”°ë¼ ì‚­ì œë©ë‹ˆë‹¤.

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Log Retention](https://kafka.apache.org/documentation/#brokerconfigs_log.retention.hours)[^5]

</details>

[^5]: Kafka ê³µì‹ ë¬¸ì„œ - Broker Configurations

### KAFKA-006
Consumer Groupì˜ ê°œë…ê³¼ ì´ë¥¼ í†µí•´ ë©”ì‹œì§€ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì–´ë–»ê²Œ êµ¬í˜„í•˜ëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**Consumer Group ê°œë…**
- ë™ì¼í•œ `group.id`ë¥¼ ê³µìœ í•˜ëŠ” Consumerë“¤ì˜ ë…¼ë¦¬ì  ê·¸ë£¹
- ê·¸ë£¹ ë‚´ ê° ConsumerëŠ” ì„œë¡œ ë‹¤ë¥¸ íŒŒí‹°ì…˜ì„ ë‹´ë‹¹
- í•˜ë‚˜ì˜ íŒŒí‹°ì…˜ì€ ê·¸ë£¹ ë‚´ í•˜ë‚˜ì˜ Consumerë§Œ ì†Œë¹„ ê°€ëŠ¥

**ë³‘ë ¬ ì²˜ë¦¬ êµ¬í˜„**
1. Topicì˜ íŒŒí‹°ì…˜ ìˆ˜ ì„¤ì • (ì˜ˆ: 6ê°œ)
2. Consumer Group ìƒì„± í›„ ì—¬ëŸ¬ Consumer ì¶”ê°€
3. Kafkaê°€ ìë™ìœ¼ë¡œ íŒŒí‹°ì…˜ì„ Consumerì— ë¶„ë°° (Rebalancing)
4. ê° Consumerê°€ í• ë‹¹ëœ íŒŒí‹°ì…˜ì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬

**ì£¼ì˜ì‚¬í•­**
- Consumer ìˆ˜ > íŒŒí‹°ì…˜ ìˆ˜ì¼ ê²½ìš°, ìœ íœ´ Consumer ë°œìƒ
- ìµœì  ë³‘ë ¬ì„±: Consumer ìˆ˜ = íŒŒí‹°ì…˜ ìˆ˜
- ì„œë¡œ ë‹¤ë¥¸ Consumer Groupì€ ê°™ì€ ë©”ì‹œì§€ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì†Œë¹„ ê°€ëŠ¥

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Consumer Groups](https://kafka.apache.org/documentation/#intro_consumers)[^6]

</details>

[^6]: Kafka ê³µì‹ ë¬¸ì„œ - Consumers ì„¹ì…˜

---

## ğŸ“Œ Kafka ê³ ê°€ìš©ì„±

### KAFKA-007
Kafkaì—ì„œ ë¦¬í”Œë¦¬ì¼€ì´ì…˜(replication)ì˜ í•„ìš”ì„±ê³¼ ì„¤ì • ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ë¦¬í”Œë¦¬ì¼€ì´ì…˜ì˜ í•„ìš”ì„±**
- ë¸Œë¡œì»¤ ì¥ì•  ì‹œ ë°ì´í„° ì†ì‹¤ ë°©ì§€
- ê³ ê°€ìš©ì„±(High Availability) ë³´ì¥
- ë¬´ì¤‘ë‹¨ ì„œë¹„ìŠ¤ ìš´ì˜ ê°€ëŠ¥

**ì„¤ì • ë°©ë²•**
- `replication.factor`: í† í”½ ìƒì„± ì‹œ ë³µì œë³¸ ìˆ˜ ì§€ì • (ê¶Œì¥: 3)
- `default.replication.factor`: ê¸°ë³¸ ë³µì œ ê³„ìˆ˜ ì„¤ì •
- `min.insync.replicas`: ìµœì†Œ ë™ê¸°í™” ë³µì œë³¸ ìˆ˜ (ê¶Œì¥: 2)

**ë™ì‘ ë°©ì‹**
- ê° íŒŒí‹°ì…˜ì—ëŠ” 1ê°œì˜ Leaderì™€ N-1ê°œì˜ Follower
- Producer/ConsumerëŠ” Leaderì™€ë§Œ í†µì‹ 
- FollowerëŠ” Leaderë¡œë¶€í„° ë°ì´í„°ë¥¼ ë³µì œ
- Leader ì¥ì•  ì‹œ ISR ì¤‘ í•˜ë‚˜ê°€ ìƒˆ Leaderë¡œ ì„ ì¶œ

```bash
kafka-topics.sh --create --topic my-topic \
  --partitions 3 --replication-factor 3
```

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Replication](https://kafka.apache.org/documentation/#replication)[^7]

</details>

[^7]: Kafka ê³µì‹ ë¬¸ì„œ - Replication ì„¹ì…˜

### KAFKA-008
Kafka í´ëŸ¬ìŠ¤í„°ì˜ ì¥ì•  ë³µêµ¬(failover) ë©”ì»¤ë‹ˆì¦˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**Leader ì„ ì¶œ ê³¼ì •**
1. Controllerê°€ ë¸Œë¡œì»¤ ì¥ì•  ê°ì§€ (ZooKeeper/KRaft í†µí•´)
2. ì¥ì•  ë¸Œë¡œì»¤ê°€ ë‹´ë‹¹í•˜ë˜ íŒŒí‹°ì…˜ì˜ ISR ëª©ë¡ í™•ì¸
3. ISR ì¤‘ í•˜ë‚˜ë¥¼ ìƒˆë¡œìš´ Leaderë¡œ ì„ ì¶œ
4. ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ë° í´ë¼ì´ì–¸íŠ¸ì— ì „íŒŒ

**Failover ì„¤ì •**
- `unclean.leader.election.enable`: ISR ì™¸ ë³µì œë³¸ì˜ ë¦¬ë” ìŠ¹ê²© í—ˆìš© ì—¬ë¶€ (ê¸°ë³¸: false)
- `leader.imbalance.check.interval.seconds`: ë¦¬ë” ì¬ë¶„ë°° ì£¼ê¸°
- `controlled.shutdown.enable`: ì •ìƒ ì¢…ë£Œ ì‹œ ë¦¬ë” ì´ì „ ì—¬ë¶€

**í´ë¼ì´ì–¸íŠ¸ ë³µêµ¬**
- Producer: ì¬ì‹œë„ ë¡œì§ìœ¼ë¡œ ìƒˆ Leaderì— ì¬ì „ì†¡
- Consumer: ìƒˆ Leaderë¡œë¶€í„° ì´ì–´ì„œ ì†Œë¹„

**ì£¼ì˜**: `unclean.leader.election.enable=true`ëŠ” ë°ì´í„° ì†ì‹¤ ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë¯€ë¡œ ì‹ ì¤‘íˆ ì„¤ì •

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Leader Election](https://kafka.apache.org/documentation/#design_replicatedlog)[^8]

</details>

[^8]: Kafka ê³µì‹ ë¬¸ì„œ - Replicated Logs

---

## ğŸ“Œ Kafka Connectì™€ Streams

### KAFKA-009
Kafka Connectì˜ ì—­í• ê³¼ ì´ë¥¼ í™œìš©í•œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**Kafka Connect ì—­í• **
- ì™¸ë¶€ ì‹œìŠ¤í…œê³¼ Kafka ê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬
- ì½”ë“œ ì‘ì„± ì—†ì´ ì„¤ì •ë§Œìœ¼ë¡œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- Source Connector: ì™¸ë¶€ â†’ Kafkaë¡œ ë°ì´í„° ìˆ˜ì§‘
- Sink Connector: Kafka â†’ ì™¸ë¶€ë¡œ ë°ì´í„° ì „ì†¡

**ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ë°©ë²•**
1. Connect í´ëŸ¬ìŠ¤í„° ì„¤ì • (standalone/distributed ëª¨ë“œ)
2. Connector í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜ (JDBC, S3, Elasticsearch ë“±)
3. Connector ì„¤ì • JSON ì‘ì„±
4. REST APIë¡œ Connector ë°°í¬

```json
{
  "name": "mysql-source",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
    "connection.url": "jdbc:mysql://localhost:3306/mydb",
    "topic.prefix": "mysql-",
    "poll.interval.ms": "1000"
  }
}
```

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Connect](https://kafka.apache.org/documentation/#connect)[^9]

</details>

[^9]: Kafka ê³µì‹ ë¬¸ì„œ - Kafka Connect

### KAFKA-010
Kafka Streamsì™€ KSQLì˜ ì°¨ì´ì  ë° ê°ê°ì˜ ì‚¬ìš© ì‚¬ë¡€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**Kafka Streams**
- Java/Scala ë¼ì´ë¸ŒëŸ¬ë¦¬ (ë³„ë„ í´ëŸ¬ìŠ¤í„° ë¶ˆí•„ìš”)
- ë³µì¡í•œ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ë¡œì§ êµ¬í˜„ ê°€ëŠ¥
- ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ì— ë‚´ì¥í•˜ì—¬ ì‚¬ìš©
- ì‚¬ìš© ì‚¬ë¡€: ì‹¤ì‹œê°„ ë°ì´í„° ë³€í™˜, ì§‘ê³„, ì¡°ì¸

**KSQL (ksqlDB)**
- SQL ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì¿¼ë¦¬ ì—”ì§„
- ë³„ë„ì˜ KSQL ì„œë²„ í´ëŸ¬ìŠ¤í„° í•„ìš”
- ì½”ë“œ ì—†ì´ SQLë§Œìœ¼ë¡œ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
- ì‚¬ìš© ì‚¬ë¡€: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘, ë°ì´í„° ë¶„ì„, ê°„ë‹¨í•œ ETL

**ì£¼ìš” ì°¨ì´ì **
| êµ¬ë¶„ | Kafka Streams | KSQL |
|------|---------------|------|
| ì–¸ì–´ | Java/Scala | SQL |
| ë°°í¬ | ì• í”Œë¦¬ì¼€ì´ì…˜ ë‚´ì¥ | ë³„ë„ í´ëŸ¬ìŠ¤í„° |
| ë³µì¡ë„ | ë†’ì€ ìœ ì—°ì„± | ë‚®ì€ ì§„ì… ì¥ë²½ |
| ì í•© ëŒ€ìƒ | ê°œë°œì | ë°ì´í„° ë¶„ì„ê°€ |

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Streams](https://kafka.apache.org/documentation/streams/)[^10]

</details>

[^10]: Kafka ê³µì‹ ë¬¸ì„œ - Kafka Streams

---

## ğŸ“Œ Kafka ë©”ì‹œì§€ ì „ë‹¬ ë³´ì¥

### KAFKA-011
Kafkaì—ì„œ Exactly-Once Semanticsë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**Exactly-Once Semantics (EOS) êµ¬í˜„ ë°©ë²•**

**1. Idempotent Producer**
- `enable.idempotence=true` ì„¤ì •
- Producer IDì™€ ì‹œí€€ìŠ¤ ë²ˆí˜¸ë¡œ ì¤‘ë³µ ë©”ì‹œì§€ ë°©ì§€
- ë‹¨ì¼ íŒŒí‹°ì…˜ ë‚´ì—ì„œ exactly-once ë³´ì¥

**2. Transactional API**
- ì—¬ëŸ¬ íŒŒí‹°ì…˜ì— ê±¸ì¹œ ì›ìì  ì“°ê¸°
- `transactional.id` ì„¤ì • í•„ìš”
```java
producer.initTransactions();
producer.beginTransaction();
producer.send(record1);
producer.send(record2);
producer.commitTransaction();
```

**3. Consumer ì„¤ì •**
- `isolation.level=read_committed`: ì»¤ë°‹ëœ íŠ¸ëœì­ì…˜ë§Œ ì½ê¸°
- ìˆ˜ë™ ì˜¤í”„ì…‹ ì»¤ë°‹ìœ¼ë¡œ ì²˜ë¦¬ ì™„ë£Œ í›„ ì»¤ë°‹

**Kafka Streams**
- `processing.guarantee=exactly_once_v2` ì„¤ì •ìœ¼ë¡œ ìë™ EOS ì§€ì›

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Transactions](https://kafka.apache.org/documentation/#semantics)[^11]

</details>

[^11]: Kafka ê³µì‹ ë¬¸ì„œ - Message Delivery Semantics

### KAFKA-012
Producer ì¸¡ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë©”ì‹œì§€ ì¤‘ë³µ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‚˜ìš”?

<details>
<summary>ë‹µë³€</summary>

**ì¤‘ë³µ ë°œìƒ ì›ì¸**
- ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ë¡œ ACK ë¯¸ìˆ˜ì‹  í›„ ì¬ì „ì†¡
- Producer ì¬ì‹œì‘ í›„ ë™ì¼ ë©”ì‹œì§€ ì¬ì „ì†¡
- ë¸Œë¡œì»¤ ì¥ì•  ë³µêµ¬ ê³¼ì •ì—ì„œì˜ ì¤‘ë³µ

**í•´ê²° ë°©ë²•**

**1. Idempotent Producer í™œì„±í™”**
```properties
enable.idempotence=true
acks=all
retries=Integer.MAX_VALUE
max.in.flight.requests.per.connection=5
```
- PID(Producer ID) + Sequence Numberë¡œ ì¤‘ë³µ ê°ì§€ ë° ë¬´ì‹œ

**2. Transactional Producer ì‚¬ìš©**
- íŠ¸ëœì­ì…˜ ë‹¨ìœ„ë¡œ ì›ìì  ì „ì†¡ ë³´ì¥
- ì¥ì•  ë³µêµ¬ ì‹œì—ë„ ì¤‘ë³µ ë°©ì§€

**3. Consumer ì¸¡ ë©±ë“±ì„± ì²˜ë¦¬**
- ë©”ì‹œì§€ì— ê³ ìœ  ID í¬í•¨
- ì²˜ë¦¬ ì „ ì¤‘ë³µ ì²´í¬ (DB unique constraint, Redis ë“±)
- ë©±ë“±í•œ ì²˜ë¦¬ ë¡œì§ ì„¤ê³„

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Idempotent Producer](https://kafka.apache.org/documentation/#producerconfigs_enable.idempotence)[^12]

</details>

[^12]: Kafka ê³µì‹ ë¬¸ì„œ - Producer Configs

### KAFKA-013
Kafka Consumerê°€ ì¬ì‹œì‘ë  ë•Œ ì˜¤í”„ì…‹(offset) ê´€ë¦¬ë¥¼ ì–´ë–»ê²Œ ìˆ˜í–‰í•˜ë‚˜ìš”?

<details>
<summary>ë‹µë³€</summary>

**Offset ì €ì¥ ìœ„ì¹˜**
- ë‚´ë¶€ í† í”½ `__consumer_offsets`ì— ì €ì¥
- Consumer Group IDì™€ Topic-Partition ë³„ë¡œ ê´€ë¦¬

**ì¬ì‹œì‘ ì‹œ ë™ì‘**
1. Consumerê°€ Groupì— ì¡°ì¸
2. ë§ˆì§€ë§‰ ì»¤ë°‹ëœ Offset ì¡°íšŒ
3. í•´ë‹¹ Offsetë¶€í„° ë©”ì‹œì§€ ì†Œë¹„ ì¬ê°œ

**Offset Reset ì •ì±… (auto.offset.reset)**
- `earliest`: ê°€ì¥ ì²˜ìŒ Offsetë¶€í„° ì‹œì‘
- `latest`: ê°€ì¥ ìµœê·¼ Offsetë¶€í„° ì‹œì‘ (ê¸°ë³¸ê°’)
- `none`: Offset ì—†ìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ

**ì»¤ë°‹ ì „ëµ**
```properties
# ìë™ ì»¤ë°‹
enable.auto.commit=true
auto.commit.interval.ms=5000

# ìˆ˜ë™ ì»¤ë°‹ (ê¶Œì¥)
enable.auto.commit=false
```

**ìˆ˜ë™ ì»¤ë°‹ ë°©ì‹**
- `commitSync()`: ë™ê¸° ì»¤ë°‹ (ë¸”ë¡œí‚¹)
- `commitAsync()`: ë¹„ë™ê¸° ì»¤ë°‹ (ë…¼ë¸”ë¡œí‚¹)

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Consumer Configs](https://kafka.apache.org/documentation/#consumerconfigs)[^13]

</details>

[^13]: Kafka ê³µì‹ ë¬¸ì„œ - Consumer Configurations

---

## ğŸ“Œ Kafka ë¡œê·¸ ê´€ë¦¬

### KAFKA-014
Kafka ë¡œê·¸ ì»´íŒ©ì…˜(log compaction)ì´ë€ ë¬´ì—‡ì´ë©°, ì–´ë–¤ ìƒí™©ì—ì„œ ì‚¬ìš©ë˜ë‚˜ìš”?

<details>
<summary>ë‹µë³€</summary>

**Log Compaction ê°œë…**
- ë™ì¼í•œ í‚¤ë¥¼ ê°€ì§„ ë©”ì‹œì§€ ì¤‘ ìµœì‹  ê°’ë§Œ ìœ ì§€í•˜ëŠ” ë³´ì¡´ ì •ì±…
- í‚¤-ê°’ ì €ì¥ì†Œì²˜ëŸ¼ ê° í‚¤ì˜ ìµœì¢… ìƒíƒœë§Œ ë³´ê´€
- ì‚­ì œê°€ ì•„ë‹Œ ì••ì¶•ì„ í†µí•´ ë¡œê·¸ í¬ê¸° ê°ì†Œ

**ì„¤ì • ë°©ë²•**
```properties
cleanup.policy=compact          # ì»´íŒ©ì…˜ í™œì„±í™”
cleanup.policy=compact,delete   # ë‘˜ ë‹¤ ì ìš©
min.cleanable.dirty.ratio=0.5   # ì»´íŒ©ì…˜ íŠ¸ë¦¬ê±° ë¹„ìœ¨
```

**ì‚¬ìš© ì‚¬ë¡€**
- **CDC (Change Data Capture)**: DB ë³€ê²½ ì´ë²¤íŠ¸ ì €ì¥
- **ìƒíƒœ ì €ì¥ì†Œ**: ì‚¬ìš©ì ì„¤ì •, ì„¸ì…˜ ì •ë³´
- **Kafka Streams State Store**: ë‚´ë¶€ ìƒíƒœ ë³µì›
- **Consumer Offset í† í”½**: `__consumer_offsets`

**Tombstone ë ˆì½”ë“œ**
- í‚¤ì— null ê°’ì„ ì „ì†¡í•˜ë©´ í•´ë‹¹ í‚¤ ì‚­ì œ í‘œì‹œ
- `delete.retention.ms` í›„ ì™„ì „ ì‚­ì œ

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Log Compaction](https://kafka.apache.org/documentation/#compaction)[^14]

</details>

[^14]: Kafka ê³µì‹ ë¬¸ì„œ - Log Compaction

---

## ğŸ“Œ Kafka ì„±ëŠ¥ íŠœë‹

### KAFKA-015
Kafka ì„±ëŠ¥ íŠœë‹ì„ ìœ„í•œ ì£¼ìš” ê³ ë ¤ ì‚¬í•­ì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?

<details>
<summary>ë‹µë³€</summary>

**Producer íŠœë‹**
- `batch.size`: ë°°ì¹˜ í¬ê¸° ì¦ê°€ (ê¸°ë³¸ 16KB â†’ 64KB ì´ìƒ)
- `linger.ms`: ë°°ì¹˜ ëŒ€ê¸° ì‹œê°„ (0 â†’ 5-100ms)
- `compression.type`: ì••ì¶• í™œì„±í™” (lz4, snappy)
- `buffer.memory`: ë²„í¼ ë©”ëª¨ë¦¬ í™•ëŒ€

**Consumer íŠœë‹**
- `fetch.min.bytes`: ìµœì†Œ fetch í¬ê¸° ì¦ê°€
- `fetch.max.wait.ms`: ëŒ€ê¸° ì‹œê°„ ì¡°ì •
- `max.poll.records`: í´ë§ë‹¹ ë ˆì½”ë“œ ìˆ˜ ì¡°ì •

**Broker íŠœë‹**
- `num.io.threads`: I/O ìŠ¤ë ˆë“œ ìˆ˜ (ë””ìŠ¤í¬ ìˆ˜ì— ë§ê²Œ)
- `num.network.threads`: ë„¤íŠ¸ì›Œí¬ ìŠ¤ë ˆë“œ ìˆ˜
- `socket.send.buffer.bytes/socket.receive.buffer.bytes`: ì†Œì¼“ ë²„í¼ í¬ê¸°
- `log.flush.interval.messages`: ë””ìŠ¤í¬ í”ŒëŸ¬ì‹œ ê°„ê²©

**ì¼ë°˜ ê³ ë ¤ì‚¬í•­**
- íŒŒí‹°ì…˜ ìˆ˜ ì ì • ì„¤ê³„
- JVM í™ ì„¤ì • (6-8GB ê¶Œì¥)
- í˜ì´ì§€ ìºì‹œë¥¼ ìœ„í•œ OS ë©”ëª¨ë¦¬ í™•ë³´

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Configuration](https://kafka.apache.org/documentation/#configuration)[^15]

</details>

[^15]: Kafka ê³µì‹ ë¬¸ì„œ - Configuration

### KAFKA-016
Kafka í´ëŸ¬ìŠ¤í„° êµ¬ì„± ì‹œ ë„¤íŠ¸ì›Œí¬ ë° í•˜ë“œì›¨ì–´ ì„¤ì •ì—ì„œ ê³ ë ¤í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ë„¤íŠ¸ì›Œí¬ ì„¤ì •**
- ë¸Œë¡œì»¤ ê°„ ì „ìš© ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ í™•ë³´ (10Gbps ê¶Œì¥)
- í´ë¼ì´ì–¸íŠ¸-ë¸Œë¡œì»¤ ê°„ ë‚®ì€ ë ˆì´í„´ì‹œ ë„¤íŠ¸ì›Œí¬
- `socket.send.buffer.bytes`, `socket.receive.buffer.bytes` íŠœë‹
- TCP ì„¤ì • ìµœì í™” (net.core.rmem_max ë“±)

**ìŠ¤í† ë¦¬ì§€**
- SSD ê¶Œì¥ (ì²˜ë¦¬ëŸ‰ í–¥ìƒ)
- RAID 10 ë˜ëŠ” JBOD êµ¬ì„±
- ì—¬ëŸ¬ ë””ìŠ¤í¬ì— ë¡œê·¸ ë””ë ‰í† ë¦¬ ë¶„ì‚° (`log.dirs`)
- XFS íŒŒì¼ì‹œìŠ¤í…œ ê¶Œì¥

**ë©”ëª¨ë¦¬**
- JVM í™: 6-8GB (ê³¼ë„í•œ GC ë°©ì§€)
- ë‚˜ë¨¸ì§€ëŠ” OS í˜ì´ì§€ ìºì‹œìš©ìœ¼ë¡œ í™•ë³´
- ì´ ë©”ëª¨ë¦¬: 32-64GB ê¶Œì¥

**CPU**
- ì••ì¶• ì‚¬ìš© ì‹œ CPU ì½”ì–´ ì¤‘ìš”
- ìµœì†Œ 8ì½”ì–´ ì´ìƒ ê¶Œì¥

**íŒŒí‹°ì…˜/ë¸Œë¡œì»¤ ë¹„ìœ¨**
- ë¸Œë¡œì»¤ë‹¹ íŒŒí‹°ì…˜ ìˆ˜ ì œí•œ (4,000ê°œ ì´í•˜ ê¶Œì¥)
- ë¦¬ë” íŒŒí‹°ì…˜ ê· ë“± ë¶„ë°°

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Hardware and OS](https://kafka.apache.org/documentation/#hwandos)[^16]

</details>

[^16]: Kafka ê³µì‹ ë¬¸ì„œ - Hardware and OS

### KAFKA-017
Kafkaì—ì„œ ë°ì´í„° ì†ì‹¤ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì „ëµì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**Producer ì„¤ì •**
- `acks=all`: ëª¨ë“  ISR ë³µì œ ì™„ë£Œ í›„ ACK
- `retries`: ì¶©ë¶„í•œ ì¬ì‹œë„ íšŸìˆ˜ ì„¤ì •
- `enable.idempotence=true`: ë©±ë“±ì„± í™œì„±í™”

**Broker ì„¤ì •**
- `replication.factor=3`: 3ê°œ ì´ìƒ ë³µì œë³¸
- `min.insync.replicas=2`: ìµœì†Œ 2ê°œ ë™ê¸°í™” í•„ìˆ˜
- `unclean.leader.election.enable=false`: ë¹„ë™ê¸° ë³µì œë³¸ì˜ ë¦¬ë” ìŠ¹ê²© ë°©ì§€
- `default.replication.factor=3`: ê¸°ë³¸ ë³µì œ ê³„ìˆ˜

**Consumer ì„¤ì •**
- `enable.auto.commit=false`: ìˆ˜ë™ ì˜¤í”„ì…‹ ì»¤ë°‹
- ì²˜ë¦¬ ì™„ë£Œ í›„ ì»¤ë°‹ (at-least-once ë³´ì¥)

**ìš´ì˜ ì „ëµ**
- ë‹¤ì¤‘ ë°ì´í„°ì„¼í„° ë³µì œ (MirrorMaker 2)
- ì •ê¸°ì ì¸ ë°±ì—… ë° ë³µêµ¬ í…ŒìŠ¤íŠ¸
- ëª¨ë‹ˆí„°ë§: Under-replicated partitions ê°ì‹œ

**ì¡°í•© ì˜ˆì‹œ**
```properties
acks=all
min.insync.replicas=2
replication.factor=3
```
â†’ ìµœì†Œ 2ê°œ ë¸Œë¡œì»¤ ì¥ì• ê¹Œì§€ ë°ì´í„° ì•ˆì „

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Durability](https://kafka.apache.org/documentation/#design_ha)[^17]

</details>

[^17]: Kafka ê³µì‹ ë¬¸ì„œ - High Availability

---

## ğŸ“Œ Kafka ë³´ì•ˆ

### KAFKA-018
Kafkaì˜ ACL(Access Control List) ë° ë³´ì•ˆ ì„¤ì • ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**ACL ê°œë…**
- ë¦¬ì†ŒìŠ¤(Topic, Consumer Group ë“±)ì— ëŒ€í•œ ì ‘ê·¼ ê¶Œí•œ ì œì–´
- Principal(ì‚¬ìš©ì/ì„œë¹„ìŠ¤)ë³„ë¡œ í—ˆìš©/ê±°ë¶€ ê·œì¹™ ì •ì˜

**ACL êµ¬ì„± ìš”ì†Œ**
- **Principal**: ì ‘ê·¼ ì£¼ì²´ (User:alice)
- **Resource**: ëŒ€ìƒ ë¦¬ì†ŒìŠ¤ (Topic:orders)
- **Operation**: í—ˆìš© ì‘ì—… (Read, Write, Create ë“±)
- **Permission**: Allow ë˜ëŠ” Deny

**ì„¤ì • ë°©ë²•**

1. **Broker ì„¤ì •**
```properties
authorizer.class.name=kafka.security.authorizer.AclAuthorizer
super.users=User:admin
allow.everyone.if.no.acl.found=false
```

2. **ACL ì¶”ê°€**
```bash
kafka-acls.sh --bootstrap-server localhost:9092 \
  --add --allow-principal User:producer \
  --operation Write --topic orders

kafka-acls.sh --bootstrap-server localhost:9092 \
  --add --allow-principal User:consumer \
  --operation Read --topic orders --group my-group
```

3. **ACL ì¡°íšŒ**
```bash
kafka-acls.sh --bootstrap-server localhost:9092 --list
```

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Authorization](https://kafka.apache.org/documentation/#security_authz)[^18]

</details>

[^18]: Kafka ê³µì‹ ë¬¸ì„œ - Authorization and ACLs

### KAFKA-019
SSL/TLS ë° SASLì„ ì‚¬ìš©í•œ Kafka ë³´ì•ˆ êµ¬ì„± ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**SSL/TLS (ì „ì†¡ ì•”í˜¸í™”)**

1. **ì¸ì¦ì„œ ìƒì„±** (keytool ì‚¬ìš©)
```bash
keytool -genkey -keystore kafka.server.keystore.jks \
  -alias localhost -validity 365 -keyalg RSA
```

2. **Broker ì„¤ì •**
```properties
listeners=SSL://0.0.0.0:9093
ssl.keystore.location=/var/ssl/kafka.server.keystore.jks
ssl.keystore.password=password
ssl.key.password=password
ssl.truststore.location=/var/ssl/kafka.server.truststore.jks
ssl.truststore.password=password
```

**SASL (ì¸ì¦)**

1. **SASL/PLAIN** (ê°„ë‹¨í•œ ì‚¬ìš©ì/ë¹„ë°€ë²ˆí˜¸)
```properties
listeners=SASL_SSL://0.0.0.0:9094
sasl.enabled.mechanisms=PLAIN
```

2. **SASL/SCRAM** (ì•ˆì „í•œ ë¹„ë°€ë²ˆí˜¸ ì €ì¥)
```bash
kafka-configs.sh --zookeeper localhost:2181 --alter \
  --add-config 'SCRAM-SHA-256=[password=secret]' \
  --entity-type users --entity-name alice
```

3. **SASL/GSSAPI** (Kerberos)
- ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì—ì„œ ì£¼ë¡œ ì‚¬ìš©
- Kerberos KDC ì—°ë™ í•„ìš”

**ê¶Œì¥ ì¡°í•©**: SASL_SSL (ì¸ì¦ + ì•”í˜¸í™”)

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Security](https://kafka.apache.org/documentation/#security)[^19]

</details>

[^19]: Kafka ê³µì‹ ë¬¸ì„œ - Security

---

## ğŸ“Œ Kafka í´ëŸ¬ìŠ¤í„° ì•ˆì •ì„±

### KAFKA-020
Kafka Broker ì¬ì‹œì‘ ì‹œ í´ëŸ¬ìŠ¤í„° ì•ˆì •ì„±ì„ ìœ ì§€í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**Rolling Restart ì ˆì°¨**
1. ë¸Œë¡œì»¤ì˜ `controlled.shutdown.enable=true` í™•ì¸
2. í•œ ë²ˆì— í•˜ë‚˜ì˜ ë¸Œë¡œì»¤ë§Œ ì¬ì‹œì‘
3. ISRì´ ë³µêµ¬ë  ë•Œê¹Œì§€ ëŒ€ê¸° í›„ ë‹¤ìŒ ë¸Œë¡œì»¤ ì§„í–‰

**ì•ˆì •ì„± ìœ ì§€ ì„¤ì •**
```properties
# Broker ì„¤ì •
controlled.shutdown.enable=true
controlled.shutdown.max.retries=3
min.insync.replicas=2

# Topic ì„¤ì •
replication.factor=3
```

**ì¬ì‹œì‘ ì „ í™•ì¸ ì‚¬í•­**
```bash
# Under-replicated íŒŒí‹°ì…˜ í™•ì¸
kafka-topics.sh --describe --under-replicated-partitions

# ISR ìƒíƒœ í™•ì¸
kafka-topics.sh --describe --topic my-topic
```

**ëª¨ë²” ì‚¬ë¡€**
- í”¼í¬ ì‹œê°„ ì™¸ ì¬ì‹œì‘ ìˆ˜í–‰
- ë¦¬ë” ì¬ë¶„ë°° ìë™í™” (`auto.leader.rebalance.enable=true`)
- ëª¨ë‹ˆí„°ë§ ì•Œë¦¼ ì„¤ì •
- ì¶©ë¶„í•œ ë³µì œë³¸ ìˆ˜ ìœ ì§€ (3ê°œ ì´ìƒ)

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Broker Configs](https://kafka.apache.org/documentation/#brokerconfigs)[^20]

</details>

[^20]: Kafka ê³µì‹ ë¬¸ì„œ - Broker Configurations

### KAFKA-021
In-Sync Replica(ISR)ì˜ ì—­í• ê³¼ ì¤‘ìš”ì„±ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ISR (In-Sync Replica) ê°œë…**
- Leaderì™€ ë™ê¸°í™”ëœ Replicaë“¤ì˜ ì§‘í•©
- Leaderë¥¼ í¬í•¨í•œ "ì¶©ë¶„íˆ ìµœì‹  ìƒíƒœ"ì¸ ë³µì œë³¸ë“¤
- `replica.lag.time.max.ms` ë‚´ì— ë³µì œëœ ë³µì œë³¸ë§Œ ISRì— í¬í•¨

**ISRì˜ ì—­í• **
1. **ë¦¬ë” ì„ ì¶œ í›„ë³´**: Leader ì¥ì•  ì‹œ ISR ì¤‘ì—ì„œ ìƒˆ Leader ì„ ì¶œ
2. **ACK ëŒ€ìƒ**: `acks=all` ì‹œ ISR ëª¨ë‘ì— ë³µì œ ì™„ë£Œ í›„ ì‘ë‹µ
3. **ë°ì´í„° ì¼ê´€ì„±**: ë™ê¸°í™”ëœ ë³µì œë³¸ë§Œ ì„œë¹„ìŠ¤ ì°¸ì—¬

**ì¤‘ìš”ì„±**
- ISR í¬ê¸°ê°€ `min.insync.replicas` ë¯¸ë§Œì´ë©´ Producer ì“°ê¸° ì‹¤íŒ¨
- ISR ì¶•ì†ŒëŠ” ë°ì´í„° ì†ì‹¤ ìœ„í—˜ ì‹ í˜¸
- Under-replicated íŒŒí‹°ì…˜ ëª¨ë‹ˆí„°ë§ í•„ìˆ˜

**ê´€ë ¨ ì„¤ì •**
```properties
min.insync.replicas=2           # ìµœì†Œ ISR ìˆ˜
replica.lag.time.max.ms=30000   # ISR íŒë‹¨ ê¸°ì¤€ (ê¸°ë³¸ 30ì´ˆ)
```

**ëª¨ë‹ˆí„°ë§ ì§€í‘œ**
- `kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions`
- 0ì´ ì•„ë‹ˆë©´ ì¦‰ì‹œ ì¡°ì‚¬ í•„ìš”

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - ISR](https://kafka.apache.org/documentation/#design_replicatedlog)[^21]

</details>

[^21]: Kafka ê³µì‹ ë¬¸ì„œ - Replicated Logs

---

## ğŸ“Œ Kafka ë©”ì‹œì§€ ìˆœì„œ ë³´ì¥

### KAFKA-022
Kafkaì—ì„œ ë©”ì‹œì§€ì˜ ìˆœì„œë¥¼ ë³´ì¥í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**íŒŒí‹°ì…˜ ë‚´ ìˆœì„œ ë³´ì¥**
- KafkaëŠ” **ë‹¨ì¼ íŒŒí‹°ì…˜ ë‚´ì—ì„œë§Œ** ë©”ì‹œì§€ ìˆœì„œ ë³´ì¥
- íŒŒí‹°ì…˜ ê°„ì—ëŠ” ìˆœì„œ ë³´ì¥ ì—†ìŒ

**ìˆœì„œ ë³´ì¥ ë°©ë²•**

1. **íŒŒí‹°ì…˜ í‚¤ ì‚¬ìš©**
```java
// ê°™ì€ í‚¤ë¥¼ ê°€ì§„ ë©”ì‹œì§€ëŠ” ê°™ì€ íŒŒí‹°ì…˜ìœ¼ë¡œ ì „ì†¡
producer.send(new ProducerRecord<>("topic", "userId-123", message));
```

2. **ë‹¨ì¼ íŒŒí‹°ì…˜ í† í”½** (ì²˜ë¦¬ëŸ‰ ì œí•œë¨)
```bash
kafka-topics.sh --create --topic ordered-topic --partitions 1
```

3. **Producer ì„¤ì •**
```properties
# ë©±ë“±ì„± í™œì„±í™” ì‹œ ìˆœì„œ ë³´ì¥ (ì‹¤íŒ¨ ì‹œì—ë„)
enable.idempotence=true
max.in.flight.requests.per.connection=5  # ë©±ë“±ì„±ê³¼ í•¨ê»˜ ì‚¬ìš© ì‹œ ì•ˆì „
```

**ì£¼ì˜ì‚¬í•­**
- `max.in.flight.requests.per.connection > 1`ì´ê³  ë©±ë“±ì„± ë¹„í™œì„±í™” ì‹œ, ì¬ì‹œë„ë¡œ ì¸í•´ ìˆœì„œ ì—­ì „ ê°€ëŠ¥
- ConsumerëŠ” ë‹¨ì¼ ìŠ¤ë ˆë“œë¡œ íŒŒí‹°ì…˜ ì²˜ë¦¬ ê¶Œì¥

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Message Ordering](https://kafka.apache.org/documentation/#design_quotasandguarantees)[^22]

</details>

[^22]: Kafka ê³µì‹ ë¬¸ì„œ - Message Ordering Guarantees

### KAFKA-023
Producerì˜ ACK ì„¤ì • ì˜µì…˜(0, 1, all)ì˜ ì°¨ì´ì ê³¼ ì˜ë¯¸ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**ACK ì„¤ì • ì˜µì…˜**

**acks=0**
- ProducerëŠ” ë¸Œë¡œì»¤ ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ì§€ ì•ŠìŒ
- ê°€ì¥ ë¹ ë¥¸ ì „ì†¡ ì†ë„
- ë©”ì‹œì§€ ì†ì‹¤ ê°€ëŠ¥ì„± ë†’ìŒ
- ì‚¬ìš© ì‚¬ë¡€: ë¡œê·¸, ë©”íŠ¸ë¦­ ë“± ì†ì‹¤ í—ˆìš© ë°ì´í„°

**acks=1**
- Leaderê°€ ë¡œì»¬ ë¡œê·¸ì— ê¸°ë¡ í›„ ì‘ë‹µ
- Leader ì¥ì•  ì‹œ ë°ì´í„° ì†ì‹¤ ê°€ëŠ¥ (Follower ë³µì œ ì „)
- ì ì ˆí•œ ì„±ëŠ¥ê³¼ ì‹ ë¢°ì„± ê· í˜•
- ì‚¬ìš© ì‚¬ë¡€: ì¼ë°˜ì ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜

**acks=all (ë˜ëŠ” -1)**
- ëª¨ë“  ISRì´ ë³µì œ ì™„ë£Œ í›„ ì‘ë‹µ
- ê°€ì¥ ë†’ì€ ë‚´êµ¬ì„± ë³´ì¥
- ê°€ì¥ ëŠë¦° ì „ì†¡ ì†ë„
- `min.insync.replicas`ì™€ í•¨ê»˜ ì‚¬ìš© ê¶Œì¥
- ì‚¬ìš© ì‚¬ë¡€: ê¸ˆìœµ ë°ì´í„°, ì£¼ë¬¸ ë“± ì¤‘ìš” ë°ì´í„°

**ë¹„êµ ìš”ì•½**
| ACK | ì†ë„ | ë‚´êµ¬ì„± | ì†ì‹¤ ìœ„í—˜ |
|-----|------|--------|-----------|
| 0 | ìµœê³  | ì—†ìŒ | ë†’ìŒ |
| 1 | ì¤‘ê°„ | Leaderë§Œ | ì¤‘ê°„ |
| all | ë‚®ìŒ | ISR ì „ì²´ | ë‚®ìŒ |

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Producer Configs](https://kafka.apache.org/documentation/#producerconfigs_acks)[^23]

</details>

[^23]: Kafka ê³µì‹ ë¬¸ì„œ - Producer Configurations (acks)

---

## ğŸ“Œ Kafka vs ë‹¤ë¥¸ ë©”ì‹œì§• ì‹œìŠ¤í…œ

### KAFKA-024
Kafkaì™€ RabbitMQ ê°™ì€ ë‹¤ë¥¸ ë©”ì‹œì§• ì‹œìŠ¤í…œì˜ ì£¼ìš” ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ì•„í‚¤í…ì²˜ ì°¨ì´**

| êµ¬ë¶„ | Kafka | RabbitMQ |
|------|-------|----------|
| ëª¨ë¸ | ë¡œê·¸ ê¸°ë°˜ | ë©”ì‹œì§€ ë¸Œë¡œì»¤ |
| ë©”ì‹œì§€ ì €ì¥ | ì˜êµ¬ ì €ì¥ (retention) | ì†Œë¹„ í›„ ì‚­ì œ |
| ì†Œë¹„ ë°©ì‹ | Pull (Consumerê°€ ê°€ì ¸ê°) | Push (Brokerê°€ ì „ë‹¬) |
| í”„ë¡œí† ì½œ | ìì²´ í”„ë¡œí† ì½œ | AMQP |

**ì£¼ìš” ì°¨ì´ì **

1. **ë©”ì‹œì§€ ì¬ì²˜ë¦¬**
   - Kafka: Offset ì¡°ì •ìœ¼ë¡œ ì¬ì²˜ë¦¬ ê°€ëŠ¥
   - RabbitMQ: ê¸°ë³¸ì ìœ¼ë¡œ ì†Œë¹„ í›„ ì‚­ì œ

2. **ì²˜ë¦¬ëŸ‰**
   - Kafka: ë†’ì€ ì²˜ë¦¬ëŸ‰ì— ìµœì í™” (ì´ˆë‹¹ ìˆ˜ë°±ë§Œ ê±´)
   - RabbitMQ: ì¤‘ê°„ ì²˜ë¦¬ëŸ‰, ë‚®ì€ ì§€ì—°ì‹œê°„

3. **Consumer í™•ì¥**
   - Kafka: íŒŒí‹°ì…˜ ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬
   - RabbitMQ: í ê²½ìŸ ë°©ì‹

4. **ì‚¬ìš© ì‚¬ë¡€**
   - Kafka: ë¡œê·¸ ìˆ˜ì§‘, ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°, ë°ì´í„° íŒŒì´í”„ë¼ì¸
   - RabbitMQ: ì‘ì—… í, RPC, ë³µì¡í•œ ë¼ìš°íŒ…

**ì„ íƒ ê¸°ì¤€**
- ëŒ€ìš©ëŸ‰ ìŠ¤íŠ¸ë¦¬ë° â†’ Kafka
- ë³µì¡í•œ ë¼ìš°íŒ…, ìœ ì—°í•œ ë©”ì‹œì§• íŒ¨í„´ â†’ RabbitMQ

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Introduction](https://kafka.apache.org/documentation/#introduction)[^24]

</details>

[^24]: Kafka ê³µì‹ ë¬¸ì„œ - Introduction

---

## ğŸ“Œ Kafka ë°°í¬ì™€ ì²˜ë¦¬ íŒ¨í„´

### KAFKA-025
Kafka í´ëŸ¬ìŠ¤í„°ì˜ Zero Downtime ë°°í¬ ì „ëµì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**Rolling Upgrade ì „ëµ**

1. **ì‚¬ì „ ì¤€ë¹„**
   - ë³µì œ ê³„ìˆ˜ 3 ì´ìƒ í™•ì¸
   - `min.insync.replicas=2` ì„¤ì •
   - Under-replicated íŒŒí‹°ì…˜ ì—†ìŒ í™•ì¸

2. **ë¸Œë¡œì»¤ ì—…ê·¸ë ˆì´ë“œ ì ˆì°¨**
```bash
# 1. í•œ ë¸Œë¡œì»¤ ì •ìƒ ì¢…ë£Œ
kafka-server-stop.sh

# 2. ìƒˆ ë²„ì „ ì„¤ì¹˜ ë° ì„¤ì •

# 3. ë¸Œë¡œì»¤ ì‹œì‘
kafka-server-start.sh config/server.properties

# 4. ISR ë³µêµ¬ í™•ì¸ í›„ ë‹¤ìŒ ë¸Œë¡œì»¤ ì§„í–‰
```

3. **í´ë¼ì´ì–¸íŠ¸ í˜¸í™˜ì„±**
   - `inter.broker.protocol.version` ì ì§„ì  ì—…ê·¸ë ˆì´ë“œ
   - `log.message.format.version` ì„¤ì • ìœ ì§€ í›„ ë³€ê²½

**ì„¤ì • ì˜ˆì‹œ**
```properties
# ì—…ê·¸ë ˆì´ë“œ ì¤‘ (ì´ì „ ë²„ì „ ìœ ì§€)
inter.broker.protocol.version=3.0
log.message.format.version=3.0

# ëª¨ë“  ë¸Œë¡œì»¤ ì—…ê·¸ë ˆì´ë“œ í›„ ì œê±°
```

**ëª¨ë‹ˆí„°ë§**
- ISR ìƒíƒœ ì§€ì† í™•ì¸
- Consumer lag ëª¨ë‹ˆí„°ë§
- í´ë¼ì´ì–¸íŠ¸ ì—ëŸ¬ í™•ì¸

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Upgrading](https://kafka.apache.org/documentation/#upgrade)[^25]

</details>

[^25]: Kafka ê³µì‹ ë¬¸ì„œ - Upgrading

### KAFKA-026
ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ì™€ ë°°ì¹˜ ì²˜ë¦¬ì˜ ì°¨ì´ì ì„ Kafka ê´€ì ì—ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**ë°°ì¹˜ ì²˜ë¦¬ (Batch Processing)**
- ì¼ì • ê¸°ê°„ ë°ì´í„°ë¥¼ ëª¨ì•„ì„œ í•œ ë²ˆì— ì²˜ë¦¬
- ë†’ì€ ì²˜ë¦¬ëŸ‰, ë†’ì€ ì§€ì—°ì‹œê°„
- Kafka í™œìš©: Consumerê°€ ì£¼ê¸°ì ìœ¼ë¡œ ëŒ€ëŸ‰ ë°ì´í„° ì†Œë¹„

**ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ (Stream Processing)**
- ë°ì´í„° ë„ì°© ì¦‰ì‹œ ì‹¤ì‹œê°„ ì²˜ë¦¬
- ë‚®ì€ ì§€ì—°ì‹œê°„, ì—°ì†ì ì¸ ì²˜ë¦¬
- Kafka í™œìš©: Kafka Streams, KSQL

**Kafkaì—ì„œì˜ ì°¨ì´**

| êµ¬ë¶„ | ë°°ì¹˜ ì²˜ë¦¬ | ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ |
|------|----------|-------------|
| ë„êµ¬ | Consumer + Spark/Flink | Kafka Streams, KSQL |
| ì§€ì—° | ë¶„~ì‹œê°„ | ë°€ë¦¬ì´ˆ~ì´ˆ |
| ìœˆë„ìš° | ê³ ì • ì‹œê°„ ë²”ìœ„ | í…€ë¸”ë§/ìŠ¬ë¼ì´ë”©/ì„¸ì…˜ |
| ìƒíƒœ | ì™¸ë¶€ ì €ì¥ì†Œ | State Store (RocksDB) |

**Kafka Streamsì˜ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ íŠ¹ì§•**
```java
StreamsBuilder builder = new StreamsBuilder();
builder.stream("input-topic")
    .filter((k, v) -> v.contains("important"))
    .mapValues(v -> v.toUpperCase())
    .to("output-topic");
```

**Lambda ì•„í‚¤í…ì²˜**
- Kafkaë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë°°ì¹˜ + ìŠ¤íŠ¸ë¦¼ ë™ì‹œ ì²˜ë¦¬
- ë°°ì¹˜ ë ˆì´ì–´: ì •í™•í•œ ê²°ê³¼
- ìŠ¤í”¼ë“œ ë ˆì´ì–´: ì‹¤ì‹œê°„ ê·¼ì‚¬ ê²°ê³¼

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Streams Concepts](https://kafka.apache.org/documentation/streams/core-concepts)[^26]

</details>

[^26]: Kafka ê³µì‹ ë¬¸ì„œ - Streams Core Concepts

### KAFKA-027
Kafkaì—ì„œ ë©€í‹° í…Œë„Œì‹œ(Multi-Tenancy)ë¥¼ ì–´ë–»ê²Œ ì§€ì›í•˜ë‚˜ìš”?

<details>
<summary>ë‹µë³€</summary>

**ë©€í‹° í…Œë„Œì‹œ êµ¬í˜„ ë°©ë²•**

1. **í† í”½ ë„¤ì´ë° ì»¨ë²¤ì…˜**
```
tenant-a.orders
tenant-b.orders
```

2. **ACL ê¸°ë°˜ ì ‘ê·¼ ì œì–´**
```bash
# í…Œë„ŒíŠ¸ AëŠ” ìì‹ ì˜ í† í”½ë§Œ ì ‘ê·¼ ê°€ëŠ¥
kafka-acls.sh --add --allow-principal User:tenant-a \
  --operation All --topic 'tenant-a.*' --resource-pattern-type prefixed
```

3. **Quota ì„¤ì •**
```bash
# í…Œë„ŒíŠ¸ë³„ ì²˜ë¦¬ëŸ‰ ì œí•œ
kafka-configs.sh --alter --add-config 'producer_byte_rate=10485760,consumer_byte_rate=20971520' \
  --entity-type users --entity-name tenant-a
```

**Quota ì¢…ë¥˜**
- `producer_byte_rate`: ì´ˆë‹¹ Producer ì „ì†¡ëŸ‰ ì œí•œ
- `consumer_byte_rate`: ì´ˆë‹¹ Consumer ìˆ˜ì‹ ëŸ‰ ì œí•œ
- `request_percentage`: CPU ì‚¬ìš©ë¥  ì œí•œ

**ê²©ë¦¬ ìˆ˜ì¤€**
| ë°©ì‹ | ê²©ë¦¬ ìˆ˜ì¤€ | ìš´ì˜ ë³µì¡ë„ |
|------|----------|-------------|
| ë„¤ì´ë° ì»¨ë²¤ì…˜ | ë‚®ìŒ | ë‚®ìŒ |
| ACL + Quota | ì¤‘ê°„ | ì¤‘ê°„ |
| ë³„ë„ í´ëŸ¬ìŠ¤í„° | ë†’ìŒ | ë†’ìŒ |

**ëª¨ë²” ì‚¬ë¡€**
- í…Œë„ŒíŠ¸ë³„ ì „ìš© Consumer Group
- ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ë¶„ë¦¬
- ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬ (VLAN/VPC)

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Quotas](https://kafka.apache.org/documentation/#design_quotas)[^27]

</details>

[^27]: Kafka ê³µì‹ ë¬¸ì„œ - Quotas

---

## ğŸ“Œ Kafka ëª¨ë‹ˆí„°ë§

### KAFKA-028
Kafka í´ëŸ¬ìŠ¤í„° ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ì£¼ìš” ì§€í‘œì™€ ì‚¬ìš© ë„êµ¬ì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?

<details>
<summary>ë‹µë³€</summary>

**ì£¼ìš” ëª¨ë‹ˆí„°ë§ ì§€í‘œ**

**Broker ì§€í‘œ**
- `UnderReplicatedPartitions`: ë³µì œ ì§€ì—° íŒŒí‹°ì…˜ ìˆ˜ (0ì´ì–´ì•¼ í•¨)
- `ActiveControllerCount`: í™œì„± ì»¨íŠ¸ë¡¤ëŸ¬ ìˆ˜ (í´ëŸ¬ìŠ¤í„°ë‹¹ 1)
- `OfflinePartitionsCount`: ì˜¤í”„ë¼ì¸ íŒŒí‹°ì…˜ ìˆ˜ (0ì´ì–´ì•¼ í•¨)
- `RequestsPerSec`: ì´ˆë‹¹ ìš”ì²­ ìˆ˜
- `BytesInPerSec/BytesOutPerSec`: ë„¤íŠ¸ì›Œí¬ ì²˜ë¦¬ëŸ‰

**Producer ì§€í‘œ**
- `record-send-rate`: ì´ˆë‹¹ ì „ì†¡ ë ˆì½”ë“œ ìˆ˜
- `record-error-rate`: ì „ì†¡ ì‹¤íŒ¨ìœ¨
- `request-latency-avg`: í‰ê·  ìš”ì²­ ì§€ì—°ì‹œê°„

**Consumer ì§€í‘œ**
- `records-lag-max`: ìµœëŒ€ Consumer Lag
- `records-consumed-rate`: ì´ˆë‹¹ ì†Œë¹„ ë ˆì½”ë“œ ìˆ˜
- `commit-latency-avg`: ì˜¤í”„ì…‹ ì»¤ë°‹ ì§€ì—°ì‹œê°„

**ëª¨ë‹ˆí„°ë§ ë„êµ¬**
- **JMX**: Kafka ê¸°ë³¸ ë©”íŠ¸ë¦­ ë…¸ì¶œ
- **Prometheus + Grafana**: ì‹œê³„ì—´ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì‹œê°í™”
- **Kafka Manager/CMAK**: í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ UI
- **Confluent Control Center**: ìƒìš© ëª¨ë‹ˆí„°ë§ ì†”ë£¨ì…˜
- **Burrow**: Consumer Lag ì „ë¬¸ ëª¨ë‹ˆí„°ë§

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Monitoring](https://kafka.apache.org/documentation/#monitoring)[^28]

</details>

[^28]: Kafka ê³µì‹ ë¬¸ì„œ - Monitoring

### KAFKA-029
Consumer Rebalance ê³¼ì •ê³¼ ì´ë¥¼ ìµœì í™”í•˜ê¸° ìœ„í•œ ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**Rebalance ë°œìƒ ì¡°ê±´**
- Consumer ê·¸ë£¹ì— ìƒˆ Consumer ì°¸ì—¬/ì´íƒˆ
- Consumerê°€ heartbeat ë¯¸ì „ì†¡ (ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ)
- í† í”½ íŒŒí‹°ì…˜ ìˆ˜ ë³€ê²½
- ì •ê·œì‹ êµ¬ë… í† í”½ ë³€ê²½

**Rebalance ê³¼ì •**
1. Group Coordinatorê°€ ë¦¬ë°¸ëŸ°ìŠ¤ íŠ¸ë¦¬ê±°
2. ëª¨ë“  Consumerê°€ íŒŒí‹°ì…˜ í• ë‹¹ í•´ì œ (Stop-the-World)
3. Consumer Leaderê°€ ìƒˆ íŒŒí‹°ì…˜ í• ë‹¹ ê³„íš ìˆ˜ë¦½
4. ê° Consumerì— íŒŒí‹°ì…˜ ì¬í• ë‹¹
5. ì†Œë¹„ ì¬ê°œ

**ìµœì í™” ë°©ë²•**

1. **Cooperative Rebalancing (ì¦ë¶„ ë¦¬ë°¸ëŸ°ìŠ¤)**
```properties
partition.assignment.strategy=org.apache.kafka.clients.consumer.CooperativeStickyAssignor
```
- ì „ì²´ ì¤‘ë‹¨ ì—†ì´ ì ì§„ì  ì¬í• ë‹¹

2. **Static Membership**
```properties
group.instance.id=consumer-1
session.timeout.ms=300000
```
- Consumer ì¬ì‹œì‘ ì‹œ ì¦‰ì‹œ íŒŒí‹°ì…˜ ë³µêµ¬

3. **ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ìµœì í™”**
```properties
session.timeout.ms=45000
heartbeat.interval.ms=15000
max.poll.interval.ms=300000
```

4. **poll() ì²˜ë¦¬ ì‹œê°„ ë‹¨ì¶•**
- `max.poll.records` ì¡°ì •
- ì²˜ë¦¬ ë¡œì§ ìµœì í™”

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Consumer Rebalance](https://kafka.apache.org/documentation/#consumerconfigs_partition.assignment.strategy)[^29]

</details>

[^29]: Kafka ê³µì‹ ë¬¸ì„œ - Consumer Configuration

---

## ğŸ“Œ Kafka Producer/Consumer ìµœì í™”

### KAFKA-030
Producer ì„±ëŠ¥ ë³‘ëª© í˜„ìƒ ë°œìƒ ì‹œ í•´ê²° ì „ëµì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ë³‘ëª© ì§„ë‹¨ ì§€í‘œ**
- `record-queue-time-avg`: ë°°ì¹˜ ëŒ€ê¸° ì‹œê°„
- `request-latency-avg`: ìš”ì²­ ì‘ë‹µ ì‹œê°„
- `buffer-available-bytes`: ì‚¬ìš© ê°€ëŠ¥ ë²„í¼

**í•´ê²° ì „ëµ**

1. **ë°°ì¹˜ ìµœì í™”**
```properties
batch.size=65536           # 64KBë¡œ ì¦ê°€
linger.ms=10               # ë°°ì¹˜ ëŒ€ê¸° ì‹œê°„
buffer.memory=67108864     # 64MB ë²„í¼
```

2. **ì••ì¶• í™œì„±í™”**
```properties
compression.type=lz4       # ë˜ëŠ” snappy, zstd
```

3. **ë³‘ë ¬ ì²˜ë¦¬ ì¦ê°€**
```properties
max.in.flight.requests.per.connection=5
```

4. **ë¹„ë™ê¸° ì „ì†¡**
```java
producer.send(record, (metadata, exception) -> {
    if (exception != null) handleError(exception);
});
```

5. **íŒŒí‹°ì…˜ ìˆ˜ ì¦ê°€**
- ë” ë§ì€ ë¸Œë¡œì»¤ì— ë¶€í•˜ ë¶„ì‚°

6. **ACK ìˆ˜ì¤€ ì¡°ì •** (ë‚´êµ¬ì„± íŠ¸ë ˆì´ë“œì˜¤í”„)
```properties
acks=1  # allì—ì„œ 1ë¡œ ë³€ê²½ (ì£¼ì˜ í•„ìš”)
```

**í•˜ë“œì›¨ì–´ ê°œì„ **
- ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ í™•ì¥
- ë¸Œë¡œì»¤ ë””ìŠ¤í¬ I/O ê°œì„  (SSD)
- ë¸Œë¡œì»¤ ìˆ˜ ì¦ê°€

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Producer Performance](https://kafka.apache.org/documentation/#producerconfigs)[^30]

</details>

[^30]: Kafka ê³µì‹ ë¬¸ì„œ - Producer Configurations

---

## ğŸ“Œ Kafka ZooKeeperì™€ KRaft

### KAFKA-031
ZooKeeperì˜ ì—­í• ê³¼ KRaft ëª¨ë“œì˜ ì°¨ì´ì ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**ZooKeeperì˜ ì—­í• **
- í´ëŸ¬ìŠ¤í„° ë©”íƒ€ë°ì´í„° ì €ì¥ (í† í”½, íŒŒí‹°ì…˜, ë¸Œë¡œì»¤ ì •ë³´)
- Controller ì„ ì¶œ
- ë¸Œë¡œì»¤ ìƒíƒœ ê°ì§€ (Ephemeral ë…¸ë“œ)
- ACL ë° ì„¤ì • ì €ì¥

**KRaft (Kafka Raft) ëª¨ë“œ**
- Kafka ìì²´ ë‚´ì¥ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ (ZooKeeper ì œê±°)
- Raft í•©ì˜ í”„ë¡œí† ì½œ ì‚¬ìš©
- Kafka 3.3ë¶€í„° í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ

**ì£¼ìš” ì°¨ì´ì **

| êµ¬ë¶„ | ZooKeeper ëª¨ë“œ | KRaft ëª¨ë“œ |
|------|---------------|------------|
| ì˜ì¡´ì„± | ZooKeeper í´ëŸ¬ìŠ¤í„° í•„ìš” | Kafkaë§Œìœ¼ë¡œ ìš´ì˜ |
| ë©”íƒ€ë°ì´í„° | ZooKeeperì— ì €ì¥ | ë‚´ë¶€ í† í”½ì— ì €ì¥ |
| í™•ì¥ì„± | íŒŒí‹°ì…˜ ìˆ˜ ì œí•œ (ìˆ˜ë§Œ ê°œ) | ìˆ˜ë°±ë§Œ íŒŒí‹°ì…˜ ê°€ëŠ¥ |
| ìš´ì˜ | ë‘ ì‹œìŠ¤í…œ ê´€ë¦¬ | ë‹¨ì¼ ì‹œìŠ¤í…œ |
| ë³µêµ¬ | ëŠë¦° ì»¨íŠ¸ë¡¤ëŸ¬ í˜ì¼ì˜¤ë²„ | ë¹ ë¥¸ ë³µêµ¬ |

**KRaft ì„¤ì • ì˜ˆì‹œ**
```properties
process.roles=broker,controller
node.id=1
controller.quorum.voters=1@localhost:9093
```

**ë§ˆì´ê·¸ë ˆì´ì…˜**: ZooKeeper â†’ KRaft ë¬´ì¤‘ë‹¨ ì „í™˜ ë„êµ¬ ì œê³µ

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - KRaft](https://kafka.apache.org/documentation/#kraft)[^31]

</details>

[^31]: Kafka ê³µì‹ ë¬¸ì„œ - KRaft

---

## ğŸ“Œ Kafka ë©”ì‹œì§€ ì••ì¶•

### KAFKA-032
Kafkaì˜ ë©”ì‹œì§€ ì••ì¶• ì˜µì…˜(gzip, snappy, lz4 ë“±)ì˜ ì¥ë‹¨ì ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ì••ì¶• ì˜µì…˜ ë¹„êµ**

| ì••ì¶• ë°©ì‹ | ì••ì¶•ë¥  | ì†ë„ | CPU ì‚¬ìš©ëŸ‰ | ê¶Œì¥ ì‚¬ìš© |
|----------|--------|------|-----------|----------|
| gzip | ë†’ìŒ | ëŠë¦¼ | ë†’ìŒ | ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ì œí•œ |
| snappy | ì¤‘ê°„ | ë¹ ë¦„ | ë‚®ìŒ | ì¼ë°˜ì  ì‚¬ìš© |
| lz4 | ì¤‘ê°„ | ë§¤ìš° ë¹ ë¦„ | ë‚®ìŒ | ê³ ì„±ëŠ¥ ê¶Œì¥ |
| zstd | ë†’ìŒ | ë¹ ë¦„ | ì¤‘ê°„ | ê· í˜• ì¡íŒ ì„ íƒ |

**ì„¤ì • ë°©ë²•**
```properties
# Producer ì„¤ì •
compression.type=lz4

# Broker ì„¤ì • (ì„ íƒ)
compression.type=producer  # Producer ì„¤ì • ìœ ì§€
```

**ì¥ë‹¨ì  ìƒì„¸**

**gzip**
- ì¥ì : ìµœê³  ì••ì¶•ë¥ , ë²”ìš© í˜¸í™˜ì„±
- ë‹¨ì : CPU ì§‘ì•½ì , ì§€ì—°ì‹œê°„ ì¦ê°€

**snappy**
- ì¥ì : ë¹ ë¥¸ ì••ì¶•/í•´ì œ, ë‚®ì€ CPU
- ë‹¨ì : ì••ì¶•ë¥  ìƒëŒ€ì ìœ¼ë¡œ ë‚®ìŒ

**lz4**
- ì¥ì : ê°€ì¥ ë¹ ë¥¸ ì†ë„, ë§¤ìš° ë‚®ì€ CPU
- ë‹¨ì : gzipë³´ë‹¤ ë‚®ì€ ì••ì¶•ë¥ 
- ê¶Œì¥: ëŒ€ë¶€ë¶„ì˜ í”„ë¡œë•ì…˜ í™˜ê²½

**zstd**
- ì¥ì : ë†’ì€ ì••ì¶•ë¥  + ì ì ˆí•œ ì†ë„
- ë‹¨ì : êµ¬ë²„ì „ í˜¸í™˜ì„± ì´ìŠˆ

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Compression](https://kafka.apache.org/documentation/#producerconfigs_compression.type)[^32]

</details>

[^32]: Kafka ê³µì‹ ë¬¸ì„œ - Producer Configurations

---

## ğŸ“Œ Kafka ì—ëŸ¬ ì²˜ë¦¬

### KAFKA-033
ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ë•Œì˜ ì²˜ë¦¬ ì „ëµ(ì˜ˆ: DLQ ë„ì… ë“±)ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**ì—ëŸ¬ ì²˜ë¦¬ ì „ëµ**

1. **ì¬ì‹œë„ (Retry)**
```java
// ì§€ìˆ˜ ë°±ì˜¤í”„ë¡œ ì¬ì‹œë„
int retries = 3;
while (retries-- > 0) {
    try {
        process(record);
        break;
    } catch (RetryableException e) {
        Thread.sleep(backoff);
    }
}
```

2. **Dead Letter Queue (DLQ)**
```java
try {
    process(record);
} catch (Exception e) {
    // DLQ í† í”½ìœ¼ë¡œ ì „ì†¡
    producer.send(new ProducerRecord<>("dlq-topic",
        record.key(), record.value()));
    consumer.commitSync();
}
```

3. **ì—ëŸ¬ í† í”½ ë¶„ë¦¬**
- ì¬ì‹œë„ ê°€ëŠ¥ ì—ëŸ¬ â†’ retry-topic
- ì˜êµ¬ ì‹¤íŒ¨ â†’ dlq-topic

4. **Skip/Ignore**
- ë¡œê¹… í›„ ë‹¤ìŒ ë©”ì‹œì§€ ì²˜ë¦¬
- ì¤‘ìš”ë„ ë‚®ì€ ë°ì´í„°ì— ì ìš©

**DLQ êµ¬í˜„ ëª¨ë²” ì‚¬ë¡€**
- ì›ë³¸ ë©”ì‹œì§€ + ì—ëŸ¬ ì •ë³´ ì €ì¥
- í—¤ë”ì— ì›ë³¸ í† í”½, íŒŒí‹°ì…˜, ì˜¤í”„ì…‹ í¬í•¨
- DLQ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì„¤ì •
- ì¬ì²˜ë¦¬ ë„êµ¬ ì¤€ë¹„

**Spring Kafka ì˜ˆì‹œ**
```java
@KafkaListener(topics = "my-topic")
@RetryableTopic(attempts = "3", backoff = @Backoff(delay = 1000))
public void listen(String message) {
    // ìë™ ì¬ì‹œë„ ë° DLQ ì „ì†¡
}
```

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Error Handling](https://kafka.apache.org/documentation/#consumerconfigs)[^33]

</details>

[^33]: Kafka ê³µì‹ ë¬¸ì„œ - Consumer Configurations

---

## ğŸ“Œ Kafka í™•ì¥ì„±

### KAFKA-034
Kafka í´ëŸ¬ìŠ¤í„° í™•ì¥(Scale-out) ì‹œ ê³ ë ¤í•´ì•¼ í•  ëª¨ë²” ì‚¬ë¡€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ë¸Œë¡œì»¤ ì¶”ê°€ ì‹œ ê³ ë ¤ì‚¬í•­**

1. **íŒŒí‹°ì…˜ ì¬ë¶„ë°°**
```bash
# ì¬ë¶„ë°° ê³„íš ìƒì„±
kafka-reassign-partitions.sh --generate \
  --topics-to-move-json-file topics.json \
  --broker-list "1,2,3,4" \
  --bootstrap-server localhost:9092

# ì¬ë¶„ë°° ì‹¤í–‰
kafka-reassign-partitions.sh --execute \
  --reassignment-json-file plan.json
```

2. **ì ì§„ì  í™•ì¥**
- í•œ ë²ˆì— í•˜ë‚˜ì˜ ë¸Œë¡œì»¤ ì¶”ê°€
- ë„¤íŠ¸ì›Œí¬ ë° ë””ìŠ¤í¬ I/O ëª¨ë‹ˆí„°ë§
- ì¬ë¶„ë°° ìŠ¤ë¡œí‹€ë§ ì ìš©

3. **ìŠ¤ë¡œí‹€ ì„¤ì •**
```bash
kafka-reassign-partitions.sh --execute \
  --throttle 50000000 \  # 50MB/s ì œí•œ
  --reassignment-json-file plan.json
```

**íŒŒí‹°ì…˜ ìˆ˜ ì¦ê°€**
- ìš´ì˜ ì¤‘ íŒŒí‹°ì…˜ ì¶”ê°€ ê°€ëŠ¥ (ê°ì†Œ ë¶ˆê°€)
- í‚¤ ê¸°ë°˜ íŒŒí‹°ì…”ë‹ ì‹œ ê¸°ì¡´ ë°ì´í„° ìˆœì„œ ì˜í–¥

**ëª¨ë²” ì‚¬ë¡€**
- ì¶©ë¶„í•œ ì´ˆê¸° íŒŒí‹°ì…˜ ìˆ˜ ê³„íš
- `auto.create.topics.enable=false` ê¶Œì¥
- Rack-awareness ì„¤ì •ìœ¼ë¡œ ì¥ì•  ë„ë©”ì¸ ë¶„ë¦¬
- Leader ì¬ë¶„ë°° ìë™í™”

**í™•ì¥ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸**
- [ ] ë””ìŠ¤í¬ ìš©ëŸ‰ ê³„íš
- [ ] ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ í™•ì¸
- [ ] ZooKeeper/KRaft ë¶€í•˜ ê²€í† 
- [ ] í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ìˆ˜ í™•ì¸

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Adding Brokers](https://kafka.apache.org/documentation/#basic_ops_cluster_expansion)[^34]

</details>

[^34]: Kafka ê³µì‹ ë¬¸ì„œ - Expanding Your Cluster

### KAFKA-035
Kafkaì—ì„œ KRaft ëª¨ë“œ ì „í™˜ ì‹œ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**KRaft ì „í™˜ ì „ í™•ì¸ì‚¬í•­**
- Kafka ë²„ì „ 3.3 ì´ìƒ (í”„ë¡œë•ì…˜ ê¶Œì¥ 3.6+)
- ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ í˜¸í™˜ì„± í™•ì¸
- í˜„ì¬ ZooKeeper í´ëŸ¬ìŠ¤í„° ìƒíƒœ ì •ìƒ í™•ì¸

**ë§ˆì´ê·¸ë ˆì´ì…˜ ì ˆì°¨**

1. **ë©”íƒ€ë°ì´í„° ìŠ¤ëƒ…ìƒ· ìƒì„±**
```bash
kafka-metadata.sh --snapshot /path/to/snapshot \
  --cluster-id <cluster-id>
```

2. **KRaft Controller êµ¬ì„±**
```properties
process.roles=controller
node.id=100
controller.quorum.voters=100@controller1:9093,101@controller2:9093
```

3. **ì ì§„ì  ì „í™˜**
- ë¸Œë¡œì»¤ë¥¼ í•˜ë‚˜ì”© KRaft ëª¨ë“œë¡œ ì¬ì‹œì‘
- Controller ì¿¼ëŸ¼ êµ¬ì„±
- ë§ˆì§€ë§‰ìœ¼ë¡œ ZooKeeper ì—°ê²° í•´ì œ

**ê³ ë ¤ì‚¬í•­**
- **ë¡¤ë°± ê³„íš**: ì „í™˜ ì „ ë°±ì—… í•„ìˆ˜
- **ë‹¤ìš´íƒ€ì„**: ë¬´ì¤‘ë‹¨ ì „í™˜ ë„êµ¬ ì œê³µë˜ë‚˜ í…ŒìŠ¤íŠ¸ í•„ìš”
- **ê¸°ëŠ¥ ì°¨ì´**: ì¼ë¶€ ê¸°ëŠ¥ì€ KRaftì—ì„œ ë‹¤ë¥´ê²Œ ë™ì‘
- **ëª¨ë‹ˆí„°ë§**: ìƒˆë¡œìš´ KRaft ê´€ë ¨ ë©”íŠ¸ë¦­ ì¶”ê°€

**KRaft ì¥ì **
- ìš´ì˜ ë‹¨ìˆœí™” (ZooKeeper ì œê±°)
- ë¹ ë¥¸ ì»¨íŠ¸ë¡¤ëŸ¬ í˜ì¼ì˜¤ë²„
- í–¥ìƒëœ í™•ì¥ì„± (ìˆ˜ë°±ë§Œ íŒŒí‹°ì…˜)

**ì£¼ì˜ì‚¬í•­**
- ê¸°ì¡´ ACL, Config ë§ˆì´ê·¸ë ˆì´ì…˜ í™•ì¸
- í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ í˜¸í™˜ì„±
- í”„ë¡œë•ì…˜ ì „ ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - ZooKeeper to KRaft Migration](https://kafka.apache.org/documentation/#kraft_zk_migration)[^35]

</details>

[^35]: Kafka ê³µì‹ ë¬¸ì„œ - KRaft Migration

---

## ğŸ“Œ Kafka ì§€ì—°(Latency) ìµœì í™”

### KAFKA-036
Kafka ë©”ì‹œì§€ ì „ì†¡ ì§€ì—°(latency)ì„ ìµœì†Œí™”í•˜ëŠ” ë°©ë²•ì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?

<details>
<summary>ë‹µë³€</summary>

**Producer ì§€ì—° ìµœì†Œí™”**
```properties
linger.ms=0              # ì¦‰ì‹œ ì „ì†¡ (ë°°ì¹˜ ëŒ€ê¸° ì—†ìŒ)
batch.size=16384         # ì‘ì€ ë°°ì¹˜
acks=1                   # Leaderë§Œ í™•ì¸ (íŠ¸ë ˆì´ë“œì˜¤í”„)
compression.type=none    # ì••ì¶• ë¹„í™œì„±í™” (CPU ì ˆì•½)
```

**Consumer ì§€ì—° ìµœì†Œí™”**
```properties
fetch.min.bytes=1                   # ì¦‰ì‹œ fetch
fetch.max.wait.ms=100               # ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™”
max.poll.records=100                # ë¹ ë¥¸ ì²˜ë¦¬ ì‚¬ì´í´
```

**Broker íŠœë‹**
```properties
num.io.threads=8                    # I/O ìŠ¤ë ˆë“œ ì¦ê°€
num.network.threads=3               # ë„¤íŠ¸ì›Œí¬ ìŠ¤ë ˆë“œ
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
```

**ì¸í”„ë¼ ìµœì í™”**
- SSD ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©
- Producer/Broker ë„¤íŠ¸ì›Œí¬ ê·¼ì ‘ ë°°ì¹˜
- ë‚®ì€ ë ˆì´í„´ì‹œ ë„¤íŠ¸ì›Œí¬ (10Gbps+)

**íŒŒí‹°ì…˜ ì „ëµ**
- íŒŒí‹°ì…˜ ìˆ˜ ì ì • ìœ ì§€ (ê³¼ë„í•œ íŒŒí‹°ì…˜ì€ ì˜¤ë²„í—¤ë“œ)
- ë¦¬ë” ê· ë“± ë¶„ë°°

**ëª¨ë‹ˆí„°ë§ ì§€í‘œ**
- `produce-throttle-time`: Producer ìŠ¤ë¡œí‹€ë§
- `fetch-latency-avg`: Consumer fetch ì§€ì—°
- `request-latency-avg`: ì „ì²´ ìš”ì²­ ì§€ì—°

**ì£¼ì˜**: ì§€ì—° ìµœì†Œí™”ëŠ” ì²˜ë¦¬ëŸ‰/ë‚´êµ¬ì„±ê³¼ íŠ¸ë ˆì´ë“œì˜¤í”„ ê´€ê³„

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Performance](https://kafka.apache.org/documentation/#configuration)[^36]

</details>

[^36]: Kafka ê³µì‹ ë¬¸ì„œ - Configuration

### KAFKA-037
Syncì™€ Async ì „ì†¡ ë°©ì‹ì˜ ì°¨ì´ì ê³¼ ê°ê°ì˜ ì¥ë‹¨ì ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ë™ê¸° ì „ì†¡ (Sync)**
```java
// ì „ì†¡ ì™„ë£Œê¹Œì§€ ë¸”ë¡œí‚¹
RecordMetadata metadata = producer.send(record).get();
System.out.println("Sent to partition: " + metadata.partition());
```

**ì¥ì **
- ì „ì†¡ ì„±ê³µ/ì‹¤íŒ¨ ì¦‰ì‹œ í™•ì¸
- ìˆœì„œ ë³´ì¥ ìš©ì´
- ì—ëŸ¬ ì²˜ë¦¬ ì§ê´€ì 

**ë‹¨ì **
- ë‚®ì€ ì²˜ë¦¬ëŸ‰ (ë§¤ ì „ì†¡ë§ˆë‹¤ ëŒ€ê¸°)
- ë„¤íŠ¸ì›Œí¬ ì§€ì—°ì— ë¯¼ê°

**ë¹„ë™ê¸° ì „ì†¡ (Async)**
```java
producer.send(record, (metadata, exception) -> {
    if (exception != null) {
        // ì—ëŸ¬ ì²˜ë¦¬
        logger.error("Send failed", exception);
    } else {
        // ì„±ê³µ ì²˜ë¦¬
        logger.info("Sent to: " + metadata.offset());
    }
});
```

**ì¥ì **
- ë†’ì€ ì²˜ë¦¬ëŸ‰ (ë³‘ë ¬ ì „ì†¡)
- ë…¼ë¸”ë¡œí‚¹ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì 
- ë°°ì¹˜ ìµœì í™” í™œìš© ê°€ëŠ¥

**ë‹¨ì **
- ì—ëŸ¬ ì²˜ë¦¬ ë³µì¡
- ë©”ëª¨ë¦¬ ê´€ë¦¬ í•„ìš” (ë²„í¼ ì´ˆê³¼ ì‹œ)
- ìˆœì„œ ë³´ì¥ ì–´ë ¤ì›€

**ì„ íƒ ê¸°ì¤€**
| ìƒí™© | ê¶Œì¥ ë°©ì‹ |
|------|----------|
| ê³ ì²˜ë¦¬ëŸ‰ í•„ìš” | Async |
| ì—„ê²©í•œ ìˆœì„œ ë³´ì¥ | Sync |
| ì‹¤ì‹œê°„ ì—ëŸ¬ ì²˜ë¦¬ | Sync |
| ëŒ€ëŸ‰ ë°ì´í„° ì „ì†¡ | Async + Callback |

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Producer API](https://kafka.apache.org/documentation/#producerapi)[^37]

</details>

[^37]: Kafka ê³µì‹ ë¬¸ì„œ - Producer API

---

## ğŸ“Œ Kafka ì¥ì•  ëŒ€ì‘

### KAFKA-038
Kafka í´ëŸ¬ìŠ¤í„° ìš´ì˜ ì‹œ ì˜ˆìƒí•  ìˆ˜ ìˆëŠ” ì¥ì• ì™€ ê·¸ì— ëŒ€í•œ ëŒ€ì‘ ë°©ì•ˆì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ì£¼ìš” ì¥ì•  ìœ í˜• ë° ëŒ€ì‘**

**1. ë¸Œë¡œì»¤ ì¥ì• **
- ì¦ìƒ: UnderReplicatedPartitions ì¦ê°€
- ëŒ€ì‘:
  - ISRì—ì„œ ìë™ ë¦¬ë” ì„ ì¶œ í™•ì¸
  - ë¸Œë¡œì»¤ ë³µêµ¬ ë˜ëŠ” ëŒ€ì²´ ë¸Œë¡œì»¤ íˆ¬ì…
  - `min.insync.replicas` ì„¤ì • í™•ì¸

**2. ë””ìŠ¤í¬ ì¥ì• **
- ì¦ìƒ: ë¡œê·¸ ì“°ê¸° ì‹¤íŒ¨, ë¸Œë¡œì»¤ ë¹„ì •ìƒ
- ëŒ€ì‘:
  - JBOD êµ¬ì„± ì‹œ í•´ë‹¹ ë””ìŠ¤í¬ë§Œ ê²©ë¦¬
  - íŒŒí‹°ì…˜ ì¬ë¶„ë°°ë¡œ ë°ì´í„° ë³µêµ¬
  - ë””ìŠ¤í¬ êµì²´ í›„ ë¸Œë¡œì»¤ ì¬ì‹œì‘

**3. ë„¤íŠ¸ì›Œí¬ íŒŒí‹°ì…˜**
- ì¦ìƒ: ë¸Œë¡œì»¤ ê°„ í†µì‹  ì‹¤íŒ¨, ISR ì¶•ì†Œ
- ëŒ€ì‘:
  - ë„¤íŠ¸ì›Œí¬ ì¥ë¹„ ì ê²€
  - `unclean.leader.election.enable=false` ìœ ì§€
  - ë¶„í•  ë³µêµ¬ í›„ ë°ì´í„° ì •í•©ì„± í™•ì¸

**4. ZooKeeper/Controller ì¥ì• **
- ì¦ìƒ: ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ë¶ˆê°€
- ëŒ€ì‘:
  - ZooKeeper ì•™ìƒë¸” ë³µêµ¬
  - Controller ì¬ì„ ì¶œ ëŒ€ê¸°
  - KRaft ì „í™˜ ê³ ë ¤

**5. Consumer Lag ê¸‰ì¦**
- ì›ì¸: ì²˜ë¦¬ ë³‘ëª©, íŒŒí‹°ì…˜ ë¶ˆê· í˜•
- ëŒ€ì‘:
  - Consumer ìŠ¤ì¼€ì¼ ì•„ì›ƒ
  - íŒŒí‹°ì…˜ ì¬ë¶„ë°°
  - ì²˜ë¦¬ ë¡œì§ ìµœì í™”

**ì¥ì•  ëŒ€ë¹„ ì²´í¬ë¦¬ìŠ¤íŠ¸**
- [ ] ë³µì œ ê³„ìˆ˜ 3 ì´ìƒ
- [ ] ë‹¤ì¤‘ AZ/ë™ ë¶„ì‚°
- [ ] ëª¨ë‹ˆí„°ë§/ì•Œë¦¼ ì„¤ì •
- [ ] ì •ê¸° DR í›ˆë ¨

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Operations](https://kafka.apache.org/documentation/#operations)[^38]

</details>

[^38]: Kafka ê³µì‹ ë¬¸ì„œ - Operations

### KAFKA-039
Consumer Lag(ì§€ì—°) ëª¨ë‹ˆí„°ë§ ë°©ë²•ê³¼ ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì „ëµì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**Consumer Lag ê°œë…**
- ë§ˆì§€ë§‰ ìƒì‚°ëœ Offsetê³¼ ë§ˆì§€ë§‰ ì†Œë¹„ëœ Offsetì˜ ì°¨ì´
- Lagì´ ì¦ê°€í•˜ë©´ Consumerê°€ Producerë¥¼ ë”°ë¼ì¡ì§€ ëª»í•¨

**ëª¨ë‹ˆí„°ë§ ë°©ë²•**

1. **kafka-consumer-groups ëª…ë ¹**
```bash
kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --describe --group my-consumer-group
```

2. **JMX ë©”íŠ¸ë¦­**
- `records-lag-max`: ìµœëŒ€ Lag
- `records-lag`: íŒŒí‹°ì…˜ë³„ Lag

3. **ëª¨ë‹ˆí„°ë§ ë„êµ¬**
- Burrow (LinkedIn ì˜¤í”ˆì†ŒìŠ¤)
- Prometheus + kafka_exporter
- Confluent Control Center

**Lag í•´ê²° ì „ëµ**

1. **Consumer í™•ì¥**
```bash
# íŒŒí‹°ì…˜ ìˆ˜ = Consumer ìˆ˜ í™•ì¸
# Consumer ì¸ìŠ¤í„´ìŠ¤ ì¶”ê°€
```

2. **ì²˜ë¦¬ ìµœì í™”**
```properties
max.poll.records=500      # ë°°ì¹˜ í¬ê¸° ì¡°ì •
fetch.max.bytes=52428800  # 50MB
```

3. **ë³‘ë ¬ ì²˜ë¦¬**
```java
// ë©”ì‹œì§€ ì²˜ë¦¬ë¥¼ ìŠ¤ë ˆë“œí’€ë¡œ ë³‘ë ¬í™”
executor.submit(() -> process(record));
```

4. **íŒŒí‹°ì…˜ ì¦ê°€**
- ë³‘ë ¬ ì²˜ë¦¬ ë‹¨ìœ„ í™•ëŒ€
- Consumer ì¶”ê°€ ì—¬ìœ  í™•ë³´

5. **ì¼ì‹œì  í•´ê²°**
- Consumer Group ë¦¬ì…‹ (ë°ì´í„° ì†ì‹¤ ì£¼ì˜)
- `auto.offset.reset=latest`ë¡œ ì¬ì‹œì‘

**ì•Œë¦¼ ì„¤ì • ê¶Œì¥ê°’**
- Warning: Lag > 10,000
- Critical: Lag > 100,000 ë˜ëŠ” ì§€ì† ì¦ê°€

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Consumer Lag](https://kafka.apache.org/documentation/#basic_ops_consumer_lag)[^39]

</details>

[^39]: Kafka ê³µì‹ ë¬¸ì„œ - Consumer Lag

---

## ğŸ“Œ Kafka ì¼ê´€ì„±

### KAFKA-040
Kafkaì—ì„œ ë°ì´í„° ì¼ê´€ì„±ì„ ë³´ì¥í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ì¼ê´€ì„± ë³´ì¥ ë©”ì»¤ë‹ˆì¦˜**

**1. ë³µì œì™€ ISR**
```properties
replication.factor=3
min.insync.replicas=2
```
- ìµœì†Œ ISR ìˆ˜ ë§Œì¡± ì‹œì—ë§Œ ì“°ê¸° í—ˆìš©
- Leader ì¥ì•  ì‹œ ìµœì‹  ë°ì´í„°ë¥¼ ê°€ì§„ ë³µì œë³¸ì´ ìŠ¹ê²©

**2. Producer ACK ì„¤ì •**
```properties
acks=all                    # ëª¨ë“  ISR ë³µì œ ì™„ë£Œ í™•ì¸
enable.idempotence=true     # ì¤‘ë³µ ë°©ì§€
```

**3. íŠ¸ëœì­ì…˜**
```java
producer.initTransactions();
try {
    producer.beginTransaction();
    producer.send(record1);
    producer.send(record2);
    producer.sendOffsetsToTransaction(offsets, consumerGroupId);
    producer.commitTransaction();
} catch (Exception e) {
    producer.abortTransaction();
}
```

**4. Consumer ê²©ë¦¬ ìˆ˜ì¤€**
```properties
isolation.level=read_committed  # ì»¤ë°‹ëœ íŠ¸ëœì­ì…˜ë§Œ ì½ê¸°
```

**5. ìˆœì„œ ë³´ì¥**
- ë‹¨ì¼ íŒŒí‹°ì…˜ ë‚´ ìˆœì„œ ë³´ì¥
- í‚¤ ê¸°ë°˜ íŒŒí‹°ì…”ë‹ìœ¼ë¡œ ê´€ë ¨ ë©”ì‹œì§€ ë™ì¼ íŒŒí‹°ì…˜

**ì¼ê´€ì„± vs ê°€ìš©ì„± íŠ¸ë ˆì´ë“œì˜¤í”„**
| ì„¤ì • | ì¼ê´€ì„± | ê°€ìš©ì„± |
|------|--------|--------|
| acks=all, min.insync.replicas=2 | ë†’ìŒ | ì¤‘ê°„ |
| acks=1 | ì¤‘ê°„ | ë†’ìŒ |
| unclean.leader.election=true | ë‚®ìŒ | ë†’ìŒ |

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Semantics](https://kafka.apache.org/documentation/#semantics)[^40]

</details>

[^40]: Kafka ê³µì‹ ë¬¸ì„œ - Delivery Semantics

---

## ğŸ“Œ Kafka Producer ì„¤ì •

### KAFKA-041
Producerì˜ ë°°ì¹˜ ì „ì†¡(batch sending) ì„¤ì •ì´ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**ë°°ì¹˜ ê´€ë ¨ ì„¤ì •**

```properties
batch.size=16384      # ë°°ì¹˜ ìµœëŒ€ í¬ê¸° (bytes)
linger.ms=0           # ë°°ì¹˜ ëŒ€ê¸° ì‹œê°„ (ms)
buffer.memory=33554432 # ì „ì²´ ë²„í¼ ë©”ëª¨ë¦¬
```

**ì„±ëŠ¥ ì˜í–¥**

**batch.size ì¦ê°€**
- ì¥ì : ë„¤íŠ¸ì›Œí¬ ì˜¤ë²„í—¤ë“œ ê°ì†Œ, ë†’ì€ ì²˜ë¦¬ëŸ‰
- ë‹¨ì : ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€, ì²« ë©”ì‹œì§€ ì§€ì—°
- ê¶Œì¥: 64KB ~ 256KB

**linger.ms ì¦ê°€**
- ì¥ì : ë°°ì¹˜ ì±„ì›€ë¥  í–¥ìƒ, ì••ì¶• íš¨ìœ¨ ì¦ê°€
- ë‹¨ì : ì§€ì—° ì‹œê°„ ì¦ê°€
- ê¶Œì¥: 5ms ~ 100ms (ì²˜ë¦¬ëŸ‰ ì¤‘ì‹œ)

**ì¡°í•© ì˜ˆì‹œ**

| ì‹œë‚˜ë¦¬ì˜¤ | batch.size | linger.ms | íš¨ê³¼ |
|----------|------------|-----------|------|
| ì €ì§€ì—° | 16KB | 0 | ì¦‰ì‹œ ì „ì†¡ |
| ê³ ì²˜ë¦¬ëŸ‰ | 128KB | 50ms | ë°°ì¹˜ ìµœì í™” |
| ê· í˜• | 64KB | 10ms | ì ì ˆí•œ ê· í˜• |

**ì••ì¶•ê³¼ì˜ ì—°ê³„**
```properties
compression.type=lz4   # ë°°ì¹˜ ë‹¨ìœ„ ì••ì¶•
```
- í° ë°°ì¹˜ + ì••ì¶• = ë†’ì€ ë„¤íŠ¸ì›Œí¬ íš¨ìœ¨

**ëª¨ë‹ˆí„°ë§ ì§€í‘œ**
- `batch-size-avg`: í‰ê·  ë°°ì¹˜ í¬ê¸°
- `record-queue-time-avg`: ë°°ì¹˜ ëŒ€ê¸° ì‹œê°„
- `compression-rate-avg`: ì••ì¶•ë¥ 

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Producer Batching](https://kafka.apache.org/documentation/#producerconfigs_batch.size)[^41]

</details>

[^41]: Kafka ê³µì‹ ë¬¸ì„œ - Producer Configurations

---

## ğŸ“Œ Kafka Consumer Offset

### KAFKA-042
Kafka Consumerì˜ ì˜¤í”„ì…‹ ì»¤ë°‹ ì „ëµ(ìë™ vs ìˆ˜ë™ ì»¤ë°‹)ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**ìë™ ì»¤ë°‹ (Auto Commit)**
```properties
enable.auto.commit=true
auto.commit.interval.ms=5000
```

**ì¥ì **
- êµ¬í˜„ ê°„ë‹¨
- ê°œë°œì ê´€ë¦¬ ë¶€ë‹´ ì—†ìŒ

**ë‹¨ì **
- ë©”ì‹œì§€ ì†ì‹¤ ìœ„í—˜ (ì²˜ë¦¬ ì „ ì»¤ë°‹)
- ì¤‘ë³µ ì²˜ë¦¬ ê°€ëŠ¥ (ì»¤ë°‹ í›„ ì²˜ë¦¬ ì‹¤íŒ¨)

**ìˆ˜ë™ ì»¤ë°‹ (Manual Commit)**
```properties
enable.auto.commit=false
```

**ë™ê¸° ì»¤ë°‹**
```java
consumer.poll(Duration.ofMillis(100));
process(records);
consumer.commitSync();  // ë¸”ë¡œí‚¹
```

**ë¹„ë™ê¸° ì»¤ë°‹**
```java
consumer.commitAsync((offsets, exception) -> {
    if (exception != null) {
        log.error("Commit failed", exception);
    }
});
```

**í˜¼í•© ì „ëµ (ê¶Œì¥)**
```java
try {
    while (running) {
        ConsumerRecords records = consumer.poll(Duration.ofMillis(100));
        process(records);
        consumer.commitAsync();  // ì¼ë°˜ì ìœ¼ë¡œ ë¹„ë™ê¸°
    }
} finally {
    consumer.commitSync();  // ì¢…ë£Œ ì‹œ ë™ê¸°
    consumer.close();
}
```

**ì»¤ë°‹ ì „ëµ ë¹„êµ**
| ì „ëµ | ë©”ì‹œì§€ ì†ì‹¤ | ì¤‘ë³µ ì²˜ë¦¬ | ì„±ëŠ¥ |
|------|-----------|----------|------|
| ìë™ ì»¤ë°‹ | ê°€ëŠ¥ | ê°€ëŠ¥ | ë†’ìŒ |
| ì²˜ë¦¬ í›„ ì»¤ë°‹ | ì—†ìŒ | ê°€ëŠ¥ | ì¤‘ê°„ |
| ì»¤ë°‹ í›„ ì²˜ë¦¬ | ê°€ëŠ¥ | ì—†ìŒ | ì¤‘ê°„ |

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Offset Management](https://kafka.apache.org/documentation/#consumerconfigs_enable.auto.commit)[^42]

</details>

[^42]: Kafka ê³µì‹ ë¬¸ì„œ - Consumer Configurations

---

## ğŸ“Œ Kafka Dead Letter Queue

### KAFKA-043
Dead Letter Queue(DLQ)ë¥¼ Kafkaì—ì„œ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**DLQ êµ¬í˜„ íŒ¨í„´**

**1. ê¸°ë³¸ DLQ êµ¬í˜„**
```java
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
        try {
            processMessage(record);
        } catch (Exception e) {
            // DLQë¡œ ì „ì†¡
            ProducerRecord<String, String> dlqRecord = new ProducerRecord<>(
                "my-topic.DLQ",
                record.key(),
                record.value()
            );
            // ì›ë³¸ ì •ë³´ë¥¼ í—¤ë”ì— ì¶”ê°€
            dlqRecord.headers()
                .add("original-topic", record.topic().getBytes())
                .add("original-partition", String.valueOf(record.partition()).getBytes())
                .add("original-offset", String.valueOf(record.offset()).getBytes())
                .add("error-message", e.getMessage().getBytes());

            dlqProducer.send(dlqRecord);
        }
    }
    consumer.commitSync();
}
```

**2. ì¬ì‹œë„ í† í”½ + DLQ íŒ¨í„´**
```
main-topic â†’ retry-topic-1 â†’ retry-topic-2 â†’ DLQ
              (1ë¶„ í›„)        (5ë¶„ í›„)      (ìµœì¢… ì‹¤íŒ¨)
```

**3. Spring Kafka í™œìš©**
```java
@KafkaListener(topics = "my-topic")
@RetryableTopic(
    attempts = "4",
    backoff = @Backoff(delay = 1000, multiplier = 2),
    dltTopicSuffix = ".DLQ"
)
public void listen(String message) {
    process(message);
}

@DltHandler
public void handleDlt(String message) {
    log.error("DLQ received: " + message);
}
```

**DLQ ìš´ì˜ ëª¨ë²” ì‚¬ë¡€**
- DLQ í† í”½ ë³„ë„ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼
- ë©”ì‹œì§€ ì›ë³¸ ì •ë³´ ë³´ì¡´ (í—¤ë” í™œìš©)
- DLQ ë©”ì‹œì§€ ì¬ì²˜ë¦¬ ë„êµ¬ ì¤€ë¹„
- DLQ ë³´ì¡´ ê¸°ê°„ ì¶©ë¶„íˆ ì„¤ì •

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Error Handling](https://kafka.apache.org/documentation/)[^43]

</details>

[^43]: Kafka ê³µì‹ ë¬¸ì„œ ë° Spring Kafka ë¬¸ì„œ

---

## ğŸ“Œ Kafka Schema Registry

### KAFKA-044
Kafka ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ ê´€ë¦¬(Schema Registry)ì˜ ì—­í• ê³¼ í•„ìš”ì„±ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**Schema Registry ì—­í• **
- ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ(Avro, Protobuf, JSON Schema)ë¥¼ ì¤‘ì•™ ì €ì¥ì†Œì—ì„œ ê´€ë¦¬
- Producer/Consumer ê°„ ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± ë³´ì¥
- ìŠ¤í‚¤ë§ˆ ë²„ì „ ê´€ë¦¬ ë° ì§„í™” ì§€ì›

**í•„ìš”ì„±**
1. **ë°ì´í„° ê³„ì•½**: Producer/Consumer ê°„ ëª…í™•í•œ ë°ì´í„° í˜•ì‹ ì •ì˜
2. **í˜¸í™˜ì„± ê²€ì¦**: ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì‹œ í•˜ìœ„/ìƒìœ„ í˜¸í™˜ì„± ìë™ ê²€ì¦
3. **íš¨ìœ¨ì  ì§ë ¬í™”**: ìŠ¤í‚¤ë§ˆ IDë§Œ ì „ì†¡í•˜ì—¬ í˜ì´ë¡œë“œ í¬ê¸° ê°ì†Œ
4. **ìŠ¤í‚¤ë§ˆ ì§„í™”**: í•„ë“œ ì¶”ê°€/ì‚­ì œ ì‹œ ê¸°ì¡´ Consumer ì˜í–¥ ìµœì†Œí™”

**í˜¸í™˜ì„± ëª¨ë“œ**
| ëª¨ë“œ | ì„¤ëª… |
|------|------|
| BACKWARD | ìƒˆ ìŠ¤í‚¤ë§ˆë¡œ ì´ì „ ë°ì´í„° ì½ê¸° ê°€ëŠ¥ |
| FORWARD | ì´ì „ ìŠ¤í‚¤ë§ˆë¡œ ìƒˆ ë°ì´í„° ì½ê¸° ê°€ëŠ¥ |
| FULL | ì–‘ë°©í–¥ í˜¸í™˜ |
| NONE | í˜¸í™˜ì„± ê²€ì‚¬ ì—†ìŒ |

**ì‚¬ìš© ì˜ˆì‹œ (Avro)**
```java
// Producer
props.put("schema.registry.url", "http://localhost:8081");
props.put("value.serializer", KafkaAvroSerializer.class);

GenericRecord record = new GenericData.Record(schema);
record.put("name", "John");
producer.send(new ProducerRecord<>("users", record));
```

**ëª¨ë²” ì‚¬ë¡€**
- BACKWARD ë˜ëŠ” FULL í˜¸í™˜ì„± ì‚¬ìš©
- í•„ë“œ ì‚­ì œ ì‹œ default ê°’ ì„¤ì •
- CI/CDì—ì„œ ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸

**ì°¸ê³ ìë£Œ**
- [Confluent Schema Registry Documentation](https://docs.confluent.io/platform/current/schema-registry/)[^44]

</details>

[^44]: Confluent Schema Registry ê³µì‹ ë¬¸ì„œ

---

## ğŸ“Œ Kafka ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™

### KAFKA-045
Kafkaì™€ NoSQL ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì—°ë™í•  ë•Œ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ì—°ë™ ë°©ì‹**

1. **Kafka Connect í™œìš©**
```json
{
  "name": "mongodb-sink",
  "config": {
    "connector.class": "com.mongodb.kafka.connect.MongoSinkConnector",
    "connection.uri": "mongodb://localhost:27017",
    "database": "mydb",
    "collection": "events",
    "topics": "my-topic"
  }
}
```

2. **Consumer ì§ì ‘ êµ¬í˜„**
```java
while (true) {
    ConsumerRecords records = consumer.poll(Duration.ofMillis(100));
    List<Document> batch = new ArrayList<>();
    for (ConsumerRecord record : records) {
        batch.add(Document.parse(record.value()));
    }
    mongoCollection.insertMany(batch);  // ë°°ì¹˜ ì‚½ì…
    consumer.commitSync();
}
```

**ê³ ë ¤ì‚¬í•­**

**1. ì¼ê´€ì„±**
- íŠ¸ëœì­ì…˜ ë¯¸ì§€ì› NoSQL: ë©±ë“±ì„± ì„¤ê³„ í•„ìˆ˜
- ì¤‘ë³µ ë©”ì‹œì§€ ì²˜ë¦¬ ë¡œì§ (upsert í™œìš©)

**2. ì„±ëŠ¥**
- ë°°ì¹˜ ì“°ê¸°ë¡œ ì²˜ë¦¬ëŸ‰ í–¥ìƒ
- ì¸ë±ìŠ¤ ì„¤ê³„ ìµœì í™”
- ë°±í”„ë ˆì…” ì²˜ë¦¬

**3. ìŠ¤í‚¤ë§ˆ ê´€ë¦¬**
- Schema Registryë¡œ ë°ì´í„° í˜•ì‹ ê´€ë¦¬
- NoSQL ìœ ì—°í•œ ìŠ¤í‚¤ë§ˆì™€ì˜ ì¡°í™”

**4. ì—ëŸ¬ ì²˜ë¦¬**
- ì¬ì‹œë„ ë¡œì§ êµ¬í˜„
- DLQ í™œìš©
- ì»¤ë„¥ì…˜ í’€ ê´€ë¦¬

**5. í™•ì¥ì„±**
- íŒŒí‹°ì…˜ ìˆ˜ì™€ Consumer ë³‘ë ¬ì„±
- NoSQL ìƒ¤ë”© ì „ëµê³¼ ì¡°í™”

**ë°ì´í„°ë² ì´ìŠ¤ë³„ ê¶Œì¥ Connector**
- MongoDB: MongoDB Kafka Connector
- Cassandra: DataStax Connector
- Elasticsearch: Confluent Elasticsearch Sink
- Redis: Redis Sink Connector

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Connect](https://kafka.apache.org/documentation/#connect)[^45]

</details>

[^45]: Kafka ê³µì‹ ë¬¸ì„œ - Kafka Connect

---

## ğŸ“Œ Kafka Streams State Store

### KAFKA-046
Kafka Streamsì˜ ìƒíƒœ ì €ì¥ì†Œ(State Store) ê´€ë¦¬ ë°©ì‹ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**State Store ê°œë…**
- Kafka Streamsì—ì„œ ìƒíƒœê°€ í•„ìš”í•œ ì—°ì‚°(ì§‘ê³„, ì¡°ì¸ ë“±)ì„ ìœ„í•œ ë¡œì»¬ ì €ì¥ì†Œ
- ê¸°ë³¸ì ìœ¼ë¡œ RocksDB ì‚¬ìš© (in-memory ì˜µì…˜ë„ ê°€ëŠ¥)

**State Store ìœ í˜•**
1. **KeyValueStore**: í‚¤-ê°’ ì €ì¥
2. **WindowStore**: ì‹œê°„ ìœˆë„ìš°ë³„ í‚¤-ê°’ ì €ì¥
3. **SessionStore**: ì„¸ì…˜ ê¸°ë°˜ í‚¤-ê°’ ì €ì¥

**ë‚´ë¶€ ë™ì‘ ë°©ì‹**
```
Input Topic â†’ State Store (RocksDB) â† Changelog Topic
                    â†“
              Output Topic
```

**Changelog Topic**
- State Store ë³€ê²½ì‚¬í•­ì„ Kafka í† í”½ì— ê¸°ë¡
- ì¥ì•  ë³µêµ¬ ì‹œ ìƒíƒœ ì¬êµ¬ì¶•ì— ì‚¬ìš©
- ìë™ ìƒì„±ë¨ (application.id-storename-changelog)

**ì„¤ì • ì˜ˆì‹œ**
```java
StreamsBuilder builder = new StreamsBuilder();
builder.stream("input-topic")
    .groupByKey()
    .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as("count-store")
        .withKeySerde(Serdes.String())
        .withValueSerde(Serdes.Long()));
```

**ê´€ë¦¬ ë°©ë²•**
```properties
# State ë””ë ‰í† ë¦¬ ì„¤ì •
state.dir=/var/kafka-streams

# Standby ë³µì œë³¸ (ë¹ ë¥¸ ë³µêµ¬)
num.standby.replicas=1
```

**ìƒíƒœ ë³µêµ¬**
1. Changelog í† í”½ì—ì„œ ìƒíƒœ ì¬êµ¬ì¶•
2. Standby ë³µì œë³¸ì´ ìˆìœ¼ë©´ ë¹ ë¥¸ ë³µêµ¬

**ëª¨ë²” ì‚¬ë¡€**
- ì¶©ë¶„í•œ ë¡œì»¬ ë””ìŠ¤í¬ ê³µê°„ í™•ë³´
- Standby ë³µì œë³¸ ì„¤ì •ìœ¼ë¡œ ë³µêµ¬ ì‹œê°„ ë‹¨ì¶•
- State Store í¬ê¸° ëª¨ë‹ˆí„°ë§

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Streams State](https://kafka.apache.org/documentation/streams/developer-guide/processor-api#state-stores)[^46]

</details>

[^46]: Kafka Streams ê³µì‹ ë¬¸ì„œ - State Stores

---

## ğŸ“Œ Kafka ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤

### KAFKA-047
Kafkaë¥¼ í™œìš©í•œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì„¤ê³„ ì‚¬ë¡€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**ì´ë²¤íŠ¸ ê¸°ë°˜ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ íŒ¨í„´**

**1. ì´ë²¤íŠ¸ ì†Œì‹± (Event Sourcing)**
```
ì£¼ë¬¸ ì„œë¹„ìŠ¤ â†’ order-events í† í”½ â†’ ì¬ê³  ì„œë¹„ìŠ¤
                              â†’ ê²°ì œ ì„œë¹„ìŠ¤
                              â†’ ì•Œë¦¼ ì„œë¹„ìŠ¤
```
- ëª¨ë“  ìƒíƒœ ë³€ê²½ì„ ì´ë²¤íŠ¸ë¡œ ì €ì¥
- ì´ë²¤íŠ¸ ì¬ìƒìœ¼ë¡œ ìƒíƒœ ë³µì› ê°€ëŠ¥

**2. CQRS (Command Query Responsibility Segregation)**
```
ëª…ë ¹(Write) â†’ Command Topic â†’ Write Service â†’ Event Topic
                                                   â†“
ì¡°íšŒ(Read) â† Read Service â† Materialized View â†â”€â”€â”€â”˜
```
- ì“°ê¸°ì™€ ì½ê¸° ëª¨ë¸ ë¶„ë¦¬
- ì½ê¸° ìµœì í™”ëœ ë·° êµ¬ì„±

**3. Saga íŒ¨í„´ (ë¶„ì‚° íŠ¸ëœì­ì…˜)**
```
Order Created â†’ Payment Processed â†’ Inventory Reserved â†’ Order Completed
      â†“ (ì‹¤íŒ¨ ì‹œ)        â†“ (ì‹¤íŒ¨ ì‹œ)         â†“ (ì‹¤íŒ¨ ì‹œ)
Order Cancelled â† Payment Refunded â† Inventory Released
```
- ë³´ìƒ íŠ¸ëœì­ì…˜ìœ¼ë¡œ ì¼ê´€ì„± ìœ ì§€

**í† í”½ ì„¤ê³„**
```
services/
â”œâ”€â”€ order-events        # ë„ë©”ì¸ ì´ë²¤íŠ¸
â”œâ”€â”€ order-commands      # ëª…ë ¹ ë©”ì‹œì§€
â”œâ”€â”€ order-dlq           # ì‹¤íŒ¨ ë©”ì‹œì§€
â””â”€â”€ order-notifications # ì•Œë¦¼ ì´ë²¤íŠ¸
```

**êµ¬í˜„ ì˜ˆì‹œ**
```java
// ì£¼ë¬¸ ì„œë¹„ìŠ¤
@KafkaListener(topics = "order-commands")
public void handleOrder(OrderCommand cmd) {
    Order order = processOrder(cmd);
    kafkaTemplate.send("order-events", new OrderCreatedEvent(order));
}

// ì¬ê³  ì„œë¹„ìŠ¤
@KafkaListener(topics = "order-events")
public void onOrderCreated(OrderCreatedEvent event) {
    inventoryService.reserve(event.getItems());
}
```

**ëª¨ë²” ì‚¬ë¡€**
- ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ ë²„ì „ ê´€ë¦¬
- ë©±ë“±ì„± ì²˜ë¦¬ í•„ìˆ˜
- ì„œë¹„ìŠ¤ë³„ Consumer Group ë¶„ë¦¬

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Use Cases](https://kafka.apache.org/documentation/#uses)[^47]

</details>

[^47]: Kafka ê³µì‹ ë¬¸ì„œ - Use Cases

---

## ğŸ“Œ Kafka ë¸Œë¡œì»¤ ì¶”ê°€

### KAFKA-048
Kafka í´ëŸ¬ìŠ¤í„°ì— ìƒˆë¡œìš´ ë¸Œë¡œì»¤ë¥¼ ì¶”ê°€í•  ë•Œ ê³ ë ¤í•´ì•¼ í•  ì£¼ìš” ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ë¸Œë¡œì»¤ ì¶”ê°€ ì ˆì°¨**

1. **ìƒˆ ë¸Œë¡œì»¤ ì„¤ì •**
```properties
broker.id=4                    # ê³ ìœ  ID
log.dirs=/var/kafka-logs
zookeeper.connect=zk1:2181,zk2:2181,zk3:2181
# ë˜ëŠ” KRaft ëª¨ë“œ
controller.quorum.voters=1@controller1:9093
```

2. **ë¸Œë¡œì»¤ ì‹œì‘**
```bash
kafka-server-start.sh config/server.properties
```

3. **íŒŒí‹°ì…˜ ì¬ë¶„ë°°** (ì„ íƒ)
```bash
# ì¬ë¶„ë°° ê³„íš ìƒì„±
kafka-reassign-partitions.sh --generate \
  --topics-to-move-json-file topics.json \
  --broker-list "1,2,3,4"

# ì‹¤í–‰
kafka-reassign-partitions.sh --execute \
  --reassignment-json-file plan.json \
  --throttle 50000000
```

**ê³ ë ¤ ìš”ì†Œ**

**1. í•˜ë“œì›¨ì–´ ì¼ê´€ì„±**
- ê¸°ì¡´ ë¸Œë¡œì»¤ì™€ ë™ì¼í•œ ì‚¬ì–‘ ê¶Œì¥
- ë””ìŠ¤í¬ ìš©ëŸ‰, ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ í™•ì¸

**2. ë„¤íŠ¸ì›Œí¬ êµ¬ì„±**
- ê¸°ì¡´ ë¸Œë¡œì»¤ì™€ ë™ì¼ ë„¤íŠ¸ì›Œí¬ ì„¸ê·¸ë¨¼íŠ¸
- ë°©í™”ë²½ ê·œì¹™ í™•ì¸ (9092, 9093 í¬íŠ¸)

**3. íŒŒí‹°ì…˜ ì¬ë¶„ë°°**
- ìë™ ë¶„ë°°ë˜ì§€ ì•ŠìŒ (ìˆ˜ë™ ì¬ë¶„ë°° í•„ìš”)
- ìŠ¤ë¡œí‹€ë§ìœ¼ë¡œ ì„±ëŠ¥ ì˜í–¥ ìµœì†Œí™”
- í”¼í¬ ì‹œê°„ ì™¸ ìˆ˜í–‰

**4. Rack Awareness**
```properties
broker.rack=rack1
```
- ì¥ì•  ë„ë©”ì¸ ë¶„ì‚°

**5. ëª¨ë‹ˆí„°ë§**
- ìƒˆ ë¸Œë¡œì»¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™•ì¸
- ë¦¬ë” ë¶„ë°° ê· í˜• í™•ì¸
- Under-replicated íŒŒí‹°ì…˜ ì—†ìŒ í™•ì¸

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Adding Servers](https://kafka.apache.org/documentation/#basic_ops_cluster_expansion)[^48]

</details>

[^48]: Kafka ê³µì‹ ë¬¸ì„œ - Cluster Expansion

---

## ğŸ“Œ Kafka Connector ê°œë°œ

### KAFKA-049
Kafka ì»¤ë„¥í„°(Connector) ê°œë°œ ë° ì»¤ìŠ¤í„°ë§ˆì´ì§• ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

<details>
<summary>ë‹µë³€</summary>

**ì»¤ë„¥í„° ìœ í˜•**
- **Source Connector**: ì™¸ë¶€ ì‹œìŠ¤í…œ â†’ Kafka
- **Sink Connector**: Kafka â†’ ì™¸ë¶€ ì‹œìŠ¤í…œ

**Source Connector ê°œë°œ**
```java
public class MySourceConnector extends SourceConnector {
    @Override
    public void start(Map<String, String> props) {
        // ì„¤ì • ì´ˆê¸°í™”
    }

    @Override
    public Class<? extends Task> taskClass() {
        return MySourceTask.class;
    }

    @Override
    public List<Map<String, String>> taskConfigs(int maxTasks) {
        // íƒœìŠ¤í¬ ì„¤ì • ë¶„ë°°
        return configs;
    }
}

public class MySourceTask extends SourceTask {
    @Override
    public List<SourceRecord> poll() {
        // ì™¸ë¶€ ì‹œìŠ¤í…œì—ì„œ ë°ì´í„° ì½ê¸°
        return Arrays.asList(
            new SourceRecord(
                sourcePartition, sourceOffset,
                "target-topic", Schema.STRING_SCHEMA, value
            )
        );
    }
}
```

**Sink Connector ê°œë°œ**
```java
public class MySinkTask extends SinkTask {
    @Override
    public void put(Collection<SinkRecord> records) {
        for (SinkRecord record : records) {
            // ì™¸ë¶€ ì‹œìŠ¤í…œì— ë°ì´í„° ì“°ê¸°
            externalSystem.write(record.value());
        }
    }

    @Override
    public void flush(Map<TopicPartition, OffsetAndMetadata> offsets) {
        // ë²„í¼ í”ŒëŸ¬ì‹œ
    }
}
```

**ì»¤ìŠ¤í„°ë§ˆì´ì§• í¬ì¸íŠ¸**
1. **ë³€í™˜ (SMT - Single Message Transform)**
```json
{
  "transforms": "addTimestamp",
  "transforms.addTimestamp.type": "org.apache.kafka.connect.transforms.InsertField$Value",
  "transforms.addTimestamp.timestamp.field": "processed_at"
}
```

2. **ì—ëŸ¬ ì²˜ë¦¬**
```json
{
  "errors.tolerance": "all",
  "errors.deadletterqueue.topic.name": "my-dlq"
}
```

**ë°°í¬**
```bash
# JAR íŒŒì¼ì„ í”ŒëŸ¬ê·¸ì¸ ë””ë ‰í† ë¦¬ì— ë°°ì¹˜
plugin.path=/usr/share/kafka-connect-plugins
```

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Connect Development](https://kafka.apache.org/documentation/#connect_development)[^49]

</details>

[^49]: Kafka ê³µì‹ ë¬¸ì„œ - Connector Development Guide

---

## ğŸ“Œ Kafka ìš´ì˜ ì§€í‘œ

### KAFKA-050
Kafka ìš´ì˜ ì‹œ ëª¨ë‹ˆí„°ë§ê³¼ ê²½ë³´ ì‹œìŠ¤í…œ ì„¤ì • ì‹œ ì¤‘ìš”í•œ í•µì‹¬ ì§€í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?

<details>
<summary>ë‹µë³€</summary>

**ë¸Œë¡œì»¤ í•µì‹¬ ì§€í‘œ**

| ì§€í‘œ | ì„¤ëª… | ì„ê³„ê°’ |
|------|------|--------|
| UnderReplicatedPartitions | ë³µì œ ì§€ì—° íŒŒí‹°ì…˜ | > 0 ê²½ê³  |
| OfflinePartitionsCount | ì˜¤í”„ë¼ì¸ íŒŒí‹°ì…˜ | > 0 ìœ„í—˜ |
| ActiveControllerCount | í™œì„± ì»¨íŠ¸ë¡¤ëŸ¬ | != 1 ìœ„í—˜ |
| RequestsPerSec | ìš”ì²­ ì²˜ë¦¬ëŸ‰ | ìš©ëŸ‰ ëŒ€ë¹„ |
| NetworkProcessorAvgIdlePercent | ë„¤íŠ¸ì›Œí¬ ìŠ¤ë ˆë“œ ìœ íœ´ìœ¨ | < 30% ê²½ê³  |
| RequestHandlerAvgIdlePercent | ìš”ì²­ í•¸ë“¤ëŸ¬ ìœ íœ´ìœ¨ | < 30% ê²½ê³  |

**Producer ì§€í‘œ**
| ì§€í‘œ | ì„¤ëª… | ì„ê³„ê°’ |
|------|------|--------|
| record-error-rate | ì „ì†¡ ì‹¤íŒ¨ìœ¨ | > 0 ê²½ê³  |
| record-send-rate | ì „ì†¡ ì²˜ë¦¬ëŸ‰ | ëª¨ë‹ˆí„°ë§ |
| request-latency-avg | í‰ê·  ì§€ì—°ì‹œê°„ | > 100ms ê²½ê³  |

**Consumer ì§€í‘œ**
| ì§€í‘œ | ì„¤ëª… | ì„ê³„ê°’ |
|------|------|--------|
| records-lag-max | ìµœëŒ€ Consumer Lag | ì¦ê°€ ì¶”ì„¸ ê²½ê³  |
| fetch-rate | ì†Œë¹„ ì²˜ë¦¬ëŸ‰ | ëª¨ë‹ˆí„°ë§ |
| commit-latency-avg | ì»¤ë°‹ ì§€ì—°ì‹œê°„ | > 50ms ê²½ê³  |

**ì‹œìŠ¤í…œ ì§€í‘œ**
- CPU ì‚¬ìš©ë¥  (< 70%)
- ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
- ë””ìŠ¤í¬ ì‚¬ìš©ë¥  (< 80%)
- ë„¤íŠ¸ì›Œí¬ I/O

**ì•Œë¦¼ ì„¤ì • ì˜ˆì‹œ (Prometheus)**
```yaml
groups:
- name: kafka
  rules:
  - alert: KafkaUnderReplicatedPartitions
    expr: kafka_server_replicamanager_underreplicatedpartitions > 0
    for: 5m
    labels:
      severity: warning

  - alert: KafkaConsumerLagHigh
    expr: kafka_consumer_group_lag > 10000
    for: 10m
    labels:
      severity: warning
```

**ì°¸ê³ ìë£Œ**
- [Apache Kafka Documentation - Monitoring](https://kafka.apache.org/documentation/#monitoring)[^50]

</details>

[^50]: Kafka ê³µì‹ ë¬¸ì„œ - Monitoring
