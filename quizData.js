// Auto-generated by build-quiz.js
// Generated at: 2026-02-15T11:11:06.349Z
// Total questions: 1273

const quizData = [
  {
    "id": "ARCH-001",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "CPU의 구조와 주요 구성 요소(ALU, 제어 유닛, 레지스터)에 대해 설명해주세요.",
    "answer": "CPU는 컴퓨터의 두뇌로서 세 가지 핵심 구성 요소로 이루어져 있습니다.\n\nALU (Arithmetic Logic Unit)\n산술 연산(덧셈, 뺄셈 등)과 논리 연산(AND, OR, NOT 등)을 수행\n비교 연산을 통해 조건 분기 결정에 필요한 플래그 생성\n\n제어 유닛 (Control Unit)\n명령어를 해독하고 실행 순서를 제어\n다른 구성 요소들에 제어 신호를 전송하여 동작을 조정\n\n레지스터 (Register)\nCPU 내부의 초고속 임시 저장 공간\n프로그램 카운터(PC), 명령어 레지스터(IR), 범용 레지스터 등으로 구분\n메모리보다 수십 배 빠른 접근 속도 제공",
    "references": [
      {
        "title": "Intel 64 and IA-32 Architectures Software Developer's Manual",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "cpu",
      "alu",
      "arithmetic",
      "logic",
      "unit",
      "control",
      "register",
      "컴퓨터의",
      "두뇌로서",
      "가지",
      "핵심",
      "구성",
      "요소로",
      "이루어져",
      "산술"
    ]
  },
  {
    "id": "ARCH-002",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "명령어 사이클(Instruction Cycle)의 단계(Fetch, Decode, Execute)에 대해 설명해주세요.",
    "answer": "명령어 사이클은 CPU가 하나의 명령어를 처리하는 과정입니다.\n\nFetch (인출)\n프로그램 카운터(PC)가 가리키는 메모리 주소에서 명령어를 가져옴\n명령어를 명령어 레지스터(IR)에 저장\nPC를 다음 명령어 주소로 증가\n\nDecode (해독)\n명령어 레지스터의 명령어를 해석\n연산 종류, 피연산자, 주소 지정 방식 등을 파악\n필요한 데이터를 레지스터나 메모리에서 준비\n\nExecute (실행)\nALU에서 실제 연산 수행\n결과를 레지스터나 메모리에 저장\n필요시 플래그 레지스터 갱신",
    "references": [
      {
        "title": "Intel 64 and IA-32 Architectures Software Developer's Manual, Vol.1",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "cpu",
      "fetch",
      "decode",
      "execute",
      "alu",
      "명령어",
      "사이클은",
      "하나의",
      "명령어를",
      "처리하는",
      "과정입니다",
      "인출",
      "프로그램",
      "카운터",
      "가리키는"
    ]
  },
  {
    "id": "ARCH-003",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "파이프라이닝(Pipelining)이 무엇이고, 어떻게 CPU 성능을 향상시키나요?",
    "answer": "파이프라이닝은 명령어 처리 단계를 중첩시켜 동시에 여러 명령어를 처리하는 기법입니다.\n\n동작 원리\n각 명령어 사이클 단계(Fetch, Decode, Execute 등)를 독립적인 스테이지로 분리\n한 명령어가 다음 단계로 넘어가면, 이전 단계에서 새 명령어 처리 시작\n세탁기-건조기를 동시에 돌리는 것과 유사\n\n성능 향상\n이상적으로 n단계 파이프라인은 n배 처리량(throughput) 증가\n단일 명령어 지연 시간(latency)은 동일하지만, 전체 처리량 향상\n현대 CPU는 14-20단계 이상의 파이프라인 사용\n\n한계\n파이프라인 해저드로 인한 스톨(stall) 발생 가능\n분기 명령어에서 파이프라인 플러시 발생 가능",
    "references": [
      {
        "title": "Intel Optimization Reference Manual",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "fetch",
      "decode",
      "execute",
      "cpu",
      "파이프라이닝은",
      "명령어",
      "처리",
      "단계를",
      "중첩시켜",
      "동시에",
      "여러",
      "명령어를",
      "처리하는",
      "기법입니다",
      "동작"
    ]
  },
  {
    "id": "ARCH-004",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "파이프라인 해저드(Pipeline Hazard)의 종류와 해결 방법에 대해 설명해주세요.",
    "answer": "파이프라인 해저드는 파이프라인의 정상적인 실행을 방해하는 상황입니다.\n\n구조적 해저드 (Structural Hazard)\n하드웨어 자원 충돌 (예: 메모리 동시 접근)\n해결: 자원 복제, 분리된 명령어/데이터 캐시 사용\n\n데이터 해저드 (Data Hazard)\n명령어 간 데이터 의존성 (RAW, WAR, WAW)\n해결: 포워딩(Forwarding), 스톨 삽입, 레지스터 리네이밍\n\n제어 해저드 (Control Hazard)\n분기 명령어로 인한 다음 명령어 불확실성\n해결: 분기 예측, 지연 분기, 투기적 실행",
    "references": [
      {
        "title": "ARM Cortex-A Series Programmer's Guide",
        "url": "https://developer.arm.com/documentation"
      }
    ],
    "keywords": [
      "structural",
      "hazard",
      "data",
      "raw",
      "war",
      "waw",
      "forwarding",
      "control",
      "파이프라인",
      "해저드는",
      "파이프라인의",
      "정상적인",
      "실행을",
      "방해하는",
      "상황입니다"
    ]
  },
  {
    "id": "ARCH-005",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "분기 예측(Branch Prediction)이 무엇이고 왜 중요한가요?",
    "answer": "분기 예측은 조건 분기 명령어의 결과를 미리 예측하여 파이프라인 효율을 높이는 기법입니다.\n\n중요성\n분기 결과를 기다리면 파이프라인이 멈춤 (스톨)\n현대 CPU는 깊은 파이프라인으로 분기 패널티가 큼 (10-20 사이클)\n예측 실패 시 파이프라인 플러시 필요\n\n분기 예측 기법\n정적 예측: 항상 분기/비분기 예측, 또는 backward taken/forward not taken\n동적 예측: 과거 분기 이력 기반 (2-bit 카운터, 히스토리 테이블)\n현대 기법: 신경망 기반 예측기, TAGE 예측기 등\n\n성능 영향\n현대 CPU의 분기 예측 정확도: 95% 이상\n루프 최적화, 분기 없는 코드 작성으로 예측 실패 최소화 가능",
    "references": [
      {
        "title": "Intel Optimization Reference Manual - Branch Prediction",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "cpu",
      "tage",
      "분기",
      "예측은",
      "조건",
      "명령어의",
      "결과를",
      "미리",
      "예측하여",
      "파이프라인",
      "효율을",
      "높이는",
      "기법입니다",
      "중요성",
      "기다리면"
    ]
  },
  {
    "id": "ARCH-006",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "Out-of-Order Execution이 무엇이고, 어떤 이점이 있나요?",
    "answer": "Out-of-Order Execution(OoOE)은 명령어를 프로그램 순서와 다르게 실행하여 성능을 높이는 기법입니다.\n\n동작 원리\n명령어를 디코딩 후 리오더 버퍼(ROB)에 저장\n피연산자가 준비된 명령어부터 실행 (데이터 흐름 순서)\n결과는 프로그램 순서대로 커밋하여 정확성 보장\n\n이점\n캐시 미스나 데이터 의존성으로 대기 중에도 다른 명령어 실행\n파이프라인 유휴 시간 최소화\nIPC(Instructions Per Cycle) 향상\n\n관련 기술\n레지스터 리네이밍: WAR, WAW 해저드 제거\n투기적 실행: 분기 결과 전에 실행 시작\n리오더 버퍼: 순서대로 커밋 보장",
    "references": [
      {
        "title": "Intel 64 Architecture - Out-of-Order Execution",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "out-of-order",
      "execution",
      "oooe",
      "rob",
      "ipc",
      "instructions",
      "per",
      "cycle",
      "war",
      "waw",
      "명령어를",
      "프로그램",
      "순서와",
      "다르게",
      "실행하여"
    ]
  },
  {
    "id": "ARCH-007",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "CISC와 RISC 아키텍처의 차이점에 대해 설명해주세요.",
    "answer": "CISC와 RISC는 CPU 명령어 집합 설계 철학의 두 가지 접근 방식입니다.\n\nCISC (Complex Instruction Set Computer)\n복잡하고 다양한 명령어 제공\n하나의 명령어로 여러 작업 수행 가능\n가변 길이 명령어\n메모리-레지스터 연산 지원\n예: x86, x86-64\n\nRISC (Reduced Instruction Set Computer)\n단순하고 적은 수의 명령어\n각 명령어가 한 사이클에 실행되도록 설계\n고정 길이 명령어\n로드/스토어 아키텍처 (메모리 접근은 전용 명령어만)\n예: ARM, RISC-V, MIPS\n\n현대적 관점\n현대 x86 CPU는 내부적으로 RISC 마이크로 연산으로 변환\n두 방식의 장점을 결합한 하이브리드 설계가 일반적",
    "references": [
      {
        "title": "ARM Architecture Reference Manual",
        "url": "https://developer.arm.com/documentation"
      }
    ],
    "keywords": [
      "cisc",
      "risc",
      "cpu",
      "complex",
      "instruction",
      "set",
      "computer",
      "reduced",
      "arm",
      "risc-v",
      "mips",
      "명령어",
      "집합",
      "설계",
      "철학의"
    ]
  },
  {
    "id": "ARCH-008",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "x86과 ARM 아키텍처의 차이점은 무엇인가요?",
    "answer": "x86과 ARM은 각각 대표적인 CISC와 RISC 아키텍처입니다.\n\nx86 (Intel/AMD)\nCISC 기반, 복잡한 명령어 세트\n높은 단일 스레드 성능\n전력 소모가 상대적으로 높음\n데스크톱, 서버 시장 주도\n후방 호환성 중시\n\nARM\nRISC 기반, 단순한 명령어 세트\n전력 효율성이 뛰어남 (와트당 성능 우수)\n모바일, 임베디드 시장 주도\n최근 서버/데스크톱 진출 (Apple M시리즈, AWS Graviton)\n라이선스 모델로 다양한 구현 가능\n\n성능 비교\nx86: 고성능 컴퓨팅, 레거시 애플리케이션\nARM: 모바일, IoT, 전력 효율 중요한 서버",
    "references": [
      {
        "title": "ARM Developer Documentation",
        "url": "https://developer.arm.com/documentation"
      },
      {
        "title": "Intel Architecture Documentation",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "arm",
      "cisc",
      "risc",
      "intel",
      "amd",
      "apple",
      "aws",
      "graviton",
      "iot",
      "각각",
      "대표적인",
      "아키텍처입니다",
      "기반",
      "복잡한",
      "명령어"
    ]
  },
  {
    "id": "ARCH-009",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "메모리 계층 구조(Memory Hierarchy)에 대해 설명해주세요.",
    "answer": "메모리 계층 구조는 속도, 용량, 비용의 트레이드오프를 최적화하기 위한 설계입니다.\n\n계층 구조 (위에서 아래로)\n레지스터: CPU 내부, 가장 빠름, 수십 개\nL1 캐시: 코어당 32-64KB, 1-4 사이클\nL2 캐시: 코어당 256KB-1MB, 10-20 사이클\nL3 캐시: 공유, 수 MB-수십 MB, 30-50 사이클\n메인 메모리 (RAM): GB 단위, 100-300 사이클\n보조 기억장치 (SSD/HDD): TB 단위, 수만-수백만 사이클\n\n설계 원칙\n상위 계층: 빠르지만 작고 비쌈\n하위 계층: 느리지만 크고 저렴\n지역성(locality) 원리를 활용하여 효율적인 데이터 접근",
    "references": [
      {
        "title": "Intel Optimization Manual - Memory Hierarchy",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "cpu",
      "ram",
      "ssd",
      "hdd",
      "메모리",
      "계층",
      "구조는",
      "속도",
      "용량",
      "비용의",
      "트레이드오프를",
      "최적화하기",
      "위한",
      "설계입니다",
      "구조"
    ]
  },
  {
    "id": "ARCH-010",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "레지스터, 캐시, 메인 메모리, 보조 기억장치의 속도와 용량을 비교해주세요.",
    "answer": "구분   용량   접근 시간   대역폭\n\n레지스터   ~1KB   <1ns   -\nL1 캐시   32-64KB   1-2ns   ~1TB/s\nL2 캐시   256KB-1MB   3-10ns   ~500GB/s\nL3 캐시   4-64MB   10-30ns   ~200GB/s\nRAM (DDR5)   16-256GB   50-100ns   ~50GB/s\nNVMe SSD   1-8TB   ~100us   ~7GB/s\nHDD   1-20TB   ~10ms   ~200MB/s\n\n핵심 포인트\n각 계층 간 속도 차이는 약 10배 이상\n레지스터에서 HDD까지 속도 차이는 약 100만 배\n용량은 반대로 상위에서 하위로 갈수록 증가",
    "references": [
      {
        "title": "Intel Memory Latency Checker",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/tool/intelr-memory-latency-checker.html"
      }
    ],
    "keywords": [
      "ram",
      "ddr5",
      "nvme",
      "ssd",
      "hdd",
      "구분",
      "용량",
      "접근",
      "시간",
      "대역폭",
      "레지스터",
      "캐시",
      "핵심",
      "포인트",
      "계층"
    ]
  },
  {
    "id": "ARCH-011",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "캐시 메모리가 왜 필요하고, 어떤 원리로 동작하나요?",
    "answer": "캐시 메모리는 CPU와 메인 메모리 간의 속도 차이를 해소하기 위해 필요합니다.\n\n필요성\nCPU는 매 사이클마다 데이터가 필요하지만, RAM 접근은 100사이클 이상 소요\n속도 격차(Memory Wall) 해소를 위한 중간 버퍼 역할\n자주 사용하는 데이터를 빠르게 접근 가능한 곳에 저장\n\n동작 원리\nCPU가 데이터 요청\n캐시에서 먼저 검색 (캐시 히트 시 바로 반환)\n캐시 미스 시 메인 메모리에서 가져와 캐시에 저장\n캐시 라인 단위(64바이트)로 데이터 이동\n\n효율성의 핵심\n지역성(Locality) 원리 활용\n히트율 90% 이상 달성 시 평균 접근 시간 크게 감소",
    "references": [
      {
        "title": "Intel 64 and IA-32 Architectures Optimization Reference Manual",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "cpu",
      "ram",
      "memory",
      "wall",
      "locality",
      "캐시",
      "메모리는",
      "메인",
      "메모리",
      "간의",
      "속도",
      "차이를",
      "해소하기",
      "필요합니다",
      "필요성"
    ]
  },
  {
    "id": "ARCH-012",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "캐시의 지역성(Locality) 원리에 대해 설명해주세요.",
    "answer": "지역성 원리는 프로그램이 특정 시간에 특정 메모리 영역에 집중적으로 접근하는 경향입니다.\n\n시간 지역성 (Temporal Locality)\n최근 접근한 데이터는 다시 접근할 가능성이 높음\n예: 루프 변수, 자주 호출되는 함수\n\n공간 지역성 (Spatial Locality)\n접근한 데이터 주변의 데이터도 곧 접근할 가능성이 높음\n예: 배열 순차 접근, 구조체 멤버 접근\n\n캐시 설계에의 적용\n시간 지역성: 최근 사용 데이터를 캐시에 유지 (LRU 교체 정책)\n공간 지역성: 캐시 라인 단위(64바이트)로 데이터 로드\n\n프로그래밍 시 활용\n배열을 행 우선 순서로 접근\n관련 데이터를 메모리상 가깝게 배치\n루프 내 데이터 재사용 극대화",
    "references": [
      {
        "title": "Intel Optimization Manual - Data Access Optimization",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "temporal",
      "locality",
      "spatial",
      "lru",
      "지역성",
      "원리는",
      "프로그램이",
      "특정",
      "시간에",
      "메모리",
      "영역에",
      "집중적으로",
      "접근하는",
      "경향입니다",
      "시간"
    ]
  },
  {
    "id": "ARCH-013",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "시간 지역성(Temporal Locality)과 공간 지역성(Spatial Locality)의 차이는 무엇인가요?",
    "answer": "시간 지역성 (Temporal Locality)\n정의: 한 번 접근한 데이터는 가까운 미래에 다시 접근할 가능성이 높음\n예시:\n루프 카운터 변수 i\n자주 호출되는 함수의 코드\n전역 설정 변수\n캐시 활용: 최근 사용 데이터를 캐시에 유지\n\n공간 지역성 (Spatial Locality)\n정의: 접근한 메모리 주소 근처의 데이터도 곧 접근할 가능성이 높음\n예시:\n배열 순차 순회: arr[0], arr[1], arr[2]...\n구조체 멤버 연속 접근\n순차적 명령어 실행\n캐시 활용: 캐시 라인 단위로 인접 데이터 함께 로드\n\n비교\n구분   시간 지역성   공간 지역성\n\n관점   시간적 재사용   공간적 인접성\n캐시 정책   교체 알고리즘 (LRU)   캐시 라인 크기",
    "references": [
      {
        "title": "ARM Cortex-A Programmer's Guide - Cache",
        "url": "https://developer.arm.com/documentation"
      }
    ],
    "keywords": [
      "temporal",
      "locality",
      "spatial",
      "lru",
      "시간",
      "지역성",
      "정의",
      "접근한",
      "데이터는",
      "가까운",
      "미래에",
      "다시",
      "접근할",
      "가능성이",
      "높음"
    ]
  },
  {
    "id": "ARCH-014",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "캐시 라인(Cache Line)이 무엇이고, 크기가 성능에 어떤 영향을 미치나요?",
    "answer": "캐시 라인은 캐시와 메인 메모리 간 데이터 전송의 최소 단위입니다.\n\n캐시 라인 특성\n일반적인 크기: 64바이트 (x86, ARM)\n메모리 주소는 캐시 라인 경계에 정렬\n1바이트만 필요해도 전체 캐시 라인 로드\n\n크기가 성능에 미치는 영향\n\n큰 캐시 라인\n장점: 공간 지역성 활용 극대화, 순차 접근에 유리\n단점: 메모리 대역폭 낭비 (불필요한 데이터 로드), False Sharing 증가\n\n작은 캐시 라인\n장점: 메모리 대역폭 효율적 사용\n단점: 공간 지역성 활용 감소, 태그 오버헤드 증가\n\n프로그래밍 고려사항\n자주 함께 사용하는 데이터는 같은 캐시 라인에 배치\n멀티스레드에서 독립 데이터는 다른 캐시 라인에 배치 (False Sharing 방지)",
    "references": [
      {
        "title": "Intel 64 and IA-32 Architectures Optimization Reference Manual",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "arm",
      "false",
      "sharing",
      "캐시",
      "라인은",
      "캐시와",
      "메인",
      "메모리",
      "데이터",
      "전송의",
      "최소",
      "단위입니다",
      "라인",
      "특성",
      "일반적인"
    ]
  },
  {
    "id": "ARCH-015",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "캐시 히트(Cache Hit)와 캐시 미스(Cache Miss)에 대해 설명해주세요.",
    "answer": "캐시 히트 (Cache Hit)\nCPU가 요청한 데이터가 캐시에 존재하는 경우\n빠른 응답 (L1: 1-4 사이클)\n히트율 = 히트 횟수 / 전체 접근 횟수\n\n캐시 미스 (Cache Miss)\n요청한 데이터가 캐시에 없는 경우\n하위 메모리 계층에서 데이터를 가져와야 함\n성능 저하 원인\n\n캐시 미스의 종류 (3C)\nCompulsory Miss (필수 미스): 최초 접근 시 발생, 피할 수 없음\nCapacity Miss (용량 미스): 캐시 용량 부족으로 발생\nConflict Miss (충돌 미스): 같은 캐시 세트에 매핑되어 발생\n\n평균 메모리 접근 시간",
    "references": [
      {
        "title": "Intel Optimization Manual - Cache Optimization",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "cache",
      "hit",
      "cpu",
      "miss",
      "compulsory",
      "capacity",
      "conflict",
      "캐시",
      "히트",
      "요청한",
      "데이터가",
      "캐시에",
      "존재하는",
      "빠른",
      "응답"
    ]
  },
  {
    "id": "ARCH-016",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "캐시 매핑 방식(Direct Mapped, Fully Associative, Set Associative)의 차이점을 설명해주세요.",
    "answer": "캐시 매핑 방식은 메모리 주소를 캐시 위치에 대응시키는 방법입니다.\n\nDirect Mapped (직접 매핑)\n각 메모리 블록이 하나의 캐시 라인에만 매핑\n장점: 하드웨어 구현 단순, 빠른 검색\n단점: 충돌 미스 빈번 발생\n\nFully Associative (완전 연관)\n메모리 블록이 어떤 캐시 라인에도 저장 가능\n장점: 충돌 미스 최소화\n단점: 모든 라인 검색 필요, 하드웨어 복잡\n\nSet Associative (세트 연관)\nn-way: 캐시를 세트로 나누고, 각 세트 내 n개 라인 중 선택\nDirect Mapped와 Fully Associative의 절충안\n현대 CPU에서 가장 많이 사용 (8-way, 16-way 등)\n\n방식   검색 복잡도   충돌 미스   사용 예\n\nDirect   O(1)   많음   초기 캐시\nFully   O(n)   적음   TLB\nSet Assoc   O(k)   중간   L1, L2, L3",
    "references": [
      {
        "title": "ARM Cache Organization",
        "url": "https://developer.arm.com/documentation"
      }
    ],
    "keywords": [
      "direct",
      "mapped",
      "fully",
      "associative",
      "set",
      "n-way",
      "cpu",
      "tlb",
      "assoc",
      "캐시",
      "매핑",
      "방식은",
      "메모리",
      "주소를",
      "위치에"
    ]
  },
  {
    "id": "ARCH-017",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "캐시 교체 정책(LRU, LFU, FIFO 등)에 대해 설명해주세요.",
    "answer": "캐시가 가득 찼을 때 어떤 데이터를 제거할지 결정하는 정책입니다.\n\nLRU (Least Recently Used)\n가장 오래전에 사용된 데이터를 교체\n시간 지역성 활용에 효과적\n구현 복잡도가 높아 의사 LRU(Pseudo-LRU) 사용\n현대 CPU에서 가장 많이 사용\n\nLFU (Least Frequently Used)\n사용 빈도가 가장 낮은 데이터를 교체\n장기적 패턴 반영\n최근 로드된 데이터가 불리함\n\nFIFO (First In First Out)\n가장 먼저 들어온 데이터를 교체\n구현이 단순\n지역성을 고려하지 않아 성능 낮음\n\nRandom\n무작위로 교체 대상 선택\n구현 매우 단순\n평균적으로 합리적인 성능",
    "references": [
      {
        "title": "Intel Optimization Manual - Cache Replacement",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "lru",
      "least",
      "recently",
      "pseudo-lru",
      "cpu",
      "lfu",
      "frequently",
      "fifo",
      "first",
      "out",
      "random",
      "캐시가",
      "가득",
      "찼을",
      "어떤"
    ]
  },
  {
    "id": "ARCH-018",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "Write-Through와 Write-Back 캐시 쓰기 정책의 차이점은 무엇인가요?",
    "answer": "캐시 쓰기 정책은 데이터 수정 시 메모리 갱신 시점을 결정합니다.\n\nWrite-Through\n캐시와 메모리를 동시에 갱신\n장점: 데이터 일관성 유지 쉬움, 간단한 구현\n단점: 매 쓰기마다 메모리 접근으로 느림\n사용: Write Buffer로 지연 시간 완화\n\nWrite-Back\n캐시만 갱신, 메모리는 나중에 갱신 (캐시 라인 교체 시)\nDirty bit로 수정 여부 표시\n장점: 쓰기 성능 우수, 메모리 대역폭 절약\n단점: 일관성 관리 복잡, 캐시 미스 시 추가 쓰기 필요\n현대 CPU의 대부분 캐시에서 사용\n\nWrite Miss 정책\nWrite-Allocate: 미스 시 캐시 라인 할당 후 쓰기\nNo-Write-Allocate: 미스 시 메모리에 직접 쓰기\n\n일반적 조합: Write-Back + Write-Allocate",
    "references": [
      {
        "title": "ARM Cortex-A Cache Policies",
        "url": "https://developer.arm.com/documentation"
      }
    ],
    "keywords": [
      "write-through",
      "write",
      "buffer",
      "write-back",
      "dirty",
      "cpu",
      "miss",
      "write-allocate",
      "no-write-allocate",
      "캐시",
      "쓰기",
      "정책은",
      "데이터",
      "수정",
      "메모리"
    ]
  },
  {
    "id": "ARCH-019",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "L1, L2, L3 캐시의 차이점과 각각의 역할에 대해 설명해주세요.",
    "answer": "멀티레벨 캐시는 속도와 용량의 균형을 맞추기 위한 계층 구조입니다.\n\nL1 캐시\n가장 빠름 (1-4 사이클)\n코어당 32-64KB\n명령어(I-Cache)와 데이터(D-Cache) 분리\n히트율 최우선, 지연 시간 최소화\n\nL2 캐시\n중간 속도 (10-20 사이클)\n코어당 256KB-1MB\n통합 캐시 (명령어 + 데이터)\nL1 미스 백업\n\nL3 캐시 (LLC: Last Level Cache)\n가장 느리지만 가장 큼 (30-50 사이클)\n전체 코어 공유, 4-64MB\n멀티코어 간 데이터 공유 지원\n메인 메모리 접근 최소화\n\n포함 관계\nInclusive: 상위 캐시가 하위 캐시 내용 포함\nExclusive: 각 레벨에 데이터가 한 번만 존재\nNon-inclusive: 혼합 방식",
    "references": [
      {
        "title": "Intel Cache Architecture",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "i-cache",
      "d-cache",
      "llc",
      "last",
      "level",
      "cache",
      "inclusive",
      "exclusive",
      "non-inclusive",
      "멀티레벨",
      "캐시는",
      "속도와",
      "용량의",
      "균형을",
      "맞추기"
    ]
  },
  {
    "id": "ARCH-020",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "캐시 일관성(Cache Coherence) 문제와 해결 방법에 대해 설명해주세요.",
    "answer": "캐시 일관성은 멀티코어 시스템에서 각 코어의 캐시가 동일한 데이터의 일관된 뷰를 유지하는 것입니다.\n\n문제 상황\n코어 A가 데이터 X를 수정 (A의 캐시에만 반영)\n코어 B가 같은 데이터 X 읽기 시 구버전 데이터 참조\n데이터 불일치로 프로그램 오류 발생\n\n해결 방법: 스누핑 프로토콜\n각 캐시가 버스를 모니터링 (스누핑)\n다른 코어의 메모리 요청 감지 시 자신의 캐시 상태 갱신\n\nMESI 프로토콜\nModified: 수정됨, 유일한 복사본\nExclusive: 배타적, 수정되지 않음\nShared: 공유됨, 여러 캐시에 존재\nInvalid: 무효, 사용 불가\n\n디렉토리 기반 프로토콜\n대규모 시스템에서 사용\n중앙 디렉토리가 캐시 상태 추적\nNUMA 시스템에서 효과적",
    "references": [
      {
        "title": "Intel MESI Protocol",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "mesi",
      "modified",
      "exclusive",
      "shared",
      "invalid",
      "numa",
      "캐시",
      "일관성은",
      "멀티코어",
      "시스템에서",
      "코어의",
      "캐시가",
      "동일한",
      "데이터의",
      "일관된"
    ]
  },
  {
    "id": "ARCH-021",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "가상 메모리(Virtual Memory)가 무엇이고 왜 필요한가요?",
    "answer": "가상 메모리는 물리 메모리를 추상화하여 각 프로세스에 독립적인 주소 공간을 제공하는 기법입니다.\n\n필요성\n메모리 보호: 프로세스 간 메모리 침범 방지\n메모리 확장: 물리 RAM보다 큰 프로그램 실행 가능\n메모리 관리 단순화: 연속적인 가상 주소 공간 제공\n공유 메모리: 같은 물리 페이지를 여러 프로세스가 공유\n\n동작 원리\n프로세스는 가상 주소 사용\nMMU(Memory Management Unit)가 가상 주소를 물리 주소로 변환\n필요한 페이지가 메모리에 없으면 디스크에서 로드 (페이지 폴트)\n\n장점\n프로세스 격리 및 보안 강화\n효율적인 물리 메모리 사용\n프로그래밍 모델 단순화",
    "references": [
      {
        "title": "Intel 64 and IA-32 Architectures - Paging",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "ram",
      "mmu",
      "memory",
      "management",
      "unit",
      "가상",
      "메모리는",
      "물리",
      "메모리를",
      "추상화하여",
      "프로세스에",
      "독립적인",
      "주소",
      "공간을",
      "제공하는"
    ]
  },
  {
    "id": "ARCH-022",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "물리 주소(Physical Address)와 논리 주소(Logical Address)의 차이는 무엇인가요?",
    "answer": "논리 주소 (가상 주소)\n프로세스가 사용하는 주소\n프로세스마다 독립적인 주소 공간 (0부터 시작)\n컴파일/링크 시점에 결정\nCPU가 생성하는 주소\n\n물리 주소\n실제 메모리(RAM)의 위치\n시스템 전체에서 유일\n메모리 버스에서 사용되는 실제 주소\n\n변환 과정\n\n변환 방법\n논리 주소 = 페이지 번호 + 페이지 오프셋\n페이지 테이블에서 페이지 번호로 프레임 번호 조회\n물리 주소 = 프레임 번호 + 페이지 오프셋\n\n장점\n프로세스 격리 (서로의 메모리 접근 불가)\n유연한 메모리 할당\n메모리 보호 구현 가능",
    "references": [
      {
        "title": "ARM Memory Management",
        "url": "https://developer.arm.com/documentation"
      }
    ],
    "keywords": [
      "cpu",
      "ram",
      "논리",
      "주소",
      "가상",
      "프로세스가",
      "사용하는",
      "프로세스마다",
      "독립적인",
      "공간",
      "부터",
      "시작",
      "컴파일",
      "링크",
      "시점에"
    ]
  },
  {
    "id": "ARCH-023",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "페이지 테이블(Page Table)의 역할과 구조에 대해 설명해주세요.",
    "answer": "페이지 테이블은 가상 주소를 물리 주소로 변환하는 매핑 테이블입니다.\n\n역할\n가상 페이지 번호 → 물리 프레임 번호 매핑\n페이지별 접근 권한 관리 (읽기/쓰기/실행)\n페이지 존재 여부 표시 (Present bit)\n\n페이지 테이블 엔트리(PTE) 구조\n프레임 번호 (물리 주소)\nPresent/Valid bit: 메모리에 존재 여부\nDirty bit: 수정 여부\nAccessed bit: 접근 여부 (LRU용)\nPermission bits: R/W/X 권한\n\n계층적 페이지 테이블 (x86-64)\n4단계: PML4 → PDPT → PD → PT\n페이지 크기: 4KB (기본), 2MB, 1GB (Huge Page)\n희소 주소 공간에서 메모리 절약",
    "references": [
      {
        "title": "Intel 64 Page Tables",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "present",
      "pte",
      "valid",
      "dirty",
      "accessed",
      "lru",
      "permission",
      "pml4",
      "pdpt",
      "huge",
      "page",
      "페이지",
      "테이블은",
      "가상",
      "주소를"
    ]
  },
  {
    "id": "ARCH-024",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "TLB(Translation Lookaside Buffer)가 무엇이고 왜 필요한가요?",
    "answer": "TLB는 최근 사용된 페이지 테이블 엔트리를 캐싱하는 하드웨어 캐시입니다.\n\n필요성\n페이지 테이블 조회는 메모리 접근 필요 (4단계 = 4번 접근)\n매 메모리 접근마다 변환 필요 → 심각한 성능 저하\nTLB로 주소 변환을 고속화\n\n특성\nCPU 내부에 위치, 매우 빠른 접근 (1 사이클)\n작은 크기 (64-1024 엔트리)\nFully Associative 또는 고연관도 구조\nITLB(명령어용), DTLB(데이터용) 분리\n\nTLB 미스 처리\n하드웨어가 페이지 테이블 워크 수행\n해당 PTE를 TLB에 로드\n페이지 폴트 시 OS 개입\n\nTLB 플러시\n컨텍스트 스위칭 시 발생 가능\nASID(Address Space ID)로 프로세스 구분하여 플러시 최소화",
    "references": [
      {
        "title": "ARM TLB Architecture",
        "url": "https://developer.arm.com/documentation"
      }
    ],
    "keywords": [
      "tlb",
      "cpu",
      "fully",
      "associative",
      "itlb",
      "dtlb",
      "pte",
      "asid",
      "address",
      "space",
      "최근",
      "사용된",
      "페이지",
      "테이블",
      "엔트리를"
    ]
  },
  {
    "id": "ARCH-025",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "페이지 폴트(Page Fault)가 발생했을 때 처리 과정을 설명해주세요.",
    "answer": "페이지 폴트는 접근하려는 페이지가 물리 메모리에 없을 때 발생하는 예외입니다.\n\n처리 과정\n예외 발생: MMU가 페이지 테이블에서 Present bit = 0 확인\nCPU 상태 저장: 현재 실행 상태를 스택에 저장\nOS 핸들러 호출: 페이지 폴트 핸들러 실행\n주소 유효성 검사: 유효한 접근인지 확인 (아니면 Segmentation Fault)\n페이지 로드: 디스크(스왑)에서 페이지를 메모리로 로드\n프레임 할당: 빈 프레임이 없으면 페이지 교체 수행\n페이지 테이블 갱신: 새 매핑 정보 기록\n명령어 재실행: 폴트 발생 명령어부터 재개\n\n페이지 폴트 종류\nMinor: 페이지가 메모리에 있지만 매핑만 없음 (빠름)\nMajor: 디스크에서 로드 필요 (느림, 수 ms)",
    "references": [
      {
        "title": "Intel Exception Handling - Page Fault",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "mmu",
      "present",
      "cpu",
      "segmentation",
      "fault",
      "minor",
      "major",
      "페이지",
      "폴트는",
      "접근하려는",
      "페이지가",
      "물리",
      "메모리에",
      "없을",
      "발생하는"
    ]
  },
  {
    "id": "ARCH-026",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "메모리 단편화(Fragmentation)의 종류와 해결 방법은 무엇인가요?",
    "answer": "메모리 단편화는 사용 가능한 메모리가 있지만 할당할 수 없는 상태입니다.\n\n외부 단편화 (External Fragmentation)\n할당된 메모리 사이에 작은 빈 공간들이 흩어져 있음\n총 빈 공간은 충분하지만 연속 공간 부족으로 할당 실패\n해결 방법:\n압축(Compaction): 메모리 재배치 (비용 큼)\n페이징: 연속 할당 불필요\n\n내부 단편화 (Internal Fragmentation)\n할당된 메모리 블록 내부의 사용되지 않는 공간\n고정 크기 블록/페이지 할당에서 발생\n해결 방법:\n다양한 크기의 블록 사용\n슬랩 할당자(Slab Allocator) 사용\n객체 풀(Object Pool) 패턴\n\n페이징의 장점\n물리 메모리를 고정 크기 프레임으로 관리\n외부 단편화 완전 해결\n내부 단편화는 마지막 페이지에서만 발생",
    "references": [
      {
        "title": "Linux Memory Management",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/"
      }
    ],
    "keywords": [
      "external",
      "fragmentation",
      "compaction",
      "internal",
      "slab",
      "allocator",
      "object",
      "pool",
      "메모리",
      "단편화는",
      "사용",
      "가능한",
      "메모리가",
      "있지만",
      "할당할"
    ]
  },
  {
    "id": "ARCH-027",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "DMA(Direct Memory Access)가 무엇이고 어떤 장점이 있나요?",
    "answer": "DMA는 CPU 개입 없이 I/O 장치와 메모리 간 직접 데이터 전송을 수행하는 기술입니다.\n\n동작 원리\nCPU가 DMA 컨트롤러에 전송 정보 설정 (소스, 목적지, 크기)\nDMA 컨트롤러가 버스 제어권 획득\n데이터 전송 수행 (CPU 무관)\n전송 완료 시 인터럽트로 CPU에 알림\n\n장점\nCPU 부하 감소: 데이터 전송 중 CPU가 다른 작업 가능\n높은 전송 속도: CPU를 거치지 않아 오버헤드 감소\n효율적 대용량 전송: 디스크, 네트워크 I/O에 필수\n\nDMA 전송 모드\nBurst Mode: 전체 블록을 한 번에 전송\nCycle Stealing: 한 번에 한 워드씩 전송, CPU와 버스 공유\nTransparent: CPU가 버스 미사용 시에만 전송\n\n사용 예\n디스크 I/O, NVMe SSD\n네트워크 카드 (NIC)\nGPU 메모리 전송",
    "references": [
      {
        "title": "Intel DMA Remapping Architecture",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "dma",
      "cpu",
      "burst",
      "mode",
      "cycle",
      "stealing",
      "transparent",
      "nvme",
      "ssd",
      "nic",
      "gpu",
      "개입",
      "없이",
      "장치와",
      "메모리"
    ]
  },
  {
    "id": "ARCH-028",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "메모리 버스(Memory Bus)와 대역폭(Bandwidth)에 대해 설명해주세요.",
    "answer": "메모리 버스\nCPU와 메인 메모리를 연결하는 통신 경로\n주소 버스, 데이터 버스, 제어 버스로 구성\n현대 시스템: 메모리 컨트롤러가 CPU 내장\n\n메모리 대역폭\n단위 시간당 전송 가능한 데이터량 (GB/s)\n계산: 버스 폭 x 클럭 x 채널 수 x 전송률\n\nDDR 메모리 대역폭 예시\nDDR4-3200: 25.6 GB/s (단일 채널)\nDDR5-4800: 38.4 GB/s (단일 채널)\n듀얼 채널 시 2배\n\n대역폭 영향 요소\n버스 폭: 64비트 (채널당)\n클럭 속도: MHz 단위\n채널 수: 듀얼, 쿼드, 옥타 채널\nDDR 배수: DDR = 2배, DDR5 = 추가 버스트\n\n성능 고려사항\n메모리 집약적 작업: 대역폭이 병목\n캐시 효율 높이면 대역폭 의존도 감소\nNUMA에서는 로컬 메모리 접근이 중요",
    "references": [
      {
        "title": "Intel Memory Bandwidth Analysis",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/tool/intelr-memory-latency-checker.html"
      }
    ],
    "keywords": [
      "cpu",
      "ddr",
      "ddr4-3200",
      "ddr5-4800",
      "mhz",
      "ddr5",
      "numa",
      "메모리",
      "버스",
      "메인",
      "메모리를",
      "연결하는",
      "통신",
      "경로",
      "주소"
    ]
  },
  {
    "id": "ARCH-029",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "멀티코어 프로세서가 무엇이고, 싱글코어와 비교했을 때 어떤 장점이 있나요?",
    "answer": "멀티코어 프로세서는 하나의 CPU 칩에 여러 개의 독립적인 처리 코어를 통합한 것입니다.\n\n멀티코어 구조\n각 코어는 독립적인 ALU, 제어 유닛, L1/L2 캐시 보유\nL3 캐시는 코어 간 공유\n메모리 컨트롤러 공유\n\n싱글코어 대비 장점\n병렬 처리: 여러 스레드/프로세스 동시 실행\n전력 효율: 클럭 높이기보다 코어 추가가 효율적\n응답성: 한 코어가 바빠도 다른 코어가 응답 가능\n처리량: 전체 시스템 throughput 증가\n\n한계\n암달의 법칙: 순차 부분이 병렬화 이점 제한\n캐시 일관성 오버헤드\n소프트웨어 병렬화 필요\n\n현대 서버 CPU\nAMD EPYC: 최대 128 코어\nIntel Xeon: 최대 60 코어\nARM Ampere: 최대 128 코어",
    "references": [
      {
        "title": "Intel Multi-Core Architecture",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "cpu",
      "alu",
      "amd",
      "epyc",
      "intel",
      "xeon",
      "arm",
      "ampere",
      "멀티코어",
      "프로세서는",
      "하나의",
      "칩에",
      "여러",
      "개의",
      "독립적인"
    ]
  },
  {
    "id": "ARCH-030",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "하이퍼스레딩(Hyper-Threading)이 무엇인가요?",
    "answer": "하이퍼스레딩(HT)은 Intel의 SMT(Simultaneous Multi-Threading) 구현으로, 하나의 물리 코어가 두 개의 논리 코어처럼 동작하는 기술입니다.\n\n동작 원리\n각 코어에 2세트의 아키텍처 상태(레지스터, PC 등) 유지\n실행 유닛(ALU, FPU 등)은 공유\n한 스레드가 대기 중일 때 다른 스레드가 실행 유닛 활용\n\n장점\n파이프라인 유휴 시간 감소\n캐시 미스, 분기 실패 시 다른 스레드 실행\n추가 실리콘 면적 5% 미만으로 성능 15-30% 향상\n\n단점\n캐시, 대역폭, 실행 유닛 경쟁\n일부 워크로드에서 성능 저하 가능\n보안 취약점 (사이드 채널 공격)\n\n사용 시 고려사항\nCPU 바운드 작업: 효과 제한적\nI/O 바운드, 메모리 바운드: 효과적\n보안 민감 환경에서는 비활성화 고려",
    "references": [
      {
        "title": "Intel Hyper-Threading Technology",
        "url": "https://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html"
      }
    ],
    "keywords": [
      "intel",
      "smt",
      "simultaneous",
      "multi-threading",
      "alu",
      "fpu",
      "cpu",
      "하이퍼스레딩",
      "구현으로",
      "하나의",
      "물리",
      "코어가",
      "개의",
      "논리",
      "코어처럼"
    ]
  },
  {
    "id": "ARCH-031",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "병렬 처리(Parallel Processing)와 동시성(Concurrency)의 차이는 무엇인가요?",
    "answer": "동시성 (Concurrency)\n여러 작업을 번갈아가며 처리하는 논리적 개념\n단일 코어에서도 구현 가능 (시분할)\n작업들이 겹치는 시간대에 진행 중\n예: 싱글 코어에서 멀티태스킹\n\n병렬 처리 (Parallelism)\n여러 작업을 동시에 실행하는 물리적 개념\n멀티코어/멀티프로세서 필요\n실제로 같은 순간에 여러 작업 실행\n예: 4코어 CPU에서 4개 스레드 동시 실행\n\n비유\n동시성: 한 요리사가 여러 요리를 번갈아 조리\n병렬 처리: 여러 요리사가 각자 요리를 동시에 조리\n\n관계\n병렬 처리는 동시성의 부분집합\n동시성 프로그램이 멀티코어에서 병렬 실행될 수 있음\n동시성 = 구조(Structure), 병렬성 = 실행(Execution)",
    "references": [
      {
        "title": "Go Concurrency Patterns",
        "url": "https://go.dev/blog/pipelines"
      }
    ],
    "keywords": [
      "concurrency",
      "parallelism",
      "cpu",
      "structure",
      "execution",
      "동시성",
      "여러",
      "작업을",
      "번갈아가며",
      "처리하는",
      "논리적",
      "개념",
      "단일",
      "코어에서도",
      "구현"
    ]
  },
  {
    "id": "ARCH-032",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "대칭형 멀티프로세싱(SMP)과 비대칭형 멀티프로세싱(AMP)의 차이는 무엇인가요?",
    "answer": "SMP (Symmetric Multi-Processing)\n모든 프로세서가 동등한 역할\n어떤 CPU도 모든 작업 실행 가능\n단일 OS가 모든 CPU 관리\n메모리, I/O 자원 공유\n현대 서버, PC의 표준 방식\n\nAMP (Asymmetric Multi-Processing)\n프로세서마다 다른 역할 할당\n마스터-슬레이브 구조 (마스터가 작업 분배)\n특정 CPU가 특정 작업 전담\n예: 하나는 OS, 다른 하나는 I/O 처리\n\n비교\n특성   SMP   AMP\n\n로드 밸런싱   자동 (OS 스케줄러)   수동 설계 필요\n유연성   높음   낮음\n복잡성   OS 복잡   하드웨어/소프트웨어 단순\n사용 예   범용 서버, PC   임베디드, 실시간 시스템\n\n현대 하이브리드\nbig.LITTLE (ARM): 고성능 + 저전력 코어 조합\nP-core + E-core (Intel): 성능 + 효율 코어 조합",
    "references": [
      {
        "title": "ARM big.LITTLE Technology",
        "url": "https://developer.arm.com/documentation"
      }
    ],
    "keywords": [
      "smp",
      "symmetric",
      "multi-processing",
      "cpu",
      "amp",
      "asymmetric",
      "little",
      "arm",
      "p-core",
      "e-core",
      "intel",
      "모든",
      "프로세서가",
      "동등한",
      "역할"
    ]
  },
  {
    "id": "ARCH-033",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "멀티코어 환경에서 캐시 일관성을 유지하는 프로토콜(MESI, MOESI 등)에 대해 설명해주세요.",
    "answer": "캐시 일관성 프로토콜은 멀티코어 시스템에서 각 캐시의 데이터 일관성을 유지합니다.\n\nMESI 프로토콜 (Intel)\nModified: 수정됨, 유일한 복사본, 메모리와 불일치\nExclusive: 배타적, 유일한 복사본, 메모리와 일치\nShared: 공유됨, 여러 캐시에 존재, 읽기 전용\nInvalid: 무효, 사용 불가\n\n상태 전이 예시\n읽기 미스: Invalid → Shared/Exclusive\n쓰기 미스: Invalid → Modified (다른 캐시 무효화)\n다른 코어 쓰기 감지: Shared → Invalid\n\nMOESI 프로토콜 (AMD)\nMESI + Owned 상태 추가\nOwned: 수정됨, 공유 가능, 메모리 쓰기 책임\n더티 데이터를 캐시 간 직접 전달 가능\n\nMESIF 프로토콜 (Intel QPI)\nMESI + Forward 상태 추가\n공유 데이터 요청에 응답하는 캐시 지정\n다중 응답 방지로 효율성 향상",
    "references": [
      {
        "title": "Intel Cache Coherence",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "mesi",
      "intel",
      "modified",
      "exclusive",
      "shared",
      "invalid",
      "moesi",
      "amd",
      "owned",
      "mesif",
      "qpi",
      "forward",
      "캐시",
      "일관성",
      "프로토콜은"
    ]
  },
  {
    "id": "ARCH-034",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "False Sharing이 무엇이고, 어떻게 성능에 영향을 미치나요?",
    "answer": "False Sharing은 서로 다른 데이터가 같은 캐시 라인에 있어 불필요한 캐시 무효화가 발생하는 현상입니다.\n\n발생 상황\ncounta와 countb가 같은 64바이트 캐시 라인에 위치\n스레드 A가 counta 수정 → 스레드 B의 캐시 라인 무효화\n스레드 B가 countb 수정 → 스레드 A의 캐시 라인 무효화\n실제 공유 데이터가 아닌데 캐시 무효화 발생\n\n성능 영향\n캐시 라인 핑퐁 (코어 간 계속 전송)\n심각한 성능 저하 (10-100배 느려질 수 있음)\n멀티스레드 확장성 저해\n\n해결 방법\n캐시 라인 크기로 패딩 추가 (64바이트)\nalignas(64) 또는 _cachelinealigned 사용\n스레드별 독립 데이터 구조 분리",
    "references": [
      {
        "title": "Intel Avoiding False Sharing",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "false",
      "sharing",
      "서로",
      "다른",
      "데이터가",
      "같은",
      "캐시",
      "라인에",
      "있어",
      "불필요한",
      "무효화가",
      "발생하는",
      "현상입니다",
      "발생",
      "상황"
    ]
  },
  {
    "id": "ARCH-035",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "NUMA(Non-Uniform Memory Access) 아키텍처에 대해 설명해주세요.",
    "answer": "NUMA는 메모리 접근 시간이 메모리 위치에 따라 달라지는 멀티프로세서 아키텍처입니다.\n\n구조\n시스템을 여러 노드로 분할\n각 노드: CPU + 로컬 메모리\n인터커넥트로 노드 간 연결 (QPI, Infinity Fabric)\n\n메모리 접근\n로컬 메모리: 빠름 (같은 노드)\n원격 메모리: 느림 (다른 노드, 1.5-2배 지연)\n\nSMP vs NUMA\nSMP(UMA): 모든 메모리 접근 시간 동일\nNUMA: 메모리 위치에 따라 접근 시간 다름\n\n성능 최적화\n데이터와 처리 스레드를 같은 노드에 배치\nnumactl, libnuma로 메모리 정책 설정\nNUMA-aware 메모리 할당자 사용\n\n사용 환경\n대규모 서버 (2소켓 이상)\n고성능 컴퓨팅\n대용량 메모리 시스템",
    "references": [
      {
        "title": "Intel NUMA Architecture",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "numa",
      "cpu",
      "qpi",
      "infinity",
      "fabric",
      "smp",
      "uma",
      "numa-aware",
      "메모리",
      "접근",
      "시간이",
      "위치에",
      "따라",
      "달라지는",
      "멀티프로세서"
    ]
  },
  {
    "id": "ARCH-036",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "I/O 처리 방식(Programmed I/O, Interrupt-driven I/O, DMA)의 차이점을 설명해주세요.",
    "answer": "Programmed I/O (폴링)\nCPU가 I/O 장치 상태를 계속 확인 (폴링)\nCPU가 직접 데이터 전송\n단점: CPU 시간 낭비, 비효율적\n용도: 단순한 임베디드 시스템\n\nInterrupt-driven I/O\nI/O 장치가 준비되면 인터럽트 발생\nCPU는 인터럽트 발생 전까지 다른 작업 수행\n데이터 전송은 여전히 CPU가 수행\n폴링보다 효율적이지만 대용량에는 부적합\n\nDMA (Direct Memory Access)\nDMA 컨트롤러가 메모리-I/O 장치 간 직접 전송\nCPU는 전송 시작/완료만 관여\n전송 완료 시 인터럽트로 통보\n대용량 데이터 전송에 최적\n\n비교\n방식   CPU 사용률   적합한 용도\n\nProgrammed I/O   매우 높음   간단한 I/O\nInterrupt I/O   중간   소량 데이터\nDMA   낮음   대용량 전송",
    "references": [
      {
        "title": "Intel I/O Architecture",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "programmed",
      "cpu",
      "interrupt-driven",
      "dma",
      "direct",
      "memory",
      "access",
      "interrupt",
      "폴링",
      "장치",
      "상태를",
      "계속",
      "확인",
      "직접",
      "데이터"
    ]
  },
  {
    "id": "ARCH-037",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "인터럽트(Interrupt)의 동작 원리와 종류에 대해 설명해주세요.",
    "answer": "인터럽트는 CPU의 정상 실행 흐름을 중단하고 특정 이벤트를 처리하는 메커니즘입니다.\n\n동작 원리\n인터럽트 발생 (하드웨어/소프트웨어)\n현재 명령어 완료 후 CPU 상태 저장\n인터럽트 벡터 테이블에서 핸들러 주소 조회\n인터럽트 서비스 루틴(ISR) 실행\n저장된 상태 복원 후 원래 작업 재개\n\n종류\n\n하드웨어 인터럽트\n외부 장치가 발생 (키보드, 네트워크, 디스크 등)\n마스커블(Maskable): 비활성화 가능\n논마스커블(NMI): 비활성화 불가 (치명적 오류)\n\n소프트웨어 인터럽트 (트랩)\n프로그램이 의도적으로 발생 (시스템 콜)\n예외(Exception): 오류 상황 (0으로 나누기, 페이지 폴트)\n\n인터럽트 우선순위\nAPIC(Advanced PIC)로 우선순위 관리\n높은 우선순위 인터럽트가 낮은 것을 선점 가능",
    "references": [
      {
        "title": "Intel Interrupt and Exception Handling",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "cpu",
      "isr",
      "maskable",
      "nmi",
      "exception",
      "apic",
      "advanced",
      "pic",
      "인터럽트는",
      "정상",
      "실행",
      "흐름을",
      "중단하고",
      "특정",
      "이벤트를"
    ]
  },
  {
    "id": "ARCH-038",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "폴링(Polling)과 인터럽트 방식의 장단점을 비교해주세요.",
    "answer": "폴링 (Polling)\nCPU가 주기적으로 장치 상태 확인\n\n장점   단점\n\n구현 단순   CPU 시간 낭비\n예측 가능한 지연 시간   이벤트 빈도 낮으면 비효율\n인터럽트 오버헤드 없음   다른 작업 블로킹\n실시간 시스템에 유리   확장성 낮음\n\n인터럽트 (Interrupt)\n장치가 이벤트 발생 시 CPU에 알림\n\n장점   단점\n\nCPU 효율적 사용   컨텍스트 스위칭 오버헤드\n빠른 응답 가능   구현 복잡\n여러 장치 동시 처리   인터럽트 폭주 가능\n확장성 좋음   우선순위 관리 필요\n\n적합한 사용 상황\n폴링: 이벤트 빈번, 짧은 대기, 실시간 제약\n인터럽트: 이벤트 드묾, 긴 대기, 범용 시스템\n\n현대적 접근: 하이브리드\nNAPI (Linux 네트워크): 인터럽트로 시작, 폴링으로 처리",
    "references": [
      {
        "title": "Linux NAPI - Interrupt Coalescing",
        "url": "https://www.kernel.org/doc/html/latest/networking/napi.html"
      }
    ],
    "keywords": [
      "polling",
      "cpu",
      "interrupt",
      "napi",
      "linux",
      "폴링",
      "주기적으로",
      "장치",
      "상태",
      "확인",
      "장점",
      "단점",
      "구현",
      "단순",
      "시간"
    ]
  },
  {
    "id": "ARCH-039",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "I/O 버퍼링(Buffering)이 무엇이고 왜 사용하나요?",
    "answer": "I/O 버퍼링은 데이터 전송 시 중간 저장 공간(버퍼)을 사용하는 기법입니다.\n\n사용 이유\n속도 차이 해소: 빠른 CPU와 느린 I/O 장치 간 속도 차이 완화\n데이터 단위 불일치: 바이트 단위 vs 블록 단위 전송\n프로세스-장치 비동기화: 프로세스가 I/O 완료를 기다리지 않아도 됨\n\n버퍼링 종류\nSingle Buffering: 버퍼 1개, 입출력 중 프로세스 대기\nDouble Buffering: 버퍼 2개, 하나 사용 중 다른 하나 채움\nCircular Buffering: 다중 버퍼를 순환 사용\n\n버퍼링 vs 캐싱\n버퍼링: 데이터 임시 저장, 전송 후 삭제\n캐싱: 재사용을 위해 데이터 유지\n\n예시\n디스크 I/O: 블록 단위로 버퍼링\n네트워크: TCP 소켓 버퍼\n키보드: 라인 버퍼링",
    "references": [
      {
        "title": "Linux Kernel I/O Buffering",
        "url": "https://www.kernel.org/doc/html/latest/"
      }
    ],
    "keywords": [
      "cpu",
      "single",
      "buffering",
      "double",
      "circular",
      "tcp",
      "버퍼링은",
      "데이터",
      "전송",
      "중간",
      "저장",
      "공간",
      "버퍼",
      "사용하는",
      "기법입니다"
    ]
  },
  {
    "id": "ARCH-040",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "메모리 맵 I/O(Memory-Mapped I/O)와 포트 맵 I/O(Port-Mapped I/O)의 차이는 무엇인가요?",
    "answer": "Memory-Mapped I/O (MMIO)\nI/O 장치 레지스터를 메모리 주소 공간에 매핑\n일반 메모리 접근 명령어로 I/O 수행 (MOV, LOAD, STORE)\n장치 접근이 메모리 접근과 동일\n현대 시스템의 주요 방식\n\nPort-Mapped I/O (PMIO)\nI/O 장치를 별도의 I/O 주소 공간에 배치\n전용 명령어 사용 (x86: IN, OUT)\n메모리와 I/O 주소 공간 분리\nx86 레거시 장치에서 사용\n\n비교\n특성   Memory-Mapped   Port-Mapped\n\n주소 공간   메모리와 공유   별도 I/O 공간\n명령어   일반 메모리 명령   전용 I/O 명령\n유연성   높음   낮음\n보호   페이지 단위 보호 가능   권한 레벨만\n캐싱   주의 필요 (비캐시 설정)   캐시 안됨\n\n현대 시스템\n대부분 MMIO 사용 (PCIe, GPU 등)\nPMIO는 레거시 호환 (키보드 컨트롤러 등)",
    "references": [
      {
        "title": "Intel I/O Address Space",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "memory-mapped",
      "mmio",
      "mov",
      "load",
      "store",
      "port-mapped",
      "pmio",
      "out",
      "pcie",
      "gpu",
      "장치",
      "레지스터를",
      "메모리",
      "주소",
      "공간에"
    ]
  },
  {
    "id": "ARCH-041",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "CPU 성능을 측정하는 지표(Clock Speed, IPC, CPI 등)에 대해 설명해주세요.",
    "answer": "Clock Speed (클럭 속도)\nCPU가 1초에 수행하는 사이클 수 (Hz)\n예: 3.5GHz = 초당 35억 사이클\n단독으로는 성능 지표로 부족\n\nIPC (Instructions Per Cycle)\n사이클당 실행하는 명령어 수\n높을수록 효율적인 파이프라인/마이크로아키텍처\n현대 CPU: 2-4 IPC\n\nCPI (Cycles Per Instruction)\n명령어 하나 실행에 필요한 평균 사이클 수\nCPI = 1/IPC\n낮을수록 좋음\n\nCPU 성능 공식\n\n기타 지표\nFLOPS: 초당 부동소수점 연산 수\nMIPS: 초당 백만 명령어 (현재는 비추천)\nThroughput: 단위 시간당 처리량",
    "references": [
      {
        "title": "Intel Performance Monitoring",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "clock",
      "speed",
      "cpu",
      "ipc",
      "instructions",
      "per",
      "cycle",
      "cpi",
      "cycles",
      "instruction",
      "flops",
      "mips",
      "throughput",
      "클럭",
      "속도"
    ]
  },
  {
    "id": "ARCH-042",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "IPC(Instructions Per Cycle)가 무엇이고 왜 중요한가요?",
    "answer": "IPC는 CPU가 한 클럭 사이클에 평균적으로 실행하는 명령어 수입니다.\n\n중요성\n클럭 속도만으로는 실제 성능 판단 불가\n같은 클럭이라도 IPC가 높으면 더 빠름\n아키텍처 효율성의 핵심 지표\n\nIPC에 영향을 미치는 요소\n파이프라인 효율: 해저드, 스톨 최소화\n분기 예측 정확도: 예측 실패 시 IPC 감소\n캐시 히트율: 미스 시 파이프라인 스톨\n명령어 수준 병렬성: 슈퍼스칼라, OoO 실행\n데이터 의존성: 명령어 간 의존성이 적을수록 유리\n\n세대별 IPC 향상\n같은 클럭에서 신세대 CPU가 더 빠른 이유\nIntel 12세대 → 13세대: ~10% IPC 향상\nAMD Zen3 → Zen4: ~13% IPC 향상\n\n측정 방법\n성능 카운터 사용 (perf, VTune)\nIPC = instructions / cycles",
    "references": [
      {
        "title": "Intel VTune Profiler - IPC Analysis",
        "url": "https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html"
      }
    ],
    "keywords": [
      "ipc",
      "cpu",
      "ooo",
      "intel",
      "amd",
      "zen3",
      "zen4",
      "vtune",
      "클럭",
      "사이클에",
      "평균적으로",
      "실행하는",
      "명령어",
      "수입니다",
      "중요성"
    ]
  },
  {
    "id": "ARCH-043",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "Amdahl의 법칙에 대해 설명하고, 병렬화의 한계를 설명해주세요.",
    "answer": "Amdahl의 법칙은 병렬화로 얻을 수 있는 최대 성능 향상의 한계를 설명합니다.\n\n공식\n\n예시\n90% 병렬화 가능한 프로그램\n무한대 프로세서 사용 시: 최대 10배 속도 향상\n10개 프로세서: 5.26배 향상\n100개 프로세서: 9.17배 향상\n\n핵심 통찰\n순차 부분(1-P)이 병렬화 이점 제한\n프로세서 수 증가 효과는 체감\n작은 순차 부분도 큰 영향\n\n병렬화의 실제 한계\n동기화 오버헤드\n통신 비용\n메모리 대역폭 병목\n로드 밸런싱 불균형\n\nGustafson의 법칙\n문제 크기를 키우면 병렬화 이점 증가\n약한 확장성(Weak Scaling) 관점",
    "references": [
      {
        "title": "Computer Architecture: A Quantitative Approach",
        "url": "https://www.elsevier.com/books/computer-architecture/hennessy/978-0-12-811905-1"
      }
    ],
    "keywords": [
      "amdahl",
      "gustafson",
      "weak",
      "scaling",
      "법칙은",
      "병렬화로",
      "얻을",
      "있는",
      "최대",
      "성능",
      "향상의",
      "한계를",
      "설명합니다",
      "공식",
      "예시"
    ]
  },
  {
    "id": "ARCH-044",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "벤치마크(Benchmark)의 종류와 성능 측정 방법에 대해 설명해주세요.",
    "answer": "벤치마크는 시스템 성능을 측정하고 비교하기 위한 표준화된 테스트입니다.\n\n벤치마크 종류\n\n마이크로벤치마크\n특정 컴포넌트 측정 (캐시, 메모리, 분기 예측)\n예: lmbench, cachebench\n\n매크로벤치마크\n실제 애플리케이션 또는 전체 시스템 성능\n예: SPEC CPU, Geekbench\n\n주요 벤치마크\n벤치마크   측정 대상   용도\n\nSPEC CPU   CPU 정수/부동소수점   서버/데스크톱 CPU\nCinebench   멀티스레드 렌더링   콘텐츠 제작\nTPC-C/TPC-H   데이터베이스   OLTP/OLAP\nSPECjbb   Java 비즈니스 로직   엔터프라이즈\nsysbench   DB, CPU, 메모리   범용 서버\n\n성능 측정 방법\n실행 시간 측정\n처리량(Throughput) 측정\n지연 시간(Latency) 측정\n자원 사용률 모니터링\n\n주의사항\n실제 워크로드와 유사한 벤치마크 선택\n여러 번 실행하여 평균/분산 확인\n벤치마크 최적화와 실제 성능은 다를 수 있음",
    "references": [
      {
        "title": "SPEC - Standard Performance Evaluation Corporation",
        "url": "https://www.spec.org/"
      }
    ],
    "keywords": [
      "spec",
      "cpu",
      "geekbench",
      "cinebench",
      "tpc-c",
      "tpc-h",
      "oltp",
      "olap",
      "specjbb",
      "java",
      "throughput",
      "latency",
      "벤치마크는",
      "시스템",
      "성능을"
    ]
  },
  {
    "id": "ARCH-045",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "프로그램 성능 최적화 시 컴퓨터 구조적 관점에서 고려해야 할 사항은 무엇인가요?",
    "answer": "캐시 최적화\n데이터 지역성 극대화 (시간적, 공간적)\n캐시 친화적 데이터 구조 사용\n행 우선 순서로 배열 접근 (C/C++)\n캐시 라인 크기 고려 (64바이트)\n\n메모리 접근 최적화\n메모리 정렬 (alignment)\n프리페칭 활용\nFalse Sharing 방지\nNUMA 지역성 고려\n\n분기 최적화\n분기 예측 친화적 코드 작성\n분기 없는 코드 (branchless) 고려\n루프 언롤링\n\n명령어 수준 병렬성\n데이터 의존성 최소화\nSIMD 명령어 활용 (SSE, AVX)\n루프 벡터화\n\n병렬 처리 최적화\n적절한 스레드 수 선택\n동기화 오버헤드 최소화\n로드 밸런싱\n\n측정 도구 활용\n프로파일러 (perf, VTune, Instruments)\n성능 카운터 분석\n병목 지점 식별",
    "references": [
      {
        "title": "Intel Optimization Reference Manual",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "false",
      "sharing",
      "numa",
      "simd",
      "sse",
      "avx",
      "vtune",
      "instruments",
      "캐시",
      "최적화",
      "데이터",
      "지역성",
      "극대화",
      "시간적",
      "공간적"
    ]
  },
  {
    "id": "ARCH-046",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "백엔드 서버에서 CPU 캐시를 효율적으로 활용하는 방법은 무엇인가요?",
    "answer": "데이터 구조 최적화\n자주 접근하는 데이터를 연속 메모리에 배치\n객체 크기를 캐시 라인(64바이트)에 맞춤\n핫 데이터와 콜드 데이터 분리\n\n메모리 접근 패턴\n순차 접근 선호 (배열 > 연결 리스트)\n포인터 체이싱 최소화\n데이터 지역성 고려한 알고리즘 선택\n\n객체 풀링\n자주 생성/삭제되는 객체 재사용\n메모리 단편화 방지\n캐시 워밍 효과\n\n멀티스레드 고려\n스레드별 데이터 분리 (False Sharing 방지)\n읽기 전용 데이터는 공유 가능\nNUMA 인지 메모리 할당\n\n실용적 예시",
    "references": [
      {
        "title": "Intel Developer Guide - Cache Optimization",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "false",
      "sharing",
      "numa",
      "데이터",
      "구조",
      "최적화",
      "자주",
      "접근하는",
      "데이터를",
      "연속",
      "메모리에",
      "배치",
      "객체",
      "크기를",
      "캐시"
    ]
  },
  {
    "id": "ARCH-047",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "데이터베이스 쿼리 성능에 CPU 캐시가 미치는 영향에 대해 설명해주세요.",
    "answer": "캐시가 중요한 이유\n데이터베이스는 대량의 데이터를 메모리에서 처리\n캐시 효율이 쿼리 처리 속도에 직접 영향\n인덱스 검색, 조인, 정렬 모두 캐시 의존적\n\n캐시 영향 사례\n\n인덱스 스캔\nB+ 트리 노드가 캐시 라인에 맞으면 효율적\n클러스터드 인덱스: 관련 데이터가 물리적으로 인접\n\n해시 조인\n해시 테이블 크기가 캐시에 맞으면 빠름\n캐시 초과 시 성능 급격히 저하\n\n컬럼 지향 저장\n필요한 컬럼만 캐시에 로드\n분석 쿼리(OLAP)에 유리\n압축으로 캐시 효율 향상\n\n최적화 기법\n워킹 셋을 캐시 크기 내로 유지\n인덱스 구조 최적화 (노드 크기)\n버퍼 풀 프리페칭\nSIMD 활용한 벡터화 처리",
    "references": [
      {
        "title": "MySQL Performance Schema",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/performance-schema.html"
      }
    ],
    "keywords": [
      "olap",
      "simd",
      "캐시가",
      "중요한",
      "이유",
      "데이터베이스는",
      "대량의",
      "데이터를",
      "메모리에서",
      "처리",
      "캐시",
      "효율이",
      "쿼리",
      "속도에",
      "직접"
    ]
  },
  {
    "id": "ARCH-048",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "멀티스레드 환경에서 False Sharing을 방지하는 방법은 무엇인가요?",
    "answer": "패딩을 사용한 분리\n\n스레드 로컬 데이터 사용\n각 스레드가 독립적인 데이터 유지\n주기적으로 결과 병합\n\n데이터 구조 재설계\n핫 데이터와 콜드 데이터 분리\n스레드별로 다른 배열 인덱스 사용\n\n실용적 패턴\n\n프레임워크 지원\nJDK @Contended 어노테이션\nC++ alignas() 키워드\nGo 구조체 필드 정렬",
    "references": [
      {
        "title": "Intel Threading Building Blocks Guide",
        "url": "https://www.intel.com/content/www/us/en/developer/tools/oneapi/onetbb.html"
      }
    ],
    "keywords": [
      "jdk",
      "contended",
      "패딩을",
      "사용한",
      "분리",
      "스레드",
      "로컬",
      "데이터",
      "사용",
      "스레드가",
      "독립적인",
      "유지",
      "주기적으로",
      "결과",
      "병합"
    ]
  },
  {
    "id": "ARCH-049",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "메모리 정렬(Memory Alignment)이 성능에 미치는 영향을 설명해주세요.",
    "answer": "메모리 정렬이란\n데이터를 특정 바이트 경계에 배치하는 것\nN바이트 데이터는 N의 배수 주소에 배치\n예: 8바이트 double은 8의 배수 주소\n\n성능 영향\n\n정렬된 접근\n단일 메모리 접근으로 데이터 로드\n캐시 라인 효율적 사용\nSIMD 명령어 최적 활용\n\n비정렬 접근\n두 번의 메모리 접근 필요할 수 있음\n일부 아키텍처에서 예외 발생 (ARM)\nx86에서는 성능 저하 (2-3배 느림)\n\n자동 패딩\n\n최적화 방법\n크기가 큰 멤버부터 선언\n#pragma pack 사용 시 주의 (성능 저하)\n캐시 라인 정렬: alignas(64)\n\nSIMD 정렬 요구사항\nSSE: 16바이트 정렬\nAVX: 32바이트 정렬\nAVX-512: 64바이트 정렬",
    "references": [
      {
        "title": "Intel Data Alignment Guide",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "simd",
      "arm",
      "sse",
      "avx",
      "avx-512",
      "메모리",
      "정렬이란",
      "데이터를",
      "특정",
      "바이트",
      "경계에",
      "배치하는",
      "데이터는",
      "배수",
      "주소에"
    ]
  },
  {
    "id": "ARCH-050",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "NUMA 시스템에서 백엔드 애플리케이션 성능을 최적화하는 방법은 무엇인가요?",
    "answer": "NUMA 인지 메모리 할당\n스레드가 사용할 데이터를 로컬 노드에 할당\nLinux: numactl, libnuma 활용\nJVM: -XX:+UseNUMA 옵션\n\n프로세스/스레드 배치\n\n스레드 풀 설계\nNUMA 노드별로 스레드 풀 분리\n워커 스레드를 특정 코어에 바인딩\n노드 간 작업 이동 최소화\n\n데이터 구조 파티셔닝\n대용량 데이터를 노드별로 분할\n각 파티션을 해당 노드 스레드가 처리\n\n데이터베이스 최적화\n버퍼 풀을 NUMA 인지하도록 설정\n연결당 전용 스레드를 같은 노드에 유지\n쿼리 실행 시 데이터 로컬리티 고려\n\n모니터링",
    "references": [
      {
        "title": "Linux NUMA Documentation",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/numa_memory_policy.html"
      }
    ],
    "keywords": [
      "numa",
      "linux",
      "jvm",
      "usenuma",
      "인지",
      "메모리",
      "할당",
      "스레드가",
      "사용할",
      "데이터를",
      "로컬",
      "노드에",
      "활용",
      "옵션",
      "프로세스"
    ]
  },
  {
    "id": "ARCH-051",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "큰 데이터를 처리할 때 메모리 계층을 고려한 최적화 전략은 무엇인가요?",
    "answer": "블록 단위 처리 (Blocking/Tiling)\n데이터를 캐시 크기에 맞는 블록으로 분할\n각 블록을 완전히 처리 후 다음 블록\n캐시 재사용 극대화\n\n스트리밍 처리\n데이터를 한 번만 순차적으로 읽음\n프리페칭 효과 극대화\nNon-temporal 저장으로 캐시 오염 방지\n\n데이터 압축\n캐시에 더 많은 데이터 적재\n압축/해제 비용 vs 메모리 접근 비용 트레이드오프\n\n외부 정렬/병합\n메모리보다 큰 데이터 처리\n디스크 I/O 최소화하는 다단계 병합\n\n컬럼 지향 처리\n필요한 컬럼만 메모리에 로드\n벡터화 처리 용이\n분석 워크로드에 효과적\n\n메모리 맵 파일\n대용량 파일을 가상 메모리에 매핑\nOS의 페이지 캐시 활용",
    "references": [
      {
        "title": "Intel Memory Optimization Guide",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "blocking",
      "tiling",
      "non-temporal",
      "블록",
      "단위",
      "처리",
      "데이터를",
      "캐시",
      "크기에",
      "맞는",
      "블록으로",
      "분할",
      "블록을",
      "완전히",
      "다음"
    ]
  },
  {
    "id": "ARCH-052",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "CPU 바운드(CPU-bound) 작업과 I/O 바운드(I/O-bound) 작업의 차이와 최적화 방법은 무엇인가요?",
    "answer": "CPU 바운드 작업\nCPU 연산이 병목\n예: 암호화, 압축, 과학 계산, 이미지 처리\n\n최적화 방법\n코어 수만큼 스레드 사용\nSIMD 명령어 활용 (SSE, AVX)\n알고리즘 최적화\n캐시 효율 개선\n비동기 I/O로 CPU 유휴 방지\n\nI/O 바운드 작업\nI/O 대기가 병목 (디스크, 네트워크, DB)\n예: 웹 서버, 파일 처리, API 호출\n\n최적화 방법\n비동기 I/O (async/await, NIO)\n이벤트 기반 아키텍처 (epoll, kqueue)\n코어 수보다 많은 스레드/코루틴 사용\nI/O 멀티플렉싱\n캐싱으로 I/O 횟수 감소\n\n스레드 풀 크기\n작업 유형   스레드 수\n\nCPU 바운드   CPU 코어 수\nI/O 바운드   코어 수 x (1 + 대기시간/처리시간)\n\n혼합 워크로드\nCPU 작업과 I/O 작업 분리\n각각 적절한 스레드 풀 사용",
    "references": [
      {
        "title": "Java Concurrency in Practice",
        "url": "https://jcip.net/"
      }
    ],
    "keywords": [
      "cpu",
      "simd",
      "sse",
      "avx",
      "api",
      "nio",
      "바운드",
      "작업",
      "연산이",
      "병목",
      "암호화",
      "압축",
      "과학",
      "계산",
      "이미지"
    ]
  },
  {
    "id": "ARCH-053",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "백엔드 시스템에서 메모리 대역폭이 성능에 미치는 영향은 무엇인가요?",
    "answer": "메모리 대역폭 병목 상황\n대용량 데이터 처리 (분석, 집계)\n캐시 미스 빈번한 워크로드\n다수 코어가 동시에 메모리 접근\n스트리밍 데이터 처리\n\n영향\nCPU가 데이터 대기로 유휴 상태\n코어 수 증가해도 성능 향상 제한\n메모리 집약적 쿼리 처리 지연\n\n대역폭 계산\n\n최적화 방법\n\n데이터 크기 감소\n압축 활용\n적절한 데이터 타입 선택 (int vs long)\n컬럼 지향 저장\n\n메모리 채널 활용\n듀얼/쿼드 채널 메모리 구성\nNUMA에서 대역폭 분산\n\n캐시 효율 향상\n블로킹 기법으로 캐시 재사용\n프리페칭 활용\n비순차 접근 최소화\n\nNon-Temporal 접근\n재사용 없는 데이터는 캐시 우회\nmmstream_si128 등 사용",
    "references": [
      {
        "title": "Intel Memory Bandwidth Analysis",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/tool/intelr-memory-latency-checker.html"
      }
    ],
    "keywords": [
      "cpu",
      "numa",
      "non-temporal",
      "메모리",
      "대역폭",
      "병목",
      "상황",
      "대용량",
      "데이터",
      "처리",
      "분석",
      "집계",
      "캐시",
      "미스",
      "빈번한"
    ]
  },
  {
    "id": "ARCH-054",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "컨텍스트 스위칭 비용을 줄이기 위한 하드웨어적/소프트웨어적 방법은 무엇인가요?",
    "answer": "하드웨어적 방법\n\n레지스터 세트 복제\n하이퍼스레딩: 스레드별 아키텍처 상태 유지\n빠른 컨텍스트 전환\n\nTLB 최적화\nASID/PCID: 프로세스별 TLB 엔트리 구분\n컨텍스트 스위칭 시 TLB 플러시 회피\n\n캐시 유지\n스위칭 후에도 캐시 데이터 유효\n웜 캐시로 빠른 재개\n\n소프트웨어적 방법\n\n경량 스레드/코루틴\n유저 공간에서 스위칭 (syscall 없음)\nGo 고루틴, Kotlin 코루틴, Java 가상 스레드\n\n스레드 수 최적화\nCPU 코어 수에 맞게 스레드 제한\n불필요한 스위칭 감소\n\nCPU 어피니티\n스레드를 특정 코어에 바인딩\n캐시 친화성 유지\n\n배치 처리\n작은 작업들을 모아서 처리\n스위칭 빈도 감소\n\nLock-free 자료구조\n블로킹 최소화\n스레드가 대기 없이 진행",
    "references": [
      {
        "title": "Linux Context Switching",
        "url": "https://www.kernel.org/doc/html/latest/scheduler/"
      }
    ],
    "keywords": [
      "tlb",
      "asid",
      "pcid",
      "kotlin",
      "java",
      "cpu",
      "lock-free",
      "하드웨어적",
      "방법",
      "레지스터",
      "세트",
      "복제",
      "하이퍼스레딩",
      "스레드별",
      "아키텍처"
    ]
  },
  {
    "id": "ARCH-055",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "서버 하드웨어 선택 시 컴퓨터 구조 관점에서 고려해야 할 사항은 무엇인가요?",
    "answer": "CPU 선택\n코어 수 vs 클럭: 워크로드 특성에 따라 결정\n병렬화 용이: 많은 코어\n순차적 처리: 높은 클럭\n캐시 크기: L3 캐시가 워킹 셋 수용 가능한지\n메모리 채널 수: 메모리 대역폭 요구사항\n\n메모리 구성\n용량: 워킹 셋 + 버퍼/캐시 충분히\n대역폭: 채널 수, DDR 세대\nNUMA 구성: 대규모 시스템에서 중요\n\n스토리지\nNVMe SSD: 고성능 I/O 필요시\nIOPS vs 처리량: 워크로드 패턴에 따라\n캐시 계층: 핫 데이터용 빠른 스토리지\n\n네트워크\n대역폭: 10G, 25G, 100G\n지연 시간: RDMA, 커널 바이패스\n\n아키텍처 선택\nx86: 범용, 소프트웨어 호환성\nARM: 전력 효율, 코어 수 우위\n전용 가속기: GPU, TPU, FPGA\n\n확장성 고려\n수직 확장 여유 (슬롯, 전원)\n수평 확장 용이성",
    "references": [
      {
        "title": "Intel Server Platform Guide",
        "url": "https://www.intel.com/content/www/us/en/products/details/servers.html"
      }
    ],
    "keywords": [
      "cpu",
      "ddr",
      "numa",
      "nvme",
      "ssd",
      "iops",
      "rdma",
      "arm",
      "gpu",
      "tpu",
      "fpga",
      "선택",
      "코어",
      "클럭",
      "워크로드"
    ]
  },
  {
    "id": "ARCH-056",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "최근 서버용 CPU의 발전 트렌드(코어 수 증가, 특수 명령어 등)에 대해 설명해주세요.",
    "answer": "코어 수 증가\nAMD EPYC: 96-128 코어\nIntel Xeon: 60 코어\nAmpere Altra: 128 코어\n칩렛 아키텍처로 확장 용이\n\n메모리 대역폭 향상\nDDR5 지원 (대역폭 2배)\n메모리 채널 수 증가 (12채널)\nCXL(Compute Express Link) 도입\n\n특수 명령어 및 가속기\nAVX-512: 벡터 처리 성능 향상\nAMX (Intel): 행렬 연산 가속\n암호화 가속 (AES-NI, SHA-NI)\nAI 추론 가속\n\n전력 효율\n칩렛 + 고급 공정 (5nm, 3nm)\n다이나믹 전력 관리\nARM 서버 CPU 성장\n\n보안 기능\n메모리 암호화 (TME, SME)\n신뢰 실행 환경 (SGX, SEV)\n사이드 채널 공격 완화\n\nI/O 발전\nPCIe 5.0 (64 GT/s)\nCXL 메모리 확장\n고속 네트워크 통합",
    "references": [
      {
        "title": "AMD EPYC Processors",
        "url": "https://www.amd.com/en/processors/epyc-server-cpu-family"
      },
      {
        "title": "Intel Xeon Scalable",
        "url": "https://www.intel.com/content/www/us/en/products/details/processors/xeon.html"
      }
    ],
    "keywords": [
      "amd",
      "epyc",
      "intel",
      "xeon",
      "ampere",
      "altra",
      "ddr5",
      "cxl",
      "compute",
      "express",
      "link",
      "avx-512",
      "amx",
      "aes-ni",
      "sha-ni"
    ]
  },
  {
    "id": "ARCH-057",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "AVX(Advanced Vector Extensions) 명령어가 무엇이고, 어떤 작업에 유용한가요?",
    "answer": "AVX란\nIntel/AMD의 SIMD 확장 명령어 세트\n하나의 명령어로 여러 데이터 동시 처리\nSSE(128비트) → AVX(256비트) → AVX-512(512비트)\n\nAVX 버전별 특징\n버전   레지스터 크기   동시 처리\n\nAVX   256비트   8 x float, 4 x double\nAVX2   256비트   정수 연산 강화\nAVX-512   512비트   16 x float, 8 x double\n\n유용한 작업\n과학 계산: 행렬 연산, 시뮬레이션\n미디어 처리: 이미지/비디오 인코딩\n머신러닝: 신경망 추론\n암호화: 대량 데이터 암/복호화\n데이터베이스: 벡터화된 쿼리 처리\n\n사용 방법\n\n주의사항\nAVX-512는 클럭 다운 발생 가능\n전력 소모 증가\n모든 CPU 지원하지 않음",
    "references": [
      {
        "title": "Intel Intrinsics Guide",
        "url": "https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html"
      }
    ],
    "keywords": [
      "avx",
      "intel",
      "amd",
      "simd",
      "sse",
      "avx-512",
      "avx2",
      "cpu",
      "확장",
      "명령어",
      "세트",
      "하나의",
      "명령어로",
      "여러",
      "데이터"
    ]
  },
  {
    "id": "ARCH-058",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "ARM 서버 CPU(예: AWS Graviton)가 x86 대비 어떤 장점이 있나요?",
    "answer": "전력 효율\n와트당 성능 우수 (최대 40% 향상)\n발열 감소로 냉각 비용 절감\nTCO(총소유비용) 절감\n\n비용 효율\nAWS Graviton3: x86 대비 40% 가격 우위\n동일 예산으로 더 많은 컴퓨팅 가능\n\n코어 밀도\nGraviton3: 64 코어\nAmpere Altra: 128 코어\n병렬 워크로드에 유리\n\n커스텀 설계\n클라우드 워크로드에 최적화\n불필요한 레거시 기능 제거\nDDR5, PCIe 5.0 조기 도입\n\n적합한 워크로드\n웹 서버, API 서버\n컨테이너, 마이크로서비스\n데이터베이스 (읽기 중심)\n빌드/CI 파이프라인\n\n고려사항\nx86 전용 소프트웨어 호환성\n일부 라이브러리 ARM 미지원\nJIT 컴파일 언어는 대체로 호환",
    "references": [
      {
        "title": "AWS Graviton Processors",
        "url": "https://aws.amazon.com/ec2/graviton/"
      },
      {
        "title": "Ampere Computing",
        "url": "https://amperecomputing.com/"
      }
    ],
    "keywords": [
      "tco",
      "aws",
      "graviton3",
      "ampere",
      "altra",
      "ddr5",
      "pcie",
      "api",
      "arm",
      "jit",
      "전력",
      "효율",
      "와트당",
      "성능",
      "우수"
    ]
  },
  {
    "id": "ARCH-059",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "SIMD(Single Instruction Multiple Data)가 무엇이고 어떻게 활용할 수 있나요?",
    "answer": "SIMD란\n하나의 명령어로 여러 데이터를 동시에 처리\n데이터 수준 병렬성 활용\nFlynn의 분류 중 하나\n\n동작 원리\n\n활용 방법\n컴파일러 자동 벡터화\nIntrinsic 함수\n라이브러리 활용\nIntel MKL, OpenBLAS\nnumpy, TensorFlow 내부적으로 사용\n\n적합한 작업\n배열 연산, 행렬 계산\n이미지/신호 처리\n암호화/해싱\n문자열 검색\n\n최적화 팁\n메모리 정렬 (16/32/64바이트)\n루프 언롤링\n데이터 레이아웃 최적화 (SoA vs AoS)",
    "references": [
      {
        "title": "Intel SIMD Programming Guide",
        "url": "https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html"
      }
    ],
    "keywords": [
      "simd",
      "flynn",
      "intrinsic",
      "intel",
      "mkl",
      "openblas",
      "tensorflow",
      "soa",
      "aos",
      "하나의",
      "명령어로",
      "여러",
      "데이터를",
      "동시에",
      "처리"
    ]
  },
  {
    "id": "ARCH-060",
    "category": "architecture",
    "categoryName": "아키텍처",
    "priority": "P1",
    "question": "컴퓨터 구조 관점에서 클라우드 인프라의 특징과 고려사항은 무엇인가요?",
    "answer": "가상화 오버헤드\n하이퍼바이저 계층 추가\nVM exit/enter 비용\n해결: 하드웨어 가상화(VT-x, VT-d), SR-IOV\n\n공유 자원 경쟁\n멀티테넌트 환경에서 CPU, 캐시, 메모리 대역폭 공유\n노이지 네이버(Noisy Neighbor) 문제\n해결: 전용 인스턴스, CPU 크레딧 제한\n\nNUMA 인지 필요성\n대형 VM은 여러 NUMA 노드 걸칠 수 있음\n메모리 지역성 고려한 배치 필요\n클라우드 제공자의 NUMA 정책 이해\n\n네트워크 성능\n물리 네트워크 공유로 지연 변동\nSR-IOV, DPDK로 커널 바이패스\n배치 그룹으로 인접 배치\n\n스토리지 특성\n네트워크 스토리지 지연 (EBS, Persistent Disk)\n로컬 NVMe는 휘발성\n캐시 계층화 전략\n\n비용 최적화\n적절한 인스턴스 타입 선택\nARM 인스턴스 활용 (Graviton)\n스팟 인스턴스로 비용 절감",
    "references": [
      {
        "title": "AWS EC2 Instance Types",
        "url": "https://aws.amazon.com/ec2/instance-types/"
      },
      {
        "title": "Google Cloud Machine Types",
        "url": "https://cloud.google.com/compute/docs/machine-types"
      }
    ],
    "keywords": [
      "vt-x",
      "vt-d",
      "sr-iov",
      "cpu",
      "noisy",
      "neighbor",
      "numa",
      "dpdk",
      "ebs",
      "persistent",
      "disk",
      "nvme",
      "arm",
      "graviton",
      "가상화"
    ]
  },
  {
    "id": "DB-001",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "Key (기본키, 후보키, 슈퍼키 등등...) 에 대해 설명해 주세요.",
    "answer": "슈퍼키(Super Key): 튜플을 유일하게 식별할 수 있는 속성들의 집합입니다.\n\n후보키(Candidate Key): 슈퍼키 중 최소성을 만족하는 키입니다.\n\n기본키(Primary Key): 후보키 중 선택된 대표 키로, NULL을 허용하지 않습니다.\n\n대체키(Alternate Key): 기본키로 선택되지 않은 후보키입니다.\n\n외래키(Foreign Key): 다른 테이블의 기본키를 참조하는 속성입니다.",
    "references": [
      {
        "title": "MySQL PRIMARY KEY",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/constraint-primary-key.html"
      }
    ],
    "keywords": [
      "super",
      "key",
      "candidate",
      "primary",
      "null",
      "alternate",
      "foreign",
      "슈퍼키",
      "튜플을",
      "유일하게",
      "식별할",
      "있는",
      "속성들의",
      "집합입니다",
      "후보키"
    ]
  },
  {
    "id": "DB-002",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "기본키는 수정이 가능한가요?",
    "answer": "기술적으로 기본키 수정은 가능합니다. 그러나 권장되지 않습니다.\n\n문제점:\n외래키로 참조하는 모든 테이블의 데이터도 함께 수정 필요\nCASCADE 설정 시 연쇄 업데이트 발생으로 성능 저하\n인덱스 재구성 비용 발생\n\n대안: Surrogate Key(대리키)를 사용하여 자연키 변경에 영향받지 않게 설계합니다.",
    "references": [
      {
        "title": "MySQL Foreign Key Constraints",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/create-table-foreign-keys.html"
      }
    ],
    "keywords": [
      "cascade",
      "surrogate",
      "key",
      "기술적으로",
      "기본키",
      "수정은",
      "가능합니다",
      "그러나",
      "권장되지",
      "않습니다",
      "문제점",
      "외래키로",
      "참조하는",
      "모든",
      "테이블의"
    ]
  },
  {
    "id": "DB-003",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "사실 MySQL의 경우, 기본키를 설정하지 않아도 테이블이 만들어집니다. 어떻게 이게 가능한 걸까요?",
    "answer": "InnoDB는 기본키가 없으면 내부적으로 GENCLUSTINDEX라는 숨겨진 클러스터드 인덱스를 생성합니다.\n\n6바이트 크기의 Row ID를 자동 생성하여 각 행을 식별합니다. 하지만 이 값은 사용자가 접근할 수 없어 쿼리 최적화에 활용할 수 없습니다.\n\n권장사항: 명시적으로 기본키를 설정하는 것이 성능과 관리 측면에서 좋습니다.",
    "references": [
      {
        "title": "InnoDB Clustered Index",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-index-types.html"
      }
    ],
    "keywords": [
      "innodb",
      "genclustindex",
      "row",
      "기본키가",
      "없으면",
      "내부적으로",
      "라는",
      "숨겨진",
      "클러스터드",
      "인덱스를",
      "생성합니다",
      "바이트",
      "크기의",
      "자동",
      "생성하여"
    ]
  },
  {
    "id": "DB-004",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "외래키 값은 NULL이 들어올 수 있나요?",
    "answer": "네, 가능합니다. 외래키 컬럼에 NOT NULL 제약이 없다면 NULL 값을 가질 수 있습니다.\n\n이는 선택적 관계(Optional Relationship)를 표현할 때 유용합니다. 예를 들어, 직원 테이블에서 부서가 아직 배정되지 않은 경우 부서_id가 NULL일 수 있습니다.",
    "references": [
      {
        "title": "MySQL Foreign Keys",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/create-table-foreign-keys.html"
      }
    ],
    "keywords": [
      "null",
      "optional",
      "relationship",
      "가능합니다",
      "외래키",
      "컬럼에",
      "제약이",
      "없다면",
      "값을",
      "가질",
      "이는",
      "선택적",
      "관계",
      "표현할",
      "유용합니다"
    ]
  },
  {
    "id": "DB-005",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "어떤 칼럼의 정의에 UNIQUE 키워드가 붙는다고 가정해 봅시다. 이 칼럼을 활용한 쿼리의 성능은 그렇지 않은 것과 비교해서 어떻게 다를까요?",
    "answer": "UNIQUE 제약조건이 설정되면 해당 컬럼에 자동으로 인덱스가 생성됩니다.\n\n성능 향상:\nWHERE 절에서 해당 컬럼 조회 시 인덱스 스캔 가능\n정렬 연산 시 인덱스 활용 가능\n\n추가 비용:\nINSERT/UPDATE 시 중복 체크를 위한 인덱스 검색 발생\n인덱스 유지 비용 증가",
    "references": [
      {
        "title": "MySQL UNIQUE Constraints",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/constraint-unique.html"
      }
    ],
    "keywords": [
      "unique",
      "where",
      "insert",
      "update",
      "제약조건이",
      "설정되면",
      "해당",
      "컬럼에",
      "자동으로",
      "인덱스가",
      "생성됩니다",
      "성능",
      "향상",
      "절에서",
      "컬럼"
    ]
  },
  {
    "id": "DB-006",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "RDB와 NoSQL의 차이에 대해 설명해 주세요.",
    "answer": "구분   RDB   NoSQL\n\n스키마   고정 스키마   유연한 스키마\n확장   수직 확장(Scale-up)   수평 확장(Scale-out)\n트랜잭션   ACID 보장   BASE 특성 (일부 ACID 지원)\n관계   JOIN으로 테이블 연결   비정규화/임베딩\n사용 사례   복잡한 쿼리, 정합성 중요   대용량, 유연한 데이터",
    "references": [
      {
        "title": "MongoDB vs RDBMS",
        "url": "https://www.mongodb.com/docs/manual/reference/sql-comparison/"
      }
    ],
    "keywords": [
      "rdb",
      "nosql",
      "scale-up",
      "scale-out",
      "acid",
      "base",
      "join",
      "구분",
      "스키마",
      "고정",
      "유연한",
      "확장",
      "수직",
      "수평",
      "트랜잭션"
    ]
  },
  {
    "id": "DB-007",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "NoSQL의 강점과, 약점이 무엇인가요?",
    "answer": "강점:\n수평 확장(Sharding)이 용이\n유연한 스키마로 빠른 개발\n대용량 데이터 처리에 적합\n다양한 데이터 모델 지원 (Document, Key-Value, Graph 등)\n\n약점:\n복잡한 JOIN 연산 어려움\nACID 트랜잭션 지원 제한적\n데이터 일관성 보장이 어려울 수 있음\n표준화된 쿼리 언어 부재",
    "references": [
      {
        "title": "MongoDB Data Modeling",
        "url": "https://www.mongodb.com/docs/manual/core/data-modeling-introduction/"
      }
    ],
    "keywords": [
      "sharding",
      "document",
      "key-value",
      "graph",
      "join",
      "acid",
      "강점",
      "수평",
      "확장",
      "용이",
      "유연한",
      "스키마로",
      "빠른",
      "개발",
      "대용량"
    ]
  },
  {
    "id": "DB-008",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "RDB의 어떠한 특징 때문에 NoSQL에 비해 부하가 많이 걸릴 \"수\" 있을까요? (주의: 무조건 NoSQL이 RDB 보다 빠르다라고 생각하면 큰일 납니다!)",
    "answer": "JOIN 연산: 여러 테이블을 조인하면 I/O와 CPU 비용 증가\n\nACID 트랜잭션: 락과 로그 기록으로 오버헤드 발생\n\n정규화된 스키마: 데이터 분산으로 여러 테이블 접근 필요\n\n스키마 변경: ALTER TABLE은 테이블 잠금과 재구성 필요\n\n하지만 NoSQL도 복잡한 쿼리나 일관성이 필요한 경우 RDB보다 느릴 수 있습니다.",
    "references": [
      {
        "title": "MySQL JOIN Optimization",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/join-optimization.html"
      }
    ],
    "keywords": [
      "join",
      "cpu",
      "acid",
      "alter",
      "table",
      "nosql",
      "rdb",
      "연산",
      "여러",
      "테이블을",
      "조인하면",
      "비용",
      "증가",
      "트랜잭션",
      "락과"
    ]
  },
  {
    "id": "DB-009",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "NoSQL을 활용한 경험이 있나요? 있다면, 왜 RDB를 선택하지 않고 해당 DB를 선택했는지 설명해 주세요.",
    "answer": "예시 답변 (Redis 사용 경험):\n\n세션 저장소와 캐시 레이어로 Redis를 사용했습니다.\n\n선택 이유:\n메모리 기반으로 빠른 읽기/쓰기 성능\nTTL 기능으로 세션 만료 자동 관리\nKey-Value 구조가 세션 데이터에 적합\nRDB의 불필요한 오버헤드 회피\n\n예시 답변 (MongoDB 사용 경험):\n스키마가 자주 변경되는 프로토타입 개발\n비정형 로그 데이터 저장",
    "references": [
      {
        "title": "Redis Use Cases",
        "url": "https://redis.io/docs/get-started/"
      }
    ],
    "keywords": [
      "redis",
      "ttl",
      "key-value",
      "rdb",
      "mongodb",
      "예시",
      "답변",
      "사용",
      "경험",
      "세션",
      "저장소와",
      "캐시",
      "레이어로",
      "사용했습니다",
      "선택"
    ]
  },
  {
    "id": "DB-010",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "트랜잭션이 무엇이고, ACID 원칙에 대해 설명해 주세요.",
    "answer": "트랜잭션: 하나의 논리적 작업 단위를 구성하는 연산들의 집합입니다.\n\nACID 원칙:\nAtomicity(원자성): 트랜잭션의 모든 연산이 완전히 수행되거나, 전혀 수행되지 않아야 합니다.\nConsistency(일관성): 트랜잭션 전후로 데이터베이스가 일관된 상태를 유지해야 합니다.\nIsolation(격리성): 동시에 실행되는 트랜잭션들이 서로 영향을 주지 않아야 합니다.\nDurability(지속성): 완료된 트랜잭션의 결과는 영구적으로 보존되어야 합니다.",
    "references": [
      {
        "title": "MySQL ACID Model",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/mysql-acid.html"
      }
    ],
    "keywords": [
      "acid",
      "atomicity",
      "consistency",
      "isolation",
      "durability",
      "트랜잭션",
      "하나의",
      "논리적",
      "작업",
      "단위를",
      "구성하는",
      "연산들의",
      "집합입니다",
      "원칙",
      "원자성"
    ]
  },
  {
    "id": "DB-011",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "ACID의 Atomicity (원자성) 는 DBMS에서 어떻게 보장되나요? (e.g., Undo/Redo 로그)",
    "answer": "Undo 로그를 통해 원자성을 보장합니다.\n\n트랜잭션 실행 중 변경 전 데이터를 Undo 로그에 기록합니다. 트랜잭션이 실패하거나 ROLLBACK되면 Undo 로그를 사용해 변경 사항을 되돌립니다.\n\n동작 과정:\n변경 전 데이터를 Undo 로그에 기록\n실제 데이터 변경 수행\n실패 시 Undo 로그로 원복",
    "references": [
      {
        "title": "InnoDB Undo Logs",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-undo-logs.html"
      }
    ],
    "keywords": [
      "undo",
      "rollback",
      "로그를",
      "원자성을",
      "보장합니다",
      "트랜잭션",
      "실행",
      "변경",
      "데이터를",
      "로그에",
      "기록합니다",
      "트랜잭션이",
      "실패하거나",
      "되면",
      "사용해"
    ]
  },
  {
    "id": "DB-012",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "ACID의 Consistency (일관성) 는 어떻게 보장되나요?",
    "answer": "일관성은 제약조건과 트리거를 통해 보장됩니다.\n\nDBMS 수준:\nPRIMARY KEY, FOREIGN KEY, UNIQUE, CHECK 제약조건\nNOT NULL 제약조건\n트리거를 통한 비즈니스 규칙 검증\n\n애플리케이션 수준:\n비즈니스 로직에서 데이터 유효성 검증\n트랜잭션 내 모든 연산이 규칙 준수하도록 설계\n\n일관성은 DBMS와 애플리케이션의 협력으로 보장됩니다.",
    "references": [
      {
        "title": "MySQL Data Integrity",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/constraint-foreign-key.html"
      }
    ],
    "keywords": [
      "dbms",
      "primary",
      "key",
      "foreign",
      "unique",
      "check",
      "null",
      "일관성은",
      "제약조건과",
      "트리거를",
      "보장됩니다",
      "수준",
      "제약조건",
      "통한",
      "비즈니스"
    ]
  },
  {
    "id": "DB-013",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "ACID의 Isolation (고립성) 은 DBMS에서 어떻게 보장되나요? (e.g., Lock, MVCC)",
    "answer": "Lock 기반:\n공유 락(S-Lock): 읽기 시 사용\n배타 락(X-Lock): 쓰기 시 사용\n락으로 동시 접근 제어\n\nMVCC (Multi-Version Concurrency Control):\n데이터의 여러 버전을 유지\n읽기 작업은 락 없이 스냅샷 읽기\n쓰기와 읽기 간 블로킹 최소화\n\nInnoDB는 MVCC와 락을 함께 사용하여 격리성을 보장합니다.",
    "references": [
      {
        "title": "InnoDB Locking and MVCC",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html"
      }
    ],
    "keywords": [
      "lock",
      "s-lock",
      "x-lock",
      "mvcc",
      "multi-version",
      "concurrency",
      "control",
      "innodb",
      "기반",
      "공유",
      "읽기",
      "사용",
      "배타",
      "쓰기",
      "락으로"
    ]
  },
  {
    "id": "DB-014",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "ACID의 Durability (지속성) 를 DBMS는 어떻게 보장하나요? (e.g., WAL, Redo 로그)",
    "answer": "WAL (Write-Ahead Logging) 방식으로 지속성을 보장합니다.\n\n데이터 변경 전 Redo 로그에 먼저 기록합니다. 커밋 시 로그를 디스크에 동기화(fsync)합니다.\n\n장애 복구:\n시스템 장애 발생\n재시작 시 Redo 로그 확인\n커밋된 트랜잭션은 Redo 로그로 재적용\n데이터 일관성 복구",
    "references": [
      {
        "title": "InnoDB Redo Log",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-redo-log.html"
      }
    ],
    "keywords": [
      "wal",
      "write-ahead",
      "logging",
      "redo",
      "방식으로",
      "지속성을",
      "보장합니다",
      "데이터",
      "변경",
      "로그에",
      "먼저",
      "기록합니다",
      "커밋",
      "로그를",
      "디스크에"
    ]
  },
  {
    "id": "DB-015",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "트랜잭션을 사용해 본 경험이 있나요? 어떤 경우에 사용할 수 있나요?",
    "answer": "사용 사례:\n계좌 이체: A 계좌 출금과 B 계좌 입금이 모두 성공하거나 모두 실패해야 함\n주문 처리: 주문 생성, 재고 감소, 결제 처리가 하나의 단위로 처리\n회원 가입: 사용자 정보 저장, 프로필 생성, 이메일 인증 토큰 생성",
    "references": [
      {
        "title": "MySQL Transaction Statements",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/commit.html"
      }
    ],
    "keywords": [
      "사용",
      "사례",
      "계좌",
      "이체",
      "출금과",
      "입금이",
      "모두",
      "성공하거나",
      "실패해야",
      "주문",
      "처리",
      "생성",
      "재고",
      "감소",
      "결제"
    ]
  },
  {
    "id": "DB-016",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "읽기(SELECT) 작업에는 트랜잭션을 걸지 않아도 될까요?",
    "answer": "상황에 따라 다릅니다.\n\n트랜잭션이 필요한 경우:\n일관된 스냅샷 읽기가 필요할 때\n여러 SELECT 간 데이터 일관성이 필요할 때\nSELECT 후 UPDATE하는 경우 (SELECT FOR UPDATE)\n\n트랜잭션 없이 가능한 경우:\n단일 SELECT 문\n실시간 최신 데이터가 필요한 경우\n일관성보다 성능이 중요한 경우\n\nMySQL InnoDB는 기본적으로 각 SELECT를 자체 트랜잭션으로 실행합니다(autocommit).",
    "references": [
      {
        "title": "MySQL Consistent Read",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-consistent-read.html"
      }
    ],
    "keywords": [
      "select",
      "update",
      "mysql",
      "innodb",
      "상황에",
      "따라",
      "다릅니다",
      "트랜잭션이",
      "필요한",
      "일관된",
      "스냅샷",
      "읽기가",
      "필요할",
      "여러",
      "데이터"
    ]
  },
  {
    "id": "DB-017",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "트랜잭션 격리 레벨(Isolation Level)에 대해 설명해 주세요.",
    "answer": "격리 수준   Dirty Read   Non-Repeatable Read   Phantom Read\n\nREAD UNCOMMITTED   O   O   O\nREAD COMMITTED   X   O   O\nREPEATABLE READ   X   X   O (InnoDB는 X)\nSERIALIZABLE   X   X   X\nDirty Read: 커밋되지 않은 데이터 읽기\nNon-Repeatable Read: 같은 쿼리가 다른 결과 반환\nPhantom Read: 조건에 맞는 행이 추가/삭제됨\n\nMySQL InnoDB 기본값은 REPEATABLE READ입니다.",
    "references": [
      {
        "title": "MySQL Transaction Isolation Levels",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html"
      }
    ],
    "keywords": [
      "dirty",
      "read",
      "non-repeatable",
      "phantom",
      "uncommitted",
      "committed",
      "repeatable",
      "innodb",
      "serializable",
      "mysql",
      "격리",
      "수준",
      "커밋되지",
      "않은",
      "데이터"
    ]
  },
  {
    "id": "DB-018",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "모든 DBMS가 4개의 격리 레벨을 모두 구현하고 있나요? 그렇지 않다면 그 이유는 무엇일까요?",
    "answer": "아니요, DBMS마다 다릅니다.\nPostgreSQL: READ UNCOMMITTED를 READ COMMITTED처럼 동작\nOracle: READ UNCOMMITTED, REPEATABLE READ 미지원\nSQL Server: 4개 모두 지원 + SNAPSHOT 추가\n\n이유:\nDBMS별 아키텍처와 MVCC 구현 방식 차이\n특정 격리 수준의 실용적 가치 부족\n성능과 구현 복잡도 고려",
    "references": [
      {
        "title": "PostgreSQL Transaction Isolation",
        "url": "https://www.postgresql.org/docs/current/transaction-iso.html"
      }
    ],
    "keywords": [
      "dbms",
      "postgresql",
      "read",
      "uncommitted",
      "committed",
      "oracle",
      "repeatable",
      "sql",
      "server",
      "snapshot",
      "mvcc",
      "아니요",
      "마다",
      "다릅니다",
      "처럼"
    ]
  },
  {
    "id": "DB-019",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "만약 MySQL을 사용하고 있다면, (InnoDB 기준) Undo 영역과 Redo 영역에 대해 설명해 주세요.",
    "answer": "Undo 영역:\n변경 전 데이터를 저장\nROLLBACK 시 원래 데이터로 복구\nMVCC에서 과거 버전 데이터 제공\n시스템 테이블스페이스 또는 별도 Undo 테이블스페이스에 저장\n\nRedo 영역:\n변경 후 데이터를 순차적으로 기록\nWAL 방식으로 커밋 전 디스크에 기록\n장애 복구 시 커밋된 트랜잭션 재적용\nib_logfile 파일에 저장",
    "references": [
      {
        "title": "InnoDB Undo Logs",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-undo-logs.html"
      }
    ],
    "keywords": [
      "undo",
      "rollback",
      "mvcc",
      "redo",
      "wal",
      "ib_logfile",
      "영역",
      "변경",
      "데이터를",
      "저장",
      "원래",
      "데이터로",
      "복구",
      "에서",
      "과거"
    ]
  },
  {
    "id": "DB-020",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "MVCC (Multi-Version Concurrency Control) 가 무엇이며, InnoDB 스토리지 엔진은 Undo 로그를 사용해 이를 어떻게 구현하나요?",
    "answer": "MVCC: 동시성 제어 기법으로, 데이터의 여러 버전을 유지하여 읽기와 쓰기가 서로 블로킹하지 않게 합니다.\n\nInnoDB 구현:\n각 행에 트랜잭션 ID와 롤백 포인터 저장\nUPDATE 시 새 버전 생성, 이전 버전은 Undo 로그에 보관\nSELECT 시 자신의 트랜잭션 시작 시점 기준 적절한 버전 읽기\n트랜잭션 완료 후 불필요한 Undo 로그는 Purge 스레드가 정리",
    "references": [
      {
        "title": "InnoDB Multi-Versioning",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html"
      }
    ],
    "keywords": [
      "mvcc",
      "innodb",
      "update",
      "undo",
      "select",
      "purge",
      "동시성",
      "제어",
      "기법으로",
      "데이터의",
      "여러",
      "버전을",
      "유지하여",
      "읽기와",
      "쓰기가"
    ]
  },
  {
    "id": "DB-021",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "그런데, 스토리지 엔진이 정확히 무엇을 하는 건가요?",
    "answer": "스토리지 엔진: 데이터의 저장, 검색, 업데이트를 담당하는 DBMS의 컴포넌트입니다.\n\n주요 역할:\n데이터를 디스크에 저장하고 읽기\n인덱스 관리\n트랜잭션 처리 (ACID 보장)\n락 관리\n버퍼 관리\n\nMySQL 스토리지 엔진:\nInnoDB: 트랜잭션, 외래키 지원 (기본값)\nMyISAM: 빠른 읽기, 트랜잭션 미지원\nMemory: 메모리 기반, 임시 데이터용",
    "references": [
      {
        "title": "MySQL Storage Engines",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/storage-engines.html"
      }
    ],
    "keywords": [
      "dbms",
      "acid",
      "mysql",
      "innodb",
      "myisam",
      "memory",
      "스토리지",
      "엔진",
      "데이터의",
      "저장",
      "검색",
      "업데이트를",
      "담당하는",
      "컴포넌트입니다",
      "주요"
    ]
  },
  {
    "id": "DB-022",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "인덱스가 무엇이고, 언제 사용하는지 설명해 주세요.",
    "answer": "인덱스: 테이블의 검색 속도를 향상시키기 위한 자료구조입니다. 책의 색인처럼 원하는 데이터의 위치를 빠르게 찾을 수 있게 합니다.\n\n사용 시점:\nWHERE 절에 자주 사용되는 컬럼\nJOIN 조건에 사용되는 컬럼\nORDER BY, GROUP BY에 사용되는 컬럼\n카디널리티(고유값 수)가 높은 컬럼\n\n사용하지 않는 경우:\n데이터가 적은 테이블\nINSERT/UPDATE/DELETE가 빈번한 컬럼",
    "references": [
      {
        "title": "MySQL Index Optimization",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/optimization-indexes.html"
      }
    ],
    "keywords": [
      "where",
      "join",
      "order",
      "group",
      "insert",
      "update",
      "delete",
      "인덱스",
      "테이블의",
      "검색",
      "속도를",
      "향상시키기",
      "위한",
      "자료구조입니다",
      "책의"
    ]
  },
  {
    "id": "DB-023",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "일반적으로 인덱스는 수정(INSERT, UPDATE, DELETE)이 잦은 테이블에선 사용하지 않기를 권합니다. 왜 그럴까요?",
    "answer": "인덱스 유지 비용이 발생하기 때문입니다.\nINSERT: 새 데이터에 대한 인덱스 엔트리 추가, B-Tree 재조정 가능\nUPDATE: 인덱스 키 값 변경 시 기존 엔트리 삭제 + 새 엔트리 추가\nDELETE: 인덱스 엔트리 삭제, B-Tree 재조정 가능\n\n인덱스가 많을수록 쓰기 작업의 오버헤드가 증가합니다. 읽기 성능 향상과 쓰기 성능 저하 간 트레이드오프를 고려해야 합니다.",
    "references": [
      {
        "title": "MySQL Index Maintenance",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-online-ddl-operations.html"
      }
    ],
    "keywords": [
      "insert",
      "b-tree",
      "update",
      "delete",
      "인덱스",
      "유지",
      "비용이",
      "발생하기",
      "때문입니다",
      "데이터에",
      "대한",
      "엔트리",
      "추가",
      "재조정",
      "가능"
    ]
  },
  {
    "id": "DB-024",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "앞 꼬리질문에 대해, 그렇다면 인덱스에서 사용하지 않겠다고 선택한 값은 위 정책을 그대로 따라가나요?",
    "answer": "아니요, 인덱스가 없는 컬럼은 인덱스 유지 비용이 없습니다.\n\n인덱스가 없는 컬럼의 변경은:\n테이블 데이터만 수정\nB-Tree 재조정 불필요\n추가적인 인덱스 I/O 없음\n\n다만, 해당 컬럼으로 검색 시 Full Table Scan이 발생합니다. 인덱스 설계 시 읽기/쓰기 패턴을 분석하여 적절한 균형을 찾아야 합니다.",
    "references": [
      {
        "title": "MySQL Query Optimization",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/query-optimization.html"
      }
    ],
    "keywords": [
      "b-tree",
      "full",
      "table",
      "scan",
      "아니요",
      "인덱스가",
      "없는",
      "컬럼은",
      "인덱스",
      "유지",
      "비용이",
      "없습니다",
      "컬럼의",
      "변경은",
      "테이블"
    ]
  },
  {
    "id": "DB-025",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "ORDER BY / GROUP BY 연산의 동작 과정을 인덱스의 존재여부와 연관지어서 설명해 주세요.",
    "answer": "인덱스가 있는 경우:\n이미 정렬된 인덱스를 순회하여 결과 반환\n추가 정렬 작업 불필요 (Filesort 회피)\n메모리와 CPU 사용 최소화\n\n인덱스가 없는 경우:\n전체 데이터를 읽어 메모리에서 정렬 (Filesort)\n데이터가 크면 디스크 임시 파일 사용\n성능 저하 발생\n\nEXPLAIN으로 \"Using filesort\"가 표시되면 인덱스를 활용하지 못한 것입니다.",
    "references": [
      {
        "title": "MySQL ORDER BY Optimization",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/order-by-optimization.html"
      }
    ],
    "keywords": [
      "filesort",
      "cpu",
      "explain",
      "using",
      "인덱스가",
      "있는",
      "이미",
      "정렬된",
      "인덱스를",
      "순회하여",
      "결과",
      "반환",
      "추가",
      "정렬",
      "작업"
    ]
  },
  {
    "id": "DB-026",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "기본키는 인덱스라고 할 수 있을까요? 그렇지 않다면, 인덱스와 기본키는 어떤 차이가 있나요?",
    "answer": "기본키는 자동으로 인덱스가 생성됩니다.\n\n차이점:\n\n구분   기본키   인덱스\n\n목적   행 식별   검색 속도 향상\nNULL   불가   가능 (UNIQUE 제외)\n개수   테이블당 1개   여러 개 가능\n종류   Clustered Index   Non-Clustered 가능\n\nInnoDB에서 기본키는 Clustered Index로, 데이터가 기본키 순서로 물리적으로 저장됩니다.",
    "references": [
      {
        "title": "InnoDB Clustered Index",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-index-types.html"
      }
    ],
    "keywords": [
      "null",
      "unique",
      "clustered",
      "index",
      "non-clustered",
      "innodb",
      "기본키는",
      "자동으로",
      "인덱스가",
      "생성됩니다",
      "차이점",
      "구분",
      "기본키",
      "인덱스",
      "목적"
    ]
  },
  {
    "id": "DB-027",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "그렇다면 외래키는요?",
    "answer": "외래키에는 자동으로 인덱스가 생성됩니다. (InnoDB 기준)\n\n이유:\n참조 무결성 검사 시 부모 테이블 조회 필요\nJOIN 연산 시 성능 향상\nON DELETE/UPDATE CASCADE 처리 시 빠른 검색\n\n외래키 인덱스가 없으면 자식 테이블에서 부모 테이블 참조 검사 시 Full Scan이 발생하여 성능이 크게 저하됩니다.",
    "references": [
      {
        "title": "MySQL Foreign Key Constraints",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/create-table-foreign-keys.html"
      }
    ],
    "keywords": [
      "innodb",
      "join",
      "delete",
      "update",
      "cascade",
      "full",
      "scan",
      "외래키에는",
      "자동으로",
      "인덱스가",
      "생성됩니다",
      "기준",
      "이유",
      "참조",
      "무결성"
    ]
  },
  {
    "id": "DB-028",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "인덱스가 데이터의 물리적 저장에도 영향을 미치나요? (e.g., Clustered Index vs Non-Clustered Index)",
    "answer": "Clustered Index는 물리적 저장에 영향을 미칩니다.\n\nClustered Index:\n테이블 데이터가 인덱스 키 순서로 물리적으로 저장\n테이블당 1개만 존재\nInnoDB에서 기본키가 Clustered Index\n\nNon-Clustered Index (Secondary Index):\n별도 공간에 인덱스 저장\n실제 데이터 위치를 가리키는 포인터 보유\n여러 개 생성 가능\n\nInnoDB의 Secondary Index는 기본키 값을 저장하여 Clustered Index를 다시 탐색합니다.",
    "references": [
      {
        "title": "InnoDB Index Types",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-index-types.html"
      }
    ],
    "keywords": [
      "clustered",
      "index",
      "innodb",
      "non-clustered",
      "secondary",
      "물리적",
      "저장에",
      "영향을",
      "미칩니다",
      "테이블",
      "데이터가",
      "인덱스",
      "순서로",
      "물리적으로",
      "저장"
    ]
  },
  {
    "id": "DB-029",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "우리가 아는 RDB가 아닌 NoSQL (ex. Redis, MongoDB 등)는 인덱스를 갖고 있나요? 만약 있다면, RDB의 인덱스와는 어떤 차이가 있을까요?",
    "answer": "네, NoSQL도 인덱스를 지원합니다.\n\nMongoDB:\nB-Tree 인덱스 사용 (RDB와 유사)\n복합 인덱스, 해시 인덱스, 지리공간 인덱스 지원\n문서의 중첩 필드에도 인덱스 가능\n\nRedis:\nKey 자체가 해시 기반 인덱스\nSorted Set으로 범위 쿼리용 인덱스 구현\nSecondary Index는 직접 구현 필요\n\n차이점:\nNoSQL은 스키마리스로 인덱스 설계가 유연\n분산 환경에서 인덱스 관리 방식 다름",
    "references": [
      {
        "title": "MongoDB Indexes",
        "url": "https://www.mongodb.com/docs/manual/indexes/"
      }
    ],
    "keywords": [
      "nosql",
      "mongodb",
      "b-tree",
      "rdb",
      "redis",
      "key",
      "sorted",
      "set",
      "secondary",
      "index",
      "인덱스를",
      "지원합니다",
      "인덱스",
      "사용",
      "유사"
    ]
  },
  {
    "id": "DB-030",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "(A, B) 컬럼 순서로 복합 인덱스를 설정한 테이블에서, WHERE A=... 조건 없이 WHERE B=... 조건만 사용하여 쿼리를 요청했습니다. 해당 쿼리는 인덱스를 탈까요?",
    "answer": "일반적으로 인덱스를 타지 않습니다.\n\n복합 인덱스는 첫 번째 컬럼부터 순차적으로 정렬됩니다. (A, B) 인덱스는 A로 먼저 정렬되고, 같은 A 값 내에서 B로 정렬됩니다.\n\nWHERE B=... 만 사용하면:\nB 값이 여러 A 값에 분산되어 있음\n인덱스 전체를 스캔해야 함 (Index Full Scan)\n옵티마이저가 Full Table Scan을 선택할 가능성 높음\n\n해결책: B 컬럼만을 위한 별도 인덱스 생성",
    "references": [
      {
        "title": "MySQL Multiple-Column Indexes",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/multiple-column-indexes.html"
      }
    ],
    "keywords": [
      "where",
      "index",
      "full",
      "scan",
      "table",
      "일반적으로",
      "인덱스를",
      "타지",
      "않습니다",
      "복합",
      "인덱스는",
      "번째",
      "컬럼부터",
      "순차적으로",
      "정렬됩니다"
    ]
  },
  {
    "id": "DB-031",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "복합 컬럼 인덱스(Composite Index) 의 작동 방식은 무엇이며, 어떤 컬럼을 인덱스의 앞 순서로 두는 것이 성능에 유리할까요?",
    "answer": "작동 방식:\nB-Tree에서 첫 번째 컬럼으로 정렬 후, 같은 값 내에서 두 번째 컬럼으로 정렬됩니다. (A, B, C) 인덱스는 A → B → C 순으로 다단계 정렬됩니다.\n\n앞 순서에 두면 유리한 컬럼:\n동등 조건(=)으로 자주 검색되는 컬럼\n카디널리티가 높은 컬럼 (고유값이 많은 컬럼)\n범위 조건은 뒤에 배치 (범위 이후 컬럼은 인덱스 활용 불가)\n\n예시: WHERE status = 'active' AND createdat > '2024-01-01'\n→ (status, createdat) 순서가 효율적",
    "references": [
      {
        "title": "MySQL Composite Index",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/multiple-column-indexes.html"
      }
    ],
    "keywords": [
      "b-tree",
      "where",
      "작동",
      "방식",
      "에서",
      "번째",
      "컬럼으로",
      "정렬",
      "같은",
      "내에서",
      "정렬됩니다",
      "인덱스는",
      "순으로",
      "다단계",
      "순서에"
    ]
  },
  {
    "id": "DB-032",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "B-Tree와 B+Tree에 대해 설명해 주세요.",
    "answer": "B-Tree:\n균형 잡힌 트리 구조로 모든 리프 노드가 같은 깊이\n각 노드에 키와 데이터를 함께 저장\n검색, 삽입, 삭제 모두 O(log N)\n\nB+Tree:\nB-Tree의 변형으로 데이터는 리프 노드에만 저장\n내부 노드는 키만 저장 → 더 많은 키 저장 가능\n리프 노드가 연결 리스트로 연결 → 범위 검색 효율적\n대부분의 RDBMS가 B+Tree 사용",
    "references": [
      {
        "title": "InnoDB Index Structures",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-physical-structure.html"
      }
    ],
    "keywords": [
      "b-tree",
      "tree",
      "rdbms",
      "균형",
      "잡힌",
      "트리",
      "구조로",
      "모든",
      "리프",
      "노드가",
      "같은",
      "깊이",
      "노드에",
      "키와",
      "데이터를"
    ]
  },
  {
    "id": "DB-033",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "그렇다면, B+Tree가 B-Tree에 비해 반드시 좋다고 할 수 있을까요? 그렇지 않다면 어떤 단점이 있을까요?",
    "answer": "B+Tree의 단점:\n단일 키 검색 시 추가 I/O: 데이터가 리프에만 있어 항상 리프까지 탐색 필요 (B-Tree는 중간에서 찾을 수 있음)\n저장 공간: 키가 내부 노드와 리프에 중복 저장될 수 있음\n삽입/삭제 복잡도: 리프 노드 연결 리스트 유지 비용\n\nB-Tree가 유리한 경우:\n특정 키를 정확히 찾는 단일 검색이 대부분인 경우\n메모리 기반 인덱스 (디스크 I/O 고려 불필요)",
    "references": [
      {
        "title": "Database Index Structures",
        "url": "https://use-the-index-luke.com/sql/anatomy/the-tree"
      }
    ],
    "keywords": [
      "tree",
      "b-tree",
      "단점",
      "단일",
      "검색",
      "추가",
      "데이터가",
      "리프에만",
      "있어",
      "항상",
      "리프까지",
      "탐색",
      "필요",
      "중간에서",
      "찾을"
    ]
  },
  {
    "id": "DB-034",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "DB 인덱스에서 Red-Black Tree를 사용하지 않고, B-Tree/B+Tree를 사용하는 이유가 있을까요?",
    "answer": "디스크 I/O 최적화 때문입니다.\n\nRed-Black Tree:\n이진 트리로 노드당 자식 2개\n트리 높이가 높음 → 디스크 접근 횟수 증가\n메모리 기반 자료구조에 적합\n\nB-Tree/B+Tree:\n다진 트리로 노드당 자식 수백~수천 개\n트리 높이가 낮음 (보통 3~4)\n한 번의 디스크 읽기로 많은 키 비교 가능\n디스크 블록 크기에 최적화\n\n100만 건 데이터: Red-Black Tree는 20번, B+Tree는 3~4번 디스크 접근",
    "references": [
      {
        "title": "Why B-Tree for Databases",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-physical-structure.html"
      }
    ],
    "keywords": [
      "red-black",
      "tree",
      "b-tree",
      "디스크",
      "최적화",
      "때문입니다",
      "이진",
      "트리로",
      "노드당",
      "자식",
      "트리",
      "높이가",
      "높음",
      "접근",
      "횟수"
    ]
  },
  {
    "id": "DB-035",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "오름차순으로 정렬된 인덱스가 있다고 할 때, ORDER BY ... DESC (내림차순) 정렬을 시도할 경우 성능이 어떻게 될까요? B-Tree/B+Tree의 구조를 기반으로 설명해 주세요.",
    "answer": "역방향 스캔으로 처리 가능하여 성능 저하가 크지 않습니다.\n\nB+Tree의 리프 노드는 양방향 연결 리스트로 구성됩니다. 따라서:\n오름차순: 왼쪽 → 오른쪽 순회\n내림차순: 오른쪽 → 왼쪽 순회 (Backward Index Scan)\n\n주의사항:\n복합 인덱스에서 일부만 DESC인 경우 문제 발생\n(A ASC, B ASC) 인덱스에서 ORDER BY A DESC, B ASC는 인덱스 활용 불가\nMySQL 8.0부터 Descending Index 지원",
    "references": [
      {
        "title": "MySQL Descending Indexes",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/descending-indexes.html"
      }
    ],
    "keywords": [
      "tree",
      "backward",
      "index",
      "scan",
      "desc",
      "asc",
      "order",
      "mysql",
      "descending",
      "역방향",
      "스캔으로",
      "처리",
      "가능하여",
      "성능",
      "저하가"
    ]
  },
  {
    "id": "DB-036",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "위도, 경도와 같은 2D/3D 공간 좌표(Spatial Data) 는 B-Tree로 인덱싱하기 어렵습니다. 이런 데이터는 어떤 자료구조(e.g., R-Tree, Geohash)를 사용하며 어떻게 동작하나요?",
    "answer": "R-Tree:\n다차원 공간 데이터를 위한 트리 구조\n최소 경계 사각형(MBR)으로 공간 객체 그룹화\n\"반경 N km 내 검색\" 같은 쿼리에 효율적\nMySQL SPATIAL INDEX가 R-Tree 사용\n\nGeohash:\n2D 좌표를 1D 문자열로 인코딩\n가까운 위치는 유사한 prefix를 가짐\nB-Tree 인덱스로 범위 검색 가능\nRedis, MongoDB 등에서 활용",
    "references": [
      {
        "title": "MySQL Spatial Indexes",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/creating-spatial-indexes.html"
      }
    ],
    "keywords": [
      "r-tree",
      "mbr",
      "mysql",
      "spatial",
      "index",
      "geohash",
      "b-tree",
      "redis",
      "mongodb",
      "다차원",
      "공간",
      "데이터를",
      "위한",
      "트리",
      "구조"
    ]
  },
  {
    "id": "DB-037",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "DB Join이 무엇인지 설명하고, 각각의 종류(INNER, LEFT/RIGHT OUTER, FULL OUTER 등)에 대해 설명해 주세요.",
    "answer": "JOIN: 두 개 이상의 테이블을 연결하여 데이터를 조회하는 연산입니다.\n\n종류:\nINNER JOIN: 양쪽 테이블에서 조건이 일치하는 행만 반환\nLEFT OUTER JOIN: 왼쪽 테이블의 모든 행 + 오른쪽 매칭 행 (없으면 NULL)\nRIGHT OUTER JOIN: 오른쪽 테이블의 모든 행 + 왼쪽 매칭 행 (없으면 NULL)\nFULL OUTER JOIN: 양쪽 테이블의 모든 행 반환 (MySQL은 UNION으로 구현)\nCROSS JOIN: 카테시안 곱, 모든 조합 반환",
    "references": [
      {
        "title": "MySQL JOIN Syntax",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/join.html"
      }
    ],
    "keywords": [
      "join",
      "inner",
      "left",
      "outer",
      "null",
      "right",
      "full",
      "mysql",
      "union",
      "cross",
      "이상의",
      "테이블을",
      "연결하여",
      "데이터를",
      "조회하는"
    ]
  },
  {
    "id": "DB-038",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "조인(JOIN) 시  드라이빙 테이블(Driving Table)과 드리븐 테이블(Driven Table) 은 무엇이며, 옵티마이저는 이 순서를 어떻게 결정하나요?",
    "answer": "드라이빙 테이블: JOIN에서 먼저 접근하는 테이블 (외부 루프)\n드리븐 테이블: 드라이빙 테이블의 각 행에 대해 조회되는 테이블 (내부 루프)\n\n옵티마이저 결정 기준:\n테이블 크기 (작은 테이블을 드라이빙으로)\n인덱스 유무 (드리븐 테이블에 인덱스가 있으면 유리)\nWHERE 조건으로 필터링 가능한 행 수\n통계 정보 기반 비용 계산\n\n힌트로 제어:",
    "references": [
      {
        "title": "MySQL Join Optimization",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/nested-loop-joins.html"
      }
    ],
    "keywords": [
      "join",
      "where",
      "드라이빙",
      "테이블",
      "에서",
      "먼저",
      "접근하는",
      "외부",
      "루프",
      "드리븐",
      "테이블의",
      "행에",
      "조회되는",
      "내부",
      "옵티마이저"
    ]
  },
  {
    "id": "DB-039",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "JOIN은 시간이 오래 걸릴 수 있어 내부적으로 다양한 물리적 조인(Physical Join) 방식을 사용합니다. Nested Loop Join, Sort Merge Join, Hash Join에 대해 설명해 주세요.",
    "answer": "Nested Loop Join:\n외부 테이블의 각 행에 대해 내부 테이블 전체 스캔\n인덱스가 있으면 효율적\n소규모 테이블이나 인덱스 있을 때 적합\n\nSort Merge Join:\n양쪽 테이블을 조인 키로 정렬\n정렬된 데이터를 순차적으로 병합\n이미 정렬된 대용량 데이터에 효율적\n\nHash Join:\n작은 테이블로 해시 테이블 생성\n큰 테이블을 스캔하며 해시 테이블 조회\n인덱스 없는 대용량 동등 조인에 효율적\nMySQL 8.0.18부터 지원",
    "references": [
      {
        "title": "MySQL Hash Join",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/hash-joins.html"
      }
    ],
    "keywords": [
      "nested",
      "loop",
      "join",
      "sort",
      "merge",
      "hash",
      "mysql",
      "외부",
      "테이블의",
      "행에",
      "내부",
      "테이블",
      "전체",
      "스캔",
      "인덱스가"
    ]
  },
  {
    "id": "DB-040",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "앞 질문들을 통해 인덱스의 중요성을 알 수 있었는데, 그렇다면 JOIN의 성능도 인덱스의 유무의 영향을 받나요? (특히 Nested Loop Join과 연관지어 설명해 보세요.)",
    "answer": "네, 인덱스는 JOIN 성능에 큰 영향을 미칩니다.\n\nNested Loop Join에서:\n\n인덱스 없는 경우:\n드라이빙 테이블 N행 × 드리븐 테이블 M행 = N×M 비교\n시간 복잡도: O(N×M)\n\n인덱스 있는 경우:\n드라이빙 테이블 N행 × 인덱스 탐색 O(log M)\n시간 복잡도: O(N × log M)\n\n권장사항:\n드리븐 테이블의 조인 컬럼에 인덱스 생성\n외래키 컬럼에 인덱스 필수",
    "references": [
      {
        "title": "MySQL Index for JOIN",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/table-scan-avoidance.html"
      }
    ],
    "keywords": [
      "join",
      "nested",
      "loop",
      "인덱스는",
      "성능에",
      "영향을",
      "미칩니다",
      "에서",
      "인덱스",
      "없는",
      "드라이빙",
      "테이블",
      "드리븐",
      "비교",
      "시간"
    ]
  },
  {
    "id": "DB-041",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "3중 조인 부터는 동작 방식이 약간 바뀝니다. 어떻게 동작하는지, 그리고 그 방식이 성능에 어떠한 영향을 주는지 설명해 주세요.",
    "answer": "3중 이상 조인의 동작:\n첫 번째 테이블(A)과 두 번째 테이블(B) 조인\n결과와 세 번째 테이블(C) 조인\n각 단계에서 중간 결과셋 생성\n\n성능 영향:\n조인 순서가 중요: 조인 순서에 따라 중간 결과 크기가 달라짐\n옵티마이저의 역할: N개 테이블 조인 시 N! 가지 순서를 비용 기반으로 선택\n중간 결과 최소화: 필터링이 잘 되는 테이블을 먼저 조인\n\n최적화:\n조인 순서 힌트 사용\n각 조인 컬럼에 인덱스 확보\n서브쿼리보다 JOIN 선호",
    "references": [
      {
        "title": "MySQL Optimizing Multi-Join",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/multiple-table-optimization.html"
      }
    ],
    "keywords": [
      "join",
      "이상",
      "조인의",
      "동작",
      "번째",
      "테이블",
      "조인",
      "결과와",
      "단계에서",
      "중간",
      "결과셋",
      "생성",
      "성능",
      "영향",
      "순서가"
    ]
  },
  {
    "id": "DB-042",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "트랜잭션 상황에서의 Deadlock (교착 상태) 상황과, 이를 해결하기 위한 방법에 대해 설명해 주세요.",
    "answer": "Deadlock: 두 개 이상의 트랜잭션이 서로가 가진 락을 기다리며 무한 대기하는 상태\n\n예시:\nT1: A 락 획득 → B 락 대기\nT2: B 락 획득 → A 락 대기\n\n해결 방법:\n예방: 락 획득 순서를 일관되게 정의\n탐지: DBMS가 주기적으로 대기 그래프 검사\n해제: Deadlock 발견 시 한 트랜잭션을 ROLLBACK\n타임아웃: 일정 시간 대기 후 포기\n\nInnoDB는 자동으로 Deadlock을 탐지하고 비용이 적은 트랜잭션을 롤백합니다.",
    "references": [
      {
        "title": "InnoDB Deadlocks",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-deadlocks.html"
      }
    ],
    "keywords": [
      "deadlock",
      "dbms",
      "rollback",
      "innodb",
      "이상의",
      "트랜잭션이",
      "서로가",
      "가진",
      "락을",
      "기다리며",
      "무한",
      "대기하는",
      "상태",
      "예시",
      "획득"
    ]
  },
  {
    "id": "DB-043",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "DB Locking에 대해 설명해 주세요.",
    "answer": "Locking: 동시성 제어를 위해 데이터에 대한 접근을 제한하는 메커니즘\n\n락 단위:\n테이블 락: 테이블 전체 잠금 (MyISAM)\n행 락: 특정 행만 잠금 (InnoDB)\n페이지 락: 디스크 페이지 단위 잠금\n\n락 유형:\n공유 락(S): 읽기 허용, 쓰기 차단\n배타 락(X): 읽기/쓰기 모두 차단\n\nInnoDB 특수 락:\nRecord Lock: 인덱스 레코드 잠금\nGap Lock: 인덱스 레코드 사이 간격 잠금\nNext-Key Lock: Record + Gap Lock",
    "references": [
      {
        "title": "InnoDB Locking",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html"
      }
    ],
    "keywords": [
      "locking",
      "myisam",
      "innodb",
      "record",
      "lock",
      "gap",
      "next-key",
      "동시성",
      "제어를",
      "데이터에",
      "대한",
      "접근을",
      "제한하는",
      "메커니즘",
      "단위"
    ]
  },
  {
    "id": "DB-044",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "공유 락(Shared Lock, S-Lock)과 배타 락(Exclusive Lock, X-Lock) 의 차이점은 무엇이며, 언제 각각 사용되나요?",
    "answer": "공유 락(S-Lock):\n다른 트랜잭션의 읽기 허용\n다른 트랜잭션의 쓰기 차단\nSELECT ... FOR SHARE 또는 LOCK IN SHARE MODE\n데이터를 읽으면서 변경 방지할 때 사용\n\n배타 락(X-Lock):\n다른 트랜잭션의 읽기/쓰기 모두 차단\nSELECT ... FOR UPDATE, INSERT, UPDATE, DELETE\n데이터 변경 시 사용\n\n요청/보유   S-Lock   X-Lock\n\nS-Lock   호환   충돌\nX-Lock   충돌   충돌",
    "references": [
      {
        "title": "InnoDB Lock Modes",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-lock-modes.html"
      }
    ],
    "keywords": [
      "s-lock",
      "select",
      "share",
      "lock",
      "mode",
      "x-lock",
      "update",
      "insert",
      "delete",
      "공유",
      "다른",
      "트랜잭션의",
      "읽기",
      "허용",
      "쓰기"
    ]
  },
  {
    "id": "DB-045",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "Optimistic Lock(낙관적 락) / Pessimistic Lock(비관적 락)에 대해 설명해 주세요.",
    "answer": "비관적 락(Pessimistic Lock):\n충돌이 발생할 것이라 가정\n데이터 접근 시 즉시 락 획득\nSELECT FOR UPDATE 사용\n충돌이 잦은 환경에 적합\n\n낙관적 락(Optimistic Lock):\n충돌이 드물다고 가정\n락 없이 작업 후 커밋 시 충돌 검사\nversion 컬럼이나 timestamp로 구현\n충돌 시 재시도 필요",
    "references": [
      {
        "title": "JPA Optimistic Locking",
        "url": "https://docs.oracle.com/javaee/7/tutorial/persistence-locking.htm"
      }
    ],
    "keywords": [
      "pessimistic",
      "lock",
      "select",
      "update",
      "optimistic",
      "비관적",
      "충돌이",
      "발생할",
      "것이라",
      "가정",
      "데이터",
      "접근",
      "즉시",
      "획득",
      "사용"
    ]
  },
  {
    "id": "DB-046",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "물리적인 Lock을 건다면, 만약 이를 수행중인 요청에 문제가 생겨 비정상 종료되면 Lock이 절대 해제되지 않는 문제가 생길 수도 있을 것 같습니다. DB는 이를 위한 해결책이 있나요? 없다면, 우리가 이 문제를 해결할 수 없을까요?",
    "answer": "DBMS의 해결책:\n커넥션 타임아웃: 비정상 연결 감지 시 자동 롤백 및 락 해제\n락 타임아웃: innodblockwait_timeout 설정으로 대기 시간 제한\n트랜잭션 롤백: 비정상 종료 시 자동 롤백으로 락 해제\nDeadlock Detection: 교착 상태 감지 시 자동 해제\n\n애플리케이션 레벨:\n트랜잭션 타임아웃 설정\ntry-finally로 명시적 롤백/커밋 보장\nConnection Pool의 유효성 검사",
    "references": [
      {
        "title": "MySQL Lock Wait Timeout",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_lock_wait_timeout"
      }
    ],
    "keywords": [
      "dbms",
      "innodblockwait_timeout",
      "deadlock",
      "detection",
      "try-finally",
      "connection",
      "pool",
      "해결책",
      "커넥션",
      "타임아웃",
      "비정상",
      "연결",
      "감지",
      "자동",
      "롤백"
    ]
  },
  {
    "id": "DB-047",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "DB 옵티마이저의 RBO(Rule-Based Optimizer)와 CBO(Cost-Based Optimizer) 의 차이점은 무엇인가요?",
    "answer": "RBO (Rule-Based Optimizer):\n미리 정의된 규칙에 따라 실행 계획 결정\n인덱스가 있으면 무조건 사용\n통계 정보 미사용\n예측 가능하지만 유연성 부족\n현재 대부분 사용하지 않음\n\nCBO (Cost-Based Optimizer):\n통계 정보 기반 비용 계산\n여러 실행 계획 중 최소 비용 선택\n테이블 크기, 인덱스 선택도 등 고려\nMySQL, PostgreSQL, Oracle 모두 CBO 사용\n\nCBO의 판단 요소:\n디스크 I/O 비용\nCPU 비용\n네트워크 비용",
    "references": [
      {
        "title": "MySQL Query Optimizer",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/query-optimization.html"
      }
    ],
    "keywords": [
      "rbo",
      "rule-based",
      "optimizer",
      "cbo",
      "cost-based",
      "mysql",
      "postgresql",
      "oracle",
      "cpu",
      "미리",
      "정의된",
      "규칙에",
      "따라",
      "실행",
      "계획"
    ]
  },
  {
    "id": "DB-048",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "쿼리가 어떤 조인 방식이나 인덱스를 사용하는지 (즉, 실행 계획) 어떻게 알 수 있나요? (e.g., EXPLAIN)",
    "answer": "EXPLAIN 명령어를 사용합니다.\n\n주요 출력 항목:\ntype: 접근 방식 (ALL, index, range, ref, const)\npossible_keys: 사용 가능한 인덱스\nkey: 실제 사용된 인덱스\nrows: 예상 검색 행 수\nExtra: 추가 정보 (Using index, Using filesort 등)\n\nEXPLAIN FORMAT=JSON: 더 상세한 정보 제공",
    "references": [
      {
        "title": "MySQL EXPLAIN Output",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/explain-output.html"
      }
    ],
    "keywords": [
      "explain",
      "all",
      "possible_keys",
      "extra",
      "using",
      "format",
      "json",
      "명령어를",
      "사용합니다",
      "주요",
      "출력",
      "항목",
      "접근",
      "방식",
      "사용"
    ]
  },
  {
    "id": "DB-049",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "쿼리 실행 계획을 볼 때, EXPLAIN과 ANALYZE (혹은 EXPLAIN ANALYZE)의 차이점은 무엇인가요?",
    "answer": "EXPLAIN:\n실제 쿼리를 실행하지 않음\n옵티마이저의 예상 실행 계획 표시\n예상 행 수, 예상 비용 제공\n빠르게 확인 가능\n\nEXPLAIN ANALYZE:\n실제 쿼리를 실행\n실제 실행 시간, 실제 행 수 표시\n예상과 실제의 차이 확인 가능\n성능 병목 정확히 파악\n\nMySQL 8.0.18부터 지원, PostgreSQL은 오래전부터 지원",
    "references": [
      {
        "title": "MySQL EXPLAIN ANALYZE",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/explain.html#explain-analyze"
      }
    ],
    "keywords": [
      "explain",
      "analyze",
      "mysql",
      "postgresql",
      "실제",
      "쿼리를",
      "실행하지",
      "않음",
      "옵티마이저의",
      "예상",
      "실행",
      "계획",
      "표시",
      "비용",
      "제공"
    ]
  },
  {
    "id": "DB-050",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "Table Full Scan, Index Range Scan에 대해 설명해 주세요.",
    "answer": "Table Full Scan:\n테이블의 모든 행을 순차적으로 읽음\n인덱스를 사용하지 않음\nEXPLAIN에서 type: ALL\n대용량 테이블에서 성능 저하\n\nIndex Range Scan:\n인덱스의 특정 범위만 스캔\nWHERE 절의 범위 조건 (<, >, BETWEEN, LIKE 'abc%')\nEXPLAIN에서 type: range\n필요한 데이터만 읽어 효율적\n\n그 외 스캔 방식:\nIndex Full Scan: 인덱스 전체 스캔\nIndex Unique Scan: 유일한 값 검색 (type: const, eq_ref)",
    "references": [
      {
        "title": "MySQL EXPLAIN Type",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain-join-types"
      }
    ],
    "keywords": [
      "table",
      "full",
      "scan",
      "explain",
      "all",
      "index",
      "range",
      "where",
      "like",
      "unique",
      "eq_ref",
      "테이블의",
      "모든",
      "행을",
      "순차적으로"
    ]
  },
  {
    "id": "DB-051",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "분명히 인덱스를 타는 쿼리임에도 옵티마이저가 Table Full Scan 방식으로 동작을 선택하는 경우가 있습니다. 왜 그럴까요?",
    "answer": "옵티마이저가 Full Scan이 더 효율적이라고 판단하기 때문입니다.\n\n주요 원인:\n선택도가 낮은 경우: 전체 데이터의 많은 비율(보통 20% 이상)을 읽어야 할 때\n테이블이 작은 경우: 인덱스 탐색 비용이 Full Scan보다 클 때\n통계 정보 부정확: ANALYZE TABLE로 갱신 필요\n인덱스 컬럼에 함수 적용: WHERE YEAR(created_at) = 2024\n타입 불일치: 암시적 형변환 발생\n\n확인 방법: EXPLAIN으로 type과 rows 확인",
    "references": [
      {
        "title": "MySQL Index Hints",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/index-hints.html"
      }
    ],
    "keywords": [
      "full",
      "scan",
      "analyze",
      "table",
      "where",
      "year",
      "created_at",
      "explain",
      "옵티마이저가",
      "효율적이라고",
      "판단하기",
      "때문입니다",
      "주요",
      "원인",
      "선택도가"
    ]
  },
  {
    "id": "DB-052",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "COUNT (개수를 세는 쿼리) 는 어떻게 동작하나요? COUNT(1), COUNT(\\*), COUNT(column) 의 동작 과정에는 차이가 있나요?",
    "answer": "*COUNT(\\):\n모든 행의 개수를 셈 (NULL 포함)\n옵티마이저가 가장 작은 인덱스 선택\nInnoDB는 실제 행을 카운트 (MyISAM과 다름)\n\nCOUNT(1):*\nCOUNT()와 동일하게 동작\n옵티마이저가 동일하게 최적화\n\nCOUNT(column):\n해당 컬럼이 NULL이 아닌 행만 카운트\nNULL 체크 로직 추가\n해당 컬럼 인덱스가 있으면 활용\n\n성능: COUNT() = COUNT(1) > COUNT(column)",
    "references": [
      {
        "title": "MySQL COUNT Function",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/aggregate-functions.html#function_count"
      }
    ],
    "keywords": [
      "count",
      "null",
      "innodb",
      "myisam",
      "모든",
      "행의",
      "개수를",
      "포함",
      "옵티마이저가",
      "가장",
      "작은",
      "인덱스",
      "선택",
      "실제",
      "행을"
    ]
  },
  {
    "id": "DB-053",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "RDBMS, NoSQL에서의 클러스터링/레플리케이션 방식에 대해 설명해 주세요.",
    "answer": "RDBMS:\nMaster-Slave 레플리케이션: Master에서 쓰기, Slave에서 읽기\nMaster-Master: 양쪽에서 쓰기 가능 (충돌 관리 필요)\nMySQL Group Replication: 동기식 복제\n\nNoSQL:\nMongoDB Replica Set: Primary-Secondary 구조, 자동 failover\nRedis Cluster: 데이터 샤딩 + 레플리케이션\nCassandra: 링 구조, 모든 노드가 동등\n\n차이점:\nRDBMS: 일관성 중시, 동기/비동기 복제\nNoSQL: 가용성 중시, 최종적 일관성 허용",
    "references": [
      {
        "title": "MySQL Replication",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/replication.html"
      }
    ],
    "keywords": [
      "rdbms",
      "master-slave",
      "master",
      "slave",
      "master-master",
      "mysql",
      "group",
      "replication",
      "nosql",
      "mongodb",
      "replica",
      "set",
      "primary-secondary",
      "redis",
      "cluster"
    ]
  },
  {
    "id": "DB-054",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "분산 환경에선, 트랜잭션을 어떻게 관리할 수 있을까요? (e.g., 2PC, Saga)",
    "answer": "2PC (Two-Phase Commit):\nPrepare 단계: 코디네이터가 모든 참여자에게 커밋 준비 요청\nCommit 단계: 모든 참여자가 준비되면 커밋, 하나라도 실패하면 롤백\n강한 일관성, 하지만 블로킹 문제\n\nSaga Pattern:\n로컬 트랜잭션들의 연속\n실패 시 보상 트랜잭션(Compensating Transaction) 실행\nChoreography: 이벤트 기반, 각 서비스가 독립적\nOrchestration: 중앙 조정자가 흐름 제어\n\n선택 기준:\n강한 일관성 필요 → 2PC\n유연성/성능 필요 → Saga",
    "references": [
      {
        "title": "MySQL XA Transactions",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/xa.html"
      }
    ],
    "keywords": [
      "two-phase",
      "commit",
      "prepare",
      "saga",
      "pattern",
      "compensating",
      "transaction",
      "choreography",
      "orchestration",
      "단계",
      "코디네이터가",
      "모든",
      "참여자에게",
      "커밋",
      "준비"
    ]
  },
  {
    "id": "DB-055",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "슬레이브 데이터 동기화 전 까지의 데이터 정합성을 지키는 방법은 무엇이 있을까요?",
    "answer": "방법:\n동기식 복제(Semi-Sync Replication):\n최소 하나의 Slave가 로그 수신 확인 후 커밋\n약간의 지연 발생하지만 데이터 손실 방지\nRead-After-Write 라우팅:\n쓰기 직후 읽기는 Master로 라우팅\n일정 시간 후 Slave로 라우팅\nGTID 기반 읽기:\nGlobal Transaction ID로 복제 위치 추적\n특정 트랜잭션이 복제될 때까지 대기\nProxySQL 등 프록시 활용:\n복제 지연 모니터링\n지연이 큰 Slave 제외",
    "references": [
      {
        "title": "MySQL Semi-Sync Replication",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/replication-semisync.html"
      }
    ],
    "keywords": [
      "semi-sync",
      "replication",
      "slave",
      "read-after-write",
      "master",
      "gtid",
      "global",
      "transaction",
      "proxysql",
      "방법",
      "동기식",
      "복제",
      "최소",
      "하나의",
      "로그"
    ]
  },
  {
    "id": "DB-056",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "만약 본인이 DB를 분산해서 관리해야 한다면, 레플리케이션 방식과 샤딩 방식 중 어떤 것을 사용할 것 같나요?",
    "answer": "상황에 따라 선택합니다.\n\n레플리케이션 선택:\n읽기 트래픽이 많고 쓰기가 적을 때\n고가용성이 중요할 때\n데이터 크기가 단일 서버에 적합할 때\n구현/운영이 간단함\n\n샤딩 선택:\n데이터 크기가 단일 서버 용량 초과\n쓰기 트래픽이 많을 때\n수평 확장이 필요할 때\n복잡하지만 확장성 높음\n\n실무에서:\n먼저 레플리케이션으로 시작하고, 한계에 도달하면 샤딩 도입. 레플리케이션 + 샤딩 조합도 가능합니다.",
    "references": [
      {
        "title": "MySQL Partitioning",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/partitioning.html"
      }
    ],
    "keywords": [
      "상황에",
      "따라",
      "선택합니다",
      "레플리케이션",
      "선택",
      "읽기",
      "트래픽이",
      "많고",
      "쓰기가",
      "적을",
      "고가용성이",
      "중요할",
      "데이터",
      "크기가",
      "단일"
    ]
  },
  {
    "id": "DB-057",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "정규화가 무엇인가요?",
    "answer": "정규화: 데이터 중복을 최소화하고 데이터 무결성을 보장하기 위해 테이블을 분리하는 과정입니다.\n\n목적:\n데이터 중복 제거\n이상현상(Anomaly) 방지\n데이터 무결성 유지\n저장 공간 효율화\n\n정규화 단계:\n1NF → 2NF → 3NF → BCNF → 4NF → 5NF\n\n실무에서는 보통 3NF 또는 BCNF까지 적용합니다.",
    "references": [
      {
        "title": "Database Normalization",
        "url": "https://en.wikipedia.org/wiki/Database_normalization"
      }
    ],
    "keywords": [
      "anomaly",
      "bcnf",
      "정규화",
      "데이터",
      "중복을",
      "최소화하고",
      "무결성을",
      "보장하기",
      "테이블을",
      "분리하는",
      "과정입니다",
      "목적",
      "중복",
      "제거",
      "이상현상"
    ]
  },
  {
    "id": "DB-058",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "정규화를 하지 않을 경우, 발생할 수 있는 이상현상(Anomaly)에 대해 설명해 주세요.",
    "answer": "삽입 이상(Insertion Anomaly):\n불필요한 데이터 없이는 원하는 데이터를 삽입할 수 없음\n예: 수강 테이블에 학생 정보를 넣으려면 과목도 필요\n\n갱신 이상(Update Anomaly):\n중복 데이터 중 일부만 수정되어 불일치 발생\n예: 학과명 변경 시 여러 행을 모두 수정해야 함\n\n삭제 이상(Deletion Anomaly):\n원하는 데이터 삭제 시 다른 필요한 데이터도 삭제됨\n예: 마지막 수강 기록 삭제 시 학생 정보도 삭제",
    "references": [
      {
        "title": "Database Anomalies",
        "url": "https://en.wikipedia.org/wiki/Database_normalization#Normal_forms"
      }
    ],
    "keywords": [
      "insertion",
      "anomaly",
      "update",
      "deletion",
      "삽입",
      "이상",
      "불필요한",
      "데이터",
      "없이는",
      "원하는",
      "데이터를",
      "삽입할",
      "없음",
      "수강",
      "테이블에"
    ]
  },
  {
    "id": "DB-059",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "각 정규화(1NF, 2NF, 3NF, BCNF)에 대해, 그 정규화가 진행되기 전/후의 테이블의 변화에 대해 설명해 주세요.",
    "answer": "1NF (제1정규형):\n조건: 모든 속성이 원자값\n변화: 다중 값을 가진 컬럼을 별도 행으로 분리\n예: 전화번호1, 전화번호2 → 전화번호 테이블 분리\n\n2NF (제2정규형):\n조건: 1NF + 부분 함수 종속 제거\n변화: 복합키의 일부에만 종속된 컬럼 분리\n예: (학번, 과목코드) → 과목명은 과목 테이블로\n\n3NF (제3정규형):\n조건: 2NF + 이행적 함수 종속 제거\n변화: A→B→C 관계에서 B→C를 별도 테이블로\n예: 학번→학과코드→학과명 → 학과 테이블 분리\n\nBCNF:\n조건: 모든 결정자가 후보키\n변화: 후보키가 아닌 결정자를 분리",
    "references": [
      {
        "title": "Normal Forms",
        "url": "https://en.wikipedia.org/wiki/Database_normalization"
      }
    ],
    "keywords": [
      "bcnf",
      "정규형",
      "조건",
      "모든",
      "속성이",
      "원자값",
      "변화",
      "다중",
      "값을",
      "가진",
      "컬럼을",
      "별도",
      "행으로",
      "분리",
      "전화번호"
    ]
  },
  {
    "id": "DB-060",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "정규화가 무조건 좋은가요? 그렇지 않다면, 어떤 상황에서 역정규화를 하는게 좋은지 설명해 주세요.",
    "answer": "정규화의 단점:\nJOIN 증가로 조회 성능 저하\n쿼리 복잡도 증가\n자주 함께 조회되는 데이터가 분산\n\n역정규화(Denormalization)가 필요한 경우:\n읽기 성능이 중요한 경우: 리포트, 대시보드\n빈번한 JOIN 제거: 조회가 많고 변경이 적은 데이터\n계산 값 저장: 집계 결과를 미리 저장\n히스토리 데이터: 변경 시점의 스냅샷 저장\n\n예시:\n주문 테이블에 상품명 중복 저장 (상품명 변경과 무관하게 주문 시점 정보 유지)\n게시글에 댓글 수 저장",
    "references": [
      {
        "title": "Denormalization",
        "url": "https://en.wikipedia.org/wiki/Denormalization"
      }
    ],
    "keywords": [
      "join",
      "denormalization",
      "정규화의",
      "단점",
      "증가로",
      "조회",
      "성능",
      "저하",
      "쿼리",
      "복잡도",
      "증가",
      "자주",
      "함께",
      "조회되는",
      "데이터가"
    ]
  },
  {
    "id": "DB-061",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "View가 무엇이고, 언제 사용할 수 있나요?",
    "answer": "View: 하나 이상의 테이블에서 유도된 가상 테이블로, 실제 데이터를 저장하지 않고 쿼리 결과를 제공합니다.\n\n사용 사례:\n보안: 민감한 컬럼을 제외한 뷰 제공\n복잡한 쿼리 단순화: 자주 사용하는 JOIN 쿼리를 뷰로 정의\n데이터 추상화: 테이블 구조 변경 시 뷰만 수정\n권한 관리: 테이블 대신 뷰에 권한 부여",
    "references": [
      {
        "title": "MySQL CREATE VIEW",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/create-view.html"
      }
    ],
    "keywords": [
      "view",
      "join",
      "하나",
      "이상의",
      "테이블에서",
      "유도된",
      "가상",
      "테이블로",
      "실제",
      "데이터를",
      "저장하지",
      "않고",
      "쿼리",
      "결과를",
      "제공합니다"
    ]
  },
  {
    "id": "DB-062",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "그렇다면, View의 값을 수정해도 실제 테이블에는 반영되지 않나요?",
    "answer": "조건을 만족하면 View를 통해 실제 테이블 수정이 가능합니다.\n\nUpdatable View 조건:\n단일 테이블 기반\n집계 함수 미사용 (SUM, COUNT 등)\nGROUP BY, HAVING, DISTINCT 미사용\nUNION 미사용\n서브쿼리 미사용 (일부 예외)\n\n수정 불가능한 View:\n여러 테이블 JOIN\n집계 결과를 보여주는 View\n읽기 전용으로 설계된 View",
    "references": [
      {
        "title": "MySQL Updatable Views",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/view-updatability.html"
      }
    ],
    "keywords": [
      "view",
      "updatable",
      "sum",
      "count",
      "group",
      "having",
      "distinct",
      "union",
      "join",
      "조건을",
      "만족하면",
      "실제",
      "테이블",
      "수정이",
      "가능합니다"
    ]
  },
  {
    "id": "DB-063",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "트래픽이 높아질 때, DB는 어떻게 관리를 할 수 있을까요? (Scale-up vs Scale-out)",
    "answer": "Scale-up (수직 확장):\nCPU, 메모리, 디스크 등 하드웨어 업그레이드\n장점: 구현 간단, 애플리케이션 변경 불필요\n단점: 비용 급증, 물리적 한계 존재\n\nScale-out (수평 확장):\n서버 수를 늘려 부하 분산\n방법: 레플리케이션, 샤딩, 파티셔닝\n장점: 이론적으로 무한 확장 가능\n단점: 구현 복잡, 분산 트랜잭션 어려움\n\n전략:\n먼저 쿼리 최적화, 인덱싱\n캐시 레이어 추가 (Redis)\nRead Replica 추가\n샤딩 도입",
    "references": [
      {
        "title": "MySQL Scaling",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/optimization.html"
      }
    ],
    "keywords": [
      "scale-up",
      "cpu",
      "scale-out",
      "redis",
      "read",
      "replica",
      "수직",
      "확장",
      "메모리",
      "디스크",
      "하드웨어",
      "업그레이드",
      "장점",
      "구현",
      "간단"
    ]
  },
  {
    "id": "DB-064",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "DB 서버를 분산하지 않고(Scale-out), 트래픽을 감당할 수 있는 방법은 없을까요?",
    "answer": "방법:\n쿼리 최적화:\n인덱스 튜닝\n실행 계획 분석 및 개선\n불필요한 컬럼 조회 제거\n캐싱:\n애플리케이션 레벨 캐시 (Redis, Memcached)\n쿼리 캐시\nORM 2차 캐시\n커넥션 풀 최적화:\n적정 커넥션 수 설정\n커넥션 재사용\n하드웨어 업그레이드:\nSSD 사용\n메모리 증설 (버퍼 풀 확대)\n비동기 처리:\n쓰기 작업 큐잉\n배치 처리",
    "references": [
      {
        "title": "MySQL Performance Tuning",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/optimization.html"
      }
    ],
    "keywords": [
      "redis",
      "memcached",
      "orm",
      "ssd",
      "방법",
      "쿼리",
      "최적화",
      "인덱스",
      "튜닝",
      "실행",
      "계획",
      "분석",
      "개선",
      "불필요한",
      "컬럼"
    ]
  },
  {
    "id": "DB-065",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "Schema가 무엇인가요?",
    "answer": "Schema: 데이터베이스의 구조와 제약조건을 정의한 것입니다.\n\n포함 내용:\n테이블 정의 (컬럼명, 데이터 타입)\n관계 정의 (외래키)\n제약조건 (PRIMARY KEY, UNIQUE, NOT NULL, CHECK)\n인덱스\n뷰, 프로시저, 트리거\n\nMySQL에서:\nSchema = Database (동일 개념)\nCREATE SCHEMA와 CREATE DATABASE는 동의어",
    "references": [
      {
        "title": "MySQL CREATE DATABASE",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/create-database.html"
      }
    ],
    "keywords": [
      "schema",
      "primary",
      "key",
      "unique",
      "null",
      "check",
      "mysql",
      "database",
      "create",
      "데이터베이스의",
      "구조와",
      "제약조건을",
      "정의한",
      "것입니다",
      "포함"
    ]
  },
  {
    "id": "DB-066",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "데이터베이스 3계층(외부/개념/내부 스키마)에 대해 설명해 주세요.",
    "answer": "ANSI/SPARC 3계층 아키텍처:\n\n외부 스키마 (External Schema):\n사용자/애플리케이션 관점\n각 사용자가 보는 데이터 구조\nView로 구현\n\n개념 스키마 (Conceptual Schema):\n전체 데이터베이스의 논리적 구조\n테이블, 관계, 제약조건 정의\n일반적으로 \"스키마\"라고 하면 이것\n\n내부 스키마 (Internal Schema):\n물리적 저장 구조\n인덱스, 파일 구조, 저장 방식\nDBA 관점\n\n데이터 독립성:\n하위 스키마 변경이 상위 스키마에 영향 최소화",
    "references": [
      {
        "title": "Three-Schema Architecture",
        "url": "https://en.wikipedia.org/wiki/Three-schema_approach"
      }
    ],
    "keywords": [
      "ansi",
      "sparc",
      "external",
      "schema",
      "view",
      "conceptual",
      "internal",
      "dba",
      "계층",
      "아키텍처",
      "외부",
      "스키마",
      "사용자",
      "애플리케이션",
      "관점"
    ]
  },
  {
    "id": "DB-067",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "DB의 Connection Pool에 대해 설명해 주세요.",
    "answer": "Connection Pool: 미리 생성된 DB 연결을 재사용하는 기법입니다.\n\n필요 이유:\nDB 연결 생성은 비용이 큼 (TCP 핸드셰이크, 인증)\n매 요청마다 연결 생성/해제는 비효율적\n\n동작 방식:\n애플리케이션 시작 시 N개의 연결 미리 생성\n요청 시 풀에서 연결 획득\n작업 완료 후 연결을 풀에 반환 (연결 유지)\n모든 연결 사용 중이면 대기 또는 새 연결 생성\n\n주요 설정:\n최소/최대 커넥션 수\n유휴 타임아웃\n최대 대기 시간\n\n구현체: HikariCP, DBCP, c3p0",
    "references": [
      {
        "title": "HikariCP",
        "url": "https://github.com/brettwooldridge/HikariCP"
      }
    ],
    "keywords": [
      "connection",
      "pool",
      "tcp",
      "hikaricp",
      "dbcp",
      "미리",
      "생성된",
      "연결을",
      "재사용하는",
      "기법입니다",
      "필요",
      "이유",
      "연결",
      "생성은",
      "비용이"
    ]
  },
  {
    "id": "DB-068",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "Client가 DB Connection을 어떻게 구성하는지 설명해 주세요.",
    "answer": "연결 과정:\nTCP 연결 수립:\n클라이언트가 DB 서버 IP:Port로 TCP 연결\n3-way handshake\n인증:\n사용자명, 비밀번호 전송\nDB 서버가 권한 확인\n세션 설정:\n문자셋, 타임존 등 설정\n연결별 설정 적용\n쿼리 실행:\nSQL 문 전송\n결과 수신\n연결 종료:\n명시적 close() 또는 타임아웃\n\nJDBC 예시:",
    "references": [
      {
        "title": "MySQL Connection Phase",
        "url": "https://dev.mysql.com/doc/dev/mysql-server/latest/page_protocol_connection_phase.html"
      }
    ],
    "keywords": [
      "tcp",
      "port",
      "sql",
      "jdbc",
      "연결",
      "과정",
      "수립",
      "클라이언트가",
      "서버",
      "인증",
      "사용자명",
      "비밀번호",
      "전송",
      "서버가",
      "권한"
    ]
  },
  {
    "id": "DB-069",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "SQL Injection에 대해 설명해 주세요.",
    "answer": "SQL Injection: 사용자 입력에 악의적인 SQL 코드를 삽입하여 DB를 조작하는 공격입니다.\n\n예시:\n\n위험:\n데이터 유출\n데이터 변조/삭제\n인증 우회\n시스템 명령 실행 (일부 DB)\n\n방지 방법:\nPrepared Statement 사용\n입력값 검증\n최소 권한 원칙\nWAF 사용",
    "references": [
      {
        "title": "OWASP SQL Injection",
        "url": "https://owasp.org/www-community/attacks/SQL_Injection"
      }
    ],
    "keywords": [
      "sql",
      "injection",
      "prepared",
      "statement",
      "waf",
      "사용자",
      "입력에",
      "악의적인",
      "코드를",
      "삽입하여",
      "조작하는",
      "공격입니다",
      "예시",
      "위험",
      "데이터"
    ]
  },
  {
    "id": "DB-070",
    "category": "database",
    "categoryName": "Database",
    "priority": "P1",
    "question": "우리가 서버 개발 과정에서 사용하는 수많은 DB 라이브러리(e.g., ORM, JDBC)들은 이 SQL Injection 문제를 어떻게 해결할까요? (e.g., Prepared Statement)",
    "answer": "Prepared Statement (Parameterized Query):\n\nSQL 구조와 데이터를 분리하여 처리합니다.\n\n동작 방식:\nSQL 템플릿을 먼저 DB에 전송 (컴파일)\n파라미터 값을 별도로 전송\nDB가 파라미터를 데이터로만 처리 (SQL로 해석 안 함)\n\nORM에서:\nJPA/Hibernate: 기본적으로 Prepared Statement 사용\n네이티브 쿼리 사용 시 주의 필요\n\n추가 방어:\n입력값 화이트리스트 검증\n이스케이프 처리 (권장하지 않음)",
    "references": [
      {
        "title": "JDBC PreparedStatement",
        "url": "https://docs.oracle.com/javase/tutorial/jdbc/basics/prepared.html"
      }
    ],
    "keywords": [
      "prepared",
      "statement",
      "parameterized",
      "query",
      "sql",
      "orm",
      "jpa",
      "hibernate",
      "구조와",
      "데이터를",
      "분리하여",
      "처리합니다",
      "동작",
      "방식",
      "템플릿을"
    ]
  },
  {
    "id": "DS-001",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "스택 2개로 큐 만들기",
    "answer": "두 개의 스택(inStack, outStack)을 사용하여 큐를 구현합니다.\n\nEnqueue: inStack에 push - O(1)\n\nDequeue: outStack이 비어있으면 inStack의 모든 요소를 outStack으로 이동 후 pop - 분할상환 O(1)",
    "references": [
      {
        "title": "Stack (Java SE 21)",
        "url": "https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/Stack.html"
      }
    ],
    "keywords": [
      "enqueue",
      "dequeue",
      "개의",
      "스택",
      "사용하여",
      "큐를",
      "구현합니다",
      "비어있으면",
      "모든",
      "요소를",
      "으로",
      "이동",
      "분할상환"
    ]
  },
  {
    "id": "DS-002",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "큐 2개로 스택 만들기",
    "answer": "두 개의 큐(q1, q2)를 사용하여 스택을 구현합니다.\n\nPush: q1에 enqueue - O(1)\n\nPop: q1의 마지막 요소를 제외한 모든 요소를 q2로 이동, 마지막 요소 반환 후 q1과 q2 교환 - O(n)",
    "references": [
      {
        "title": "Queue (Java SE 21)",
        "url": "https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/Queue.html"
      }
    ],
    "keywords": [
      "push",
      "pop",
      "개의",
      "사용하여",
      "스택을",
      "구현합니다",
      "마지막",
      "요소를",
      "제외한",
      "모든",
      "이동",
      "요소",
      "반환",
      "교환"
    ]
  },
  {
    "id": "DS-003",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Prefix, Infix, Postfix 에 대해 설명하고, 이를 스택을 활용해서 계산/하는 방법에 대해 설명해 주세요.",
    "answer": "표기법 종류\nInfix: 연산자가 피연산자 사이에 위치 (예: A + B)\nPrefix: 연산자가 피연산자 앞에 위치 (예: + A B)\nPostfix: 연산자가 피연산자 뒤에 위치 (예: A B +)\n\nPostfix 계산 (스택 활용)\n피연산자면 스택에 push\n연산자면 스택에서 두 개를 pop하여 연산 후 결과를 push\n최종적으로 스택에 남은 값이 결과\n\nInfix → Postfix 변환\n피연산자는 바로 출력\n연산자는 스택의 top보다 우선순위가 높으면 push, 아니면 pop 후 push\n여는 괄호는 push, 닫는 괄호는 여는 괄호까지 pop",
    "references": [
      {
        "title": "Expression Evaluation - GeeksforGeeks",
        "url": "https://www.geeksforgeeks.org/expression-evaluation/"
      }
    ],
    "keywords": [
      "infix",
      "prefix",
      "postfix",
      "표기법",
      "종류",
      "연산자가",
      "피연산자",
      "사이에",
      "위치",
      "앞에",
      "뒤에",
      "계산",
      "스택",
      "활용",
      "피연산자면"
    ]
  },
  {
    "id": "DS-004",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "(C++ 한정) Deque의 Random Access 시간복잡도는 O(1) 입니다. 이게 어떻게 가능한걸까요?",
    "answer": "C++ deque는 청크(chunk) 기반 구조로 구현됩니다.\n\n구조\n고정 크기의 청크 배열들과 이를 가리키는 포인터 배열(map)로 구성\n각 청크는 연속된 메모리 블록\n\nRandom Access 원리\nindex를 청크 크기로 나누어 어떤 청크인지 계산 - O(1)\n나머지로 청크 내 위치 계산 - O(1)\nmap 배열에서 해당 청크 포인터 접근 - O(1)",
    "references": [
      {
        "title": "std::deque - cppreference",
        "url": "https://en.cppreference.com/w/cpp/container/deque"
      }
    ],
    "keywords": [
      "random",
      "access",
      "청크",
      "기반",
      "구조로",
      "구현됩니다",
      "구조",
      "고정",
      "크기의",
      "배열들과",
      "이를",
      "가리키는",
      "포인터",
      "배열",
      "구성"
    ]
  },
  {
    "id": "DS-005",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "해시 자료구조에 대해 설명해 주세요.",
    "answer": "해시 테이블은 키(Key)를 해시 함수를 통해 인덱스로 변환하여 값(Value)을 저장하는 자료구조입니다.\n\n구성 요소\n해시 함수: 키를 고정 크기의 해시값으로 변환\n버킷/슬롯: 실제 데이터가 저장되는 공간\n충돌 처리: 같은 해시값을 가진 키들을 처리하는 방법\n\n시간복잡도\n평균: 삽입, 삭제, 검색 모두 O(1)\n최악(모든 키가 충돌): O(n)",
    "references": [
      {
        "title": "HashMap (Java SE 21)",
        "url": "https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/HashMap.html"
      }
    ],
    "keywords": [
      "key",
      "value",
      "해시",
      "테이블은",
      "함수를",
      "인덱스로",
      "변환하여",
      "저장하는",
      "자료구조입니다",
      "구성",
      "요소",
      "함수",
      "키를",
      "고정",
      "크기의"
    ]
  },
  {
    "id": "DS-006",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "값이 주어졌을 때, 어떻게 하면 충돌이 최대한 적은 해시 함수를 설계할 수 있을까요?",
    "answer": "좋은 해시 함수의 조건\n균등 분포: 해시값이 버킷 전체에 고르게 분포\n결정적: 같은 입력에 항상 같은 출력\n빠른 계산: O(1) 시간 내 계산 가능\n\n설계 기법\n나눗셈법: h(k) = k mod m (m은 소수 권장)\n곱셈법: h(k) = floor(m  (k  A mod 1)) (A는 황금비 등)\n문자열: 다항식 해싱 h = s[0]p^(n-1) + s[1]p^(n-2) + ...\n\n실용적 팁\n테이블 크기를 소수로 설정\n입력 데이터의 특성 분석 후 적합한 함수 선택",
    "references": [
      {
        "title": "Hash function - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Hash_function"
      }
    ],
    "keywords": [
      "좋은",
      "해시",
      "함수의",
      "조건",
      "균등",
      "분포",
      "해시값이",
      "버킷",
      "전체에",
      "고르게",
      "결정적",
      "같은",
      "입력에",
      "항상",
      "출력"
    ]
  },
  {
    "id": "DS-007",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "해시값이 충돌했을 때, 어떤 방식으로 처리할 수 있을까요?",
    "answer": "체이닝 (Chaining)\n각 버킷에 연결 리스트(또는 트리)를 두어 충돌 요소들을 연결\n장점: 구현 간단, 삭제 용이\n단점: 추가 메모리 필요\n개방 주소법 (Open Addressing)\n선형 탐사: 충돌 시 다음 버킷으로 이동 h(k, i) = (h(k) + i) mod m\n이차 탐사: h(k, i) = (h(k) + c1i + c2i^2) mod m\n이중 해싱: h(k, i) = (h1(k) + i*h2(k)) mod m\n\n방식   클러스터링   캐시 성능   삭제\n\n체이닝   없음   낮음   쉬움\n선형 탐사   심함   높음   어려움\n이중 해싱   적음   중간   어려움",
    "references": [
      {
        "title": "Hash table - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Hash_table#Collision_resolution"
      }
    ],
    "keywords": [
      "chaining",
      "open",
      "addressing",
      "체이닝",
      "버킷에",
      "연결",
      "리스트",
      "트리",
      "두어",
      "충돌",
      "요소들을",
      "장점",
      "구현",
      "간단",
      "삭제"
    ]
  },
  {
    "id": "DS-008",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "본인이 사용하는 언어에서는, 어떤 방식으로 해시 충돌을 처리하나요?",
    "answer": "Java (HashMap)\n체이닝 방식 사용\nJava 8 이후: 버킷 내 요소가 8개 이상이면 연결 리스트를 Red-Black Tree로 변환\n6개 이하로 줄어들면 다시 연결 리스트로 변환\n이를 통해 최악의 경우에도 O(log n) 보장\n\nPython (dict)\n개방 주소법 (Pseudo-random probing) 사용\n해시값을 기반으로 의사 난수 탐사 수행\n\nC++ (unordered_map)\n체이닝 방식 사용\n연결 리스트로 충돌 처리",
    "references": [
      {
        "title": "HashMap (Java SE 21)",
        "url": "https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/HashMap.html"
      }
    ],
    "keywords": [
      "java",
      "hashmap",
      "red-black",
      "tree",
      "python",
      "pseudo-random",
      "unordered_map",
      "체이닝",
      "방식",
      "사용",
      "이후",
      "버킷",
      "요소가",
      "이상이면",
      "연결"
    ]
  },
  {
    "id": "DS-009",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Double Hashing 의 장점과 단점에 대해서 설명하고, 단점을 어떻게 해결할 수 있을지 설명해 주세요.",
    "answer": "Double Hashing: h(k, i) = (h1(k) + i * h2(k)) mod m\n\n장점\n1차/2차 클러스터링 문제 해결\n선형/이차 탐사보다 균등한 분포\n테이블 전체를 효율적으로 활용\n\n단점\n해시 함수 2개 계산으로 오버헤드 증가\nh2(k)가 0이 되면 무한 루프 발생 가능\n캐시 지역성이 떨어짐\n\n해결 방법\nh2(k)가 0이 되지 않도록 설계: h2(k) = 1 + (k mod (m-1))\n테이블 크기 m을 소수로 설정하여 모든 슬롯 탐사 보장\n캐시 문제는 클러스터 단위 탐사로 완화 가능",
    "references": [
      {
        "title": "Double hashing - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Double_hashing"
      }
    ],
    "keywords": [
      "double",
      "hashing",
      "장점",
      "클러스터링",
      "문제",
      "해결",
      "선형",
      "이차",
      "탐사보다",
      "균등한",
      "분포",
      "테이블",
      "전체를",
      "효율적으로",
      "활용"
    ]
  },
  {
    "id": "DS-010",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Load Factor에 대해 설명해 주세요. 본인이 사용하는 언어에서의 해시 자료구조는 Load Factor에 관련한 정책이 어떻게 구성되어 있나요?",
    "answer": "Load Factor (적재율) = 저장된 요소 수 / 버킷 수\n\nLoad Factor가 높아지면 충돌 확률이 증가하여 성능이 저하됩니다.\n\nJava HashMap 정책\n기본 Load Factor: 0.75\n기본 초기 용량: 16\nLoad Factor 초과 시 용량을 2배로 확장 (rehashing)\n생성자에서 초기 용량과 Load Factor 지정 가능\n\nPython dict\nLoad Factor 약 2/3 (0.67) 유지\n초과 시 4배 또는 2배로 확장\n\nC++ unorderedmap\n기본 maxloadfactor: 1.0\nmaxload_factor() 메서드로 조정 가능",
    "references": [
      {
        "title": "HashMap (Java SE 21)",
        "url": "https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/HashMap.html"
      }
    ],
    "keywords": [
      "load",
      "factor",
      "java",
      "hashmap",
      "python",
      "maxload_factor",
      "적재율",
      "저장된",
      "요소",
      "버킷",
      "높아지면",
      "충돌",
      "확률이",
      "증가하여",
      "성능이"
    ]
  },
  {
    "id": "DS-011",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "다른 자료구조와 비교하여, 해시 테이블은 멀티스레드 환경에서 심각한 수준의 Race Condition 문제에 빠질 위험이 있습니다. 성능 감소를 최소화 한 채로 해당 문제를 해결할 수 있는 방법을 설계해 보세요.",
    "answer": "문제점: rehashing, 체이닝 수정 등에서 Race Condition 발생\n\n해결 방법\n세분화된 락 (Lock Striping)\n전체 테이블이 아닌 버킷 그룹별로 락 적용\nJava ConcurrentHashMap이 사용하는 방식\n동시에 다른 세그먼트 접근 가능\nLock-Free 구조\nCAS(Compare-And-Swap) 연산 활용\n체이닝의 연결 리스트를 atomic하게 수정\nCopy-on-Write\n수정 시 새 버킷 배열 생성\n읽기 작업이 많은 경우 효율적\nRead-Write Lock\n읽기는 동시에, 쓰기는 배타적으로\nReentrantReadWriteLock 활용\n\nJava ConcurrentHashMap 특징\n세분화된 락 + CAS 조합\n읽기는 락 없이 수행\nputIfAbsent, computeIfAbsent 등 원자적 연산 제공",
    "references": [
      {
        "title": "ConcurrentHashMap (Java SE 21)",
        "url": "https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/ConcurrentHashMap.html"
      }
    ],
    "keywords": [
      "race",
      "condition",
      "lock",
      "striping",
      "java",
      "concurrenthashmap",
      "lock-free",
      "cas",
      "compare-and-swap",
      "copy-on-write",
      "read-write",
      "reentrantreadwritelock",
      "문제점",
      "체이닝",
      "수정"
    ]
  },
  {
    "id": "DS-012",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "트리와 이진트리, 이진탐색트리에 대해 설명해 주세요.",
    "answer": "트리 (Tree)\n노드와 간선으로 구성된 계층적 자료구조\n사이클이 없는 연결 그래프\n루트 노드에서 모든 노드로 유일한 경로 존재\n\n이진 트리 (Binary Tree)\n각 노드가 최대 2개의 자식을 가지는 트리\n왼쪽 자식, 오른쪽 자식으로 구분\n종류: 완전 이진 트리, 포화 이진 트리, 편향 이진 트리\n\n이진 탐색 트리 (BST)\n이진 트리에 정렬 속성 추가\n왼쪽 서브트리: 현재 노드보다 작은 값\n오른쪽 서브트리: 현재 노드보다 큰 값\n중복 허용 여부는 구현에 따라 다름",
    "references": [
      {
        "title": "Binary search tree - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Binary_search_tree"
      }
    ],
    "keywords": [
      "tree",
      "binary",
      "bst",
      "트리",
      "노드와",
      "간선으로",
      "구성된",
      "계층적",
      "자료구조",
      "사이클이",
      "없는",
      "연결",
      "그래프",
      "루트",
      "노드에서"
    ]
  },
  {
    "id": "DS-013",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "이진탐색트리에서 중위 탐색을 하게 되면, 그 결과는 어떤 의미를 가지나요?",
    "answer": "중위 순회 (Inorder Traversal): 왼쪽 → 현재 → 오른쪽\n\nBST에서 중위 순회를 수행하면 오름차순으로 정렬된 결과를 얻습니다.\n\n이유\nBST 속성상 왼쪽 서브트리의 모든 값 < 현재 노드 < 오른쪽 서브트리의 모든 값\n중위 순회는 왼쪽을 먼저 방문하므로 작은 값부터 출력\n\n활용\nBST가 올바르게 구성되었는지 검증\nk번째 작은/큰 원소 찾기\n정렬된 데이터 출력",
    "references": [
      {
        "title": "Tree traversal - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Tree_traversal#In-order"
      }
    ],
    "keywords": [
      "inorder",
      "traversal",
      "bst",
      "중위",
      "순회",
      "왼쪽",
      "현재",
      "오른쪽",
      "에서",
      "순회를",
      "수행하면",
      "오름차순으로",
      "정렬된",
      "결과를",
      "얻습니다"
    ]
  },
  {
    "id": "DS-014",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "이진탐색트리의 주요 연산에 대한 시간복잡도를 설명하고, 왜 그런 시간복잡도가 도출되는지 설명해 주세요.",
    "answer": "시간복잡도\n연산   평균   최악\n\n검색   O(log n)   O(n)\n삽입   O(log n)   O(n)\n삭제   O(log n)   O(n)\n\n평균 O(log n) 이유\n균형 잡힌 BST의 높이는 log n\n각 연산은 루트에서 리프까지 한 경로만 탐색\n각 단계에서 탐색 범위가 절반으로 감소\n\n최악 O(n) 이유\n편향 트리(Skewed Tree)인 경우\n예: 1, 2, 3, 4, 5 순서로 삽입하면 오른쪽으로만 편향\n높이가 n이 되어 연결 리스트와 동일한 성능",
    "references": [
      {
        "title": "Binary search tree - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Binary_search_tree#Time_complexity"
      }
    ],
    "keywords": [
      "bst",
      "skewed",
      "tree",
      "시간복잡도",
      "연산",
      "평균",
      "최악",
      "검색",
      "삽입",
      "삭제",
      "이유",
      "균형",
      "잡힌",
      "높이는",
      "연산은"
    ]
  },
  {
    "id": "DS-015",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "이진탐색트리의 한계점에 대해 설명해주세요.",
    "answer": "편향 문제\n삽입 순서에 따라 한쪽으로 치우칠 수 있음\n최악의 경우 연결 리스트와 동일한 O(n) 성능\n균형 유지 불가\n기본 BST는 자체적으로 균형을 맞추지 않음\n삽입/삭제 시 균형이 깨질 수 있음\n재균형 비용\n균형을 맞추려면 추가 작업(회전 등) 필요\nAVL, Red-Black Tree 등 별도 자료구조 필요\n중복 처리 복잡\n중복 키 처리 정책이 필요\n왼쪽/오른쪽 어디에 넣을지, 또는 카운트 방식 등\n\n해결책: AVL Tree, Red-Black Tree 등 자가 균형 BST 사용",
    "references": [
      {
        "title": "Self-balancing binary search tree - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Self-balancing_binary_search_tree"
      }
    ],
    "keywords": [
      "bst",
      "avl",
      "red-black",
      "tree",
      "편향",
      "문제",
      "삽입",
      "순서에",
      "따라",
      "한쪽으로",
      "치우칠",
      "있음",
      "최악의",
      "연결",
      "리스트와"
    ]
  },
  {
    "id": "DS-016",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "이진탐색트리의 값 삽입, 삭제 방법에 대해 설명하고, 어떤식으로 값을 삽입하면 편향이 발생할까요?",
    "answer": "삽입\n루트부터 시작하여 값을 비교\n작으면 왼쪽, 크면 오른쪽으로 이동\nnull 위치에 도달하면 새 노드 삽입\n\n삭제\n리프 노드: 단순히 삭제\n자식 1개: 자식을 현재 위치로 이동\n자식 2개:\n오른쪽 서브트리의 최솟값(후속자) 또는 왼쪽 서브트리의 최댓값(선행자)을 찾음\n해당 값으로 현재 노드 대체 후 그 노드 삭제\n\n편향 발생 케이스\n정렬된 데이터 삽입: 1, 2, 3, 4, 5 → 오른쪽 편향\n역순 정렬 데이터: 5, 4, 3, 2, 1 → 왼쪽 편향\n특정 패턴: 1, 10, 2, 9, 3, 8 → 지그재그 편향",
    "references": [
      {
        "title": "Binary search tree operations",
        "url": "https://en.wikipedia.org/wiki/Binary_search_tree#Operations"
      }
    ],
    "keywords": [
      "삽입",
      "루트부터",
      "시작하여",
      "값을",
      "비교",
      "작으면",
      "왼쪽",
      "크면",
      "오른쪽으로",
      "이동",
      "위치에",
      "도달하면",
      "노드",
      "삭제",
      "리프"
    ]
  },
  {
    "id": "DS-017",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "이진탐색트리와 동일한 로직을 사용하면, 삼진탐색트리도 정의할 수 있을까요? 안 된다면, 그 이유에 대해 설명해 주세요.",
    "answer": "단순 확장은 불가능합니다.\n\n이유\n\n이진탐색트리는 2개의 자식과 1개의 기준값으로 \"작다/크다\"를 명확히 구분합니다. 삼진탐색트리로 확장하려면:\n기준값 2개 필요: 3개의 자식을 구분하려면 2개의 키 값이 필요\n구간 정의: 작음 / 사이 / 큼 으로 3구간 분할\n\n이는 2-3 Tree와 유사한 구조가 됩니다:\n각 노드에 1~2개의 키\n2개의 키가 있으면 3개의 자식\n\n결론\n단순히 자식 수만 3개로 늘리는 것은 불가능하며, B-Tree 계열처럼 노드 내 키 개수도 함께 늘려야 합니다. 이 경우 구현 복잡도가 증가하고, 실질적인 이점이 적어 실제로는 거의 사용되지 않습니다.",
    "references": [
      {
        "title": "2-3 tree - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/2%E2%80%933_tree"
      }
    ],
    "keywords": [
      "tree",
      "b-tree",
      "단순",
      "확장은",
      "불가능합니다",
      "이유",
      "이진탐색트리는",
      "개의",
      "자식과",
      "기준값으로",
      "작다",
      "크다",
      "명확히",
      "구분합니다",
      "삼진탐색트리로"
    ]
  },
  {
    "id": "DS-018",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "힙에 대해 설명해 주세요.",
    "answer": "힙 (Heap)은 완전 이진 트리 형태의 자료구조로, 힙 속성을 만족합니다.\n\n종류\n최대 힙 (Max Heap): 부모 >= 자식\n최소 힙 (Min Heap): 부모 <= 자식\n\n특징\n루트에 최댓값(최대 힙) 또는 최솟값(최소 힙) 위치\n삽입/삭제: O(log n)\n최댓값/최솟값 조회: O(1)\n완전 이진 트리이므로 배열로 효율적 구현 가능\n\n활용\n우선순위 큐 구현\n힙 정렬\n다익스트라 알고리즘\n중앙값 찾기 (최대 힙 + 최소 힙)",
    "references": [
      {
        "title": "PriorityQueue (Java SE 21)",
        "url": "https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/PriorityQueue.html"
      }
    ],
    "keywords": [
      "heap",
      "max",
      "min",
      "완전",
      "이진",
      "트리",
      "형태의",
      "자료구조로",
      "속성을",
      "만족합니다",
      "종류",
      "최대",
      "부모",
      "자식",
      "최소"
    ]
  },
  {
    "id": "DS-019",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "힙을 배열로 구현한다고 가정하면, 어떻게 값을 저장할 수 있을까요?",
    "answer": "완전 이진 트리의 특성을 활용하여 배열에 레벨 순서로 저장합니다.\n\n인덱스 관계 (0-based)\n부모: (i - 1) / 2\n왼쪽 자식: 2  i + 1\n오른쪽 자식: 2  i + 2\n\n인덱스 관계 (1-based)\n부모: i / 2\n왼쪽 자식: 2  i\n오른쪽 자식: 2  i + 1\n\n장점\n포인터 없이 인덱스 연산으로 부모/자식 접근 O(1)\n메모리 효율적 (노드 포인터 불필요)\n캐시 지역성 우수",
    "references": [
      {
        "title": "Binary heap - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Binary_heap#Heap_implementation"
      }
    ],
    "keywords": [
      "완전",
      "이진",
      "트리의",
      "특성을",
      "활용하여",
      "배열에",
      "레벨",
      "순서로",
      "저장합니다",
      "인덱스",
      "관계",
      "부모",
      "왼쪽",
      "자식",
      "오른쪽"
    ]
  },
  {
    "id": "DS-020",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "힙의 삽입, 삭제 방식에 대해 설명하고, 왜 이진탐색트리와 달리 편향이 발생하지 않는지 설명해 주세요.",
    "answer": "삽입 (Insert)\n배열의 맨 끝(마지막 레벨의 가장 오른쪽)에 삽입\nHeapify-up: 부모와 비교하여 힙 속성 위반 시 교환, 루트까지 반복\n\n삭제 (Delete Root)\n루트와 마지막 요소 교환\n마지막 요소 제거\nHeapify-down: 자식과 비교하여 힙 속성 위반 시 교환, 리프까지 반복\n\n편향이 발생하지 않는 이유\n\n힙은 완전 이진 트리를 항상 유지합니다:\n삽입: 항상 마지막 위치에 추가\n삭제: 마지막 요소로 대체\n\n따라서 트리의 높이는 항상 log n으로 유지되며, BST처럼 삽입 순서에 따라 편향될 수 없습니다.",
    "references": [
      {
        "title": "Binary heap operations",
        "url": "https://en.wikipedia.org/wiki/Binary_heap#Insert"
      }
    ],
    "keywords": [
      "insert",
      "heapify-up",
      "delete",
      "root",
      "heapify-down",
      "bst",
      "삽입",
      "배열의",
      "마지막",
      "레벨의",
      "가장",
      "오른쪽",
      "부모와",
      "비교하여",
      "속성"
    ]
  },
  {
    "id": "DS-021",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "힙 정렬의 시간복잡도는 어떻게 되나요? Stable 한가요?",
    "answer": "시간복잡도\n힙 구성: O(n) - Bottom-up heapify\n정렬: O(n log n) - n개 요소 각각 O(log n) 삭제\n전체: O(n log n) - 최선, 평균, 최악 모두 동일\n\n공간복잡도: O(1) - 제자리 정렬 (In-place)\n\nStable 여부: 아니오 (Unstable)\n\n같은 값을 가진 요소들의 상대적 순서가 보장되지 않습니다.\n\n예시\n\n힙 연산 중 루트와 마지막 요소 교환 과정에서 원래 순서가 깨집니다.",
    "references": [
      {
        "title": "Heapsort - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Heapsort"
      }
    ],
    "keywords": [
      "bottom-up",
      "in-place",
      "stable",
      "unstable",
      "시간복잡도",
      "구성",
      "정렬",
      "요소",
      "각각",
      "삭제",
      "전체",
      "최선",
      "평균",
      "최악",
      "모두"
    ]
  },
  {
    "id": "DS-022",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "BBST (Balanced Binary Search Tree) 와, 그 종류에 대해 설명해 주세요.",
    "answer": "BBST (균형 이진 탐색 트리)는 삽입/삭제 시 자동으로 균형을 유지하여 O(log n) 성능을 보장하는 BST입니다.\n\n주요 종류\n\n종류   균형 조건   특징\n\nAVL Tree   좌우 높이 차이 <= 1   엄격한 균형, 검색 빠름\nRed-Black Tree   색상 규칙 4가지   삽입/삭제 빠름, 실무 많이 사용\n2-3 Tree   모든 리프 같은 깊이   B-Tree의 기초\n2-3-4 Tree   노드당 2~4개 자식   Red-Black Tree와 동치\nB-Tree   디스크 최적화   데이터베이스에서 사용\nSplay Tree   최근 접근 노드를 루트로   분할상환 O(log n)",
    "references": [
      {
        "title": "Self-balancing BST - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Self-balancing_binary_search_tree"
      }
    ],
    "keywords": [
      "bbst",
      "bst",
      "avl",
      "tree",
      "red-black",
      "b-tree",
      "splay",
      "균형",
      "이진",
      "탐색",
      "트리",
      "삽입",
      "삭제",
      "자동으로",
      "균형을"
    ]
  },
  {
    "id": "DS-023",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Red Black Tree는 어떻게 균형을 유지할 수 있을까요?",
    "answer": "Red-Black Tree는 색상 규칙과 회전 연산을 통해 균형을 유지합니다.\n\n균형 유지 방법\n삽입 시\n새 노드를 RED로 삽입\n규칙 위반 시 다음 연산 수행:\nRecoloring: 부모/삼촌이 RED면 색상 변경\nRotation: 부모가 RED, 삼촌이 BLACK이면 회전\n삭제 시\nBLACK 노드 삭제 시 \"이중 흑색\" 문제 발생\n형제 노드의 색상에 따라 회전 및 재색칠\n\n회전 연산\nLeft Rotation: 오른쪽 자식을 부모로 올림\nRight Rotation: 왼쪽 자식을 부모로 올림\n\n이 규칙들로 인해 가장 긴 경로가 가장 짧은 경로의 2배를 넘지 않아 균형이 유지됩니다.",
    "references": [
      {
        "title": "Red-black tree - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Red%E2%80%93black_tree#Insertion"
      }
    ],
    "keywords": [
      "red-black",
      "tree",
      "red",
      "recoloring",
      "rotation",
      "black",
      "left",
      "right",
      "색상",
      "규칙과",
      "회전",
      "연산을",
      "균형을",
      "유지합니다",
      "균형"
    ]
  },
  {
    "id": "DS-024",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Red Black Tree의 주요 성질 4가지에 대해 설명해 주세요.",
    "answer": "Red-Black Tree의 5가지 성질 (주요 4가지 + 1)\n모든 노드는 RED 또는 BLACK\n루트 노드는 BLACK\n모든 리프(NIL)는 BLACK\n실제 데이터가 없는 NIL 노드도 BLACK으로 취급\nRED 노드의 자식은 모두 BLACK (No Double Red)\nRED 노드가 연속으로 나타날 수 없음\nBlack Height 일관성\n임의의 노드에서 리프까지의 모든 경로에서 BLACK 노드 수가 동일\n\n이 성질들의 결과\n가장 긴 경로(RED-BLACK 교대) <= 2  가장 짧은 경로(BLACK만)\n높이가 최대 2  log(n+1)로 제한\n모든 연산이 O(log n) 보장",
    "references": [
      {
        "title": "Red-black tree properties",
        "url": "https://en.wikipedia.org/wiki/Red%E2%80%93black_tree#Properties"
      }
    ],
    "keywords": [
      "red-black",
      "tree",
      "red",
      "black",
      "nil",
      "double",
      "height",
      "가지",
      "성질",
      "주요",
      "모든",
      "노드는",
      "루트",
      "리프",
      "실제"
    ]
  },
  {
    "id": "DS-025",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "2-3-4 Tree, AVL Tree 등의 다른 BBST 가 있음에도, 왜 Red Black Tree가 많이 사용될까요?",
    "answer": "Red-Black Tree의 장점\n삽입/삭제 성능\nAVL Tree보다 회전 횟수가 적음\n삽입: 최대 2회 회전, 삭제: 최대 3회 회전\nAVL은 삭제 시 O(log n)회 회전 가능\n구현 단순성\n2-3-4 Tree보다 구현이 간단 (노드 타입이 하나)\n2-3-4 Tree는 노드 분할/병합 로직 복잡\n균형 유지 비용\n트리   삽입 회전   삭제 회전\n\nAVL   O(log n)   O(log n)\nRed-Black   O(1)   O(1)\n실제 사용 사례\nJava: TreeMap, TreeSet\nC++ STL: map, set\nLinux: CFS 스케줄러\n\nAVL이 나은 경우: 검색이 삽입/삭제보다 훨씬 많은 경우 (더 엄격한 균형)",
    "references": [
      {
        "title": "TreeMap (Java SE 21)",
        "url": "https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/TreeMap.html"
      }
    ],
    "keywords": [
      "red-black",
      "tree",
      "avl",
      "java",
      "treemap",
      "treeset",
      "stl",
      "linux",
      "cfs",
      "장점",
      "삽입",
      "삭제",
      "성능",
      "보다",
      "회전"
    ]
  },
  {
    "id": "DS-026",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "정렬 알고리즘에 대해 설명해 주세요.",
    "answer": "정렬 알고리즘은 데이터를 특정 순서로 재배열하는 알고리즘입니다.\n\n분류\n\n알고리즘   평균   최악   공간   Stable\n\nBubble Sort   O(n^2)   O(n^2)   O(1)   Yes\nSelection Sort   O(n^2)   O(n^2)   O(1)   No\nInsertion Sort   O(n^2)   O(n^2)   O(1)   Yes\nMerge Sort   O(n log n)   O(n log n)   O(n)   Yes\nQuick Sort   O(n log n)   O(n^2)   O(log n)   No\nHeap Sort   O(n log n)   O(n log n)   O(1)   No\nCounting Sort   O(n+k)   O(n+k)   O(k)   Yes\nRadix Sort   O(d(n+k))   O(d(n+k))   O(n+k)   Yes\n\n비교 기반 정렬의 하한: O(n log n)\n\n비교 기반 정렬은 결정 트리로 모델링되며, 최소 n!개의 리프가 필요하므로 높이는 최소 log(n!) = O(n log n)",
    "references": [
      {
        "title": "Sorting algorithm - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Sorting_algorithm"
      }
    ],
    "keywords": [
      "stable",
      "bubble",
      "sort",
      "yes",
      "selection",
      "insertion",
      "merge",
      "quick",
      "heap",
      "counting",
      "radix",
      "정렬",
      "알고리즘은",
      "데이터를",
      "특정"
    ]
  },
  {
    "id": "DS-027",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Quick Sort와 Merge Sort를 비교해 주세요.",
    "answer": "항목   Quick Sort   Merge Sort\n\n평균 시간   O(n log n)   O(n log n)\n최악 시간   O(n^2)   O(n log n)\n공간   O(log n)   O(n)\nStable   No   Yes\n방식   분할 정복 (In-place)   분할 정복\n캐시 효율   좋음   보통\n\nQuick Sort 장점\nIn-place로 메모리 효율적\n캐시 지역성이 좋아 실제로 더 빠름\n평균적으로 상수 계수가 작음\n\nMerge Sort 장점\n최악에도 O(n log n) 보장\nStable 정렬\n연결 리스트 정렬에 적합 (O(1) 공간)\n병렬화 용이\n\n선택 기준\n일반적인 경우: Quick Sort\n안정성 필요: Merge Sort\n최악 보장 필요: Merge Sort",
    "references": [
      {
        "title": "Quicksort - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Quicksort"
      }
    ],
    "keywords": [
      "quick",
      "sort",
      "merge",
      "stable",
      "yes",
      "in-place",
      "항목",
      "평균",
      "시간",
      "최악",
      "공간",
      "방식",
      "분할",
      "정복",
      "캐시"
    ]
  },
  {
    "id": "DS-028",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Quick Sort에서 O(N^2)이 걸리는 예시를 들고, 이를 개선할 수 있는 방법에 대해 설명해 주세요.",
    "answer": "O(n^2) 발생 예시\n이미 정렬된 배열에서 첫 번째/마지막 요소를 피벗으로 선택\n매번 1개와 n-1개로 분할 → n + (n-1) + ... + 1 = O(n^2)\n\n개선 방법\nRandomized Pivot\n피벗을 무작위로 선택\n최악 확률이 매우 낮아짐\nMedian of Three\n첫 번째, 중간, 마지막 중 중앙값을 피벗으로 선택\n정렬/역정렬 데이터에서 효과적\nIntro Sort\nQuick Sort + Heap Sort 혼합\n재귀 깊이가 2*log(n) 초과 시 Heap Sort로 전환\nC++ STL sort가 사용\n3-way Partitioning\n중복이 많은 데이터에 효과적\n피벗보다 작은/같은/큰 세 그룹으로 분할",
    "references": [
      {
        "title": "Quicksort - Worst case",
        "url": "https://en.wikipedia.org/wiki/Quicksort#Worst-case_analysis"
      }
    ],
    "keywords": [
      "randomized",
      "pivot",
      "median",
      "three",
      "intro",
      "sort",
      "quick",
      "heap",
      "stl",
      "partitioning",
      "발생",
      "예시",
      "이미",
      "정렬된",
      "배열에서"
    ]
  },
  {
    "id": "DS-029",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Stable Sort가 무엇이고, 어떤 정렬 알고리즘이 Stable 한지 설명해 주세요.",
    "answer": "Stable Sort: 같은 키를 가진 요소들의 상대적 순서가 정렬 후에도 유지되는 정렬\n\n예시\n\nStable 알고리즘\nBubble Sort\nInsertion Sort\nMerge Sort\nCounting Sort\nRadix Sort\nTim Sort\n\nUnstable 알고리즘\nSelection Sort\nQuick Sort\nHeap Sort\n\n중요성\n다중 키 정렬: 먼저 2차 키로 정렬 후 1차 키로 Stable 정렬\n데이터베이스: 기존 순서 유지 필요 시",
    "references": [
      {
        "title": "Sorting algorithm stability",
        "url": "https://en.wikipedia.org/wiki/Sorting_algorithm#Stability"
      }
    ],
    "keywords": [
      "stable",
      "sort",
      "bubble",
      "insertion",
      "merge",
      "counting",
      "radix",
      "tim",
      "unstable",
      "selection",
      "quick",
      "heap",
      "같은",
      "키를",
      "가진"
    ]
  },
  {
    "id": "DS-030",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Merge Sort를 재귀를 사용하지 않고 구현할 수 있을까요?",
    "answer": "네, Bottom-Up 방식으로 반복문을 사용하여 구현할 수 있습니다.\n\nBottom-Up Merge Sort\n크기 1인 부분 배열부터 시작\n인접한 부분 배열들을 병합\n부분 배열 크기를 2배씩 늘려가며 반복\n\n장점\n스택 오버플로우 위험 없음\n호출 스택 오버헤드 없음\n연결 리스트에서 특히 효율적 (O(1) 공간)\n\n단점\nTop-Down보다 코드가 약간 복잡\n캐시 효율이 약간 낮을 수 있음",
    "references": [
      {
        "title": "Merge sort - Bottom-up",
        "url": "https://en.wikipedia.org/wiki/Merge_sort#Bottom-up_implementation"
      }
    ],
    "keywords": [
      "bottom-up",
      "merge",
      "sort",
      "top-down",
      "방식으로",
      "반복문을",
      "사용하여",
      "구현할",
      "크기",
      "부분",
      "배열부터",
      "시작",
      "인접한",
      "배열들을",
      "병합"
    ]
  },
  {
    "id": "DS-031",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Radix Sort에 대해 설명해 주세요.",
    "answer": "Radix Sort는 자릿수별로 정렬을 반복하는 비교 기반이 아닌 정렬 알고리즘입니다.\n\n종류\nLSD (Least Significant Digit): 가장 작은 자릿수부터 정렬\nMSD (Most Significant Digit): 가장 큰 자릿수부터 정렬\n\nLSD Radix Sort 과정\n\n시간복잡도: O(d * (n + k))\nd: 최대 자릿수\nn: 요소 개수\nk: 기수 (10진법이면 10)\n\n특징\nStable (Counting Sort 사용 시)\n정수, 문자열 정렬에 적합\n음수 처리 시 추가 로직 필요",
    "references": [
      {
        "title": "Radix sort - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Radix_sort"
      }
    ],
    "keywords": [
      "radix",
      "sort",
      "lsd",
      "least",
      "significant",
      "digit",
      "msd",
      "most",
      "stable",
      "counting",
      "자릿수별로",
      "정렬을",
      "반복하는",
      "비교",
      "기반이"
    ]
  },
  {
    "id": "DS-032",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Bubble, Selection, Insertion Sort의 속도를 비교해 주세요.",
    "answer": "알고리즘   최선   평균   최악   비교 횟수   교환 횟수\n\nBubble   O(n)   O(n^2)   O(n^2)   O(n^2)   O(n^2)\nSelection   O(n^2)   O(n^2)   O(n^2)   O(n^2)   O(n)\nInsertion   O(n)   O(n^2)   O(n^2)   O(n^2)   O(n^2)\n\n실제 성능 (일반적인 경우)\n\nInsertion Sort > Bubble Sort > Selection Sort\n\n이유\nInsertion Sort: 정렬된 부분에서 이진 탐색 가능, 교환 대신 시프트 사용\nSelection Sort: 비교는 항상 O(n^2), 교환은 O(n)으로 적음\nBubble Sort: 비교와 교환 모두 많음\n\nSelection Sort가 나은 경우\n쓰기 비용이 매우 높은 경우 (교환 횟수 O(n))\n예: 플래시 메모리",
    "references": [
      {
        "title": "Comparison of sorting algorithms",
        "url": "https://en.wikipedia.org/wiki/Sorting_algorithm#Comparison_of_algorithms"
      }
    ],
    "keywords": [
      "bubble",
      "selection",
      "insertion",
      "sort",
      "알고리즘",
      "최선",
      "평균",
      "최악",
      "비교",
      "횟수",
      "교환",
      "실제",
      "성능",
      "일반적인",
      "이유"
    ]
  },
  {
    "id": "DS-033",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "값이 거의 정렬되어 있거나, 아예 정렬되어 있다면, 위 세 알고리즘의 성능 비교 결과는 달라질까요?",
    "answer": "예, 크게 달라집니다.\n\n거의/완전 정렬된 데이터의 성능\n\n알고리즘   시간복잡도   이유\n\nInsertion Sort   O(n)   각 요소가 거의 제자리이므로 이동이 적음\nBubble Sort   O(n)   Early termination 적용 시\nSelection Sort   O(n^2)   항상 전체 탐색 필요\n\nInsertion Sort가 가장 효율적인 이유\n이미 정렬된 부분은 비교 1번으로 통과\n완전 정렬 시 n-1번 비교로 종료\n\nBubble Sort (최적화 버전)\n한 패스에서 교환이 없으면 종료\n완전 정렬 시 O(n)\n\nSelection Sort\n항상 남은 요소 중 최솟값을 찾아야 함\n데이터 상태와 무관하게 O(n^2)\n\n결론: 거의 정렬된 데이터에는 Insertion Sort가 최적",
    "references": [
      {
        "title": "Insertion sort - Best case",
        "url": "https://en.wikipedia.org/wiki/Insertion_sort#Best,_worst,_and_average_cases"
      }
    ],
    "keywords": [
      "insertion",
      "sort",
      "bubble",
      "early",
      "selection",
      "크게",
      "달라집니다",
      "거의",
      "완전",
      "정렬된",
      "데이터의",
      "성능",
      "알고리즘",
      "시간복잡도",
      "이유"
    ]
  },
  {
    "id": "DS-034",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "본인이 사용하고 있는 언어에선, 어떤 정렬 알고리즘을 사용하여 정렬 함수를 제공하고 있을까요?",
    "answer": "Java\nArrays.sort() (primitive): Dual-Pivot Quick Sort\nArrays.sort() (Object): Tim Sort\nCollections.sort(): Tim Sort\n\nPython\nsorted(), list.sort(): Tim Sort\n\nC++\nstd::sort(): Intro Sort (Quick Sort + Heap Sort + Insertion Sort)\nstd::stable_sort(): Merge Sort\n\nJavaScript\nArray.sort(): 엔진마다 다름 (V8: Tim Sort)\n\nTim Sort 특징\nMerge Sort + Insertion Sort 혼합\n실제 데이터의 부분 정렬을 활용 (Run 탐지)\nStable, O(n log n), 최선 O(n)\n\nDual-Pivot Quick Sort\n피벗 2개 사용하여 3분할\n기존 Quick Sort보다 평균 성능 향상",
    "references": [
      {
        "title": "Arrays.sort (Java SE 21)",
        "url": "https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/Arrays.html#sort(int%5B%5D"
      }
    ],
    "keywords": [
      "java",
      "arrays",
      "dual-pivot",
      "quick",
      "sort",
      "object",
      "tim",
      "collections",
      "python",
      "intro",
      "heap",
      "insertion",
      "stable_sort",
      "merge",
      "javascript"
    ]
  },
  {
    "id": "DS-035",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "정렬해야 하는 데이터는 50G 인데, 메모리가 4G라면, 어떤 방식으로 정렬을 진행할 수 있을까요?",
    "answer": "외부 정렬 (External Sort)를 사용합니다.\n\nK-way Merge Sort 방식\n\n1단계: 분할 및 내부 정렬\n데이터를 메모리에 맞는 청크로 분할 (예: 3.5GB씩)\n각 청크를 메모리에서 정렬\n정렬된 청크를 임시 파일로 저장\n약 15개의 정렬된 파일 생성\n\n2단계: K-way Merge\n각 파일에서 일부를 버퍼로 읽음\n최소 힙으로 각 파일의 최솟값 관리\n힙에서 최솟값 추출 → 출력\n해당 파일에서 다음 값 읽어 힙에 삽입\n모든 파일이 끝날 때까지 반복\n\n최적화 기법\nReplacement Selection: 초기 런 길이를 평균 2배로\nPolyphase Merge: 테이프 장치 최적화\nSSD 활용: 랜덤 읽기 성능 향상\n\n시간복잡도: O(n log n)",
    "references": [
      {
        "title": "External sorting - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/External_sorting"
      }
    ],
    "keywords": [
      "external",
      "sort",
      "k-way",
      "merge",
      "replacement",
      "selection",
      "polyphase",
      "ssd",
      "외부",
      "정렬",
      "사용합니다",
      "방식",
      "단계",
      "분할",
      "내부"
    ]
  },
  {
    "id": "DS-036",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "그래프 자료구조에 대해 설명하고, 이를 구현할 수 있는 두 방법에 대해 설명해 주세요.",
    "answer": "그래프는 정점(Vertex)과 간선(Edge)으로 구성된 자료구조입니다.\n\n종류: 방향/무방향, 가중치/비가중치, 순환/비순환\n\n구현 방법\n인접 행렬 (Adjacency Matrix)\n2차원 배열 사용\nmatrix[i][j] = 1이면 i→j 간선 존재\n인접 리스트 (Adjacency List)\n각 정점마다 연결된 정점들의 리스트 저장\n\n항목   인접 행렬   인접 리스트\n\n공간   O(V^2)   O(V + E)\n간선 확인   O(1)   O(degree)\n모든 간선 순회   O(V^2)   O(V + E)",
    "references": [
      {
        "title": "Graph (data structure) - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Graph_(abstract_data_type"
      }
    ],
    "keywords": [
      "vertex",
      "edge",
      "adjacency",
      "matrix",
      "list",
      "그래프는",
      "정점",
      "간선",
      "으로",
      "구성된",
      "자료구조입니다",
      "종류",
      "방향",
      "무방향",
      "가중치"
    ]
  },
  {
    "id": "DS-037",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "각 방법에 대해, \"두 정점이 연결되었는지\" 확인하는 시간복잡도와 \"한 정점에 연결된 모든 정점을 찾는\" 시간복잡도, 그리고 공간복잡도를 비교해 주세요.",
    "answer": "V = 정점 수, E = 간선 수, d = 특정 정점의 차수(degree)\n\n연산   인접 행렬   인접 리스트\n\n두 정점 연결 확인   O(1)   O(d)\n한 정점의 모든 인접 정점   O(V)   O(d)\n공간복잡도   O(V^2)   O(V + E)\n\n상세 설명\n\n인접 행렬\n연결 확인: matrix[u][v] 직접 접근 → O(1)\n인접 정점: 행 전체 탐색 필요 → O(V)\n공간: V x V 배열 → O(V^2)\n\n인접 리스트\n연결 확인: u의 리스트에서 v 검색 → O(d)\n정렬/해시 사용 시 O(log d) 또는 O(1) 가능\n인접 정점: 리스트 순회 → O(d)\n공간: 각 간선이 리스트에 저장 → O(V + E)\n\n선택 기준\n밀집 그래프 (E ≈ V^2): 인접 행렬\n희소 그래프 (E << V^2): 인접 리스트",
    "references": [
      {
        "title": "Adjacency list - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Adjacency_list#Trade-offs"
      }
    ],
    "keywords": [
      "정점",
      "간선",
      "특정",
      "정점의",
      "차수",
      "연산",
      "인접",
      "행렬",
      "리스트",
      "연결",
      "확인",
      "모든",
      "공간복잡도",
      "상세",
      "설명"
    ]
  },
  {
    "id": "DS-038",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "정점의 개수가 N개, 간선의 개수가 N^3 개라면, 어떤 방식으로 구현하는 것이 효율적일까요?",
    "answer": "인접 행렬이 더 효율적입니다.\n\n분석\n정점: N개\n간선: N^3개 (매우 밀집된 그래프, 다중 간선 가능)\n\n공간복잡도 비교\n인접 행렬: O(N^2)\n인접 리스트: O(N + N^3) = O(N^3)\n\n인접 행렬이 유리한 이유\n공간 효율: N^2 < N^3 (N > 1일 때)\n간선 접근 속도: O(1) vs O(N^3/N) = O(N^2)\n캐시 효율: 연속된 메모리 접근\n\n단, 다중 간선 고려 시\n같은 정점 쌍 사이에 여러 간선이 있다면\n인접 행렬에 개수나 리스트를 저장하는 방식 필요\n이 경우에도 기본 구조는 행렬이 효율적\n\n결론: 간선이 N^3개로 매우 많은 밀집 그래프에서는 인접 행렬이 공간과 시간 모두에서 효율적",
    "references": [
      {
        "title": "Dense graph - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Dense_graph"
      }
    ],
    "keywords": [
      "인접",
      "행렬이",
      "효율적입니다",
      "분석",
      "정점",
      "간선",
      "매우",
      "밀집된",
      "그래프",
      "다중",
      "가능",
      "공간복잡도",
      "비교",
      "행렬",
      "리스트"
    ]
  },
  {
    "id": "DS-039",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "사이클이 없는 그래프는 모두 트리인가요? 그렇지 않다면, 예시를 들어주세요.",
    "answer": "아니오, 사이클이 없는 그래프가 모두 트리는 아닙니다.\n\n트리의 정의\n트리는 다음 조건을 모두 만족해야 합니다:\n사이클이 없음\n연결되어 있음 (모든 정점 쌍 사이에 경로 존재)\n간선 수 = 정점 수 - 1\n\n반례: 포레스트 (Forest)\n사이클 없음\n연결되어 있지 않음 (두 개의 분리된 컴포넌트)\n트리가 아님\n\n반례: 방향 비순환 그래프 (DAG)\n사이클 없음 (방향 고려)\n무방향으로 보면 사이클 존재\n트리가 아님\n\n정리\n사이클 없음 + 연결됨 = 트리\n사이클 없음 + 연결 안 됨 = 포레스트 (트리들의 집합)",
    "references": [
      {
        "title": "Tree (graph theory) - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Tree_(graph_theory"
      }
    ],
    "keywords": [
      "forest",
      "dag",
      "아니오",
      "사이클이",
      "없는",
      "그래프가",
      "모두",
      "트리는",
      "아닙니다",
      "트리의",
      "정의",
      "다음",
      "조건을",
      "만족해야",
      "없음"
    ]
  },
  {
    "id": "DS-040",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "그래프에서, 최단거리를 구하는 방법에 대해 설명해 주세요.",
    "answer": "상황별 최단 거리 알고리즘\n\n조건   알고리즘   시간복잡도\n\n가중치 없음   BFS   O(V + E)\n가중치 양수 (단일 출발)   Dijkstra   O((V+E) log V)\n음수 가중치 (단일 출발)   Bellman-Ford   O(VE)\n모든 쌍   Floyd-Warshall   O(V^3)\n음수 사이클 탐지   Bellman-Ford   O(VE)\nDAG   위상정렬 + DP   O(V + E)\n\n주요 알고리즘\n\nBFS: 가중치 없는 그래프에서 최단 경로\n\nDijkstra: 우선순위 큐로 최소 거리 정점 선택, 음수 가중치 불가\n\nBellman-Ford: 모든 간선을 V-1번 완화, 음수 가중치 가능\n\nFloyd-Warshall: DP로 모든 쌍 최단 거리, d[i][j] = min(d[i][j], d[i][k] + d[k][j])",
    "references": [
      {
        "title": "Shortest path problem - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Shortest_path_problem"
      }
    ],
    "keywords": [
      "bfs",
      "dijkstra",
      "bellman-ford",
      "floyd-warshall",
      "dag",
      "v-1",
      "상황별",
      "최단",
      "거리",
      "알고리즘",
      "조건",
      "시간복잡도",
      "가중치",
      "없음",
      "양수"
    ]
  },
  {
    "id": "DS-041",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "트리에서는 어떤 방식으로 최단거리를 구할 수 있을까요? (위 방법을 사용하지 않고)",
    "answer": "트리의 특성: 두 정점 사이에 유일한 경로가 존재\n\n방법 1: LCA (Lowest Common Ancestor) 활용\n전처리: O(n log n) 또는 O(n)\n쿼리: O(log n) 또는 O(1)\n\n방법 2: 단순 DFS/BFS\n한 정점에서 시작하여 목표 정점까지 탐색\n시간: O(n)\n유일한 경로이므로 최단 거리 보장\n\n방법 3: Euler Tour + Sparse Table\nEuler Tour로 트리를 배열로 변환\nRMQ(Range Minimum Query)로 LCA 계산\n전처리: O(n log n), 쿼리: O(1)\n\n가중치 트리\ndist[x]: 루트에서 x까지의 거리",
    "references": [
      {
        "title": "Lowest common ancestor - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Lowest_common_ancestor"
      }
    ],
    "keywords": [
      "lca",
      "lowest",
      "common",
      "ancestor",
      "dfs",
      "bfs",
      "euler",
      "tour",
      "sparse",
      "table",
      "rmq",
      "range",
      "minimum",
      "query",
      "트리의"
    ]
  },
  {
    "id": "DS-042",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "다익스트라 알고리즘에서, 힙을 사용하지 않고 구현한다면 시간복잡도가 어떻게 변화할까요?",
    "answer": "힙 사용 시: O((V + E) log V)\n\n힙 미사용 시: O(V^2)\n\n힙 미사용 구현\n\n시간복잡도 분석\n최소 정점 찾기: V번 × O(V) = O(V^2)\n거리 갱신: 총 O(E)\n전체: O(V^2 + E) = O(V^2)\n\n언제 힙 미사용이 유리한가?\n밀집 그래프 (E ≈ V^2)인 경우\n힙 사용: O(V^2 log V)\n힙 미사용: O(V^2)\n희소 그래프 (E << V^2)에서는 힙이 유리",
    "references": [
      {
        "title": "Dijkstra's algorithm - Running time",
        "url": "https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm#Running_time"
      }
    ],
    "keywords": [
      "사용",
      "미사용",
      "구현",
      "시간복잡도",
      "분석",
      "최소",
      "정점",
      "찾기",
      "거리",
      "갱신",
      "전체",
      "언제",
      "미사용이",
      "유리한가",
      "밀집"
    ]
  },
  {
    "id": "DS-043",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "정점의 개수가 N개, 간선의 개수가 N^3 개라면, 어떤 알고리즘이 효율적일까요?",
    "answer": "단일 출발점: 힙 없는 Dijkstra - O(N^2)\n\n모든 쌍: Floyd-Warshall - O(N^3)\n\n분석\n\n알고리즘   시간복잡도   E = N^3일 때\n\nDijkstra (힙)   O((V+E) log V)   O(N^3 log N)\nDijkstra (배열)   O(V^2)   O(N^2)\nBellman-Ford   O(VE)   O(N^4)\nFloyd-Warshall   O(V^3)   O(N^3)\n\n단일 출발점 최단 경로\n힙 없는 Dijkstra가 O(N^2)로 가장 효율적\n힙 사용 시 O(N^3 log N)으로 오히려 느림\n\n모든 쌍 최단 경로\nFloyd-Warshall: O(N^3)\nDijkstra N번: O(N^3) (힙 없는 버전)\n둘 다 비슷하지만 Floyd-Warshall이 구현 간단\n\n결론: 매우 밀집된 그래프에서는 힙의 오버헤드가 역효과를 내므로, 단순한 O(V^2) 구현이 효율적",
    "references": [
      {
        "title": "Floyd-Warshall algorithm - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm"
      }
    ],
    "keywords": [
      "dijkstra",
      "floyd-warshall",
      "bellman-ford",
      "단일",
      "출발점",
      "없는",
      "모든",
      "분석",
      "알고리즘",
      "시간복잡도",
      "배열",
      "최단",
      "경로",
      "가장",
      "효율적"
    ]
  },
  {
    "id": "DS-044",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "A\\* 알고리즘에 대해 설명해 주세요. 이 알고리즘은 다익스트라와 비교해서 어떤 성능을 낼까요?",
    "answer": "*A\\ 알고리즘은 휴리스틱을 사용한 최단 경로 알고리즘입니다.\n\n핵심 공식\ng(n): 시작점에서 n까지의 실제 비용\nh(n): n에서 목표점까지의 추정 비용 (휴리스틱)\nf(n): 총 예상 비용\n\n휴리스틱 조건\nAdmissible: h(n) <= 실제 비용 (과대평가 금지) → 최단 경로 보장\nConsistent: h(n) <= cost(n, m) + h(m) → 효율성 향상\n\n다익스트라와 비교*\n\n항목   Dijkstra   A\n\n휴리스틱   없음 (h=0)   있음\n탐색 방향   모든 방향   목표 방향\n탐색 노드 수   많음   적음\n최적성   항상 최적   admissible h면 최적\n\n성능\n좋은 휴리스틱: 다익스트라보다 훨씬 빠름\nh=0이면 다익스트라와 동일\n최악: 다익스트라와 같은 O((V+E) log V)",
    "references": [
      {
        "title": "A* search algorithm - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/A*_search_algorithm"
      }
    ],
    "keywords": [
      "admissible",
      "consistent",
      "dijkstra",
      "알고리즘은",
      "휴리스틱을",
      "사용한",
      "최단",
      "경로",
      "알고리즘입니다",
      "핵심",
      "공식",
      "시작점에서",
      "까지의",
      "실제",
      "비용"
    ]
  },
  {
    "id": "DS-045",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "음수 간선이 있을 때와, 음수 사이클이 있을 때 각각 어떤 최단거리 알고리즘을 사용해야 하는지 설명해 주세요.",
    "answer": "음수 간선이 있을 때 (음수 사이클 없음)\n\n알고리즘   사용 가능   시간복잡도\n\nDijkstra   불가   -\nBellman-Ford   가능   O(VE)\nSPFA   가능   평균 O(E), 최악 O(VE)\nFloyd-Warshall   가능   O(V^3)\n\nDijkstra가 불가능한 이유\n한 번 확정된 최단 거리가 나중에 더 짧아질 수 있음\nGreedy 접근이 실패\n\n음수 사이클이 있을 때\n\n최단 거리가 정의되지 않음 (무한히 작아질 수 있음)\n\n대응 방법\nBellman-Ford로 음수 사이클 탐지\nV번째 반복에서도 갱신이 발생하면 음수 사이클 존재\nFloyd-Warshall로 탐지\nd[i][i] < 0이면 음수 사이클 존재",
    "references": [
      {
        "title": "Bellman-Ford algorithm - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm"
      }
    ],
    "keywords": [
      "dijkstra",
      "bellman-ford",
      "spfa",
      "floyd-warshall",
      "greedy",
      "음수",
      "간선이",
      "있을",
      "사이클",
      "없음",
      "알고리즘",
      "사용",
      "가능",
      "시간복잡도",
      "불가"
    ]
  },
  {
    "id": "DS-046",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "재귀함수에 대해 설명해 주세요.",
    "answer": "재귀함수는 자기 자신을 호출하는 함수입니다.\n\n구성 요소\nBase Case (기저 조건): 재귀를 멈추는 조건\nRecursive Case: 자기 자신을 호출하는 부분\n문제 축소: 각 호출마다 문제 크기가 감소\n\n예시: 팩토리얼\n\n장점\n코드가 간결하고 이해하기 쉬움\n분할 정복, 트리 탐색 등에 자연스러움\n\n단점\n호출 스택 오버헤드\nStack Overflow 위험\n반복문보다 느릴 수 있음\n\n활용\n트리/그래프 탐색 (DFS)\n분할 정복 (Merge Sort, Quick Sort)\n동적 계획법 (메모이제이션)\n백트래킹",
    "references": [
      {
        "title": "Recursion (computer science) - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Recursion_(computer_science"
      }
    ],
    "keywords": [
      "base",
      "case",
      "recursive",
      "stack",
      "overflow",
      "dfs",
      "merge",
      "sort",
      "quick",
      "재귀함수는",
      "자기",
      "자신을",
      "호출하는",
      "함수입니다",
      "구성"
    ]
  },
  {
    "id": "DS-047",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "재귀 함수의 동작 과정을 Call Stack을 활용해서 설명해 주세요.",
    "answer": "Call Stack: 함수 호출 정보를 저장하는 스택 자료구조\n\n저장 정보\n반환 주소 (Return Address)\n지역 변수\n매개변수\n이전 스택 프레임 포인터\n\nfactorial(4) 호출 과정\n\nStack Overflow\n스택 크기는 제한적 (보통 1MB)\n재귀 깊이가 너무 깊으면 오버플로우 발생",
    "references": [
      {
        "title": "Call stack - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Call_stack"
      }
    ],
    "keywords": [
      "call",
      "stack",
      "return",
      "address",
      "overflow",
      "함수",
      "호출",
      "정보를",
      "저장하는",
      "스택",
      "자료구조",
      "저장",
      "정보",
      "반환",
      "주소"
    ]
  },
  {
    "id": "DS-048",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "언어의 스펙에 따라, 재귀함수의 최적화를 진행해주는 경우가 있습니다. 어떤 경우에 재귀함수의 최적화가 가능하며, 이를 어떻게 최적화 할 수 있을지 설명해 주세요.",
    "answer": "꼬리 재귀 최적화 (Tail Call Optimization, TCO)\n\n꼬리 재귀 조건\n재귀 호출이 함수의 마지막 연산이어야 함\n재귀 호출 결과를 그대로 반환\n\n최적화 방법\n컴파일러가 재귀를 반복문으로 변환\n스택 프레임을 재사용하여 O(1) 공간\n\n언어별 지원\n언어   TCO 지원\n\nScheme, Haskell   필수 (스펙)\nScala, Kotlin   지원 (@tailrec)\nJavaScript   ES6 스펙 (구현은 제한적)\nJava, Python   미지원\nC/C++   컴파일러 최적화로 가능",
    "references": [
      {
        "title": "Tail call - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Tail_call"
      }
    ],
    "keywords": [
      "tail",
      "call",
      "optimization",
      "tco",
      "scheme",
      "haskell",
      "scala",
      "kotlin",
      "javascript",
      "es6",
      "java",
      "python",
      "꼬리",
      "재귀",
      "최적화"
    ]
  },
  {
    "id": "DS-049",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "MST가 무엇이고, 어떻게 구할 수 있을지 설명해 주세요.",
    "answer": "MST (최소 신장 트리)는 그래프의 모든 정점을 연결하면서 간선 가중치 합이 최소인 트리입니다.\n\n특징\n정점 V개, 간선 V-1개\n사이클 없음\n연결 그래프\n\n구하는 알고리즘\nKruskal 알고리즘\n모든 간선을 가중치 순으로 정렬\n가장 작은 간선부터 선택\n사이클이 생기면 건너뜀 (Union-Find로 확인)\nV-1개 간선 선택 시 종료\n\n시간복잡도: O(E log E)\nPrim 알고리즘\n임의의 정점에서 시작\n현재 트리와 연결된 간선 중 최소 가중치 선택\n새 정점을 트리에 추가\n모든 정점 포함 시 종료\n\n시간복잡도: O(E log V) (힙 사용)",
    "references": [
      {
        "title": "Minimum spanning tree - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Minimum_spanning_tree"
      }
    ],
    "keywords": [
      "mst",
      "v-1",
      "kruskal",
      "union-find",
      "prim",
      "최소",
      "신장",
      "트리",
      "그래프의",
      "모든",
      "정점을",
      "연결하면서",
      "간선",
      "가중치",
      "합이"
    ]
  },
  {
    "id": "DS-050",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Kruskal 알고리즘에서 사용하는 Union-Find 자료구조에 대해 설명해 주세요.",
    "answer": "Union-Find (Disjoint Set Union, DSU)는 서로소 집합을 관리하는 자료구조입니다.\n\n주요 연산\nFind(x): x가 속한 집합의 대표(루트) 반환\nUnion(x, y): x와 y가 속한 집합을 합침\n\n최적화 기법\nPath Compression (경로 압축)\nFind 시 모든 노드를 루트에 직접 연결\nUnion by Rank/Size\n작은 트리를 큰 트리에 붙임\n\n시간복잡도\n두 최적화 적용 시: O(α(n)) ≈ O(1)\nα: 아커만 함수의 역함수 (매우 느리게 증가)",
    "references": [
      {
        "title": "Disjoint-set data structure - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Disjoint-set_data_structure"
      }
    ],
    "keywords": [
      "union-find",
      "disjoint",
      "set",
      "union",
      "dsu",
      "find",
      "path",
      "compression",
      "rank",
      "size",
      "서로소",
      "집합을",
      "관리하는",
      "자료구조입니다",
      "주요"
    ]
  },
  {
    "id": "DS-051",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Kruskal 과 Prim 중, 어떤 것이 더 빠를까요?",
    "answer": "상황에 따라 다릅니다.\n\n알고리즘   시간복잡도   적합한 경우\n\nKruskal   O(E log E)   희소 그래프\nPrim (힙)   O(E log V)   밀집 그래프\nPrim (배열)   O(V^2)   매우 밀집된 그래프\n\n비교 분석\n\n희소 그래프 (E ≈ V)\nKruskal: O(V log V)\nPrim: O(V log V)\n비슷하지만 Kruskal이 구현 간단\n\n밀집 그래프 (E ≈ V^2)\nKruskal: O(V^2 log V)\nPrim (힙): O(V^2 log V)\nPrim (배열): O(V^2)\nPrim (배열)이 유리\n\n추가 고려사항\nKruskal: 간선 정렬 필요, Union-Find 오버헤드\nPrim: 시작점 필요, 우선순위 큐 관리\n\n결론\nE < V log V: Kruskal\nE > V log V: Prim\n일반적으로 큰 차이 없음",
    "references": [
      {
        "title": "Prim's algorithm - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Prim%27s_algorithm"
      }
    ],
    "keywords": [
      "kruskal",
      "prim",
      "union-find",
      "상황에",
      "따라",
      "다릅니다",
      "알고리즘",
      "시간복잡도",
      "적합한",
      "희소",
      "그래프",
      "밀집",
      "배열",
      "매우",
      "밀집된"
    ]
  },
  {
    "id": "DS-052",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Kruskal 과 Prim 알고리즘을 통해 얻어진 결과물은 무조건 트리인가요? 만약 그렇다면 증명해 주세요. 그렇지 않다면, 반례를 설명해 주세요.",
    "answer": "예, 항상 트리입니다. (연결 그래프가 입력인 경우)\n\n트리의 조건\n사이클이 없음\n연결되어 있음\n간선 수 = 정점 수 - 1\n\nKruskal 증명\n사이클 없음: Union-Find로 사이클 형성 간선을 명시적으로 제외\n연결성: 연결 그래프에서 V-1개 간선 선택 시 모든 정점 연결\n간선 수: 정확히 V-1개 선택하면 종료\n\nPrim 증명\n사이클 없음: 항상 트리에 포함되지 않은 정점으로 확장\n이미 트리에 있는 정점으로 간선을 추가하지 않음\n연결성: 시작점에서 확장하므로 모든 선택된 정점이 연결됨\n간선 수: V개 정점 모두 포함 시 V-1개 간선\n\n비연결 그래프인 경우\n최소 신장 포레스트가 생성됨\n각 연결 요소에 대해 별도의 트리",
    "references": [
      {
        "title": "Kruskal's algorithm correctness",
        "url": "https://en.wikipedia.org/wiki/Kruskal%27s_algorithm#Correctness"
      }
    ],
    "keywords": [
      "kruskal",
      "union-find",
      "v-1",
      "prim",
      "항상",
      "트리입니다",
      "연결",
      "그래프가",
      "입력인",
      "트리의",
      "조건",
      "사이클이",
      "없음",
      "연결되어",
      "있음"
    ]
  },
  {
    "id": "DS-053",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Thread Safe 한 자료구조가 있을까요? 없다면, 어떻게 Thread Safe 하게 구성할 수 있을까요?",
    "answer": "Thread Safe 자료구조 존재합니다.\n\nJava 제공 Thread Safe 자료구조\nConcurrentHashMap\nCopyOnWriteArrayList\nBlockingQueue (LinkedBlockingQueue 등)\nConcurrentLinkedQueue\nCollections.synchronizedXxx()\n\nThread Safe 구성 방법\n동기화 (Synchronization)\nLock 사용\nAtomic 연산\nImmutable 객체\n불변 객체는 본질적으로 Thread Safe\nThread Local\n각 스레드가 독립된 복사본 보유",
    "references": [
      {
        "title": "ConcurrentHashMap (Java SE 21)",
        "url": "https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/ConcurrentHashMap.html"
      }
    ],
    "keywords": [
      "thread",
      "safe",
      "java",
      "concurrenthashmap",
      "copyonwritearraylist",
      "blockingqueue",
      "linkedblockingqueue",
      "concurrentlinkedqueue",
      "collections",
      "synchronization",
      "lock",
      "atomic",
      "immutable",
      "local",
      "자료구조"
    ]
  },
  {
    "id": "DS-054",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "배열의 길이를 알고 있다면, 조금 더 빠른 Thread Safe 한 연산을 만들 순 없을까요?",
    "answer": "예, 분할 잠금(Lock Striping)을 사용할 수 있습니다.\n\n방법 1: 세그먼트별 락\n배열을 여러 세그먼트로 분할\n각 세그먼트에 별도의 락\n서로 다른 세그먼트는 동시 접근 가능\n\n방법 2: 인덱스별 락 (Fine-grained)\n각 인덱스마다 독립된 락\n최대 병렬성, 메모리 오버헤드 큼\n\n방법 3: Lock-Free with CAS\n\n방법 4: 읽기 최적화\nReadWriteLock: 읽기는 동시에, 쓰기만 배타적\nStampedLock: 낙관적 읽기 지원\n\n최적 선택: 접근 패턴에 따라 세그먼트 수 조정",
    "references": [
      {
        "title": "AtomicReferenceArray (Java SE 21)",
        "url": "https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/atomic/AtomicReferenceArray.html"
      }
    ],
    "keywords": [
      "lock",
      "striping",
      "fine-grained",
      "lock-free",
      "cas",
      "readwritelock",
      "stampedlock",
      "분할",
      "잠금",
      "사용할",
      "방법",
      "세그먼트별",
      "배열을",
      "여러",
      "세그먼트로"
    ]
  },
  {
    "id": "DS-055",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "사용하고 있는 언어의 자료구조는 Thread Safe 한가요? 그렇지 않다면, Thread Safe 한 Wrapped Data Structure 를 제공하고 있나요?",
    "answer": "Java 기본 컬렉션: Thread Safe 하지 않음\n\nArrayList, HashMap, HashSet 등은 동기화되지 않음\n\nThread Safe 대안\nCollections.synchronizedXxx()\n모든 메서드를 synchronized로 래핑\n단순하지만 성능 저하 (전체 락)\njava.util.concurrent 패키지\n기본   Thread Safe\n\nHashMap   ConcurrentHashMap\nArrayList   CopyOnWriteArrayList\nLinkedList   ConcurrentLinkedQueue\nTreeMap   ConcurrentSkipListMap\nHashSet   ConcurrentHashMap.newKeySet()\n레거시 Thread Safe 컬렉션\nVector (ArrayList 대신)\nHashtable (HashMap 대신)\n성능이 낮아 권장하지 않음\n\nPython: GIL로 인해 일부 연산은 atomic하지만, 완전한 Thread Safe는 아님. queue.Queue 등 제공",
    "references": [
      {
        "title": "Collections.synchronizedList (Java SE 21)",
        "url": "https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/Collections.html#synchronizedList(java.util.List"
      }
    ],
    "keywords": [
      "java",
      "thread",
      "safe",
      "arraylist",
      "hashmap",
      "hashset",
      "collections",
      "concurrenthashmap",
      "copyonwritearraylist",
      "linkedlist",
      "concurrentlinkedqueue",
      "treemap",
      "concurrentskiplistmap",
      "vector",
      "hashtable"
    ]
  },
  {
    "id": "DS-056",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "문자열을 저장하고, 처리하는 주요 자료구조 및 알고리즘 (Trie, KMP, Rabin Karp 등) 에 대해 설명해 주세요.",
    "answer": "자료구조\n\nTrie (Prefix Tree)\n문자열을 문자 단위로 트리에 저장\n접두사 검색에 최적화\n시간: 삽입/검색 O(m), m = 문자열 길이\n공간: O(알파벳 크기 * 총 문자 수)\n활용: 자동완성, 사전\n\nSuffix Tree / Suffix Array\n모든 접미사를 저장\n부분 문자열 검색 O(m)\n공간: Suffix Array가 더 효율적\n\n알고리즘 (패턴 매칭)\n\n알고리즘   시간복잡도   특징\n\nNaive   O(nm)   단순 비교\nKMP   O(n+m)   실패 함수로 불필요한 비교 스킵\nRabin-Karp   O(n+m) 평균   해시 기반, 다중 패턴에 유리\nBoyer-Moore   O(n/m) 최선   뒤에서부터 비교\n\nKMP: 접두사=접미사 정보를 활용하여 불일치 시 패턴을 효율적으로 이동\n\nRabin-Karp: 롤링 해시로 윈도우 해시값을 O(1)에 갱신, 해시 일치 시 실제 비교",
    "references": [
      {
        "title": "Trie - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Trie"
      }
    ],
    "keywords": [
      "trie",
      "prefix",
      "tree",
      "suffix",
      "array",
      "naive",
      "kmp",
      "rabin-karp",
      "boyer-moore",
      "자료구조",
      "문자열을",
      "문자",
      "단위로",
      "트리에",
      "저장"
    ]
  },
  {
    "id": "DS-057",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "이진탐색이 무엇인지 설명하고, 시간복잡도를 증명해 보세요.",
    "answer": "이진 탐색: 정렬된 배열에서 중간값과 비교하여 탐색 범위를 절반씩 줄여나가는 알고리즘\n\n알고리즘\n\n시간복잡도: O(log n)\n\n증명\n각 단계에서 탐색 범위가 절반으로 감소\nk번째 단계의 탐색 범위: n / 2^k\n탐색 종료 조건: n / 2^k <= 1\n따라서: 2^k >= n → k >= log₂n\n최대 반복 횟수: O(log n)\n\n점화식 증명",
    "references": [
      {
        "title": "Binary search algorithm - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Binary_search_algorithm"
      }
    ],
    "keywords": [
      "이진",
      "탐색",
      "정렬된",
      "배열에서",
      "중간값과",
      "비교하여",
      "범위를",
      "절반씩",
      "줄여나가는",
      "알고리즘",
      "시간복잡도",
      "증명",
      "단계에서",
      "범위가",
      "절반으로"
    ]
  },
  {
    "id": "DS-058",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "Lower Bound, Upper Bound 는 무엇이고, 이를 어떻게 구현할 수 있을까요?",
    "answer": "정의 (정렬된 배열에서)\nLower Bound: target 이상인 첫 번째 위치\nUpper Bound: target 초과인 첫 번째 위치\n\n예시: [1, 2, 2, 2, 3, 4]에서 target=2\nLower Bound: index 1 (첫 번째 2)\nUpper Bound: index 4 (첫 번째 3)\n2의 개수 = Upper - Lower = 4 - 1 = 3\n\n구현\n\n차이점: < vs <= 부등호 하나 차이\n\n활용: 특정 값의 개수, 범위 쿼리, 삽입 위치 찾기",
    "references": [
      {
        "title": "std::lower_bound - cppreference",
        "url": "https://en.cppreference.com/w/cpp/algorithm/lower_bound"
      }
    ],
    "keywords": [
      "lower",
      "bound",
      "upper",
      "정의",
      "정렬된",
      "배열에서",
      "이상인",
      "번째",
      "위치",
      "초과인",
      "예시",
      "에서",
      "개수",
      "구현",
      "차이점"
    ]
  },
  {
    "id": "DS-059",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "이진탐색의 논리를 적용하여 삼진탐색을 작성한다고 가정한다면, 시간복잡도는 어떻게 변화할까요? (실제 존재하는 삼진탐색 알고리즘은 무시하세요!)",
    "answer": "삼진 탐색 (가상): 배열을 3등분하여 탐색\n\n시간복잡도: O(log₃n) = O(log n)\n\n분석\n각 단계에서 범위가 1/3로 감소\n최대 반복 횟수: log₃n\n밑 변환: log₃n = log₂n / log₂3 ≈ 0.63  log₂n\n\n비교 횟수 분석\n이진 탐색: 단계당 1~2번 비교, 총 log₂n 단계\n삼진 탐색: 단계당 2번 비교 필요, 총 log₃n 단계\n\n총 비교 횟수\n이진: 약 log₂n ≈ 1.0  log₂n 비교\n삼진: 약 2  log₃n ≈ 2  0.63  log₂n ≈ 1.26  log₂n 비교\n\n결론\n빅오 표기법: 동일한 O(log n)\n실제 비교 횟수: 이진 탐색이 더 적음\n분기를 늘려도 비교 횟수 증가로 이점 상쇄\n캐시 효율도 이진 탐색이 유리",
    "references": [
      {
        "title": "Ternary search - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Ternary_search"
      }
    ],
    "keywords": [
      "삼진",
      "탐색",
      "가상",
      "배열을",
      "등분하여",
      "시간복잡도",
      "분석",
      "단계에서",
      "범위가",
      "감소",
      "최대",
      "반복",
      "횟수",
      "변환",
      "비교"
    ]
  },
  {
    "id": "DS-060",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "기존 이진탐색 로직에서 부등호의 범위가 바뀐다면, 어떤 영향이 있을까요?",
    "answer": "부등호 변경은 탐색 결과와 종료 조건에 큰 영향을 줍니다.\n\n주요 변경 포인트\n비교 부등호 (< vs <=)\n루프 조건 (< vs <=)\nright 초기값\n\n잘못된 부등호의 결과\n무한 루프: mid 계산과 범위 갱신이 맞지 않을 때\nOff-by-one 에러: 정확히 하나 벗어난 결과\n경계 누락: 첫 번째/마지막 요소 탐색 실패\n\n안전한 패턴",
    "references": [
      {
        "title": "Binary search - Implementation issues",
        "url": "https://en.wikipedia.org/wiki/Binary_search_algorithm#Implementation_issues"
      }
    ],
    "keywords": [
      "off-by-one",
      "부등호",
      "변경은",
      "탐색",
      "결과와",
      "종료",
      "조건에",
      "영향을",
      "줍니다",
      "주요",
      "변경",
      "포인트",
      "비교",
      "루프",
      "조건"
    ]
  },
  {
    "id": "DS-061",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "그리디 알고리즘과 동적 계획법을 비교해 주세요.",
    "answer": "항목   그리디   동적 계획법 (DP)\n\n접근법   현재 최선의 선택   모든 경우 고려\n최적 보장   특정 조건 시만   항상 보장\n시간복잡도   일반적으로 낮음   상태 수에 비례\n공간복잡도   O(1) 가능   상태 저장 필요\n되돌림   없음   있음 (서브문제 재활용)\n\n그리디 알고리즘\n각 단계에서 지역 최적해 선택\n탐욕 선택 속성: 지역 최적이 전역 최적으로 이어짐\n최적 부분 구조: 부분 문제의 최적해로 전체 최적해 구성\n예: 거스름돈, 활동 선택, Huffman 코딩\n\n동적 계획법\n중복 부분 문제: 같은 부분 문제가 반복\n최적 부분 구조: 부분 문제의 최적해로 전체 최적해 구성\n메모이제이션 또는 타뷸레이션으로 중복 계산 방지\n예: 피보나치, 배낭 문제, 최장 공통 부분 수열",
    "references": [
      {
        "title": "Greedy algorithm - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Greedy_algorithm"
      }
    ],
    "keywords": [
      "huffman",
      "항목",
      "그리디",
      "동적",
      "계획법",
      "접근법",
      "현재",
      "최선의",
      "선택",
      "모든",
      "고려",
      "최적",
      "보장",
      "특정",
      "조건"
    ]
  },
  {
    "id": "DS-062",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "그렇다면, 어떤 경우에 각각의 기법을 사용할 수 있을까요?",
    "answer": "그리디를 사용할 수 있는 경우\n\n조건\n탐욕 선택 속성: 현재 최선이 전체 최선으로 이어짐\n최적 부분 구조: 부분 문제의 최적해가 전체 최적해 구성\n\n대표 문제\n거스름돈 (특정 화폐 단위)\n활동 선택 (회의실 배정)\n최소 신장 트리 (Kruskal, Prim)\n다익스트라 최단 경로\nHuffman 인코딩\n\nDP를 사용해야 하는 경우\n\n조건\n중복 부분 문제: 같은 계산이 반복\n최적 부분 구조: 있지만 그리디로 안 됨\n선택이 미래에 영향을 미침\n\n대표 문제\n0/1 배낭 문제 (그리디 불가)\n최장 공통 부분 수열 (LCS)\n편집 거리\n행렬 체인 곱셈\n동전 교환 (일반적인 화폐 단위)\n\n판단 기준",
    "references": [
      {
        "title": "Dynamic programming - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Dynamic_programming"
      }
    ],
    "keywords": [
      "kruskal",
      "prim",
      "huffman",
      "lcs",
      "그리디를",
      "사용할",
      "있는",
      "조건",
      "탐욕",
      "선택",
      "속성",
      "현재",
      "최선이",
      "전체",
      "최선으로"
    ]
  },
  {
    "id": "DS-063",
    "category": "ds",
    "categoryName": "자료구조",
    "priority": "P1",
    "question": "동적 계획법으로 풀 수 있는 모든 문제는 재귀로 변환하여 풀 수 있나요?",
    "answer": "예, 가능합니다.\n\nDP와 재귀(메모이제이션)는 수학적으로 동치입니다.\n\n두 가지 접근법\nTop-Down (재귀 + 메모이제이션)\nBottom-Up (타뷸레이션)\n\n차이점\n\n항목   Top-Down   Bottom-Up\n\n구현   직관적   상태 순서 고려 필요\n필요한 상태만   계산   모두 계산\n스택 오버플로우   가능   없음\n공간 최적화   어려움   용이\n\n결론: 모든 DP 문제는 재귀로 표현 가능하며, 메모이제이션을 추가하면 동일한 시간복잡도 달성",
    "references": [
      {
        "title": "Memoization - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Memoization"
      }
    ],
    "keywords": [
      "top-down",
      "bottom-up",
      "가능합니다",
      "재귀",
      "메모이제이션",
      "수학적으로",
      "동치입니다",
      "가지",
      "접근법",
      "타뷸레이션",
      "차이점",
      "항목",
      "구현",
      "직관적",
      "상태"
    ]
  },
  {
    "id": "NET-001",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "HTTP에 대해 설명해 주세요.",
    "answer": "HTTP(HyperText Transfer Protocol)는 웹에서 클라이언트와 서버 간 데이터를 주고받는 애플리케이션 계층 프로토콜입니다. 요청-응답 모델 기반이며, Stateless 특성을 가집니다.",
    "references": [
      {
        "title": "RFC 9110 - HTTP Semantics",
        "url": "https://www.rfc-editor.org/rfc/rfc9110"
      }
    ],
    "keywords": [
      "http",
      "hypertext",
      "transfer",
      "protocol",
      "stateless",
      "웹에서",
      "클라이언트와",
      "서버",
      "데이터를",
      "주고받는",
      "애플리케이션",
      "계층",
      "프로토콜입니다",
      "요청",
      "응답"
    ]
  },
  {
    "id": "NET-002",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "HTTP의 특성인 Stateless에 대해 설명해 주세요.",
    "answer": "Stateless란 서버가 클라이언트의 이전 요청 상태를 저장하지 않는 특성입니다. 각 요청은 독립적으로 처리되며, 필요한 모든 정보를 요청에 포함해야 합니다. 이로 인해 서버 확장이 용이합니다.",
    "references": [
      {
        "title": "RFC 9110 Section 3.3",
        "url": "https://www.rfc-editor.org/rfc/rfc9110#section-3.3"
      }
    ],
    "keywords": [
      "stateless",
      "서버가",
      "클라이언트의",
      "이전",
      "요청",
      "상태를",
      "저장하지",
      "않는",
      "특성입니다",
      "요청은",
      "독립적으로",
      "처리되며",
      "필요한",
      "모든",
      "정보를"
    ]
  },
  {
    "id": "NET-003",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "Stateless와 Connectionless에 대해 설명해 주세요.",
    "answer": "Stateless: 서버가 클라이언트 상태를 저장하지 않음. 각 요청이 독립적\nConnectionless: 요청-응답 후 연결을 끊음. HTTP/1.0의 기본 동작\n\nStateless는 \"상태 비저장\", Connectionless는 \"연결 비유지\"를 의미합니다.",
    "references": [
      {
        "title": "RFC 9110",
        "url": "https://www.rfc-editor.org/rfc/rfc9110"
      }
    ],
    "keywords": [
      "stateless",
      "connectionless",
      "http",
      "서버가",
      "클라이언트",
      "상태를",
      "저장하지",
      "않음",
      "요청이",
      "독립적",
      "요청",
      "응답",
      "연결을",
      "끊음",
      "기본"
    ]
  },
  {
    "id": "NET-004",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "왜 HTTP는 Stateless 구조를 채택하고 있을까요?",
    "answer": "서버 확장성: 상태를 저장하지 않아 어떤 서버든 요청 처리 가능\n단순성: 서버 구현이 단순해지고 리소스 절약\n장애 복구: 서버 장애 시에도 다른 서버가 바로 대체 가능",
    "references": [
      {
        "title": "RFC 9110 Section 3.3",
        "url": "https://www.rfc-editor.org/rfc/rfc9110#section-3.3"
      }
    ],
    "keywords": [
      "서버",
      "확장성",
      "상태를",
      "저장하지",
      "않아",
      "어떤",
      "서버든",
      "요청",
      "처리",
      "가능",
      "단순성",
      "구현이",
      "단순해지고",
      "리소스",
      "절약"
    ]
  },
  {
    "id": "NET-005",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "Connectionless의 논리대로면 성능이 되게 좋지 않을 것으로 보이는데, 해결 방법이 있을까요?",
    "answer": "HTTP/1.1부터 Keep-Alive(Persistent Connection)를 도입하여 해결합니다. 하나의 TCP 연결로 여러 요청/응답을 처리하여 연결 설정 오버헤드를 줄입니다.",
    "references": [
      {
        "title": "RFC 9112 Section 9.3",
        "url": "https://www.rfc-editor.org/rfc/rfc9112#section-9.3"
      }
    ],
    "keywords": [
      "http",
      "keep-alive",
      "persistent",
      "connection",
      "tcp",
      "부터",
      "도입하여",
      "해결합니다",
      "하나의",
      "연결로",
      "여러",
      "요청",
      "응답을",
      "처리하여",
      "연결"
    ]
  },
  {
    "id": "NET-006",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "TCP의 keep-alive와 HTTP의 keep-alive의 차이는 무엇인가요?",
    "answer": "TCP Keep-Alive: 연결이 살아있는지 확인하는 프로브 패킷. 유휴 연결 감지 목적\nHTTP Keep-Alive: 하나의 TCP 연결로 여러 HTTP 요청/응답을 처리. 성능 최적화 목적\n\nTCP는 \"연결 상태 확인\", HTTP는 \"연결 재사용\"이 목적입니다.",
    "references": [
      {
        "title": "RFC 9112",
        "url": "https://www.rfc-editor.org/rfc/rfc9112"
      }
    ],
    "keywords": [
      "tcp",
      "keep-alive",
      "http",
      "연결이",
      "살아있는지",
      "확인하는",
      "프로브",
      "패킷",
      "유휴",
      "연결",
      "감지",
      "목적",
      "하나의",
      "연결로",
      "여러"
    ]
  },
  {
    "id": "NET-007",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "HTTP/1.1과 HTTP/2의 차이점은 무엇인가요?",
    "answer": "구분   HTTP/1.1   HTTP/2\n\n전송 방식   텍스트   바이너리 프레임\n다중화   불가 (순차 처리)   멀티플렉싱 지원\n헤더   중복 전송   HPACK 압축\n서버 푸시   미지원   지원",
    "references": [
      {
        "title": "RFC 9113 - HTTP/2",
        "url": "https://www.rfc-editor.org/rfc/rfc9113"
      }
    ],
    "keywords": [
      "http",
      "hpack",
      "구분",
      "전송",
      "방식",
      "텍스트",
      "바이너리",
      "프레임",
      "다중화",
      "불가",
      "순차",
      "처리",
      "멀티플렉싱",
      "지원",
      "헤더"
    ]
  },
  {
    "id": "NET-008",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "HOL Blocking 에 대해 설명해 주세요.",
    "answer": "HOL(Head-of-Line) Blocking은 앞선 요청이 완료될 때까지 뒤의 요청이 대기하는 현상입니다.\nHTTP/1.1: 파이프라이닝에서 앞 응답 지연 시 뒤 응답도 지연\nHTTP/2: 애플리케이션 레벨 HOL은 해결, TCP 레벨 HOL은 존재\nHTTP/3: QUIC 사용으로 TCP HOL도 해결",
    "references": [
      {
        "title": "RFC 9113 Section 1",
        "url": "https://www.rfc-editor.org/rfc/rfc9113#section-1"
      }
    ],
    "keywords": [
      "hol",
      "head-of-line",
      "blocking",
      "http",
      "tcp",
      "quic",
      "앞선",
      "요청이",
      "완료될",
      "때까지",
      "뒤의",
      "대기하는",
      "현상입니다",
      "파이프라이닝에서",
      "응답"
    ]
  },
  {
    "id": "NET-009",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "HTTP/3.0의 주요 특징에 대해 설명해 주세요.",
    "answer": "QUIC 프로토콜: UDP 기반으로 TCP의 HOL Blocking 해결\n0-RTT 연결: 이전 연결 정보로 빠른 재연결\n연결 마이그레이션: IP 변경 시에도 연결 유지 (Connection ID 사용)\n내장 TLS 1.3: 보안이 기본 포함",
    "references": [
      {
        "title": "RFC 9114 - HTTP/3",
        "url": "https://www.rfc-editor.org/rfc/rfc9114"
      }
    ],
    "keywords": [
      "quic",
      "udp",
      "tcp",
      "hol",
      "blocking",
      "rtt",
      "connection",
      "tls",
      "프로토콜",
      "기반으로",
      "해결",
      "연결",
      "이전",
      "정보로",
      "빠른"
    ]
  },
  {
    "id": "NET-010",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "왜 HTTP는 TCP를 사용하나요?",
    "answer": "HTTP는 신뢰성 있는 데이터 전송이 필요하기 때문입니다.\n웹 페이지, 파일 등은 데이터 손실 없이 정확하게 전달되어야 함\nTCP는 순서 보장, 재전송, 흐름/혼잡 제어 제공\nUDP는 이런 기능이 없어 애플리케이션에서 직접 구현 필요",
    "references": [
      {
        "title": "RFC 9110 Section 3.3",
        "url": "https://www.rfc-editor.org/rfc/rfc9110#section-3.3"
      }
    ],
    "keywords": [
      "http",
      "tcp",
      "udp",
      "신뢰성",
      "있는",
      "데이터",
      "전송이",
      "필요하기",
      "때문입니다",
      "페이지",
      "파일",
      "등은",
      "손실",
      "없이",
      "정확하게"
    ]
  },
  {
    "id": "NET-011",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "그렇다면, 왜 HTTP/3 에서는 UDP를 사용하나요? 위에서 언급한 UDP의 문제가 해결되었나요?",
    "answer": "QUIC 프로토콜이 UDP 위에서 TCP의 기능을 구현합니다.\n신뢰성: QUIC이 재전송, 순서 보장 직접 구현\nTCP HOL 해결: 스트림 단위 독립 처리로 한 스트림 손실이 다른 스트림에 영향 없음\nUDP 선택 이유: 커널 수정 없이 사용자 공간에서 빠른 개선 가능",
    "references": [
      {
        "title": "RFC 9000 - QUIC",
        "url": "https://www.rfc-editor.org/rfc/rfc9000"
      }
    ],
    "keywords": [
      "quic",
      "udp",
      "tcp",
      "hol",
      "프로토콜이",
      "위에서",
      "기능을",
      "구현합니다",
      "신뢰성",
      "재전송",
      "순서",
      "보장",
      "직접",
      "구현",
      "해결"
    ]
  },
  {
    "id": "NET-012",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "그런데, 브라우저는 어떤 서버가 TCP를 쓰는지 UDP를 쓰는지 어떻게 알 수 있나요?",
    "answer": "Alt-Svc(Alternative Services) 헤더를 통해 알 수 있습니다.\n브라우저는 먼저 TCP(HTTP/1.1 또는 HTTP/2)로 연결\n서버가 Alt-Svc: h3=\":443\" 헤더로 HTTP/3 지원 알림\n브라우저가 다음 요청부터 QUIC(UDP) 사용",
    "references": [
      {
        "title": "RFC 7838 - HTTP Alternative Services",
        "url": "https://www.rfc-editor.org/rfc/rfc7838"
      }
    ],
    "keywords": [
      "alt-svc",
      "alternative",
      "services",
      "tcp",
      "http",
      "quic",
      "udp",
      "헤더를",
      "브라우저는",
      "먼저",
      "연결",
      "서버가",
      "헤더로",
      "지원",
      "알림"
    ]
  },
  {
    "id": "NET-013",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "HTTP 응답코드에 대해 설명해 주세요.",
    "answer": "HTTP 응답코드는 3자리 숫자로 요청 처리 결과를 나타냅니다.\n\n범위   의미   예시\n\n1xx   정보   100 Continue\n2xx   성공   200 OK, 201 Created\n3xx   리다이렉션   301 Moved, 304 Not Modified\n4xx   클라이언트 오류   400 Bad Request, 404 Not Found\n5xx   서버 오류   500 Internal Server Error",
    "references": [
      {
        "title": "RFC 9110 Section 15",
        "url": "https://www.rfc-editor.org/rfc/rfc9110#section-15"
      }
    ],
    "keywords": [
      "http",
      "continue",
      "created",
      "moved",
      "modified",
      "bad",
      "request",
      "found",
      "internal",
      "server",
      "error",
      "응답코드는",
      "자리",
      "숫자로",
      "요청"
    ]
  },
  {
    "id": "NET-014",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "401 (Unauthorized) 와 403 (Forbidden)은 의미적으로 어떤 차이가 있나요?",
    "answer": "401 Unauthorized: 인증(Authentication) 필요. 로그인하지 않은 상태\n403 Forbidden: 인가(Authorization) 실패. 로그인은 했지만 권한 없음\n\n예: 관리자 페이지 접근 시\n비로그인 사용자 -> 401\n일반 사용자 -> 403",
    "references": [
      {
        "title": "RFC 9110 Section 15.5.2, 15.5.4",
        "url": "https://www.rfc-editor.org/rfc/rfc9110#section-15.5.2"
      }
    ],
    "keywords": [
      "unauthorized",
      "authentication",
      "forbidden",
      "authorization",
      "인증",
      "필요",
      "로그인하지",
      "않은",
      "상태",
      "인가",
      "실패",
      "로그인은",
      "했지만",
      "권한",
      "없음"
    ]
  },
  {
    "id": "NET-015",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "200 (ok) 와 201 (created) 의 차이에 대해 설명해 주세요.",
    "answer": "200 OK: 요청이 성공적으로 처리됨 (일반적인 성공)\n201 Created: 요청 결과로 새로운 리소스가 생성됨\n\n주로 POST 요청에서 리소스 생성 시 201을, GET/PUT/DELETE 등에서는 200을 사용합니다. 201 응답에는 Location 헤더로 생성된 리소스 URI를 포함할 수 있습니다.",
    "references": [
      {
        "title": "RFC 9110 Section 15.3.1, 15.3.2",
        "url": "https://www.rfc-editor.org/rfc/rfc9110#section-15.3.1"
      }
    ],
    "keywords": [
      "created",
      "post",
      "get",
      "put",
      "delete",
      "location",
      "uri",
      "요청이",
      "성공적으로",
      "처리됨",
      "일반적인",
      "성공",
      "요청",
      "결과로",
      "새로운"
    ]
  },
  {
    "id": "NET-016",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "필요하다면 저희가 직접 응답코드를 정의해서 사용할 수 있을까요? 예를 들어 285번 처럼요.",
    "answer": "기술적으로 가능하지만 권장하지 않습니다.\n클라이언트가 해당 코드를 이해하지 못할 수 있음\n표준을 따르지 않아 호환성 문제 발생\n미등록 코드는 같은 클래스(2xx면 성공)로 해석됨\n\n대신 표준 코드 + 응답 본문에 상세 정보를 포함하는 방식을 권장합니다.",
    "references": [
      {
        "title": "RFC 9110 Section 15",
        "url": "https://www.rfc-editor.org/rfc/rfc9110#section-15"
      }
    ],
    "keywords": [
      "기술적으로",
      "가능하지만",
      "권장하지",
      "않습니다",
      "클라이언트가",
      "해당",
      "코드를",
      "이해하지",
      "못할",
      "있음",
      "표준을",
      "따르지",
      "않아",
      "호환성",
      "문제"
    ]
  },
  {
    "id": "NET-017",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "HTTP Method 에 대해 설명해 주세요.",
    "answer": "HTTP Method는 리소스에 대해 수행할 동작을 정의합니다.\n\nMethod   설명   멱등성   안전\n\nGET   리소스 조회   O   O\nPOST   리소스 생성   X   X\nPUT   리소스 전체 수정   O   X\nPATCH   리소스 부분 수정   X   X\nDELETE   리소스 삭제   O   X\nHEAD   헤더만 조회   O   O\nOPTIONS   지원 메서드 확인   O   O",
    "references": [
      {
        "title": "RFC 9110 Section 9",
        "url": "https://www.rfc-editor.org/rfc/rfc9110#section-9"
      }
    ],
    "keywords": [
      "http",
      "method",
      "get",
      "post",
      "put",
      "patch",
      "delete",
      "head",
      "options",
      "리소스에",
      "수행할",
      "동작을",
      "정의합니다",
      "설명",
      "멱등성"
    ]
  },
  {
    "id": "NET-018",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "HTTP Method의 멱등성에 대해 설명해 주세요.",
    "answer": "멱등성(Idempotency)은 동일한 요청을 여러 번 보내도 결과가 같은 특성입니다.\n멱등 메서드: GET, PUT, DELETE, HEAD, OPTIONS\n비멱등 메서드: POST, PATCH\n\n예: DELETE /users/1을 여러 번 호출해도 결과는 \"해당 유저 없음\"으로 동일합니다.",
    "references": [
      {
        "title": "RFC 9110 Section 9.2.2",
        "url": "https://www.rfc-editor.org/rfc/rfc9110#section-9.2.2"
      }
    ],
    "keywords": [
      "idempotency",
      "get",
      "put",
      "delete",
      "head",
      "options",
      "post",
      "patch",
      "멱등성",
      "동일한",
      "요청을",
      "여러",
      "보내도",
      "결과가",
      "같은"
    ]
  },
  {
    "id": "NET-019",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "GET과 POST의 차이는 무엇인가요?",
    "answer": "구분   GET   POST\n\n목적   리소스 조회   리소스 생성/처리\n데이터 위치   URL 쿼리스트링   Request Body\n캐싱   가능   불가\n멱등성   O   X\n북마크   가능   불가\n데이터 길이   URL 길이 제한   제한 없음",
    "references": [
      {
        "title": "RFC 9110 Section 9.3.1, 9.3.3",
        "url": "https://www.rfc-editor.org/rfc/rfc9110#section-9.3.1"
      }
    ],
    "keywords": [
      "get",
      "post",
      "url",
      "request",
      "body",
      "구분",
      "목적",
      "리소스",
      "조회",
      "생성",
      "처리",
      "데이터",
      "위치",
      "쿼리스트링",
      "캐싱"
    ]
  },
  {
    "id": "NET-020",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "POST와 PUT, PATCH의 차이는 무엇인가요?",
    "answer": "메서드   용도   멱등성\n\nPOST   리소스 생성 (서버가 URI 결정)   X\nPUT   리소스 전체 교체/생성 (클라이언트가 URI 지정)   O\nPATCH   리소스 부분 수정   X\nPUT은 전체 데이터를 보내 덮어쓰기\nPATCH는 변경할 필드만 전송",
    "references": [
      {
        "title": "RFC 9110 Section 9.3.3, 9.3.4",
        "url": "https://www.rfc-editor.org/rfc/rfc9110#section-9.3.3"
      }
    ],
    "keywords": [
      "post",
      "uri",
      "put",
      "patch",
      "메서드",
      "용도",
      "멱등성",
      "리소스",
      "생성",
      "서버가",
      "결정",
      "전체",
      "교체",
      "클라이언트가",
      "지정"
    ]
  },
  {
    "id": "NET-021",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "HTTP 1.1 이후로, GET에도 Body에 데이터를 실을 수 있게 되었습니다. 그럼에도 불구하고 왜 아직도 이런 방식을 지양하는 것일까요?",
    "answer": "캐싱 문제: 캐시는 URL 기반으로 동작, Body는 캐시 키에 포함 안 됨\n호환성: 일부 서버/프록시/라이브러리가 GET Body를 무시하거나 오류 발생\n의미론 위반: GET은 \"조회\"의 의미, Body는 \"데이터 전송\"의 의미\n로깅/디버깅 어려움: URL만 로그에 남으면 요청 재현 불가",
    "references": [
      {
        "title": "RFC 9110 Section 9.3.1",
        "url": "https://www.rfc-editor.org/rfc/rfc9110#section-9.3.1"
      }
    ],
    "keywords": [
      "url",
      "body",
      "get",
      "캐싱",
      "문제",
      "캐시는",
      "기반으로",
      "동작",
      "캐시",
      "키에",
      "포함",
      "호환성",
      "일부",
      "서버",
      "프록시"
    ]
  },
  {
    "id": "NET-022",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "쿠키와 세션의 차이에 대해 설명해 주세요.",
    "answer": "구분   쿠키   세션\n\n저장 위치   클라이언트 (브라우저)   서버\n보안   상대적으로 취약   상대적으로 안전\n용량   약 4KB 제한   서버 메모리 의존\n만료   설정된 기간   브라우저 종료 또는 타임아웃\n속도   빠름   서버 조회 필요",
    "references": [
      {
        "title": "RFC 6265 - HTTP State Management",
        "url": "https://www.rfc-editor.org/rfc/rfc6265"
      }
    ],
    "keywords": [
      "구분",
      "쿠키",
      "세션",
      "저장",
      "위치",
      "클라이언트",
      "브라우저",
      "서버",
      "보안",
      "상대적으로",
      "취약",
      "안전",
      "용량",
      "제한",
      "메모리"
    ]
  },
  {
    "id": "NET-023",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "세션 방식의 로그인 과정에 대해 설명해 주세요.",
    "answer": "클라이언트가 ID/PW로 로그인 요청\n서버가 인증 후 세션 ID 생성, 서버 메모리/DB에 저장\n서버가 Set-Cookie 헤더로 세션 ID를 클라이언트에 전달\n클라이언트는 이후 요청마다 Cookie 헤더에 세션 ID 포함\n서버가 세션 ID로 사용자 정보 조회하여 인증 처리",
    "references": [
      {
        "title": "RFC 6265 - HTTP Cookies",
        "url": "https://www.rfc-editor.org/rfc/rfc6265"
      }
    ],
    "keywords": [
      "set-cookie",
      "cookie",
      "클라이언트가",
      "로그인",
      "요청",
      "서버가",
      "인증",
      "세션",
      "생성",
      "서버",
      "메모리",
      "저장",
      "헤더로",
      "클라이언트에",
      "전달"
    ]
  },
  {
    "id": "NET-024",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "Stateless의 의미를 살펴보면, 세션은 적절하지 않은 인증 방법 아닌가요?",
    "answer": "맞습니다. 세션은 서버에 상태를 저장하므로 Stateless 원칙에 위배됩니다.\n\n세션의 문제점:\n서버 메모리 사용\n서버 확장 시 세션 동기화 필요\n서버 장애 시 세션 유실\n\n대안: JWT(JSON Web Token) 같은 토큰 방식은 상태를 클라이언트에 저장하여 Stateless 유지 가능합니다.",
    "references": [
      {
        "title": "RFC 7519 - JWT",
        "url": "https://www.rfc-editor.org/rfc/rfc7519"
      }
    ],
    "keywords": [
      "stateless",
      "jwt",
      "json",
      "web",
      "token",
      "맞습니다",
      "세션은",
      "서버에",
      "상태를",
      "저장하므로",
      "원칙에",
      "위배됩니다",
      "세션의",
      "문제점",
      "서버"
    ]
  },
  {
    "id": "NET-025",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "규모가 커져 서버가 여러 개가 된다면, 세션을 어떻게 관리할 수 있을까요?",
    "answer": "Sticky Session: 로드밸런서가 같은 사용자를 같은 서버로 라우팅\n세션 클러스터링: 서버 간 세션 복제 (Tomcat Session Replication)\n세션 스토리지: Redis, Memcached 등 외부 저장소에 세션 저장\n토큰 방식: JWT로 Stateless하게 전환\n\n가장 일반적인 방식은 Redis를 이용한 세션 스토리지입니다.",
    "references": [
      {
        "title": "MDN - HTTP Session",
        "url": "https://developer.mozilla.org/en-US/docs/Web/HTTP/Session"
      }
    ],
    "keywords": [
      "sticky",
      "session",
      "tomcat",
      "replication",
      "redis",
      "memcached",
      "jwt",
      "stateless",
      "로드밸런서가",
      "같은",
      "사용자를",
      "서버로",
      "라우팅",
      "세션",
      "클러스터링"
    ]
  },
  {
    "id": "NET-026",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "공개키와 대칭키에 대해 설명해 주세요.",
    "answer": "대칭키 암호화:\n암호화/복호화에 동일한 키 사용\n빠른 속도, 키 교환 문제 존재\n예: AES, DES\n\n공개키(비대칭키) 암호화:\n공개키로 암호화, 개인키로 복호화 (또는 반대)\n느린 속도, 안전한 키 교환\n예: RSA, ECDSA\n\nHTTPS는 공개키로 대칭키를 교환한 후, 대칭키로 통신합니다.",
    "references": [
      {
        "title": "RFC 8446 - TLS 1.3",
        "url": "https://www.rfc-editor.org/rfc/rfc8446"
      }
    ],
    "keywords": [
      "aes",
      "des",
      "rsa",
      "ecdsa",
      "https",
      "대칭키",
      "암호화",
      "복호화에",
      "동일한",
      "사용",
      "빠른",
      "속도",
      "교환",
      "문제",
      "존재"
    ]
  },
  {
    "id": "NET-027",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "왜 HTTPS Handshake 과정에서는 인증서를 사용하는 것 일까요?",
    "answer": "중간자 공격(MITM) 방지를 위해서입니다.\n\n공개키만으로는 해당 키가 진짜 서버의 것인지 확인할 수 없습니다. 인증서는:\n신뢰할 수 있는 CA(인증기관)가 서버 신원을 보증\n서버의 공개키가 변조되지 않았음을 증명\n도메인 소유권 확인",
    "references": [
      {
        "title": "RFC 8446 Section 4.4.2",
        "url": "https://www.rfc-editor.org/rfc/rfc8446#section-4.4.2"
      }
    ],
    "keywords": [
      "mitm",
      "중간자",
      "공격",
      "방지를",
      "위해서입니다",
      "공개키만으로는",
      "해당",
      "키가",
      "진짜",
      "서버의",
      "것인지",
      "확인할",
      "없습니다",
      "인증서는",
      "신뢰할"
    ]
  },
  {
    "id": "NET-028",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "SSL과 TLS의 차이는 무엇인가요?",
    "answer": "TLS는 SSL의 후속 버전입니다.\nSSL: Netscape에서 개발, SSL 3.0이 마지막 버전 (보안 취약점으로 사용 중단)\nTLS: IETF에서 표준화, SSL 3.0 기반으로 TLS 1.0 시작\n\n현재는 TLS 1.2/1.3이 표준이며, \"SSL\"은 관용적으로 TLS를 포함하여 부르는 경우가 많습니다.",
    "references": [
      {
        "title": "RFC 8446 - TLS 1.3",
        "url": "https://www.rfc-editor.org/rfc/rfc8446"
      }
    ],
    "keywords": [
      "tls",
      "ssl",
      "netscape",
      "ietf",
      "후속",
      "버전입니다",
      "에서",
      "개발",
      "마지막",
      "버전",
      "보안",
      "취약점으로",
      "사용",
      "중단",
      "표준화"
    ]
  },
  {
    "id": "NET-029",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "XSS에 대해서 설명해 주세요.",
    "answer": "XSS(Cross-Site Scripting)는 공격자가 웹페이지에 악성 스크립트를 삽입하는 공격입니다.\n\n유형:\nStored XSS: DB에 저장된 악성 스크립트가 실행\nReflected XSS: URL 파라미터의 스크립트가 즉시 반영\nDOM-based XSS: 클라이언트 측 JS에서 발생\n\n방지: 입력값 검증, 출력 인코딩, CSP 헤더 사용",
    "references": [
      {
        "title": "OWASP XSS Prevention",
        "url": "https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html"
      }
    ],
    "keywords": [
      "xss",
      "cross-site",
      "scripting",
      "stored",
      "reflected",
      "url",
      "dom-based",
      "csp",
      "공격자가",
      "웹페이지에",
      "악성",
      "스크립트를",
      "삽입하는",
      "공격입니다",
      "유형"
    ]
  },
  {
    "id": "NET-030",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "CSRF랑 XSS는 어떤 차이가 있나요?",
    "answer": "구분   XSS   CSRF\n\n공격 대상   사용자 브라우저   서버\n공격 방식   악성 스크립트 실행   사용자 권한으로 요청 위조\n목적   쿠키 탈취, 세션 하이재킹   사용자 모르게 행위 수행\n방지   입력 검증, 출력 인코딩   CSRF 토큰, SameSite 쿠키",
    "references": [
      {
        "title": "OWASP CSRF Prevention",
        "url": "https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html"
      }
    ],
    "keywords": [
      "xss",
      "csrf",
      "samesite",
      "구분",
      "공격",
      "대상",
      "사용자",
      "브라우저",
      "서버",
      "방식",
      "악성",
      "스크립트",
      "실행",
      "권한으로",
      "요청"
    ]
  },
  {
    "id": "NET-031",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "XSS는 프론트엔드에서만 막을 수 있나요?",
    "answer": "아닙니다. 백엔드에서도 반드시 방어해야 합니다.\n백엔드: 입력값 검증/필터링, 출력 시 HTML 인코딩\n프론트엔드: innerHTML 대신 textContent 사용, sanitize 라이브러리\nHTTP 헤더: Content-Security-Policy(CSP), X-XSS-Protection\n\n프론트엔드만으로는 API 직접 호출 등을 막을 수 없어 다층 방어가 필수입니다.",
    "references": [
      {
        "title": "MDN CSP",
        "url": "https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP"
      }
    ],
    "keywords": [
      "html",
      "http",
      "content-security-policy",
      "csp",
      "x-xss-protection",
      "api",
      "아닙니다",
      "백엔드에서도",
      "반드시",
      "방어해야",
      "백엔드",
      "입력값",
      "검증",
      "필터링",
      "출력"
    ]
  },
  {
    "id": "NET-032",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "SOP 정책에 대해 설명해 주세요.",
    "answer": "SOP(Same-Origin Policy)는 브라우저 보안 정책으로, 다른 출처의 리소스 접근을 제한합니다.\n\n동일 출처 조건 (모두 일치해야 함):\n프로토콜 (http/https)\n호스트 (domain)\n포트\n\n예: https://example.com:443과 https://example.com:8080은 다른 출처입니다.",
    "references": [
      {
        "title": "MDN Same-Origin Policy",
        "url": "https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy"
      }
    ],
    "keywords": [
      "sop",
      "same-origin",
      "policy",
      "브라우저",
      "보안",
      "정책으로",
      "다른",
      "출처의",
      "리소스",
      "접근을",
      "제한합니다",
      "동일",
      "출처",
      "조건",
      "모두"
    ]
  },
  {
    "id": "NET-033",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "CORS 정책이 무엇인가요?",
    "answer": "CORS(Cross-Origin Resource Sharing)는 SOP를 우회하여 다른 출처의 리소스를 안전하게 요청할 수 있게 하는 메커니즘입니다.\n\n서버가 응답 헤더로 허용할 출처를 지정합니다:\nAccess-Control-Allow-Origin: 허용할 출처\nAccess-Control-Allow-Methods: 허용할 HTTP 메서드\nAccess-Control-Allow-Headers: 허용할 헤더",
    "references": [
      {
        "title": "MDN CORS",
        "url": "https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS"
      }
    ],
    "keywords": [
      "cors",
      "cross-origin",
      "resource",
      "sharing",
      "sop",
      "access-control-allow-origin",
      "access-control-allow-methods",
      "http",
      "access-control-allow-headers",
      "우회하여",
      "다른",
      "출처의",
      "리소스를",
      "안전하게",
      "요청할"
    ]
  },
  {
    "id": "NET-034",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "Preflight에 대해 설명해 주세요.",
    "answer": "Preflight 요청은 실제 요청 전에 서버가 해당 요청을 허용하는지 확인하는 OPTIONS 요청입니다.\n\n발생 조건 (Simple Request가 아닌 경우):\nGET/POST/HEAD 외의 메서드\n커스텀 헤더 포함\nContent-Type이 application/json 등\n\n과정:\n브라우저가 OPTIONS 요청 전송\n서버가 CORS 헤더로 허용 여부 응답\n허용 시 실제 요청 전송",
    "references": [
      {
        "title": "MDN Preflight Request",
        "url": "https://developer.mozilla.org/en-US/docs/Glossary/Preflight_request"
      }
    ],
    "keywords": [
      "preflight",
      "options",
      "simple",
      "request",
      "get",
      "post",
      "head",
      "content-type",
      "cors",
      "요청은",
      "실제",
      "요청",
      "전에",
      "서버가",
      "해당"
    ]
  },
  {
    "id": "NET-035",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "TCP와 UDP의 차이에 대해 설명해 주세요.",
    "answer": "구분   TCP   UDP\n\n연결   연결 지향 (3-way handshake)   비연결\n신뢰성   순서 보장, 재전송   보장 안 함\n속도   상대적으로 느림   빠름\n흐름/혼잡 제어   있음   없음\n용도   HTTP, 파일 전송   스트리밍, DNS, 게임",
    "references": [
      {
        "title": "RFC 9293 - TCP",
        "url": "https://www.rfc-editor.org/rfc/rfc9293"
      }
    ],
    "keywords": [
      "tcp",
      "udp",
      "http",
      "dns",
      "구분",
      "연결",
      "지향",
      "비연결",
      "신뢰성",
      "순서",
      "보장",
      "재전송",
      "속도",
      "상대적으로",
      "느림"
    ]
  },
  {
    "id": "NET-036",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "Checksum이 무엇인가요?",
    "answer": "Checksum은 데이터 전송 중 오류를 감지하기 위한 값입니다.\n송신자: 데이터를 계산하여 체크섬 값 생성 후 함께 전송\n수신자: 받은 데이터로 체크섬 재계산, 일치 여부 확인\n\n일치하지 않으면 데이터가 손상된 것으로 판단합니다. 오류 \"감지\"만 가능하고 \"정정\"은 불가합니다.",
    "references": [
      {
        "title": "RFC 9293 Section 3.1",
        "url": "https://www.rfc-editor.org/rfc/rfc9293#section-3.1"
      }
    ],
    "keywords": [
      "checksum",
      "데이터",
      "전송",
      "오류를",
      "감지하기",
      "위한",
      "값입니다",
      "송신자",
      "데이터를",
      "계산하여",
      "체크섬",
      "생성",
      "함께",
      "수신자",
      "받은"
    ]
  },
  {
    "id": "NET-037",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "TCP와 UDP 중 어느 프로토콜이 Checksum을 수행할까요?",
    "answer": "둘 다 Checksum을 수행합니다.\nTCP: 필수 (헤더 + 데이터 + 의사 헤더)\nUDP: IPv4에서는 선택, IPv6에서는 필수\n\nUDP는 IPv4에서 체크섬을 0으로 설정하여 생략할 수 있지만, IPv6에서는 IP 헤더에 체크섬이 없어 UDP 체크섬이 필수입니다.",
    "references": [
      {
        "title": "RFC 768 - UDP",
        "url": "https://www.rfc-editor.org/rfc/rfc768"
      }
    ],
    "keywords": [
      "checksum",
      "tcp",
      "udp",
      "ipv4",
      "ipv6",
      "수행합니다",
      "필수",
      "헤더",
      "데이터",
      "의사",
      "에서는",
      "선택",
      "에서",
      "체크섬을",
      "으로"
    ]
  },
  {
    "id": "NET-038",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "그렇다면, Checksum을 통해 오류를 정정할 수 있나요?",
    "answer": "아니요, Checksum은 오류 감지(Detection)만 가능하고 정정(Correction)은 불가합니다.\n\n오류 발견 시:\nTCP: 해당 세그먼트 폐기 후 재전송 요청\nUDP: 해당 데이터그램 폐기 (재전송 없음)\n\n오류 정정이 필요하면 FEC(Forward Error Correction) 같은 별도 메커니즘이 필요합니다.",
    "references": [
      {
        "title": "RFC 9293",
        "url": "https://www.rfc-editor.org/rfc/rfc9293"
      }
    ],
    "keywords": [
      "checksum",
      "detection",
      "correction",
      "tcp",
      "udp",
      "fec",
      "forward",
      "error",
      "아니요",
      "오류",
      "감지",
      "가능하고",
      "정정",
      "불가합니다",
      "발견"
    ]
  },
  {
    "id": "NET-039",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "TCP가 신뢰성을 보장하는 방법에 대해 설명해 주세요.",
    "answer": "순서 번호(Sequence Number): 데이터 순서 보장\n확인 응답(ACK): 수신 확인, 미수신 시 재전송\n체크섬: 데이터 무결성 검증\n타임아웃 재전송: ACK 미수신 시 재전송\n흐름 제어(Flow Control): 수신자 버퍼 오버플로우 방지\n혼잡 제어(Congestion Control): 네트워크 혼잡 시 전송량 조절",
    "references": [
      {
        "title": "RFC 9293",
        "url": "https://www.rfc-editor.org/rfc/rfc9293"
      }
    ],
    "keywords": [
      "sequence",
      "number",
      "ack",
      "flow",
      "control",
      "congestion",
      "순서",
      "번호",
      "데이터",
      "보장",
      "확인",
      "응답",
      "수신",
      "미수신",
      "재전송"
    ]
  },
  {
    "id": "NET-040",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "TCP의 혼잡 제어 처리 방법에 대해 설명해 주세요.",
    "answer": "Slow Start: 지수적으로 윈도우 크기 증가 (1 -> 2 -> 4 -> 8...)\nCongestion Avoidance: 임계점 도달 후 선형 증가\nFast Retransmit: 3개의 중복 ACK 수신 시 즉시 재전송\nFast Recovery: 손실 후 Slow Start 대신 혼잡 회피 상태로 복구\n\n손실 감지 시 윈도우 크기를 절반으로 줄이고 다시 증가시킵니다.",
    "references": [
      {
        "title": "RFC 5681 - TCP Congestion Control",
        "url": "https://www.rfc-editor.org/rfc/rfc5681"
      }
    ],
    "keywords": [
      "slow",
      "start",
      "congestion",
      "avoidance",
      "fast",
      "retransmit",
      "ack",
      "recovery",
      "지수적으로",
      "윈도우",
      "크기",
      "증가",
      "임계점",
      "도달",
      "선형"
    ]
  },
  {
    "id": "NET-041",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "본인이 새로운 통신 프로토콜을 TCP나 UDP를 사용해서 구현한다고 하면, 어떤 기준으로 프로토콜을 선택하시겠어요?",
    "answer": "TCP 선택 시:\n데이터 손실이 치명적인 경우 (파일 전송, 금융 거래)\n순서가 중요한 경우\n신뢰성이 최우선인 경우\n\nUDP 선택 시:\n실시간성이 중요한 경우 (게임, 스트리밍, VoIP)\n일부 손실이 허용되는 경우\n직접 신뢰성 메커니즘을 구현할 경우 (QUIC처럼)",
    "references": [
      {
        "title": "RFC 9293",
        "url": "https://www.rfc-editor.org/rfc/rfc9293"
      }
    ],
    "keywords": [
      "tcp",
      "udp",
      "voip",
      "quic",
      "선택",
      "데이터",
      "손실이",
      "치명적인",
      "파일",
      "전송",
      "금융",
      "거래",
      "순서가",
      "중요한",
      "신뢰성이"
    ]
  },
  {
    "id": "NET-042",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "3-Way Handshake에 대해 설명해 주세요.",
    "answer": "TCP 연결 수립을 위한 3단계 과정입니다.\nSYN: 클라이언트 -> 서버 (연결 요청, seq=x)\nSYN-ACK: 서버 -> 클라이언트 (요청 수락, seq=y, ack=x+1)\nACK: 클라이언트 -> 서버 (연결 확립, ack=y+1)\n\n이 과정으로 양방향 통신 준비와 초기 순서 번호 교환이 완료됩니다.",
    "references": [
      {
        "title": "RFC 9293 Section 3.5",
        "url": "https://www.rfc-editor.org/rfc/rfc9293#section-3.5"
      }
    ],
    "keywords": [
      "tcp",
      "syn",
      "syn-ack",
      "ack",
      "연결",
      "수립을",
      "위한",
      "단계",
      "과정입니다",
      "클라이언트",
      "서버",
      "요청",
      "수락",
      "확립",
      "과정으로"
    ]
  },
  {
    "id": "NET-043",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "ACK, SYN 같은 정보는 어떻게 전달하는 것 일까요?",
    "answer": "TCP 헤더의 플래그 비트를 통해 전달합니다.\n\nTCP 헤더에는 6개의 제어 플래그가 있습니다:\nSYN: 연결 요청\nACK: 확인 응답\nFIN: 연결 종료\nRST: 연결 리셋\nPSH: 데이터 즉시 전달\nURG: 긴급 데이터\n\n각 플래그는 1비트로, 설정(1) 또는 해제(0) 상태입니다.",
    "references": [
      {
        "title": "RFC 9293 Section 3.1",
        "url": "https://www.rfc-editor.org/rfc/rfc9293#section-3.1"
      }
    ],
    "keywords": [
      "tcp",
      "syn",
      "ack",
      "fin",
      "rst",
      "psh",
      "urg",
      "헤더의",
      "플래그",
      "비트를",
      "전달합니다",
      "헤더에는",
      "개의",
      "제어",
      "플래그가"
    ]
  },
  {
    "id": "NET-044",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "2-Way Handshaking 를 하지않는 이유에 대해 설명해 주세요.",
    "answer": "양방향 통신 준비 확인이 불가능하기 때문입니다.\n\n2-Way의 문제:\n클라이언트는 서버의 수신 능력만 확인\n서버는 클라이언트의 수신 능력 확인 불가\n이전 연결의 지연된 SYN 패킷이 새 연결로 오인될 수 있음\n\n3-Way로 양쪽 모두 송수신 가능함을 확인하고, 초기 순서 번호를 안전하게 교환합니다.",
    "references": [
      {
        "title": "RFC 9293 Section 3.5",
        "url": "https://www.rfc-editor.org/rfc/rfc9293#section-3.5"
      }
    ],
    "keywords": [
      "way",
      "syn",
      "양방향",
      "통신",
      "준비",
      "확인이",
      "불가능하기",
      "때문입니다",
      "문제",
      "클라이언트는",
      "서버의",
      "수신",
      "능력만",
      "확인",
      "서버는"
    ]
  },
  {
    "id": "NET-045",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "두 호스트가 동시에 연결을 시도하면, 연결이 가능한가요? 가능하다면 어떻게 통신 연결을 수행하나요?",
    "answer": "가능합니다. 이를 Simultaneous Open이라 합니다.\n\n과정:\nA -> B: SYN\nB -> A: SYN (동시에)\nA: B의 SYN 수신, SYN-ACK 전송\nB: A의 SYN 수신, SYN-ACK 전송\n양쪽 모두 SYN-ACK 수신하여 연결 수립\n\n결과적으로 4개의 세그먼트로 연결이 수립됩니다.",
    "references": [
      {
        "title": "RFC 9293 Section 3.5",
        "url": "https://www.rfc-editor.org/rfc/rfc9293#section-3.5"
      }
    ],
    "keywords": [
      "simultaneous",
      "open",
      "syn",
      "syn-ack",
      "가능합니다",
      "이를",
      "이라",
      "과정",
      "동시에",
      "수신",
      "전송",
      "양쪽",
      "모두",
      "수신하여",
      "연결"
    ]
  },
  {
    "id": "NET-046",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "SYN Flooding 에 대해 설명해 주세요.",
    "answer": "SYN Flooding은 TCP 3-way handshake를 악용한 DoS 공격입니다.\n\n공격 방식:\n공격자가 위조된 IP로 대량의 SYN 패킷 전송\n서버가 SYN-ACK 전송 후 ACK 대기 (half-open 상태)\n대기 큐가 가득 차 정상 연결 불가\n\n방어: SYN Cookie, SYN Proxy, 방화벽 rate limiting",
    "references": [
      {
        "title": "RFC 4987 - TCP SYN Flooding Attacks",
        "url": "https://www.rfc-editor.org/rfc/rfc4987"
      }
    ],
    "keywords": [
      "syn",
      "flooding",
      "tcp",
      "dos",
      "syn-ack",
      "ack",
      "half-open",
      "cookie",
      "proxy",
      "악용한",
      "공격입니다",
      "공격",
      "방식",
      "공격자가",
      "위조된"
    ]
  },
  {
    "id": "NET-047",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "위 질문과 모순될 수 있지만, 3-Way Handshake의 속도 문제 때문에 이동 수를 줄이는 0-RTT 기법을 많이 적용하고 있습니다. 어떤 방식으로 가능한 걸까요?",
    "answer": "TLS 1.3과 QUIC에서 0-RTT를 지원합니다.\n\n원리:\n최초 연결 시 서버가 Session Ticket/PSK 발급\n재연결 시 저장된 키로 첫 패킷부터 암호화된 데이터 전송\nHandshake와 데이터 전송이 동시에 진행\n\n주의: Replay Attack 취약점이 있어, 멱등한 요청에만 사용 권장",
    "references": [
      {
        "title": "RFC 8446 Section 2.3",
        "url": "https://www.rfc-editor.org/rfc/rfc8446#section-2.3"
      }
    ],
    "keywords": [
      "tls",
      "quic",
      "rtt",
      "session",
      "ticket",
      "psk",
      "handshake",
      "replay",
      "attack",
      "에서",
      "지원합니다",
      "원리",
      "최초",
      "연결",
      "서버가"
    ]
  },
  {
    "id": "NET-048",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "4-Way Handshake에 대해 설명해 주세요.",
    "answer": "TCP 연결 종료를 위한 4단계 과정입니다.\nFIN: 클라이언트 -> 서버 (종료 요청)\nACK: 서버 -> 클라이언트 (요청 확인)\nFIN: 서버 -> 클라이언트 (서버도 종료 준비 완료)\nACK: 클라이언트 -> 서버 (종료 확인)\n\n양방향 스트림을 각각 독립적으로 종료하기 때문에 4단계가 필요합니다.",
    "references": [
      {
        "title": "RFC 9293 Section 3.6",
        "url": "https://www.rfc-editor.org/rfc/rfc9293#section-3.6"
      }
    ],
    "keywords": [
      "tcp",
      "fin",
      "ack",
      "연결",
      "종료를",
      "위한",
      "단계",
      "과정입니다",
      "클라이언트",
      "서버",
      "종료",
      "요청",
      "확인",
      "서버도",
      "준비"
    ]
  },
  {
    "id": "NET-049",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "패킷이 4-way handshake 목적인지 어떻게 파악할 수 있을까요?",
    "answer": "TCP 헤더의 FIN 플래그로 파악합니다.\nFIN 플래그가 설정된 세그먼트 = 연결 종료 요청\n현재 연결 상태(ESTABLISHED, FIN_WAIT 등)와 함께 판단\n\nTCP는 상태 기계(State Machine)로 동작하며, 현재 상태와 받은 플래그 조합으로 다음 동작을 결정합니다.",
    "references": [
      {
        "title": "RFC 9293 Section 3.6",
        "url": "https://www.rfc-editor.org/rfc/rfc9293#section-3.6"
      }
    ],
    "keywords": [
      "tcp",
      "fin",
      "established",
      "fin_wait",
      "state",
      "machine",
      "헤더의",
      "플래그로",
      "파악합니다",
      "플래그가",
      "설정된",
      "세그먼트",
      "연결",
      "종료",
      "요청"
    ]
  },
  {
    "id": "NET-050",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "빨리 끊어야 할 경우엔, (즉, 4-way Handshake를 할 여유가 없다면) 어떻게 종료할 수 있을까요?",
    "answer": "RST(Reset) 플래그를 사용하여 즉시 종료합니다.\n\nRST 세그먼트를 보내면:\n상대방에게 즉시 연결 종료 통보\nTIME_WAIT 상태 없이 바로 종료\n송수신 버퍼 데이터 폐기\n\n사용 예: 존재하지 않는 포트로 연결 시도, 비정상 상황, 강제 종료",
    "references": [
      {
        "title": "RFC 9293 Section 3.5.2",
        "url": "https://www.rfc-editor.org/rfc/rfc9293#section-3.5.2"
      }
    ],
    "keywords": [
      "rst",
      "reset",
      "time_wait",
      "플래그를",
      "사용하여",
      "즉시",
      "종료합니다",
      "세그먼트를",
      "보내면",
      "상대방에게",
      "연결",
      "종료",
      "통보",
      "상태",
      "없이"
    ]
  },
  {
    "id": "NET-051",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "4-Way Handshake 과정에서 중간에 한쪽 네트워크가 강제로 종료된다면, 반대쪽은 이를 어떻게 인식할 수 있을까요?",
    "answer": "TCP Keep-Alive: 주기적으로 프로브 패킷 전송, 응답 없으면 연결 종료\n타임아웃: 재전송 타임아웃 초과 시 연결 종료로 판단\n애플리케이션 레벨: 자체 heartbeat 메커니즘 구현\n\nOS의 Keep-Alive는 기본 2시간으로 설정되어 있어, 빠른 감지가 필요하면 애플리케이션에서 별도 구현합니다.",
    "references": [
      {
        "title": "RFC 9293 Section 3.8.4",
        "url": "https://www.rfc-editor.org/rfc/rfc9293#section-3.8.4"
      }
    ],
    "keywords": [
      "tcp",
      "keep-alive",
      "주기적으로",
      "프로브",
      "패킷",
      "전송",
      "응답",
      "없으면",
      "연결",
      "종료",
      "타임아웃",
      "재전송",
      "초과",
      "종료로",
      "판단"
    ]
  },
  {
    "id": "NET-052",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "왜 종료 후에 바로 끝나지 않고, TIME_WAIT 상태로 대기하는 것 일까요?",
    "answer": "지연된 패킷 처리: 네트워크에 남아있는 이전 연결의 패킷이 새 연결에 영향 주지 않도록\n마지막 ACK 손실 대비: 상대방이 FIN을 재전송하면 ACK를 다시 보낼 수 있도록\n\nTIME_WAIT 시간은 2MSL(Maximum Segment Lifetime, 보통 60초)입니다. 이 시간 동안 같은 소켓 쌍으로 새 연결이 불가합니다.",
    "references": [
      {
        "title": "RFC 9293 Section 3.6.1",
        "url": "https://www.rfc-editor.org/rfc/rfc9293#section-3.6.1"
      }
    ],
    "keywords": [
      "ack",
      "fin",
      "time_wait",
      "maximum",
      "segment",
      "lifetime",
      "지연된",
      "패킷",
      "처리",
      "네트워크에",
      "남아있는",
      "이전",
      "연결의",
      "패킷이",
      "연결에"
    ]
  },
  {
    "id": "NET-053",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "웹소켓과 소켓 통신의 차이에 대해 설명해 주세요.",
    "answer": "구분   소켓(TCP/UDP)   웹소켓\n\n계층   Transport Layer   Application Layer\n프로토콜   TCP/UDP 직접 사용   HTTP 업그레이드 후 WS 프로토콜\n환경   모든 애플리케이션   웹 브라우저\n연결   직접 연결   HTTP Handshake 후 연결\n데이터   바이트 스트림   메시지 기반 프레임",
    "references": [
      {
        "title": "RFC 6455 - WebSocket Protocol",
        "url": "https://www.rfc-editor.org/rfc/rfc6455"
      }
    ],
    "keywords": [
      "tcp",
      "udp",
      "transport",
      "layer",
      "application",
      "http",
      "handshake",
      "구분",
      "소켓",
      "웹소켓",
      "계층",
      "프로토콜",
      "직접",
      "사용",
      "업그레이드"
    ]
  },
  {
    "id": "NET-054",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "소켓과 포트의 차이가 무엇인가요?",
    "answer": "포트(Port): 16비트 숫자(0-65535)로 프로세스를 식별하는 논리적 주소\n소켓(Socket): (IP주소 + 포트 + 프로토콜)의 조합으로 네트워크 통신 끝점(Endpoint)\n\n포트는 \"문 번호\"이고, 소켓은 \"실제 통신 채널\"입니다. 하나의 포트에 여러 소켓이 존재할 수 있습니다.",
    "references": [
      {
        "title": "RFC 9293",
        "url": "https://www.rfc-editor.org/rfc/rfc9293"
      }
    ],
    "keywords": [
      "port",
      "socket",
      "endpoint",
      "포트",
      "비트",
      "숫자",
      "프로세스를",
      "식별하는",
      "논리적",
      "주소",
      "소켓",
      "프로토콜",
      "조합으로",
      "네트워크",
      "통신"
    ]
  },
  {
    "id": "NET-055",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "여러 소켓이 있다고 할 때, 그 소켓의 포트 번호는 모두 다른가요?",
    "answer": "아니요, 같은 포트를 공유할 수 있습니다.\n\n소켓은 5-tuple로 구분됩니다:\n(출발 IP, 출발 Port, 목적 IP, 목적 Port, 프로토콜)\n\n예: 웹서버 80번 포트에 여러 클라이언트 연결 시, 각 연결은 클라이언트의 IP/Port가 다르므로 서로 다른 소켓입니다.",
    "references": [
      {
        "title": "RFC 9293 Section 3.1",
        "url": "https://www.rfc-editor.org/rfc/rfc9293#section-3.1"
      }
    ],
    "keywords": [
      "port",
      "아니요",
      "같은",
      "포트를",
      "공유할",
      "소켓은",
      "구분됩니다",
      "출발",
      "목적",
      "프로토콜",
      "웹서버",
      "포트에",
      "여러",
      "클라이언트",
      "연결"
    ]
  },
  {
    "id": "NET-056",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "사용자의 요청이 무수히 많아지면, 소켓도 무수히 생성되나요?",
    "answer": "기본적으로 그렇습니다. 하지만 제한이 있습니다:\n\n제한 요소:\n파일 디스크립터 제한 (ulimit)\n포트 번호 범위 (ephemeral port)\n메모리\n\n해결 방법:\nConnection Pooling\nKeep-Alive로 연결 재사용\n비동기 I/O (epoll, kqueue)\n로드밸런싱",
    "references": [
      {
        "title": "RFC 9293",
        "url": "https://www.rfc-editor.org/rfc/rfc9293"
      }
    ],
    "keywords": [
      "connection",
      "pooling",
      "keep-alive",
      "기본적으로",
      "그렇습니다",
      "제한이",
      "제한",
      "요소",
      "파일",
      "디스크립터",
      "포트",
      "번호",
      "범위",
      "메모리",
      "해결"
    ]
  },
  {
    "id": "NET-057",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "멀티플렉싱과 디멀티플렉싱에 대해 설명해 주세요.",
    "answer": "멀티플렉싱 (Multiplexing):\n여러 소켓의 데이터를 모아 하나의 네트워크 링크로 전송\n송신 측에서 발생\n\n디멀티플렉싱 (Demultiplexing):\n수신된 세그먼트를 올바른 소켓으로 분배\n수신 측에서 발생\nTCP는 4-tuple, UDP는 2-tuple(목적 IP/Port)로 구분",
    "references": [
      {
        "title": "RFC 9293",
        "url": "https://www.rfc-editor.org/rfc/rfc9293"
      }
    ],
    "keywords": [
      "multiplexing",
      "demultiplexing",
      "tcp",
      "udp",
      "port",
      "멀티플렉싱",
      "여러",
      "소켓의",
      "데이터를",
      "모아",
      "하나의",
      "네트워크",
      "링크로",
      "전송",
      "송신"
    ]
  },
  {
    "id": "NET-058",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "디멀티플렉싱의 과정에 대해 설명해 주세요.",
    "answer": "세그먼트가 Transport Layer에 도착\n헤더에서 목적 포트 번호 확인\nUDP: (목적 IP, 목적 Port)로 소켓 식별\nTCP: (출발 IP, 출발 Port, 목적 IP, 목적 Port)로 소켓 식별\n해당 소켓의 버퍼로 데이터 전달\n애플리케이션이 버퍼에서 데이터 읽음",
    "references": [
      {
        "title": "RFC 9293",
        "url": "https://www.rfc-editor.org/rfc/rfc9293"
      }
    ],
    "keywords": [
      "transport",
      "layer",
      "udp",
      "port",
      "tcp",
      "세그먼트가",
      "도착",
      "헤더에서",
      "목적",
      "포트",
      "번호",
      "확인",
      "소켓",
      "식별",
      "출발"
    ]
  },
  {
    "id": "NET-059",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "IP 주소는 무엇이며, 어떤 기능을 하고 있나요?",
    "answer": "IP 주소는 네트워크에서 장치를 식별하는 논리적 주소입니다.\n\n기능:\n주소 지정(Addressing): 네트워크상 장치 고유 식별\n라우팅: 패킷이 목적지까지 경로 설정\n네트워크/호스트 구분: 서브넷 마스크로 네트워크와 호스트 부분 구분\n\nIPv4는 32비트(4바이트), IPv6는 128비트(16바이트)입니다.",
    "references": [
      {
        "title": "RFC 791 - IPv4",
        "url": "https://www.rfc-editor.org/rfc/rfc791"
      }
    ],
    "keywords": [
      "addressing",
      "ipv4",
      "ipv6",
      "주소는",
      "네트워크에서",
      "장치를",
      "식별하는",
      "논리적",
      "주소입니다",
      "기능",
      "주소",
      "지정",
      "네트워크상",
      "장치",
      "고유"
    ]
  },
  {
    "id": "NET-060",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "IPv6는 IPv4의 주소 고갈 문제를 해결하기 위해 만들어졌지만, 아직도 수많은 기기가 IPv4를 사용하고 있습니다. 고갈 문제를 어떻게 해결할 수 있을까요?",
    "answer": "NAT(Network Address Translation): 사설 IP를 공인 IP로 변환, 하나의 공인 IP로 여러 기기 사용\nCIDR(Classless Inter-Domain Routing): 클래스 기반 할당 대신 유연한 서브넷 할당\n사설 IP 주소: 10.x.x.x, 172.16-31.x.x, 192.168.x.x 대역 내부 사용\nDHCP: 동적 IP 할당으로 효율적 사용",
    "references": [
      {
        "title": "RFC 1918 - Private IP",
        "url": "https://www.rfc-editor.org/rfc/rfc1918"
      }
    ],
    "keywords": [
      "nat",
      "network",
      "address",
      "translation",
      "cidr",
      "classless",
      "inter-domain",
      "routing",
      "dhcp",
      "사설",
      "공인",
      "변환",
      "하나의",
      "여러",
      "기기"
    ]
  },
  {
    "id": "NET-061",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "IPv4와 IPv6의 차이에 대해 설명해 주세요.",
    "answer": "구분   IPv4   IPv6\n\n주소 길이   32비트   128비트\n주소 개수   약 43억 개   거의 무한대\n표기법   점으로 구분 (192.168.0.1)   콜론으로 구분 (2001:db8::1)\n헤더 크기   가변 (20-60바이트)   고정 (40바이트)\n체크섬   있음   없음\nIPSec   선택   필수",
    "references": [
      {
        "title": "RFC 8200 - IPv6",
        "url": "https://www.rfc-editor.org/rfc/rfc8200"
      }
    ],
    "keywords": [
      "ipv4",
      "ipv6",
      "ipsec",
      "구분",
      "주소",
      "길이",
      "비트",
      "개수",
      "거의",
      "무한대",
      "표기법",
      "점으로",
      "콜론으로",
      "헤더",
      "크기"
    ]
  },
  {
    "id": "NET-062",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "수많은 사람들이 유동 IP를 사용하고 있지만, 수많은 공유기에서는 고정 주소를 제공하는 기능이 이미 존재합니다. 어떻게 가능한 걸까요?",
    "answer": "내부 네트워크(사설 IP)와 외부 네트워크(공인 IP)를 구분하기 때문입니다.\n공유기 내부: DHCP로 사설 IP 할당 (192.168.x.x)\nMAC 주소 기반으로 특정 기기에 항상 같은 사설 IP 할당 가능 (DHCP Reservation)\n외부로 나갈 때: NAT로 공인 IP로 변환\n\n즉, \"내부 고정 IP\"와 \"외부 유동 IP\"는 별개입니다.",
    "references": [
      {
        "title": "RFC 2131 - DHCP",
        "url": "https://www.rfc-editor.org/rfc/rfc2131"
      }
    ],
    "keywords": [
      "dhcp",
      "mac",
      "reservation",
      "nat",
      "내부",
      "네트워크",
      "사설",
      "외부",
      "공인",
      "구분하기",
      "때문입니다",
      "공유기",
      "할당",
      "주소",
      "기반으로"
    ]
  },
  {
    "id": "NET-063",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "IPv4를 사용하는 장비와 IPv6를 사용하는 같은 네트워크 내에서 통신이 가능한가요? 가능하다면 어떤 방법을 사용하나요?",
    "answer": "직접 통신은 불가능하지만 전환 기술로 가능합니다:\nDual Stack: 장비가 IPv4/IPv6 모두 지원\n터널링(Tunneling): IPv6 패킷을 IPv4로 캡슐화 (6to4, Teredo)\nNAT64/DNS64: IPv6 전용 네트워크에서 IPv4 서버 접근\n번역(Translation): 프로토콜 변환\n\n가장 일반적인 방법은 Dual Stack입니다.",
    "references": [
      {
        "title": "RFC 4213 - IPv6 Transition",
        "url": "https://www.rfc-editor.org/rfc/rfc4213"
      }
    ],
    "keywords": [
      "dual",
      "stack",
      "ipv4",
      "ipv6",
      "tunneling",
      "teredo",
      "nat64",
      "dns64",
      "translation",
      "직접",
      "통신은",
      "불가능하지만",
      "전환",
      "기술로",
      "가능합니다"
    ]
  },
  {
    "id": "NET-064",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "IP가 송신자와 수신자를 정확하게 전송되는 것을 보장해 주나요?",
    "answer": "아니요, IP는 Best Effort 서비스입니다.\n\nIP가 보장하지 않는 것:\n패킷 전달 보장 (손실 가능)\n순서 보장 (순서 바뀜 가능)\n중복 방지 (중복 수신 가능)\n무결성 (손상 가능)\n\n신뢰성이 필요하면 상위 계층(TCP)에서 처리합니다.",
    "references": [
      {
        "title": "RFC 791",
        "url": "https://www.rfc-editor.org/rfc/rfc791"
      }
    ],
    "keywords": [
      "best",
      "effort",
      "tcp",
      "아니요",
      "서비스입니다",
      "보장하지",
      "않는",
      "패킷",
      "전달",
      "보장",
      "손실",
      "가능",
      "순서",
      "바뀜",
      "중복"
    ]
  },
  {
    "id": "NET-065",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "IPv4에서 수행하는 Checksum과 TCP에서 수행하는 Checksum은 어떤 차이가 있나요?",
    "answer": "구분   IPv4 Checksum   TCP Checksum\n\n범위   IP 헤더만   헤더 + 데이터 + 의사 헤더\n목적   라우팅 정보 무결성   전체 세그먼트 무결성\n재계산   매 홉마다 (TTL 변경)   종단 간 1회\nIPv6   제거됨   필수\n\nIPv6에서 IP 체크섬이 제거된 이유: 상위 계층에서 이미 검증하므로 중복 제거.",
    "references": [
      {
        "title": "RFC 791",
        "url": "https://www.rfc-editor.org/rfc/rfc791"
      }
    ],
    "keywords": [
      "ipv4",
      "checksum",
      "tcp",
      "ttl",
      "ipv6",
      "구분",
      "범위",
      "헤더만",
      "헤더",
      "데이터",
      "의사",
      "목적",
      "라우팅",
      "정보",
      "무결성"
    ]
  },
  {
    "id": "NET-066",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "TTL(Hop Limit)이란 무엇인가요?",
    "answer": "TTL(Time To Live)은 패킷이 네트워크에서 존재할 수 있는 최대 홉 수입니다.\n각 라우터 통과 시 TTL 1 감소\nTTL이 0이 되면 패킷 폐기, ICMP 오류 메시지 전송\n라우팅 루프로 인한 무한 순환 방지\n\nIPv6에서는 Hop Limit으로 명칭 변경. 일반적으로 64, 128, 255로 설정합니다.",
    "references": [
      {
        "title": "RFC 791 Section 3.2",
        "url": "https://www.rfc-editor.org/rfc/rfc791#section-3.2"
      }
    ],
    "keywords": [
      "ttl",
      "time",
      "live",
      "icmp",
      "ipv6",
      "hop",
      "limit",
      "패킷이",
      "네트워크에서",
      "존재할",
      "있는",
      "최대",
      "수입니다",
      "라우터",
      "통과"
    ]
  },
  {
    "id": "NET-067",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "IP 주소와 MAC 주소의 차이에 대해 설명해 주세요.",
    "answer": "구분   IP 주소   MAC 주소\n\n계층   Network Layer (L3)   Data Link Layer (L2)\n유형   논리적 주소   물리적 주소\n할당   네트워크 관리자/DHCP   제조사 (NIC에 고정)\n변경   가능 (위치에 따라)   불변 (하드웨어 고유)\n길이   32비트(IPv4) / 128비트(IPv6)   48비트\n\nIP는 \"최종 목적지\", MAC은 \"다음 홉\"을 식별합니다.",
    "references": [
      {
        "title": "RFC 826 - ARP",
        "url": "https://www.rfc-editor.org/rfc/rfc826"
      }
    ],
    "keywords": [
      "mac",
      "network",
      "layer",
      "data",
      "link",
      "dhcp",
      "nic",
      "ipv4",
      "ipv6",
      "구분",
      "주소",
      "계층",
      "유형",
      "논리적",
      "물리적"
    ]
  },
  {
    "id": "NET-068",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "DHCP가 무엇인지 설명해 주세요.",
    "answer": "DHCP(Dynamic Host Configuration Protocol)는 네트워크 장치에 IP 주소 및 네트워크 설정을 자동으로 할당하는 프로토콜입니다.\n\n제공 정보:\nIP 주소\n서브넷 마스크\n기본 게이트웨이\nDNS 서버 주소\n\n관리자가 수동으로 IP를 설정할 필요 없이 자동화됩니다.",
    "references": [
      {
        "title": "RFC 2131 - DHCP",
        "url": "https://www.rfc-editor.org/rfc/rfc2131"
      }
    ],
    "keywords": [
      "dhcp",
      "dynamic",
      "host",
      "configuration",
      "protocol",
      "dns",
      "네트워크",
      "장치에",
      "주소",
      "설정을",
      "자동으로",
      "할당하는",
      "프로토콜입니다",
      "제공",
      "정보"
    ]
  },
  {
    "id": "NET-069",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "DHCP는 몇 계층 프로토콜인가요?",
    "answer": "Application Layer (7계층) 프로토콜입니다.\nTransport Layer: UDP 사용 (포트 67-서버, 68-클라이언트)\n클라이언트가 IP를 받기 전에 통신해야 하므로 브로드캐스트 사용\n연결 설정 없이 빠르게 동작해야 하므로 UDP 선택",
    "references": [
      {
        "title": "RFC 2131",
        "url": "https://www.rfc-editor.org/rfc/rfc2131"
      }
    ],
    "keywords": [
      "application",
      "layer",
      "transport",
      "udp",
      "계층",
      "프로토콜입니다",
      "사용",
      "포트",
      "서버",
      "클라이언트",
      "클라이언트가",
      "받기",
      "전에",
      "통신해야",
      "하므로"
    ]
  },
  {
    "id": "NET-070",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "DHCP는 어떻게 동작하나요?",
    "answer": "DORA 과정으로 동작합니다:\nDiscover: 클라이언트가 브로드캐스트로 DHCP 서버 탐색\nOffer: 서버가 사용 가능한 IP 주소 제안\nRequest: 클라이언트가 제안된 IP 사용 요청\nAcknowledge: 서버가 IP 할당 확인 및 임대 정보 전달\n\n모든 과정이 UDP 브로드캐스트로 진행됩니다.",
    "references": [
      {
        "title": "RFC 2131 Section 3",
        "url": "https://www.rfc-editor.org/rfc/rfc2131#section-3"
      }
    ],
    "keywords": [
      "dora",
      "discover",
      "dhcp",
      "offer",
      "request",
      "acknowledge",
      "udp",
      "과정으로",
      "동작합니다",
      "클라이언트가",
      "브로드캐스트로",
      "서버",
      "탐색",
      "서버가",
      "사용"
    ]
  },
  {
    "id": "NET-071",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "DHCP에서 UDP를 사용하는 이유가 무엇인가요?",
    "answer": "브로드캐스트 필요: TCP는 연결 지향이라 브로드캐스트 불가\nIP 없는 상태: TCP 연결에는 IP가 필요하지만, DHCP는 IP 할당 전에 동작\n단순성: 4개의 메시지만 교환하므로 TCP 오버헤드 불필요\n속도: 빠른 IP 할당을 위해 연결 설정 과정 생략",
    "references": [
      {
        "title": "RFC 2131",
        "url": "https://www.rfc-editor.org/rfc/rfc2131"
      }
    ],
    "keywords": [
      "tcp",
      "dhcp",
      "브로드캐스트",
      "필요",
      "연결",
      "지향이라",
      "불가",
      "없는",
      "상태",
      "연결에는",
      "필요하지만",
      "할당",
      "전에",
      "동작",
      "단순성"
    ]
  },
  {
    "id": "NET-072",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "DHCP에서, IP 주소 말고 추가로 제공해주는 정보가 있나요?",
    "answer": "예, DHCP는 다양한 네트워크 설정을 제공합니다:\n서브넷 마스크: 네트워크 범위 정의\n기본 게이트웨이: 외부 네트워크 접근용 라우터\nDNS 서버 주소: 도메인 이름 해석\n임대 시간(Lease Time): IP 사용 가능 기간\n도메인 이름: 네트워크 도메인\nNTP 서버: 시간 동기화 서버",
    "references": [
      {
        "title": "RFC 2132 - DHCP Options",
        "url": "https://www.rfc-editor.org/rfc/rfc2132"
      }
    ],
    "keywords": [
      "dhcp",
      "dns",
      "lease",
      "time",
      "ntp",
      "다양한",
      "네트워크",
      "설정을",
      "제공합니다",
      "서브넷",
      "마스크",
      "범위",
      "정의",
      "기본",
      "게이트웨이"
    ]
  },
  {
    "id": "NET-073",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "DHCP의 유효기간은 얼마나 긴가요?",
    "answer": "서버 설정에 따라 다릅니다. 일반적으로:\n가정용: 24시간 ~ 7일\n기업 환경: 8시간 ~ 24시간\n공공 Wi-Fi: 1~2시간\n\n클라이언트는 임대 시간의 50%(T1)에 갱신 시도, 87.5%(T2)에 재바인딩을 시도합니다. 만료 시 IP를 반납하고 새로 할당받습니다.",
    "references": [
      {
        "title": "RFC 2131 Section 4.4",
        "url": "https://www.rfc-editor.org/rfc/rfc2131#section-4.4"
      }
    ],
    "keywords": [
      "wi-fi",
      "서버",
      "설정에",
      "따라",
      "다릅니다",
      "일반적으로",
      "가정용",
      "시간",
      "기업",
      "환경",
      "공공",
      "클라이언트는",
      "임대",
      "시간의",
      "갱신"
    ]
  },
  {
    "id": "NET-074",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "DNS에 대해 설명해 주세요.",
    "answer": "DNS(Domain Name System)는 도메인 이름을 IP 주소로 변환하는 분산 데이터베이스 시스템입니다.\n\n구성 요소:\nRoot DNS: 최상위, TLD 서버 정보 보유\nTLD DNS: .com, .kr 등 관리\nAuthoritative DNS: 실제 도메인 레코드 보유\nRecursive Resolver: 클라이언트 대신 질의 수행\n\n사람이 기억하기 쉬운 이름으로 네트워크 접근을 가능하게 합니다.",
    "references": [
      {
        "title": "RFC 1035 - DNS",
        "url": "https://www.rfc-editor.org/rfc/rfc1035"
      }
    ],
    "keywords": [
      "dns",
      "domain",
      "name",
      "system",
      "root",
      "tld",
      "authoritative",
      "recursive",
      "resolver",
      "도메인",
      "이름을",
      "주소로",
      "변환하는",
      "분산",
      "데이터베이스"
    ]
  },
  {
    "id": "NET-075",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "DNS는 몇 계층 프로토콜인가요?",
    "answer": "Application Layer (7계층) 프로토콜입니다.\n기본적으로 UDP 포트 53 사용\n응답이 512바이트 초과 시 TCP 사용\nZone Transfer(영역 전송) 시 TCP 사용\n\nDNS over HTTPS(DoH), DNS over TLS(DoT) 등 보안 DNS도 애플리케이션 계층에서 동작합니다.",
    "references": [
      {
        "title": "RFC 1035",
        "url": "https://www.rfc-editor.org/rfc/rfc1035"
      }
    ],
    "keywords": [
      "application",
      "layer",
      "udp",
      "tcp",
      "zone",
      "transfer",
      "dns",
      "https",
      "doh",
      "tls",
      "dot",
      "계층",
      "프로토콜입니다",
      "기본적으로",
      "포트"
    ]
  },
  {
    "id": "NET-076",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "UDP와 TCP 중 어떤 것을 사용하나요?",
    "answer": "둘 다 사용합니다.\n\nUDP 사용 (기본):\n일반적인 DNS 질의/응답\n빠른 응답 필요\n메시지 크기가 512바이트 이하\n\nTCP 사용:\n응답이 512바이트 초과 (EDNS로 확장 가능)\nZone Transfer (AXFR/IXFR)\nDNS over TLS (DoT)",
    "references": [
      {
        "title": "RFC 1035 Section 4.2",
        "url": "https://www.rfc-editor.org/rfc/rfc1035#section-4.2"
      }
    ],
    "keywords": [
      "udp",
      "dns",
      "tcp",
      "edns",
      "zone",
      "transfer",
      "axfr",
      "ixfr",
      "tls",
      "dot",
      "사용합니다",
      "사용",
      "기본",
      "일반적인",
      "질의"
    ]
  },
  {
    "id": "NET-077",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "DNS Recursive Query, Iterative Query가 무엇인가요?",
    "answer": "Recursive Query:\n클라이언트가 DNS 서버에 완전한 답변 요청\n서버가 다른 서버에 질의하여 최종 결과 반환\n클라이언트 -> Resolver 간 사용\n\nIterative Query:\n서버가 알고 있는 정보만 반환 (다음 질의할 서버 힌트)\n질의자가 직접 다음 서버에 질의\nResolver -> 다른 DNS 서버 간 사용",
    "references": [
      {
        "title": "RFC 1035 Section 4.3",
        "url": "https://www.rfc-editor.org/rfc/rfc1035#section-4.3"
      }
    ],
    "keywords": [
      "recursive",
      "query",
      "dns",
      "resolver",
      "iterative",
      "클라이언트가",
      "서버에",
      "완전한",
      "답변",
      "요청",
      "서버가",
      "다른",
      "질의하여",
      "최종",
      "결과"
    ]
  },
  {
    "id": "NET-078",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "DNS 쿼리 과정에서 손실이 발생한다면, 어떻게 처리하나요?",
    "answer": "DNS 클라이언트(Resolver)가 재전송을 처리합니다:\n타임아웃: 일정 시간 내 응답 없으면 재전송\n재시도: 보통 2-5회 재시도\n대체 서버: 실패 시 다른 DNS 서버로 질의\nTCP 폴백: UDP 실패 시 TCP로 재시도\n\nUDP 자체는 신뢰성을 보장하지 않으므로 애플리케이션 레벨에서 처리합니다.",
    "references": [
      {
        "title": "RFC 1035 Section 4.2.1",
        "url": "https://www.rfc-editor.org/rfc/rfc1035#section-4.2.1"
      }
    ],
    "keywords": [
      "dns",
      "resolver",
      "tcp",
      "udp",
      "클라이언트",
      "재전송을",
      "처리합니다",
      "타임아웃",
      "일정",
      "시간",
      "응답",
      "없으면",
      "재전송",
      "재시도",
      "보통"
    ]
  },
  {
    "id": "NET-079",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "캐싱된 DNS 쿼리가 잘못 될 수도 있습니다. 이 경우, 어떻게 에러를 보정할 수 있나요?",
    "answer": "TTL 만료: 캐시된 레코드는 TTL 후 자동 삭제, 새로 질의\n캐시 플러시: 수동으로 DNS 캐시 삭제 (ipconfig /flushdns)\nDNSSEC: DNS 응답에 서명 추가하여 위변조 감지\nDNS 캐시 포이즈닝 방지: 랜덤 포트, 트랜잭션 ID 사용\n\nDNSSEC은 DNS 응답의 무결성과 출처를 검증합니다.",
    "references": [
      {
        "title": "RFC 4033 - DNSSEC",
        "url": "https://www.rfc-editor.org/rfc/rfc4033"
      }
    ],
    "keywords": [
      "ttl",
      "dns",
      "dnssec",
      "만료",
      "캐시된",
      "레코드는",
      "자동",
      "삭제",
      "새로",
      "질의",
      "캐시",
      "플러시",
      "수동으로",
      "응답에",
      "서명"
    ]
  },
  {
    "id": "NET-080",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "DNS 레코드 타입 중 A, CNAME, AAAA의 차이에 대해서 설명해주세요.",
    "answer": "레코드   설명   예시\n\nA   도메인 -> IPv4 주소   example.com -> 192.168.1.1\nAAAA   도메인 -> IPv6 주소   example.com -> 2001:db8::1\nCNAME   도메인 -> 다른 도메인 (별칭)   www.example.com -> example.com\n\nCNAME은 실제 IP를 가진 도메인을 가리키며, 최종적으로 A/AAAA 레코드로 해석됩니다.",
    "references": [
      {
        "title": "RFC 1035 Section 3.2.2",
        "url": "https://www.rfc-editor.org/rfc/rfc1035#section-3.2.2"
      }
    ],
    "keywords": [
      "ipv4",
      "aaaa",
      "ipv6",
      "cname",
      "레코드",
      "설명",
      "예시",
      "도메인",
      "주소",
      "다른",
      "별칭",
      "실제",
      "가진",
      "도메인을",
      "가리키며"
    ]
  },
  {
    "id": "NET-081",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "hosts 파일은 어떤 역할을 하나요? DNS와 비교하였을 때 어떤 것이 우선순위가 더 높나요?",
    "answer": "hosts 파일은 로컬에서 도메인-IP 매핑을 정의하는 텍스트 파일입니다.\n위치: Windows(C:\\Windows\\System32\\drivers\\etc\\hosts), Linux/Mac(/etc/hosts)\nDNS 쿼리 전에 먼저 참조됨\n\n우선순위: hosts 파일 > DNS\n\n용도: 로컬 개발 환경 설정, 특정 도메인 차단, 테스트",
    "references": [
      {
        "title": "RFC 952 - DoD Hostnames",
        "url": "https://www.rfc-editor.org/rfc/rfc952"
      }
    ],
    "keywords": [
      "windows",
      "system32",
      "linux",
      "mac",
      "dns",
      "파일은",
      "로컬에서",
      "도메인",
      "매핑을",
      "정의하는",
      "텍스트",
      "파일입니다",
      "위치",
      "쿼리",
      "전에"
    ]
  },
  {
    "id": "NET-082",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "OSI 7계층에 대해 설명해 주세요.",
    "answer": "계층   이름   역할   프로토콜/장비\n\n7   Application   사용자 인터페이스   HTTP, FTP, DNS\n6   Presentation   데이터 변환, 암호화   SSL/TLS, JPEG\n5   Session   세션 관리   NetBIOS\n4   Transport   종단 간 통신   TCP, UDP\n3   Network   라우팅   IP, 라우터\n2   Data Link   물리 주소 지정   Ethernet, 스위치\n1   Physical   전기 신호 전송   케이블, 허브",
    "references": [
      {
        "title": "ISO/IEC 7498-1",
        "url": "https://www.iso.org/standard/20269.html"
      }
    ],
    "keywords": [
      "application",
      "http",
      "ftp",
      "dns",
      "presentation",
      "ssl",
      "tls",
      "jpeg",
      "session",
      "netbios",
      "transport",
      "tcp",
      "udp",
      "network",
      "data"
    ]
  },
  {
    "id": "NET-083",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "Transport Layer와, Network Layer의 차이에 대해 설명해 주세요.",
    "answer": "구분   Network Layer (L3)   Transport Layer (L4)\n\n주소   IP 주소 (호스트)   포트 번호 (프로세스)\n통신 단위   패킷   세그먼트\n범위   호스트 간   프로세스 간 (End-to-End)\n신뢰성   Best Effort   TCP는 신뢰성 보장\n프로토콜   IP, ICMP   TCP, UDP\n\nNetwork Layer는 \"어디로\", Transport Layer는 \"누구에게, 어떻게\"를 담당합니다.",
    "references": [
      {
        "title": "RFC 1122",
        "url": "https://www.rfc-editor.org/rfc/rfc1122"
      }
    ],
    "keywords": [
      "network",
      "layer",
      "transport",
      "end-to-end",
      "best",
      "effort",
      "tcp",
      "icmp",
      "udp",
      "구분",
      "주소",
      "호스트",
      "포트",
      "번호",
      "프로세스"
    ]
  },
  {
    "id": "NET-084",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "L3 Switch와 Router의 차이에 대해 설명해 주세요.",
    "answer": "구분   L3 Switch   Router\n\n처리   하드웨어 (ASIC)   소프트웨어\n속도   매우 빠름   상대적으로 느림\n기능   기본 라우팅   NAT, 방화벽, VPN 등\n용도   LAN 내부   WAN 연결, 인터넷\n포트   많음 (24-48개)   적음 (2-8개)\n\nL3 Switch는 \"라우팅 가능한 스위치\", Router는 \"다양한 네트워크 기능 장비\"입니다.",
    "references": [
      {
        "title": "RFC 1812 - Router Requirements",
        "url": "https://www.rfc-editor.org/rfc/rfc1812"
      }
    ],
    "keywords": [
      "switch",
      "router",
      "asic",
      "nat",
      "vpn",
      "lan",
      "wan",
      "구분",
      "처리",
      "하드웨어",
      "소프트웨어",
      "속도",
      "매우",
      "빠름",
      "상대적으로"
    ]
  },
  {
    "id": "NET-085",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "각 Layer는 패킷을 어떻게 명칭하나요? 예를 들어, Transport Layer의 경우 Segment라 부릅니다.",
    "answer": "계층   PDU (Protocol Data Unit)\n\nApplication (L7)   Data / Message\nTransport (L4)   Segment (TCP) / Datagram (UDP)\nNetwork (L3)   Packet\nData Link (L2)   Frame\nPhysical (L1)   Bit\n\n각 계층에서 헤더가 추가되며, 이를 캡슐화(Encapsulation)라 합니다.",
    "references": [
      {
        "title": "ISO/IEC 7498-1",
        "url": "https://www.iso.org/standard/20269.html"
      }
    ],
    "keywords": [
      "pdu",
      "protocol",
      "data",
      "unit",
      "application",
      "message",
      "transport",
      "segment",
      "tcp",
      "datagram",
      "udp",
      "network",
      "packet",
      "link",
      "frame"
    ]
  },
  {
    "id": "NET-086",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "각각의 Header의 Packing Order에 대해 설명해 주세요.",
    "answer": "캡슐화(송신) 순서:\n\n역캡슐화(수신) 순서: 역순으로 헤더 제거\n\n각 계층은 상위 계층의 전체를 데이터로 취급하고 자신의 헤더를 붙입니다.",
    "references": [
      {
        "title": "RFC 1122",
        "url": "https://www.rfc-editor.org/rfc/rfc1122"
      }
    ],
    "keywords": [
      "캡슐화",
      "송신",
      "순서",
      "역캡슐화",
      "수신",
      "역순으로",
      "헤더",
      "제거",
      "계층은",
      "상위",
      "계층의",
      "전체를",
      "데이터로",
      "취급하고",
      "자신의"
    ]
  },
  {
    "id": "NET-087",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "ARP에 대해 설명해 주세요.",
    "answer": "ARP(Address Resolution Protocol)는 IP 주소를 MAC 주소로 변환하는 프로토콜입니다.\n\n동작 과정:\nARP Request: \"이 IP의 MAC 주소가 뭐야?\" (브로드캐스트)\nARP Reply: \"내 MAC 주소는 이거야\" (유니캐스트)\nARP 테이블에 캐싱\n\n같은 네트워크 내에서만 동작하며, 다른 네트워크는 게이트웨이의 MAC 주소를 사용합니다.",
    "references": [
      {
        "title": "RFC 826 - ARP",
        "url": "https://www.rfc-editor.org/rfc/rfc826"
      }
    ],
    "keywords": [
      "arp",
      "address",
      "resolution",
      "protocol",
      "mac",
      "request",
      "reply",
      "주소를",
      "주소로",
      "변환하는",
      "프로토콜입니다",
      "동작",
      "과정",
      "주소가",
      "뭐야"
    ]
  },
  {
    "id": "NET-088",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "라우터 내의 포워딩 과정에 대해 설명해 주세요.",
    "answer": "패킷 수신: 입력 포트에서 프레임 수신, 역캡슐화\n목적지 확인: IP 헤더에서 목적지 IP 추출\n테이블 검색: 포워딩 테이블에서 최장 접두어 매칭 (Longest Prefix Match)\nTTL 감소: TTL 1 감소, 0이면 폐기\n출력 포트 결정: 매칭된 엔트리의 출력 포트로 전달\n재캡슐화: 새로운 L2 헤더 추가 후 전송",
    "references": [
      {
        "title": "RFC 1812 Section 5",
        "url": "https://www.rfc-editor.org/rfc/rfc1812#section-5"
      }
    ],
    "keywords": [
      "longest",
      "prefix",
      "match",
      "ttl",
      "패킷",
      "수신",
      "입력",
      "포트에서",
      "프레임",
      "역캡슐화",
      "목적지",
      "확인",
      "헤더에서",
      "추출",
      "테이블"
    ]
  },
  {
    "id": "NET-089",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "라우팅과 포워딩의 차이는 무엇인가요?",
    "answer": "구분   라우팅 (Routing)   포워딩 (Forwarding)\n\n역할   경로 결정   패킷 전달\n시점   사전 계산 (Control Plane)   실시간 처리 (Data Plane)\n결과물   포워딩 테이블 생성   실제 패킷 이동\n프로토콜   OSPF, BGP, RIP   -\n\n라우팅은 \"지도 그리기\", 포워딩은 \"지도 보고 이동\"입니다.",
    "references": [
      {
        "title": "RFC 1812",
        "url": "https://www.rfc-editor.org/rfc/rfc1812"
      }
    ],
    "keywords": [
      "routing",
      "forwarding",
      "control",
      "plane",
      "data",
      "ospf",
      "bgp",
      "rip",
      "구분",
      "라우팅",
      "포워딩",
      "역할",
      "경로",
      "결정",
      "패킷"
    ]
  },
  {
    "id": "NET-090",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "라우팅 알고리즘에 대해 설명해 주세요.",
    "answer": "Link State (링크 상태):\n전체 네트워크 토폴로지 파악\n다익스트라 알고리즘으로 최단 경로 계산\n예: OSPF, IS-IS\n\nDistance Vector (거리 벡터):\n이웃에게 자신의 라우팅 테이블 공유\n벨만-포드 알고리즘\n예: RIP, BGP (Path Vector)\n\n경로 결정 기준: 홉 수, 대역폭, 지연, 비용 등",
    "references": [
      {
        "title": "RFC 2328 - OSPF",
        "url": "https://www.rfc-editor.org/rfc/rfc2328"
      }
    ],
    "keywords": [
      "link",
      "state",
      "ospf",
      "is-is",
      "distance",
      "vector",
      "rip",
      "bgp",
      "path",
      "링크",
      "상태",
      "전체",
      "네트워크",
      "토폴로지",
      "파악"
    ]
  },
  {
    "id": "NET-091",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "포워딩 테이블의 구조에 대해 설명해 주세요.",
    "answer": "포워딩 테이블의 기본 구조:\n\n목적지 네트워크   서브넷 마스크   다음 홉   출력 인터페이스   메트릭\n\n192.168.1.0   /24   10.0.0.1   eth0   10\n0.0.0.0   /0   10.0.0.254   eth1   1\nLongest Prefix Match: 가장 구체적인 경로 선택\nDefault Route: 0.0.0.0/0으로 매칭되지 않는 모든 트래픽 처리",
    "references": [
      {
        "title": "RFC 1812 Section 5.2",
        "url": "https://www.rfc-editor.org/rfc/rfc1812#section-5.2"
      }
    ],
    "keywords": [
      "longest",
      "prefix",
      "match",
      "default",
      "route",
      "포워딩",
      "테이블의",
      "기본",
      "구조",
      "목적지",
      "네트워크",
      "서브넷",
      "마스크",
      "다음",
      "출력"
    ]
  },
  {
    "id": "NET-092",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "로드밸런서가 무엇인가요?",
    "answer": "로드밸런서는 들어오는 트래픽을 여러 서버에 분산시키는 장치/소프트웨어입니다.\n\n목적:\n부하 분산으로 성능 향상\n고가용성 (서버 장애 시 다른 서버로 라우팅)\n확장성 (서버 추가/제거 용이)\n\n종류: 하드웨어(F5), 소프트웨어(Nginx, HAProxy), 클라우드(AWS ALB/NLB)",
    "references": [
      {
        "title": "RFC 7098 - Load Balancing",
        "url": "https://www.rfc-editor.org/rfc/rfc7098"
      }
    ],
    "keywords": [
      "nginx",
      "haproxy",
      "aws",
      "alb",
      "nlb",
      "로드밸런서는",
      "들어오는",
      "트래픽을",
      "여러",
      "서버에",
      "분산시키는",
      "장치",
      "소프트웨어입니다",
      "목적",
      "부하"
    ]
  },
  {
    "id": "NET-093",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "L4 로드밸런서와, L7 로드밸런서의 차이에 대해 설명해 주세요.",
    "answer": "구분   L4 로드밸런서   L7 로드밸런서\n\n계층   Transport (TCP/UDP)   Application (HTTP)\n분산 기준   IP, Port   URL, Header, Cookie\n속도   빠름   상대적으로 느림\n기능   단순 분산   콘텐츠 기반 라우팅, SSL 종료\n예시   AWS NLB   AWS ALB, Nginx\n\nL4는 패킷 레벨, L7은 요청 내용 레벨에서 결정합니다.",
    "references": [
      {
        "title": "RFC 7098",
        "url": "https://www.rfc-editor.org/rfc/rfc7098"
      }
    ],
    "keywords": [
      "transport",
      "tcp",
      "udp",
      "application",
      "http",
      "port",
      "url",
      "header",
      "cookie",
      "ssl",
      "aws",
      "nlb",
      "alb",
      "nginx",
      "구분"
    ]
  },
  {
    "id": "NET-094",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "로드밸런서 알고리즘에 대해 설명해 주세요.",
    "answer": "정적 알고리즘:\nRound Robin: 순차적으로 분배\nWeighted Round Robin: 가중치에 따라 분배\nIP Hash: 클라이언트 IP 해시로 서버 결정\n\n동적 알고리즘:\nLeast Connection: 연결 수가 가장 적은 서버로\nLeast Response Time: 응답 시간이 가장 빠른 서버로\nResource Based: 서버 리소스 상태 기반",
    "references": [
      {
        "title": "RFC 7098 Section 4",
        "url": "https://www.rfc-editor.org/rfc/rfc7098#section-4"
      }
    ],
    "keywords": [
      "round",
      "robin",
      "weighted",
      "hash",
      "least",
      "connection",
      "response",
      "time",
      "resource",
      "based",
      "정적",
      "알고리즘",
      "순차적으로",
      "분배",
      "가중치에"
    ]
  },
  {
    "id": "NET-095",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "로드밸런싱 대상이 되는 장치중 일부 장치가 문제가 생겨 접속이 불가능하다고 가정해 봅시다. 이 경우, 로드밸런서가 해당 장비로 요청을 보내지 않도록 하려면 어떻게 해야 할까요?",
    "answer": "Health Check (헬스 체크)를 사용합니다.\n\n방식:\nTCP Check: 포트 연결 가능 여부 확인\nHTTP Check: 특정 URL 요청 후 200 응답 확인\nCustom Script: 사용자 정의 스크립트 실행\n\n동작:\n주기적으로 헬스 체크 수행 (예: 10초마다)\n연속 실패 시 해당 서버를 풀에서 제외\n복구 확인 시 다시 풀에 추가",
    "references": [
      {
        "title": "AWS ELB Health Checks",
        "url": "https://docs.aws.amazon.com/elasticloadbalancing/"
      }
    ],
    "keywords": [
      "health",
      "check",
      "tcp",
      "http",
      "url",
      "custom",
      "script",
      "헬스",
      "체크",
      "사용합니다",
      "방식",
      "포트",
      "연결",
      "가능",
      "여부"
    ]
  },
  {
    "id": "NET-096",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "로드밸런서 장치를 사용하지 않고, DNS를 활용해서 유사하게 로드밸런싱을 하는 방법에 대해 설명해 주세요.",
    "answer": "DNS Round Robin을 사용합니다.\n\n방법:\n하나의 도메인에 여러 A 레코드(IP) 등록\nDNS 서버가 질의마다 IP 순서를 바꿔 응답\n\n장점: 구현 간단, 추가 장비 불필요\n\n단점:\n헬스 체크 불가 (장애 서버로도 라우팅)\nDNS 캐싱으로 균등 분산 어려움\n세밀한 제어 불가\n\nAWS Route 53의 가중치 기반 라우팅 등 고급 DNS 서비스로 보완 가능합니다.",
    "references": [
      {
        "title": "RFC 1794 - DNS Round Robin",
        "url": "https://www.rfc-editor.org/rfc/rfc1794"
      }
    ],
    "keywords": [
      "dns",
      "round",
      "robin",
      "aws",
      "route",
      "사용합니다",
      "방법",
      "하나의",
      "도메인에",
      "여러",
      "레코드",
      "등록",
      "서버가",
      "질의마다",
      "순서를"
    ]
  },
  {
    "id": "NET-097",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "서브넷 마스크와, 게이트웨이에 대해 설명해 주세요.",
    "answer": "서브넷 마스크:\nIP 주소에서 네트워크/호스트 부분을 구분\n예: 255.255.255.0 (/24) -> 앞 24비트가 네트워크\n같은 네트워크인지 판단하는 데 사용\n\n게이트웨이 (Default Gateway):\n다른 네트워크로 나가는 출구 (라우터)\n목적지가 같은 서브넷이 아니면 게이트웨이로 전송\n일반적으로 서브넷의 첫 번째 또는 마지막 IP",
    "references": [
      {
        "title": "RFC 950 - Subnetting",
        "url": "https://www.rfc-editor.org/rfc/rfc950"
      }
    ],
    "keywords": [
      "default",
      "gateway",
      "서브넷",
      "마스크",
      "주소에서",
      "네트워크",
      "호스트",
      "부분을",
      "구분",
      "비트가",
      "같은",
      "네트워크인지",
      "판단하는",
      "사용",
      "게이트웨이"
    ]
  },
  {
    "id": "NET-098",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "NAT에 대해 설명해 주세요.",
    "answer": "NAT(Network Address Translation)은 사설 IP를 공인 IP로 변환하는 기술입니다.\n\n종류:\nStatic NAT: 1:1 고정 매핑\nDynamic NAT: 풀에서 동적 할당\nPAT/NAPT: 포트 번호까지 변환 (가장 일반적, 1:N)\n\n장점: IPv4 주소 절약, 내부 네트워크 보안\n단점: End-to-End 연결성 저해, P2P 통신 어려움",
    "references": [
      {
        "title": "RFC 3022 - NAT",
        "url": "https://www.rfc-editor.org/rfc/rfc3022"
      }
    ],
    "keywords": [
      "nat",
      "network",
      "address",
      "translation",
      "static",
      "dynamic",
      "pat",
      "napt",
      "ipv4",
      "end-to-end",
      "p2p",
      "사설",
      "공인",
      "변환하는",
      "기술입니다"
    ]
  },
  {
    "id": "NET-099",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "서브넷 마스크의 표현 방식에 대해 설명해 주세요.",
    "answer": "점 표기법 (Dotted Decimal):\n예: 255.255.255.0\n각 옥텟을 10진수로 표현\nCIDR 표기법 (Prefix Length):\n예: /24\n네트워크 비트 수만 표시\n192.168.1.0/24 = 192.168.1.0 ~ 192.168.1.255\n\nCIDR   서브넷 마스크   호스트 수\n\n/24   255.255.255.0   254\n/16   255.255.0.0   65,534",
    "references": [
      {
        "title": "RFC 4632 - CIDR",
        "url": "https://www.rfc-editor.org/rfc/rfc4632"
      }
    ],
    "keywords": [
      "dotted",
      "decimal",
      "cidr",
      "prefix",
      "length",
      "표기법",
      "옥텟을",
      "진수로",
      "표현",
      "네트워크",
      "비트",
      "수만",
      "표시",
      "서브넷",
      "마스크"
    ]
  },
  {
    "id": "NET-100",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "그렇다면, 255.0.255.0 같은 꼴의 서브넷 마스크도 가능한가요?",
    "answer": "이론적으로 불가능합니다.\n\n서브넷 마스크는 연속된 1비트 뒤에 연속된 0비트가 와야 합니다.\n유효: 11111111.11111111.11111111.00000000 (255.255.255.0)\n무효: 11111111.00000000.11111111.00000000 (255.0.255.0)\n\n비연속 마스크는 라우팅 테이블 최적화와 주소 관리를 복잡하게 만들어 표준에서 허용하지 않습니다.",
    "references": [
      {
        "title": "RFC 4632",
        "url": "https://www.rfc-editor.org/rfc/rfc4632"
      }
    ],
    "keywords": [
      "이론적으로",
      "불가능합니다",
      "서브넷",
      "마스크는",
      "연속된",
      "비트",
      "뒤에",
      "비트가",
      "와야",
      "유효",
      "무효",
      "비연속",
      "라우팅",
      "테이블",
      "최적화와"
    ]
  },
  {
    "id": "NET-101",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "www.github.com을 브라우저에 입력하고 엔터를 쳤을 때, 네트워크 상 어떤 일이 일어나는지 최대한 자세하게 설명해 주세요.",
    "answer": "URL 파싱: 프로토콜(https), 도메인(www.github.com) 추출\nDNS 조회: 로컬 캐시 -> hosts -> DNS 서버로 IP 획득\nTCP 연결: 3-way handshake로 연결 수립\nTLS 핸드셰이크: 인증서 검증, 대칭키 교환\nHTTP 요청: GET / HTTP/1.1 요청 전송\n서버 처리: 웹서버/WAS가 요청 처리\nHTTP 응답: HTML, CSS, JS 등 응답\n렌더링: 브라우저가 DOM 파싱, 화면 표시\n연결 종료: Keep-Alive 또는 4-way handshake",
    "references": [
      {
        "title": "MDN - How the Web Works",
        "url": "https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/How_the_Web_works"
      }
    ],
    "keywords": [
      "url",
      "dns",
      "tcp",
      "tls",
      "http",
      "get",
      "html",
      "css",
      "dom",
      "keep-alive",
      "파싱",
      "프로토콜",
      "도메인",
      "추출",
      "조회"
    ]
  },
  {
    "id": "NET-102",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "DNS 쿼리를 통해 얻어진 IP는 어디를 가리키고 있나요?",
    "answer": "일반적으로 실제 서버가 아닌 중간 장치를 가리킵니다:\nCDN 엣지 서버: CloudFlare, Akamai 등 (가장 가까운 캐시 서버)\n로드밸런서: 트래픽을 분산하는 진입점\n리버스 프록시: Nginx 등 프론트 서버\n방화벽/WAF: 보안 장비\n\n실제 애플리케이션 서버는 내부 네트워크에 있고, 외부에 직접 노출되지 않는 것이 일반적입니다.",
    "references": [
      {
        "title": "RFC 1035",
        "url": "https://www.rfc-editor.org/rfc/rfc1035"
      }
    ],
    "keywords": [
      "cdn",
      "cloudflare",
      "akamai",
      "nginx",
      "waf",
      "일반적으로",
      "실제",
      "서버가",
      "아닌",
      "중간",
      "장치를",
      "가리킵니다",
      "엣지",
      "서버",
      "가장"
    ]
  },
  {
    "id": "NET-103",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "Web Server와 Web Application Server의 차이에 대해 설명해 주세요.",
    "answer": "구분   Web Server   WAS (Web Application Server)\n\n역할   정적 콘텐츠 제공   동적 콘텐츠 생성\n처리   HTML, CSS, 이미지   비즈니스 로직, DB 연동\n예시   Nginx, Apache   Tomcat, Node.js, Spring\n프로토콜   HTTP   HTTP + 애플리케이션 프로토콜\n\n일반적으로 Web Server가 앞단에서 정적 파일/리버스 프록시 역할을 하고, WAS가 실제 로직을 처리합니다.",
    "references": [
      {
        "title": "MDN - Web Server",
        "url": "https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_is_a_web_server"
      }
    ],
    "keywords": [
      "web",
      "server",
      "application",
      "html",
      "css",
      "nginx",
      "apache",
      "tomcat",
      "node",
      "spring",
      "http",
      "구분",
      "역할",
      "정적",
      "콘텐츠"
    ]
  },
  {
    "id": "NET-104",
    "category": "network",
    "categoryName": "Network",
    "priority": "P1",
    "question": "URL, URI, URN은 어떤 차이가 있나요?",
    "answer": "URI (Uniform Resource Identifier):\n리소스를 식별하는 가장 큰 개념\nURL과 URN을 포함\n\nURL (Uniform Resource Locator):\n리소스의 위치를 나타냄\n예: https://example.com/page.html\n\nURN (Uniform Resource Name):\n리소스의 이름을 나타냄 (위치 독립적)\n예: urn:isbn:0451450523\n\n관계: URI = URL + URN (URL과 URN은 URI의 하위 집합)",
    "references": [
      {
        "title": "RFC 3986 - URI",
        "url": "https://www.rfc-editor.org/rfc/rfc3986"
      }
    ],
    "keywords": [
      "uri",
      "uniform",
      "resource",
      "identifier",
      "url",
      "urn",
      "locator",
      "name",
      "리소스를",
      "식별하는",
      "가장",
      "개념",
      "포함",
      "리소스의",
      "위치를"
    ]
  },
  {
    "id": "OS-001",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "시스템 콜이 무엇인지 설명해 주세요.",
    "answer": "시스템 콜은 사용자 프로그램이 운영체제 커널의 서비스를 요청하기 위한 프로그래밍 인터페이스입니다. 사용자 모드에서 실행되는 프로세스가 파일 읽기/쓰기, 프로세스 생성, 네트워크 통신 등 커널 권한이 필요한 작업을 수행할 때 시스템 콜을 통해 커널 모드로 전환하여 해당 서비스를 요청합니다.",
    "references": [
      {
        "title": "Linux man-pages: syscalls",
        "url": "https://man7.org/linux/man-pages/man2/syscalls.2.html"
      }
    ],
    "keywords": [
      "시스템",
      "콜은",
      "사용자",
      "프로그램이",
      "운영체제",
      "커널의",
      "서비스를",
      "요청하기",
      "위한",
      "프로그래밍",
      "인터페이스입니다",
      "모드에서",
      "실행되는",
      "프로세스가",
      "파일"
    ]
  },
  {
    "id": "OS-002",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "우리가 사용하는 시스템 콜의 예시를 들어주세요.",
    "answer": "프로세스 제어: fork(), exec(), exit(), wait()\n파일 조작: open(), read(), write(), close()\n장치 관리: ioctl(), read(), write()\n정보 유지: getpid(), alarm(), sleep()\n통신: pipe(), socket(), connect(), accept()\n메모리 관리: mmap(), brk(), sbrk()",
    "references": [
      {
        "title": "Linux man-pages: syscalls",
        "url": "https://man7.org/linux/man-pages/man2/syscalls.2.html"
      }
    ],
    "keywords": [
      "프로세스",
      "제어",
      "파일",
      "조작",
      "장치",
      "관리",
      "정보",
      "유지",
      "통신",
      "메모리"
    ]
  },
  {
    "id": "OS-003",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.",
    "answer": "사용자 프로그램이 시스템 콜 래퍼 함수 호출\n시스템 콜 번호를 레지스터에 저장\n소프트웨어 인터럽트(trap) 발생 (x86: int 0x80 또는 syscall 명령어)\nCPU가 커널 모드로 전환\n커널의 시스템 콜 핸들러가 시스템 콜 테이블에서 해당 함수 찾아 실행\n결과를 레지스터에 저장하고 사용자 모드로 복귀",
    "references": [
      {
        "title": "Linux Kernel Documentation: Adding a New System Call",
        "url": "https://www.kernel.org/doc/html/latest/process/adding-syscalls.html"
      }
    ],
    "keywords": [
      "cpu",
      "사용자",
      "프로그램이",
      "시스템",
      "래퍼",
      "함수",
      "호출",
      "번호를",
      "레지스터에",
      "저장",
      "소프트웨어",
      "인터럽트",
      "발생",
      "명령어",
      "커널"
    ]
  },
  {
    "id": "OS-004",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "시스템 콜의 유형에 대해 설명해 주세요.",
    "answer": "프로세스 제어: 프로세스 생성/종료, 실행, 대기 (fork, exec, exit, wait)\n파일 관리: 파일 생성/삭제, 열기/닫기, 읽기/쓰기 (open, close, read, write)\n장치 관리: 장치 요청/해제, 읽기/쓰기 (ioctl, read, write)\n정보 유지: 시간/날짜, 시스템 데이터 (time, getpid, uname)\n통신: 연결 생성/삭제, 메시지 송수신 (socket, send, recv, pipe)\n보호: 권한 설정/확인 (chmod, chown, umask)",
    "references": [
      {
        "title": "POSIX.1-2017 System Interfaces",
        "url": "https://pubs.opengroup.org/onlinepubs/9699919799/"
      }
    ],
    "keywords": [
      "프로세스",
      "제어",
      "생성",
      "종료",
      "실행",
      "대기",
      "파일",
      "관리",
      "삭제",
      "열기",
      "닫기",
      "읽기",
      "쓰기",
      "장치",
      "요청"
    ]
  },
  {
    "id": "OS-005",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "운영체제의 Dual Mode 에 대해 설명해 주세요.",
    "answer": "Dual Mode는 CPU가 사용자 모드(User Mode)와 커널 모드(Kernel Mode) 두 가지 실행 모드를 가지는 것입니다.\n사용자 모드: 일반 애플리케이션이 실행되며, 하드웨어 직접 접근이나 특권 명령어 실행이 제한됨\n커널 모드: OS 커널이 실행되며, 모든 명령어와 하드웨어에 접근 가능\n\n모드 비트(Mode bit)로 현재 모드를 구분하며, 시스템 콜이나 인터럽트 발생 시 커널 모드로 전환됩니다.",
    "references": [
      {
        "title": "Intel SDM Vol.3: Protected Mode",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "dual",
      "mode",
      "cpu",
      "user",
      "kernel",
      "사용자",
      "모드",
      "커널",
      "가지",
      "실행",
      "모드를",
      "가지는",
      "것입니다",
      "일반",
      "애플리케이션이"
    ]
  },
  {
    "id": "OS-006",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "왜 유저모드와 커널모드를 구분해야 하나요?",
    "answer": "시스템 보호: 사용자 프로그램이 커널 메모리나 다른 프로세스의 메모리에 접근하는 것을 방지\n안정성: 잘못된 사용자 프로그램이 시스템 전체를 손상시키는 것을 방지\n보안: 악의적인 프로그램이 하드웨어를 직접 제어하거나 민감한 데이터에 접근하는 것을 차단\n자원 관리: OS가 하드웨어 자원을 중앙에서 관리하여 공정한 분배 가능",
    "references": [
      {
        "title": "Linux Kernel Documentation: Memory Protection",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/"
      }
    ],
    "keywords": [
      "시스템",
      "보호",
      "사용자",
      "프로그램이",
      "커널",
      "메모리나",
      "다른",
      "프로세스의",
      "메모리에",
      "접근하는",
      "것을",
      "방지",
      "안정성",
      "잘못된",
      "전체를"
    ]
  },
  {
    "id": "OS-007",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?",
    "answer": "시스템 콜 번호(System Call Number)를 통해 구분합니다.\n각 시스템 콜은 고유한 번호가 할당됨 (예: Linux x86-64에서 read=0, write=1, open=2)\n시스템 콜 호출 시 해당 번호를 레지스터(x86-64: rax)에 저장\n커널은 시스템 콜 테이블(syscalltable)에서 번호에 해당하는 핸들러 함수를 찾아 실행\n이 테이블은 커널 컴파일 시 정적으로 생성됨",
    "references": [
      {
        "title": "Linux syscall table",
        "url": "https://github.com/torvalds/linux/blob/master/arch/x86/entry/syscalls/syscall_64.tbl"
      }
    ],
    "keywords": [
      "system",
      "call",
      "number",
      "linux",
      "시스템",
      "번호",
      "구분합니다",
      "콜은",
      "고유한",
      "번호가",
      "할당됨",
      "에서",
      "호출",
      "해당",
      "번호를"
    ]
  },
  {
    "id": "OS-008",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "인터럽트가 무엇인지 설명해 주세요.",
    "answer": "인터럽트는 CPU가 현재 실행 중인 작업을 일시 중단하고, 특정 이벤트를 처리하도록 알리는 신호입니다.\n하드웨어 인터럽트: 외부 장치(키보드, 마우스, 디스크 등)에서 발생\n소프트웨어 인터럽트(트랩): 프로그램에서 의도적으로 발생 (시스템 콜, 예외 등)\n\n인터럽트 발생 시 CPU는 현재 상태를 저장하고, 인터럽트 서비스 루틴(ISR)을 실행한 후 원래 작업으로 복귀합니다.",
    "references": [
      {
        "title": "Linux Kernel Documentation: Interrupts",
        "url": "https://www.kernel.org/doc/html/latest/core-api/genericirq.html"
      }
    ],
    "keywords": [
      "cpu",
      "isr",
      "인터럽트는",
      "현재",
      "실행",
      "중인",
      "작업을",
      "일시",
      "중단하고",
      "특정",
      "이벤트를",
      "처리하도록",
      "알리는",
      "신호입니다",
      "하드웨어"
    ]
  },
  {
    "id": "OS-009",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "인터럽트는 어떻게 처리하나요?",
    "answer": "인터럽트 발생: 하드웨어 또는 소프트웨어에서 인터럽트 신호 발생\n현재 상태 저장: CPU는 현재 실행 중인 명령어의 PC, 레지스터 등을 스택에 저장\n인터럽트 벡터 참조: 인터럽트 번호로 IDT(Interrupt Descriptor Table)에서 핸들러 주소 확인\nISR 실행: 해당 인터럽트 서비스 루틴(Interrupt Service Routine) 실행\n상태 복원: 저장했던 상태를 복원하고 원래 작업으로 복귀",
    "references": [
      {
        "title": "Intel SDM Vol.3: Interrupt and Exception Handling",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "cpu",
      "idt",
      "interrupt",
      "descriptor",
      "table",
      "isr",
      "service",
      "routine",
      "인터럽트",
      "발생",
      "하드웨어",
      "소프트웨어에서",
      "신호",
      "현재",
      "상태"
    ]
  },
  {
    "id": "OS-010",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Polling 방식에 대해 설명해 주세요.",
    "answer": "Polling은 CPU가 주기적으로 장치의 상태를 확인하여 이벤트 발생 여부를 검사하는 방식입니다.\n\n장점:\n구현이 단순함\n인터럽트 오버헤드가 없음\n예측 가능한 응답 시간\n\n단점:\nCPU 자원 낭비 (busy waiting)\n이벤트가 없어도 계속 확인해야 함\n응답 지연 가능성 (폴링 주기에 따라)\n\n일반적으로 인터럽트 방식이 효율적이지만, 짧은 대기 시간이 예상되거나 실시간 시스템에서는 폴링이 사용됩니다.",
    "references": [
      {
        "title": "Linux Kernel Documentation: Device Drivers",
        "url": "https://www.kernel.org/doc/html/latest/driver-api/"
      }
    ],
    "keywords": [
      "polling",
      "cpu",
      "주기적으로",
      "장치의",
      "상태를",
      "확인하여",
      "이벤트",
      "발생",
      "여부를",
      "검사하는",
      "방식입니다",
      "장점",
      "구현이",
      "단순함",
      "인터럽트"
    ]
  },
  {
    "id": "OS-011",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "HW / SW 인터럽트에 대해 설명해 주세요.",
    "answer": "하드웨어 인터럽트 (Hardware Interrupt):\n외부 장치(키보드, 마우스, 네트워크 카드, 타이머 등)에서 발생\n비동기적: 언제든지 발생 가능\n인터럽트 컨트롤러(PIC/APIC)를 통해 CPU에 전달\n예: 키보드 입력, 디스크 I/O 완료, 타이머 틱\n\n소프트웨어 인터럽트 (Software Interrupt/Trap):\n프로그램 실행 중 의도적으로 발생\n동기적: 특정 명령어 실행 시 발생\n시스템 콜, 예외(Exception), 오류 처리에 사용\n예: int 0x80, syscall 명령어, divide by zero",
    "references": [
      {
        "title": "Linux Kernel: Hardware Interrupts",
        "url": "https://www.kernel.org/doc/html/latest/core-api/genericirq.html"
      }
    ],
    "keywords": [
      "hardware",
      "interrupt",
      "pic",
      "apic",
      "cpu",
      "software",
      "trap",
      "exception",
      "하드웨어",
      "인터럽트",
      "외부",
      "장치",
      "키보드",
      "마우스",
      "네트워크"
    ]
  },
  {
    "id": "OS-012",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?",
    "answer": "인터럽트 우선순위(Interrupt Priority)를 통해 처리합니다.\n우선순위 기반 처리: 각 인터럽트에 우선순위가 할당되며, 높은 우선순위 인터럽트가 먼저 처리됨\n중첩 인터럽트(Nested Interrupt): 낮은 우선순위 ISR 실행 중 높은 우선순위 인터럽트가 발생하면 선점 가능\n인터럽트 마스킹: 중요한 작업 중 특정 인터럽트를 비활성화\n인터럽트 컨트롤러(APIC): 우선순위 관리 및 중재 담당\n\n일반적 우선순위: 전원 > 기계 오류 > 타이머 > 디스크 I/O > 네트워크 > 키보드",
    "references": [
      {
        "title": "Intel APIC Documentation",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "interrupt",
      "priority",
      "nested",
      "isr",
      "apic",
      "인터럽트",
      "우선순위",
      "처리합니다",
      "기반",
      "처리",
      "인터럽트에",
      "우선순위가",
      "할당되며",
      "높은",
      "인터럽트가"
    ]
  },
  {
    "id": "OS-013",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "프로세스가 무엇인가요?",
    "answer": "프로세스는 실행 중인 프로그램입니다. 프로그램이 메모리에 적재되어 CPU를 할당받아 실행되는 상태를 말합니다.\n\n프로세스는 다음을 포함합니다:\n코드 영역: 실행할 프로그램 코드\n데이터 영역: 전역 변수, 정적 변수\n힙 영역: 동적 할당 메모리\n스택 영역: 함수 호출, 지역 변수\nPCB: 프로세스 상태 정보\n\n각 프로세스는 독립적인 주소 공간을 가지며, OS가 자원 할당 및 스케줄링의 단위로 관리합니다.",
    "references": [
      {
        "title": "Linux Kernel: Process Management",
        "url": "https://www.kernel.org/doc/html/latest/scheduler/"
      }
    ],
    "keywords": [
      "cpu",
      "pcb",
      "프로세스는",
      "실행",
      "중인",
      "프로그램입니다",
      "프로그램이",
      "메모리에",
      "적재되어",
      "할당받아",
      "실행되는",
      "상태를",
      "말합니다",
      "다음을",
      "포함합니다"
    ]
  },
  {
    "id": "OS-014",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.",
    "answer": "구분   프로그램   프로세스   스레드\n\n정의   디스크에 저장된 실행 파일   실행 중인 프로그램   프로세스 내 실행 단위\n상태   정적 (passive)   동적 (active)   동적\n메모리   없음   독립적 주소 공간   프로세스 주소 공간 공유\n자원   없음   OS로부터 할당   프로세스 자원 공유\n생성 비용   -   높음   낮음\n통신   -   IPC 필요   공유 메모리로 직접 통신\n\n스레드는 코드, 데이터, 힙을 공유하고 각자의 스택과 레지스터를 가집니다.",
    "references": [
      {
        "title": "POSIX Threads (pthreads)",
        "url": "https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/pthread.h.html"
      }
    ],
    "keywords": [
      "ipc",
      "구분",
      "프로그램",
      "프로세스",
      "스레드",
      "정의",
      "디스크에",
      "저장된",
      "실행",
      "파일",
      "중인",
      "단위",
      "상태",
      "정적",
      "동적"
    ]
  },
  {
    "id": "OS-015",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "PCB가 무엇인가요?",
    "answer": "PCB(Process Control Block)는 운영체제가 프로세스를 관리하기 위해 유지하는 자료구조입니다. Linux에서는 task_struct로 구현됩니다.\n\nPCB에 저장되는 정보:\n프로세스 상태: Ready, Running, Waiting 등\n프로그램 카운터(PC): 다음 실행할 명령어 주소\nCPU 레지스터: 컨텍스트 스위칭 시 저장/복원\n스케줄링 정보: 우선순위, 스케줄링 큐 포인터\n메모리 관리 정보: 페이지 테이블, 세그먼트 테이블\nI/O 상태 정보: 열린 파일 목록, I/O 장치\n계정 정보: PID, CPU 사용 시간",
    "references": [
      {
        "title": "Linux Kernel: task_struct",
        "url": "https://github.com/torvalds/linux/blob/master/include/linux/sched.h"
      }
    ],
    "keywords": [
      "pcb",
      "process",
      "control",
      "block",
      "linux",
      "task_struct",
      "ready",
      "running",
      "waiting",
      "cpu",
      "pid",
      "운영체제가",
      "프로세스를",
      "관리하기",
      "유지하는"
    ]
  },
  {
    "id": "OS-016",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "그렇다면, 스레드는 PCB를 갖고 있을까요?",
    "answer": "Linux에서는 스레드도 자체 PCB(taskstruct)를 가집니다.\n\nLinux는 프로세스와 스레드를 구분하지 않고 모두 taskstruct로 관리합니다. 다만 스레드들은:\n같은 메모리 공간(mm_struct)을 공유\n같은 파일 디스크립터 테이블 공유\n같은 시그널 핸들러 공유\n각자의 스택, 레지스터, PC는 별도 유지\n\n다른 OS에서는 TCB(Thread Control Block)라는 별도 구조체를 사용하기도 합니다. TCB는 PCB보다 작으며 스레드별 정보(스택 포인터, 레지스터, 상태)만 저장합니다.",
    "references": [
      {
        "title": "Linux Kernel: clone() system call",
        "url": "https://man7.org/linux/man-pages/man2/clone.2.html"
      }
    ],
    "keywords": [
      "linux",
      "pcb",
      "mm_struct",
      "tcb",
      "thread",
      "control",
      "block",
      "에서는",
      "스레드도",
      "자체",
      "가집니다",
      "프로세스와",
      "스레드를",
      "구분하지",
      "않고"
    ]
  },
  {
    "id": "OS-017",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?",
    "answer": "프로세스 생성: fork() 시스템 콜\n부모 프로세스의 복사본 생성\nCopy-on-Write로 메모리 효율적 복사\n새로운 PID 할당, 별도의 주소 공간\n\n스레드 생성: clone() 시스템 콜 (내부적으로 pthreadcreate가 사용)\nCLONEVM: 메모리 공간 공유\nCLONEFILES: 파일 디스크립터 공유\nCLONEFS: 파일 시스템 정보 공유\nCLONE_SIGHAND: 시그널 핸들러 공유\n\nLinux에서는 프로세스와 스레드 모두 clone()을 기반으로 하며, 플래그에 따라 공유 범위가 결정됩니다.",
    "references": [
      {
        "title": "Linux man-pages: fork(2)",
        "url": "https://man7.org/linux/man-pages/man2/fork.2.html"
      },
      {
        "title": "Linux man-pages: clone(2)",
        "url": "https://man7.org/linux/man-pages/man2/clone.2.html"
      }
    ],
    "keywords": [
      "copy-on-write",
      "pid",
      "clonevm",
      "clonefiles",
      "clonefs",
      "clone_sighand",
      "linux",
      "프로세스",
      "생성",
      "시스템",
      "부모",
      "프로세스의",
      "복사본",
      "메모리",
      "효율적"
    ]
  },
  {
    "id": "OS-018",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?",
    "answer": "좀비 프로세스 (Zombie Process):\n자식 프로세스가 종료되었지만 부모가 wait()를 호출하지 않은 상태\nPCB(task_struct)가 메모리에 남아 종료 상태 정보 유지\n부모가 wait()를 호출하면 자원 회수\n부모가 종료되면 init(PID 1)이 입양하여 처리\n\n고아 프로세스 (Orphan Process):\n부모 프로세스가 먼저 종료된 자식 프로세스\ninit 프로세스(systemd)가 새로운 부모가 됨\ninit은 주기적으로 wait()를 호출하여 고아 프로세스 정리",
    "references": [
      {
        "title": "Linux man-pages: wait(2)",
        "url": "https://man7.org/linux/man-pages/man2/wait.2.html"
      }
    ],
    "keywords": [
      "zombie",
      "process",
      "pcb",
      "task_struct",
      "pid",
      "orphan",
      "좀비",
      "프로세스",
      "자식",
      "프로세스가",
      "종료되었지만",
      "부모가",
      "호출하지",
      "않은",
      "상태"
    ]
  },
  {
    "id": "OS-019",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "리눅스에서, 데몬프로세스에 대해 설명해 주세요.",
    "answer": "데몬(Daemon) 프로세스는 백그라운드에서 실행되며 특정 서비스를 제공하는 프로세스입니다.\n\n특징:\n터미널과 분리되어 실행 (controlling terminal 없음)\n보통 시스템 부팅 시 시작되어 계속 실행\n이름이 'd'로 끝나는 경우가 많음 (sshd, httpd, mysqld)\n부모 프로세스가 init(PID 1)\n\n데몬 생성 과정:\nfork()로 자식 생성 후 부모 종료\nsetsid()로 새 세션 생성\n작업 디렉토리를 /로 변경\n파일 디스크립터(stdin, stdout, stderr) 닫기\n로그 파일 또는 syslog로 출력 리디렉션",
    "references": [
      {
        "title": "Linux man-pages: daemon(7)",
        "url": "https://man7.org/linux/man-pages/man7/daemon.7.html"
      }
    ],
    "keywords": [
      "daemon",
      "pid",
      "데몬",
      "프로세스는",
      "백그라운드에서",
      "실행되며",
      "특정",
      "서비스를",
      "제공하는",
      "프로세스입니다",
      "특징",
      "터미널과",
      "분리되어",
      "실행",
      "없음"
    ]
  },
  {
    "id": "OS-020",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.",
    "answer": "init 프로세스 (PID 1)가 프로세스 트리의 루트입니다. 현대 Linux에서는 주로 systemd가 이 역할을 합니다.\n\n특징:\n커널 부팅 후 가장 먼저 실행되는 사용자 공간 프로세스\n모든 프로세스의 조상 (직/간접적 부모)\n고아 프로세스를 입양하여 좀비 방지\n시스템 종료 시 모든 프로세스 정리\n\n역할:\n시스템 초기화 스크립트 실행\n데몬 프로세스 시작 및 관리\n런레벨/타겟 관리\n고아 프로세스 회수\n\npstree 명령어로 프로세스 트리 구조를 확인할 수 있습니다.",
    "references": [
      {
        "title": "systemd Documentation",
        "url": "https://www.freedesktop.org/wiki/Software/systemd/"
      }
    ],
    "keywords": [
      "pid",
      "linux",
      "프로세스",
      "트리의",
      "루트입니다",
      "현대",
      "에서는",
      "주로",
      "역할을",
      "특징",
      "커널",
      "부팅",
      "가장",
      "먼저",
      "실행되는"
    ]
  },
  {
    "id": "OS-021",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "프로세스 주소공간에 대해 설명해 주세요.",
    "answer": "프로세스 주소공간은 프로세스가 사용하는 가상 메모리 영역으로, 다음과 같이 구성됩니다:\n\n영역   설명   특성\n\nText(Code)   실행 코드   읽기 전용\nData   초기화된 전역/정적 변수   읽기/쓰기\nBSS   초기화되지 않은 전역/정적 변수   읽기/쓰기, 0으로 초기화\nHeap   동적 할당 메모리 (malloc)   낮은 주소 -> 높은 주소로 증가\nStack   함수 호출, 지역 변수   높은 주소 -> 낮은 주소로 증가\n\nHeap과 Stack 사이에는 공유 라이브러리, mmap 영역이 위치합니다.",
    "references": [
      {
        "title": "Linux Kernel: Memory Layout",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/"
      }
    ],
    "keywords": [
      "text",
      "code",
      "data",
      "bss",
      "heap",
      "stack",
      "프로세스",
      "주소공간은",
      "프로세스가",
      "사용하는",
      "가상",
      "메모리",
      "영역으로",
      "다음과",
      "같이"
    ]
  },
  {
    "id": "OS-022",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "초기화 하지 않은 변수들은 어디에 저장될까요?",
    "answer": "BSS(Block Started by Symbol) 영역에 저장됩니다.\n초기화되지 않은 전역 변수와 정적 변수가 위치\n프로그램 로드 시 운영체제가 자동으로 0으로 초기화\n실행 파일에는 크기 정보만 저장 (실제 데이터 X) -> 파일 크기 절약\nData 영역과 달리 초기값을 저장할 필요가 없음",
    "references": [
      {
        "title": "ELF Format Specification",
        "url": "https://refspecs.linuxfoundation.org/elf/elf.pdf"
      }
    ],
    "keywords": [
      "bss",
      "block",
      "started",
      "symbol",
      "data",
      "영역에",
      "저장됩니다",
      "초기화되지",
      "않은",
      "전역",
      "변수와",
      "정적",
      "변수가",
      "위치",
      "프로그램"
    ]
  },
  {
    "id": "OS-023",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?",
    "answer": "Stack과 Heap은 고정 크기가 아니며, 실제로는 제한적입니다.\n\nStack:\n기본 크기: Linux에서 보통 8MB (ulimit -s로 확인)\n컴파일 시 또는 실행 시 설정 가능\n초과 시 Stack Overflow 발생\n\nHeap:\n이론상 가상 주소 공간까지 확장 가능\n실제로는 물리 메모리 + 스왑 공간으로 제한\nbrk(), sbrk() 시스템 콜로 동적 확장\n큰 할당은 mmap()으로 별도 영역 사용\n\n그림에서는 Heap과 Stack이 서로 향해 자라는 것처럼 보이지만, 실제로는 경계가 명확히 관리됩니다.",
    "references": [
      {
        "title": "Linux man-pages: getrlimit(2)",
        "url": "https://man7.org/linux/man-pages/man2/getrlimit.2.html"
      }
    ],
    "keywords": [
      "stack",
      "heap",
      "linux",
      "overflow",
      "고정",
      "크기가",
      "아니며",
      "실제로는",
      "제한적입니다",
      "기본",
      "크기",
      "에서",
      "보통",
      "확인",
      "컴파일"
    ]
  },
  {
    "id": "OS-024",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?",
    "answer": "Stack이 일반적으로 더 빠릅니다.\n\nStack이 빠른 이유:\n캐시 지역성: Stack은 연속적으로 사용되어 캐시 히트율이 높음\n단순한 할당/해제: 스택 포인터(SP)만 이동하면 됨 (O(1))\n메모리 관리 오버헤드 없음: 별도의 메타데이터 관리 불필요\n\nHeap이 느린 이유:\n복잡한 할당 알고리즘: free list 탐색, 단편화 처리 필요\n캐시 지역성 낮음: 할당된 메모리가 분산될 수 있음\n동기화 오버헤드: 멀티스레드 환경에서 락 필요\n시스템 콜 가능성: brk(), mmap() 호출 필요할 수 있음",
    "references": [
      {
        "title": "glibc malloc internals",
        "url": "https://sourceware.org/glibc/wiki/MallocInternals"
      }
    ],
    "keywords": [
      "stack",
      "heap",
      "일반적으로",
      "빠릅니다",
      "빠른",
      "이유",
      "캐시",
      "지역성",
      "연속적으로",
      "사용되어",
      "히트율이",
      "높음",
      "단순한",
      "할당",
      "해제"
    ]
  },
  {
    "id": "OS-025",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "다음과 같이 공간을 분할하는 이유가 있을까요?",
    "answer": "메모리 영역 분할의 이유:\n보안 및 보호\nCode 영역을 읽기 전용으로 설정하여 코드 변조 방지\n각 영역에 적절한 권한(읽기/쓰기/실행) 부여 가능\n메모리 효율성\nCode 영역: 여러 프로세스가 공유 가능 (같은 프로그램)\nBSS 영역: 실행 파일에 실제 데이터 저장 불필요\n관리 용이성\n각 영역의 특성에 맞는 관리 방식 적용\nStack: LIFO 방식의 단순한 관리\nHeap: 동적 할당을 위한 복잡한 관리\n확장성\nStack과 Heap이 반대 방향으로 성장하여 공간 활용 최적화",
    "references": [
      {
        "title": "Linux Kernel: Virtual Memory Areas",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/concepts.html"
      }
    ],
    "keywords": [
      "code",
      "bss",
      "stack",
      "lifo",
      "heap",
      "메모리",
      "영역",
      "분할의",
      "이유",
      "보안",
      "보호",
      "영역을",
      "읽기",
      "전용으로",
      "설정하여"
    ]
  },
  {
    "id": "OS-026",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "스레드의 주소공간은 어떻게 구성되어 있을까요?",
    "answer": "스레드는 프로세스의 주소공간을 공유하되, 일부 영역은 개별적으로 가집니다.\n\n공유하는 영역:\nCode(Text) 영역\nData 영역\nBSS 영역\nHeap 영역\n열린 파일 디스크립터\n시그널 핸들러\n\n개별적인 영역:\nStack: 각 스레드마다 별도의 스택 (기본 2MB 정도)\n레지스터: PC, SP 등 CPU 레지스터\nTLS(Thread Local Storage): 스레드별 전역 변수\n스레드 ID\n\n이러한 구조 덕분에 스레드 간 통신이 빠르지만, 동기화 문제에 주의해야 합니다.",
    "references": [
      {
        "title": "POSIX Threads: Thread Local Storage",
        "url": "https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_key_create.html"
      }
    ],
    "keywords": [
      "code",
      "text",
      "data",
      "bss",
      "heap",
      "stack",
      "cpu",
      "tls",
      "thread",
      "local",
      "storage",
      "스레드는",
      "프로세스의",
      "주소공간을",
      "공유하되"
    ]
  },
  {
    "id": "OS-027",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "\"스택\"영역과 \"힙\"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.",
    "answer": "Stack 영역 - 자료구조 스택과 직접 연관:\nLIFO(Last In First Out) 방식으로 동작\n함수 호출 시 스택 프레임 push, 반환 시 pop\n스택 포인터(SP)가 가리키는 위치로 관리\n함수 호출 순서의 역순으로 반환되어야 하므로 스택 구조가 적합\n\nHeap 영역 - 자료구조 힙과 무관:\n자료구조 힙(우선순위 큐)과는 관계 없음\n\"heap\"은 단순히 \"더미, 무더기\"라는 의미\n비순차적으로 할당/해제 가능한 메모리 풀\n다양한 알고리즘으로 관리 (free list, buddy system 등)\n\n힙 영역은 할당 순서와 무관하게 해제할 수 있어야 하므로 스택 구조가 아닌 동적 메모리 관리 방식을 사용합니다.",
    "references": [
      {
        "title": "Computer Systems: A Programmer's Perspective",
        "url": "https://csapp.cs.cmu.edu/"
      }
    ],
    "keywords": [
      "stack",
      "lifo",
      "last",
      "first",
      "out",
      "heap",
      "영역",
      "자료구조",
      "스택과",
      "직접",
      "연관",
      "방식으로",
      "동작",
      "함수",
      "호출"
    ]
  },
  {
    "id": "OS-028",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?",
    "answer": "Heap과 Stack 사이의 mmap 영역에 위치합니다.\n\n이유:\n유연한 크기 할당: mmap 영역은 동적으로 크기 조절 가능\n주소 충돌 방지: Heap/Stack 성장과 독립적인 영역\n커널 관리 용이: 페이지 단위로 매핑/해제 가능\n공유 설정: 여러 프로세스의 가상 주소를 같은 물리 페이지에 매핑\n\n매핑 방식:\n\n공유 메모리는 각 프로세스에서 다른 가상 주소를 가질 수 있지만, 같은 물리 메모리를 참조합니다.",
    "references": [
      {
        "title": "Linux man-pages: mmap(2)",
        "url": "https://man7.org/linux/man-pages/man2/mmap.2.html"
      }
    ],
    "keywords": [
      "heap",
      "stack",
      "사이의",
      "영역에",
      "위치합니다",
      "이유",
      "유연한",
      "크기",
      "할당",
      "영역은",
      "동적으로",
      "조절",
      "가능",
      "주소",
      "충돌"
    ]
  },
  {
    "id": "OS-029",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?",
    "answer": "Stack 크기 결정 시점:\n프로세스 시작 시 OS 기본값 적용 (Linux 기본 8MB)\n컴파일 시 링커 옵션으로 설정 가능\n실행 전 ulimit -s 명령으로 수정 가능\n\nHeap 크기 결정 시점:\n런타임에 동적으로 결정\nmalloc/free 호출에 따라 확장/축소\n시스템 메모리 한도까지 확장 가능\n\n사용자가 수정하는 방법:\n\n프로그램 실행 시 환경 변수나 런타임 옵션으로도 조정 가능합니다.",
    "references": [
      {
        "title": "Linux man-pages: ulimit",
        "url": "https://man7.org/linux/man-pages/man3/ulimit.3.html"
      }
    ],
    "keywords": [
      "stack",
      "linux",
      "heap",
      "크기",
      "결정",
      "시점",
      "프로세스",
      "시작",
      "기본값",
      "적용",
      "기본",
      "컴파일",
      "링커",
      "옵션으로",
      "설정"
    ]
  },
  {
    "id": "OS-030",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.",
    "answer": "장기 스케줄러 (Long-term Scheduler / Job Scheduler):\n디스크의 작업을 메모리에 적재할지 결정\ndegree of multiprogramming 제어\nI/O bound와 CPU bound 프로세스의 적절한 혼합 유지\n\n중기 스케줄러 (Medium-term Scheduler):\n메모리에서 프로세스를 일시적으로 제거 (swapping)\n메모리 부족 시 프로세스를 디스크로 스왑 아웃\n메모리 확보 후 다시 스왑 인\n\n단기 스케줄러 (Short-term Scheduler / CPU Scheduler):\nReady 큐에서 어떤 프로세스에게 CPU를 할당할지 결정\n매우 빈번하게 실행 (밀리초 단위)\n가장 빠른 성능이 요구됨",
    "references": [
      {
        "title": "Linux Kernel: Scheduler",
        "url": "https://www.kernel.org/doc/html/latest/scheduler/"
      }
    ],
    "keywords": [
      "long-term",
      "scheduler",
      "job",
      "cpu",
      "medium-term",
      "short-term",
      "ready",
      "장기",
      "스케줄러",
      "디스크의",
      "작업을",
      "메모리에",
      "적재할지",
      "결정",
      "제어"
    ]
  },
  {
    "id": "OS-031",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?",
    "answer": "현대 OS는 주로 단기 스케줄러만 사용합니다.\n\n장기 스케줄러 - 거의 사용 안 함:\n과거 배치 시스템에서 사용\n현대 시분할 시스템에서는 프로세스가 즉시 메모리에 적재\n가상 메모리로 대체됨\n\n중기 스케줄러 - 제한적 사용:\nSwapping 개념은 존재하나 다른 방식으로 구현\nLinux의 OOM Killer: 메모리 부족 시 프로세스 종료\n페이지 단위 스왑이 프로세스 단위 스왑을 대체\n\n단기 스케줄러 - 핵심적으로 사용:\nLinux CFS (Completely Fair Scheduler)\n실시간 스케줄러 (SCHEDFIFO, SCHEDRR)",
    "references": [
      {
        "title": "Linux CFS Scheduler",
        "url": "https://www.kernel.org/doc/html/latest/scheduler/sched-design-CFS.html"
      }
    ],
    "keywords": [
      "swapping",
      "linux",
      "oom",
      "killer",
      "cfs",
      "completely",
      "fair",
      "scheduler",
      "schedfifo",
      "schedrr",
      "현대",
      "주로",
      "단기",
      "스케줄러만",
      "사용합니다"
    ]
  },
  {
    "id": "OS-032",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "프로세스의 스케쥴링 상태에 대해 설명해 주세요.",
    "answer": "5가지 기본 프로세스 상태:\n\n상태   설명\n\nNew   프로세스 생성 중\nReady   실행 대기 중, CPU 할당만 기다림\nRunning   CPU에서 실행 중\nWaiting (Blocked)   I/O나 이벤트 완료 대기\nTerminated   실행 완료\n\n상태 전이:\nNew -> Ready: 프로세스 생성 완료\nReady -> Running: CPU 할당 (dispatch)\nRunning -> Ready: 타임 슬라이스 만료, 선점\nRunning -> Waiting: I/O 요청, 이벤트 대기\nWaiting -> Ready: I/O 완료, 이벤트 발생\nRunning -> Terminated: 실행 완료, exit()",
    "references": [
      {
        "title": "Linux Kernel: Process States",
        "url": "https://github.com/torvalds/linux/blob/master/include/linux/sched.h"
      }
    ],
    "keywords": [
      "new",
      "ready",
      "cpu",
      "running",
      "waiting",
      "blocked",
      "terminated",
      "가지",
      "기본",
      "프로세스",
      "상태",
      "설명",
      "생성",
      "실행",
      "대기"
    ]
  },
  {
    "id": "OS-033",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?",
    "answer": "비선점(Non-preemptive) 스케줄링에서 불가능한 상태 전이:\n\nRunning -> Ready 전이가 타이머 인터럽트에 의해 발생할 수 없습니다.\n\n비선점 스케줄링에서는 프로세스가 자발적으로 CPU를 반납할 때만 전이 가능:\nI/O 요청 (Running -> Waiting)\n프로세스 종료 (Running -> Terminated)\nyield() 호출 (Running -> Ready)\n\n선점(Preemptive) 스케줄링에서는 모든 상태 전이 가능:\n타이머 인터럽트로 강제 전이\n높은 우선순위 프로세스에 의한 선점\n\n비선점 방식에서는 한 프로세스가 CPU를 독점하면 다른 프로세스가 기아 상태에 빠질 수 있습니다.",
    "references": [
      {
        "title": "Operating System Concepts - Silberschatz",
        "url": "https://www.os-book.com/"
      }
    ],
    "keywords": [
      "non-preemptive",
      "running",
      "ready",
      "cpu",
      "waiting",
      "terminated",
      "preemptive",
      "비선점",
      "스케줄링에서",
      "불가능한",
      "상태",
      "전이",
      "전이가",
      "타이머",
      "인터럽트에"
    ]
  },
  {
    "id": "OS-034",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?",
    "answer": "Suspended (중단) 상태로 전이될 수 있습니다.\n\nSuspended Ready:\nReady 상태에서 메모리 부족으로 스왑 아웃\n메모리에 없지만 실행 준비 완료\n메모리 확보 시 Ready 상태로 복귀\n\nSuspended Waiting (Suspended Blocked):\nWaiting 상태에서 스왑 아웃\nI/O 완료 시 Suspended Ready로 전이\n메모리 확보 후 Ready 상태로 복귀\n\n현대 Linux의 처리 방식:\n프로세스 단위 스왑보다 페이지 단위 스왑 사용\nOOM Killer: 극심한 메모리 부족 시 프로세스 종료\ncgroups: 메모리 사용량 제한",
    "references": [
      {
        "title": "Linux OOM Killer",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/concepts.html"
      }
    ],
    "keywords": [
      "suspended",
      "ready",
      "waiting",
      "blocked",
      "linux",
      "oom",
      "killer",
      "중단",
      "상태로",
      "전이될",
      "상태에서",
      "메모리",
      "부족으로",
      "스왑",
      "아웃"
    ]
  },
  {
    "id": "OS-035",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?",
    "answer": "컨텍스트 스위칭 과정:\n현재 프로세스 상태 저장\nCPU 레지스터 (범용, PC, SP, 상태 레지스터)\nPCB에 저장\n커널 모드 진입\n인터럽트 또는 시스템 콜에 의해 발생\n권한 레벨 변경\n스케줄러 실행\n다음 실행할 프로세스 선택\nReady 큐에서 프로세스 선택\n새 프로세스 상태 복원\n새 프로세스의 PCB에서 레지스터 복원\n메모리 매핑 변경 (페이지 테이블 교체)\nTLB 플러시 또는 ASID 변경\n사용자 모드 복귀\n새 프로세스 실행 시작\n\n컨텍스트 스위칭은 순수한 오버헤드이므로 최소화가 중요합니다.",
    "references": [
      {
        "title": "Linux Kernel: Context Switching",
        "url": "https://www.kernel.org/doc/html/latest/scheduler/"
      }
    ],
    "keywords": [
      "cpu",
      "pcb",
      "ready",
      "tlb",
      "asid",
      "컨텍스트",
      "스위칭",
      "과정",
      "현재",
      "프로세스",
      "상태",
      "저장",
      "레지스터",
      "범용",
      "커널"
    ]
  },
  {
    "id": "OS-036",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?",
    "answer": "프로세스 컨텍스트 스위칭 (비용 높음):\nCPU 레지스터 저장/복원\n페이지 테이블 교체 (CR3 레지스터 변경)\nTLB 전체 플러시 필요 (PCID 미사용 시)\n캐시 미스 증가 가능성\n메모리 매핑 정보 변경\n\n스레드 컨텍스트 스위칭 (같은 프로세스 내, 비용 낮음):\nCPU 레지스터 저장/복원\n스택 포인터 변경\n페이지 테이블 유지 (주소 공간 공유)\nTLB 유지 가능\n캐시 히트율 높음\n\n구분   프로세스 스위칭   스레드 스위칭\n\n페이지 테이블   교체 필요   유지\nTLB   플러시   유지\n캐시 효율   낮음   높음\n비용   높음   낮음",
    "references": [
      {
        "title": "Linux Kernel: Thread Switching",
        "url": "https://www.kernel.org/doc/html/latest/scheduler/"
      }
    ],
    "keywords": [
      "cpu",
      "cr3",
      "tlb",
      "pcid",
      "프로세스",
      "컨텍스트",
      "스위칭",
      "비용",
      "높음",
      "레지스터",
      "저장",
      "복원",
      "페이지",
      "테이블",
      "교체"
    ]
  },
  {
    "id": "OS-037",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?",
    "answer": "커널 스택에 저장되는 정보 (스택 프레임 형태):\n\n인터럽트/트랩 발생 시 하드웨어가 자동 저장:\n\n커널이 추가 저장 (ptregs 구조체):\n\n전체 컨텍스트는 PCB(taskstruct)의 thread_struct에 저장되며, 커널 스택은 프로세스마다 별도로 존재합니다.",
    "references": [
      {
        "title": "Linux Kernel: pt_regs structure",
        "url": "https://github.com/torvalds/linux/blob/master/arch/x86/include/asm/ptrace.h"
      }
    ],
    "keywords": [
      "pcb",
      "thread_struct",
      "커널",
      "스택에",
      "저장되는",
      "정보",
      "스택",
      "프레임",
      "형태",
      "인터럽트",
      "트랩",
      "발생",
      "하드웨어가",
      "자동",
      "저장"
    ]
  },
  {
    "id": "OS-038",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "컨텍스트 스위칭은 언제 일어날까요?",
    "answer": "컨텍스트 스위칭이 발생하는 경우:\n타이머 인터럽트\n타임 슬라이스(quantum) 만료\n선점형 스케줄링에서 주기적 발생\nI/O 요청\n프로세스가 I/O를 요청하여 Waiting 상태로 전환\n다른 Ready 프로세스에게 CPU 할당\n시스템 콜\n특정 시스템 콜 후 스케줄러 호출\nsleep(), yield() 등\n인터럽트 처리 후\n하드웨어 인터럽트 처리 완료 후\n더 높은 우선순위 프로세스가 Ready 상태가 된 경우\n프로세스 종료/생성\nexit() 호출 시\nfork() 후 자식에게 CPU 할당\n동기화 대기\nmutex, semaphore 획득 실패 시",
    "references": [
      {
        "title": "Linux Kernel: Scheduling Points",
        "url": "https://www.kernel.org/doc/html/latest/scheduler/"
      }
    ],
    "keywords": [
      "waiting",
      "ready",
      "cpu",
      "컨텍스트",
      "스위칭이",
      "발생하는",
      "타이머",
      "인터럽트",
      "타임",
      "슬라이스",
      "만료",
      "선점형",
      "스케줄링에서",
      "주기적",
      "발생"
    ]
  },
  {
    "id": "OS-039",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?",
    "answer": "알고리즘   설명   선점 여부\n\nFCFS (FIFO)   먼저 도착한 순서대로 실행   비선점\nSJF   실행 시간이 짧은 작업 우선   비선점\nSRTF   남은 시간이 짧은 작업 우선   선점\nPriority   우선순위가 높은 작업 우선   둘 다 가능\nRound Robin   타임 슬라이스만큼 순환 실행   선점\nMLQ   여러 큐에 우선순위별 배치   선점\nMLFQ   동적 우선순위 조정   선점\n\nLinux CFS (Completely Fair Scheduler):\n가상 런타임 기반의 공정한 스케줄링\nRed-Black Tree로 프로세스 관리\nO(log n) 복잡도",
    "references": [
      {
        "title": "Linux CFS Scheduler",
        "url": "https://www.kernel.org/doc/html/latest/scheduler/sched-design-CFS.html"
      }
    ],
    "keywords": [
      "fcfs",
      "fifo",
      "sjf",
      "srtf",
      "priority",
      "round",
      "robin",
      "mlq",
      "mlfq",
      "linux",
      "cfs",
      "completely",
      "fair",
      "scheduler",
      "red-black"
    ]
  },
  {
    "id": "OS-040",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.",
    "answer": "Time Slice(Quantum)가 너무 작을 때:\n장점: 응답 시간 향상, 대화형 프로세스에 유리\n단점: 컨텍스트 스위칭 오버헤드 증가\n극단적으로 작으면 대부분의 시간을 스위칭에 소비\n\nTime Slice가 너무 클 때:\n장점: 컨텍스트 스위칭 오버헤드 감소\n단점: 응답 시간 증가, FCFS와 유사해짐\n대화형 프로세스의 반응성 저하\n\n적절한 Time Slice 결정 기준:\n컨텍스트 스위칭 시간보다 충분히 커야 함 (보통 10~100ms)\n대화형 시스템: 작은 값 선호 (10~20ms)\n배치 시스템: 큰 값 선호 (100~200ms)\n\n일반적으로 컨텍스트 스위칭 시간의 100배 이상이 적절합니다.",
    "references": [
      {
        "title": "Linux Kernel: Scheduler Tuning",
        "url": "https://www.kernel.org/doc/html/latest/scheduler/sched-design-CFS.html"
      }
    ],
    "keywords": [
      "time",
      "slice",
      "quantum",
      "fcfs",
      "너무",
      "작을",
      "장점",
      "응답",
      "시간",
      "향상",
      "대화형",
      "프로세스에",
      "유리",
      "단점",
      "컨텍스트"
    ]
  },
  {
    "id": "OS-041",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?",
    "answer": "우선순위 기반 선점 스케줄링 (Priority Preemptive) 또는 실시간 스케줄링 (SCHEDFIFO, SCHEDRR)이 적합합니다.\n\n이유:\n높은 우선순위 부여: 상시 실행 프로세스에 최고 우선순위 할당\n선점 보장: 다른 프로세스가 실행 중이어도 즉시 CPU 획득\n예측 가능한 실행: 응답 시간 보장\n\nLinux 실시간 스케줄링:\n\n주의사항:\n다른 프로세스의 기아(starvation) 가능성\n상시 프로세스가 CPU를 독점하지 않도록 적절한 sleep 필요\nWatchdog 같은 시스템 프로세스에 적합",
    "references": [
      {
        "title": "Linux man-pages: sched(7)",
        "url": "https://man7.org/linux/man-pages/man7/sched.7.html"
      }
    ],
    "keywords": [
      "priority",
      "preemptive",
      "schedfifo",
      "schedrr",
      "cpu",
      "linux",
      "watchdog",
      "우선순위",
      "기반",
      "선점",
      "스케줄링",
      "실시간",
      "적합합니다",
      "이유",
      "높은"
    ]
  },
  {
    "id": "OS-042",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "동시성과 병렬성의 차이에 대해 설명해 주세요.",
    "answer": "동시성 (Concurrency):\n여러 작업이 논리적으로 동시에 진행되는 것처럼 보임\n싱글 코어에서도 가능 (시분할, 컨텍스트 스위칭)\n작업들이 번갈아가며 실행\n예: 한 명의 요리사가 여러 요리를 번갈아 진행\n\n병렬성 (Parallelism):\n여러 작업이 물리적으로 동시에 실행\n멀티 코어/프로세서 필요\n실제로 같은 시점에 여러 작업 수행\n예: 여러 요리사가 각자 요리를 동시에 진행\n\n구분   동시성   병렬성\n\n실행   논리적 동시   물리적 동시\n코어   싱글 코어 가능   멀티 코어 필요\n목적   응답성 향상   처리량 향상\n관계   병렬성 포함 가능   동시성 포함",
    "references": [
      {
        "title": "Go Blog: Concurrency is not Parallelism",
        "url": "https://go.dev/blog/waza-talk"
      }
    ],
    "keywords": [
      "concurrency",
      "parallelism",
      "동시성",
      "여러",
      "작업이",
      "논리적으로",
      "동시에",
      "진행되는",
      "것처럼",
      "보임",
      "싱글",
      "코어에서도",
      "가능",
      "시분할",
      "컨텍스트"
    ]
  },
  {
    "id": "OS-043",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?",
    "answer": "MLFQ가 해결하는 문제점들:\nSJF의 실행 시간 예측 문제\nSJF는 실행 시간을 미리 알아야 함\nMLFQ는 과거 행동을 기반으로 동적 판단\n우선순위 스케줄링의 기아(Starvation) 문제\n낮은 우선순위 프로세스가 영원히 대기\nMLFQ는 주기적 부스팅(aging)으로 해결\nRR의 응답성 vs 처리량 딜레마\nI/O bound: 높은 우선순위 큐 (짧은 quantum)\nCPU bound: 낮은 우선순위 큐 (긴 quantum)\n프로세스 특성 변화 대응\n프로세스의 I/O/CPU bound 특성이 실행 중 변할 수 있음\n동적으로 큐 이동하여 적응\n\nMLFQ 규칙:\n새 프로세스는 최상위 큐에서 시작\n타임 슬라이스 소진 시 하위 큐로 이동\n주기적으로 모든 프로세스를 최상위로 부스팅",
    "references": [
      {
        "title": "OSTEP: Multi-level Feedback Queue",
        "url": "https://pages.cs.wisc.edu/~remzi/OSTEP/cpu-sched-mlfq.pdf"
      }
    ],
    "keywords": [
      "mlfq",
      "sjf",
      "starvation",
      "cpu",
      "해결하는",
      "문제점들",
      "실행",
      "시간",
      "예측",
      "문제",
      "시간을",
      "미리",
      "알아야",
      "과거",
      "행동을"
    ]
  },
  {
    "id": "OS-044",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요?",
    "answer": "FIFO(FCFS)가 적합한 시나리오:\n배치 처리 시스템\n야간 배치 작업, 데이터 처리 파이프라인\n응답 시간보다 처리 순서가 중요\n비슷한 실행 시간의 작업들\n모든 작업의 실행 시간이 유사할 때\nConvoy Effect가 발생하지 않음\n실시간 시스템에서 같은 우선순위 작업\nLinux SCHED_FIFO: 같은 우선순위 내에서 FIFO\n선점되지 않는 한 완료까지 실행\n단순함이 중요한 시스템\n구현 및 디버깅이 쉬움\n오버헤드가 거의 없음\n임베디드 시스템, 리소스 제한 환경\n\n장점:\n구현 단순, 오버헤드 최소\n기아 없음 (모든 작업 순서대로 실행)\n예측 가능한 실행 순서",
    "references": [
      {
        "title": "Linux man-pages: SCHED_FIFO",
        "url": "https://man7.org/linux/man-pages/man7/sched.7.html"
      }
    ],
    "keywords": [
      "fifo",
      "fcfs",
      "convoy",
      "effect",
      "linux",
      "sched_fifo",
      "적합한",
      "시나리오",
      "배치",
      "처리",
      "시스템",
      "야간",
      "작업",
      "데이터",
      "파이프라인"
    ]
  },
  {
    "id": "OS-045",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "우리는 스케줄링 알고리즘을 \"프로세스\" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?",
    "answer": "Linux에서는 프로세스와 스레드를 동일하게 스케줄링합니다.\n\nLinux 커널은 프로세스와 스레드를 모두 task_struct로 관리하며, 스케줄러 관점에서 동등하게 취급합니다. 스케줄링의 기본 단위는 \"task\"입니다.\n\n스케줄링 모델에 따른 차이:\n\n모델   스케줄링 주체   특징\n\n1:1 (커널 스레드)   커널   Linux 기본, 모든 스레드가 커널에 의해 스케줄링\nN:1 (유저 스레드)   유저 라이브러리   커널은 프로세스만 인식, 라이브러리가 스레드 스케줄링\nM:N (하이브리드)   둘 다   유저/커널 스레드 매핑, Go goroutine 등\n\n현대 Linux(NPTL)는 1:1 모델을 사용하므로, 각 스레드가 독립적인 커널 스케줄링 대상입니다.",
    "references": [
      {
        "title": "Linux NPTL",
        "url": "https://man7.org/linux/man-pages/man7/nptl.7.html"
      }
    ],
    "keywords": [
      "linux",
      "task_struct",
      "nptl",
      "에서는",
      "프로세스와",
      "스레드를",
      "동일하게",
      "스케줄링합니다",
      "커널은",
      "모두",
      "관리하며",
      "스케줄러",
      "관점에서",
      "동등하게",
      "취급합니다"
    ]
  },
  {
    "id": "OS-046",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?",
    "answer": "다릅니다. 각각 다른 스케줄러에 의해 관리됩니다.\n\n커널 스레드 스케줄링:\nOS 커널의 스케줄러가 담당\nCFS, 실시간 스케줄러 등 사용\n시스템 전체 관점에서 공정성 보장\n하드웨어 타이머 기반 선점\n\n유저 스레드 스케줄링:\n유저 공간 라이브러리/런타임이 담당\n애플리케이션별 맞춤 알고리즘 가능\n협력적(cooperative) 스케줄링이 일반적\n컨텍스트 스위칭 비용 낮음\n\n예시:\nGo goroutine: Go 런타임의 M:N 스케줄러\nJava Virtual Threads: JVM의 협력적 스케줄링\nPython greenlet: 유저 레벨 협력적 스케줄링\n\n유저 스레드의 장점은 커스터마이징과 낮은 오버헤드, 단점은 멀티코어 활용 제한(N:1 모델)입니다.",
    "references": [
      {
        "title": "Go Scheduler Design",
        "url": "https://golang.org/src/runtime/proc.go"
      }
    ],
    "keywords": [
      "cfs",
      "java",
      "virtual",
      "threads",
      "jvm",
      "python",
      "다릅니다",
      "각각",
      "다른",
      "스케줄러에",
      "의해",
      "관리됩니다",
      "커널",
      "스레드",
      "스케줄링"
    ]
  },
  {
    "id": "OS-047",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "뮤텍스와 세마포어의 차이점은 무엇인가요?",
    "answer": "구분   뮤텍스 (Mutex)   세마포어 (Semaphore)\n\n값   이진 (0 또는 1)   정수 (0 이상)\n소유권   있음 (lock한 스레드만 unlock 가능)   없음\n용도   상호 배제 (mutual exclusion)   자원 카운팅, 동기화\n해제   소유자만 가능   누구나 가능\n\n뮤텍스:\n한 번에 하나의 스레드만 임계 영역 접근\n잠금을 획득한 스레드만 해제 가능\nPriority Inheritance 지원 가능\n\n세마포어:\nN개의 스레드가 동시 접근 가능 (counting semaphore)\n생산자-소비자 문제 해결에 적합\n신호(signaling) 메커니즘으로 사용 가능",
    "references": [
      {
        "title": "POSIX Threads: pthread_mutex",
        "url": "https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_mutex_lock.html"
      }
    ],
    "keywords": [
      "mutex",
      "semaphore",
      "priority",
      "inheritance",
      "구분",
      "뮤텍스",
      "세마포어",
      "이진",
      "정수",
      "이상",
      "소유권",
      "있음",
      "스레드만",
      "가능",
      "없음"
    ]
  },
  {
    "id": "OS-048",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.",
    "answer": "둘 다 값이 0 또는 1이지만 중요한 차이가 있습니다.\n\n구분   이진 세마포어   뮤텍스\n\n소유권   없음   있음\n해제   아무나 가능   소유자만 가능\n용도   시그널링, 동기화   상호 배제\nPriority Inheritance   미지원   지원 가능\n재귀 잠금   불가   지원 가능 (recursive mutex)\n\n예시 차이점:\n\n핵심 차이: 뮤텍스는 \"소유권\" 개념이 있어 잠금을 획득한 스레드만 해제할 수 있지만, 이진 세마포어는 다른 스레드가 해제할 수 있습니다.",
    "references": [
      {
        "title": "Linux man-pages: sem_overview",
        "url": "https://man7.org/linux/man-pages/man7/sem_overview.7.html"
      }
    ],
    "keywords": [
      "priority",
      "inheritance",
      "값이",
      "이지만",
      "중요한",
      "차이가",
      "구분",
      "이진",
      "세마포어",
      "뮤텍스",
      "소유권",
      "없음",
      "있음",
      "해제",
      "아무나"
    ]
  },
  {
    "id": "OS-049",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?",
    "answer": "Spin Lock: 락 획득까지 루프를 돌며 계속 확인 (busy waiting)\n\n장점:\n컨텍스트 스위칭 오버헤드 없음\n짧은 대기 시간에 효율적\n구현이 단순함\n멀티코어에서 효과적\n\n단점:\nCPU 자원 낭비 (busy waiting)\n싱글 코어에서 비효율적 (락 소유자 실행 불가)\n대기 시간이 길면 심각한 낭비\nPriority Inversion 문제 가능\n\n해결 방법:\nAdaptive Spin Lock: 일정 횟수 스핀 후 sleep\nHybrid Lock: 짧은 스핀 후 블로킹 대기로 전환\nExponential Backoff: 스핀 간격을 점차 증가\nMCS/CLH Lock: 공정성을 보장하는 큐 기반 스핀락",
    "references": [
      {
        "title": "Linux Kernel: Spinlocks",
        "url": "https://www.kernel.org/doc/html/latest/locking/spinlocks.html"
      }
    ],
    "keywords": [
      "spin",
      "lock",
      "cpu",
      "priority",
      "inversion",
      "adaptive",
      "hybrid",
      "exponential",
      "backoff",
      "mcs",
      "clh",
      "획득까지",
      "루프를",
      "돌며",
      "계속"
    ]
  },
  {
    "id": "OS-050",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?",
    "answer": "장점:\n커널이 대기 큐 관리 -> 공정성 보장\n프로세스 간 동기화 가능\n블로킹 대기로 CPU 낭비 없음\n우선순위 상속 등 고급 기능 지원\n\n단점:\n시스템 콜 오버헤드 (모드 전환 비용)\n경쟁이 없는 경우에도 오버헤드 발생\n빈번한 락 사용 시 성능 저하\n\n해결 방법:\nFutex (Fast Userspace Mutex):\n경쟁이 없으면 유저 공간에서만 처리\n경쟁 발생 시에만 커널 호출\nLinux pthread_mutex의 실제 구현\nLock-Free 자료구조:\nCAS 등 원자적 연산 사용\n락 자체를 사용하지 않음\nUser-space Spin Lock:\n짧은 임계 영역에서 효과적\n커널 개입 없음",
    "references": [
      {
        "title": "Linux man-pages: futex(7)",
        "url": "https://man7.org/linux/man-pages/man7/futex.7.html"
      }
    ],
    "keywords": [
      "cpu",
      "futex",
      "fast",
      "userspace",
      "mutex",
      "linux",
      "pthread_mutex",
      "lock-free",
      "cas",
      "user-space",
      "spin",
      "lock",
      "장점",
      "커널이",
      "대기"
    ]
  },
  {
    "id": "OS-051",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Deadlock 에 대해 설명해 주세요.",
    "answer": "교착 상태(Deadlock)는 두 개 이상의 프로세스가 서로 상대방이 점유한 자원을 기다리며 무한히 대기하는 상태입니다.\n\n예시:\n\n특징:\n모든 프로세스가 영원히 진행 불가\n자원 낭비 (점유된 자원 사용 불가)\n외부 개입 없이 해결 불가\n\n실생활 비유:\n좁은 골목에서 두 차가 마주침. 양쪽 다 상대가 빠지기를 기다리며 이동 불가.\n\n데이터베이스에서:\n트랜잭션 A가 row1 잠금, row2 대기\n트랜잭션 B가 row2 잠금, row1 대기",
    "references": [
      {
        "title": "Linux Kernel: Lockdep",
        "url": "https://www.kernel.org/doc/html/latest/locking/lockdep-design.html"
      }
    ],
    "keywords": [
      "deadlock",
      "교착",
      "상태",
      "이상의",
      "프로세스가",
      "서로",
      "상대방이",
      "점유한",
      "자원을",
      "기다리며",
      "무한히",
      "대기하는",
      "상태입니다",
      "예시",
      "특징"
    ]
  },
  {
    "id": "OS-052",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.",
    "answer": "교착 상태는 다음 4가지 조건이 모두 충족될 때 발생합니다:\n상호 배제 (Mutual Exclusion)\n자원은 한 번에 하나의 프로세스만 사용 가능\n예: 프린터, 뮤텍스\n점유 대기 (Hold and Wait)\n자원을 점유한 상태에서 다른 자원을 기다림\n하나 이상의 자원을 가진 채로 추가 자원 요청\n비선점 (No Preemption)\n점유된 자원을 강제로 빼앗을 수 없음\n프로세스가 자발적으로 반납해야 함\n순환 대기 (Circular Wait)\n프로세스들이 순환 형태로 자원을 대기\nP1 -> P2 -> P3 -> P1 형태의 대기 사이클\n\n이 4가지 조건이 동시에 성립해야 데드락 발생. 하나라도 깨면 데드락 방지 가능.",
    "references": [
      {
        "title": "Coffman conditions - Operating System Concepts",
        "url": "https://www.os-book.com/"
      }
    ],
    "keywords": [
      "mutual",
      "exclusion",
      "hold",
      "wait",
      "preemption",
      "circular",
      "교착",
      "상태는",
      "다음",
      "가지",
      "조건이",
      "모두",
      "충족될",
      "발생합니다",
      "상호"
    ]
  },
  {
    "id": "OS-053",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?",
    "answer": "각 조건이 빠졌을 때 데드락이 발생하지 않는 이유:\n\n상호 배제가 없는 경우:\n자원을 동시에 공유 가능\n대기할 필요 없이 모두 접근 가능\n예: 읽기 전용 파일\n\n점유 대기가 없는 경우:\n모든 자원을 한 번에 요청하거나\n자원 요청 전 점유 자원 모두 반납\n순환 대기가 형성될 수 없음\n\n비선점이 없는 경우:\n필요시 다른 프로세스의 자원을 빼앗을 수 있음\n순환 대기를 강제로 깨뜨릴 수 있음\n예: 메모리 페이지 교체\n\n순환 대기가 없는 경우:\n자원에 순서 부여하고 순서대로만 요청\n선형 대기만 존재 -> 사이클 형성 불가\n예: 자원 번호 오름차순으로만 요청\n\n4가지 조건은 필요조건이므로 하나라도 없으면 데드락 불가능.",
    "references": [
      {
        "title": "OSTEP: Deadlock",
        "url": "https://pages.cs.wisc.edu/~remzi/OSTEP/threads-bugs.pdf"
      }
    ],
    "keywords": [
      "조건이",
      "빠졌을",
      "데드락이",
      "발생하지",
      "않는",
      "이유",
      "상호",
      "배제가",
      "없는",
      "자원을",
      "동시에",
      "공유",
      "가능",
      "대기할",
      "필요"
    ]
  },
  {
    "id": "OS-054",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "어떤 방식으로 예방할 수 있을까요?",
    "answer": "예방 (Prevention) - 4가지 조건 중 하나 제거:\n상호 배제 제거: 가능하면 공유 자원 사용 (실용적이지 않음)\n점유 대기 제거: 모든 자원 한 번에 요청, 또는 자원 없이 요청\n비선점 허용: 자원 선점 가능하게 설계\n순환 대기 제거: 자원에 순서 부여, 오름차순 요청만 허용\n회피 (Avoidance) - 안전 상태 유지:\nBanker's Algorithm: 자원 요청 시 안전 상태 검사\n안전하지 않으면 요청 거부\n탐지 및 복구 (Detection & Recovery):\n주기적으로 자원 할당 그래프 검사\n데드락 발견 시: 프로세스 종료 또는 자원 선점\n무시 (Ostrich Algorithm):\n데드락을 무시하고 발생 시 재시작\n현대 대부분의 OS가 채택 (빈도가 낮고 비용이 높음)",
    "references": [
      {
        "title": "Banker's Algorithm",
        "url": "https://www.geeksforgeeks.org/bankers-algorithm-in-operating-system-2/"
      }
    ],
    "keywords": [
      "prevention",
      "avoidance",
      "banker",
      "algorithm",
      "detection",
      "recovery",
      "ostrich",
      "예방",
      "가지",
      "조건",
      "하나",
      "제거",
      "상호",
      "배제",
      "가능하면"
    ]
  },
  {
    "id": "OS-055",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "왜 현대 OS는 Deadlock을 처리하지 않을까요?",
    "answer": "현대 OS(Linux, Windows 등)는 Ostrich Algorithm을 채택합니다.\n\n데드락 처리를 하지 않는 이유:\n발생 빈도가 낮음\n대부분의 애플리케이션에서 드물게 발생\n비용 대비 효과가 낮음\n처리 비용이 높음\n탐지: 주기적인 그래프 검사 오버헤드\n예방: 자원 활용률 저하, 기아 가능성\n회피: Banker's Algorithm의 높은 계산 비용\n복구가 어려움\n어떤 프로세스를 종료할지 결정 어려움\n자원 선점 시 일관성 문제\n사용자가 해결 가능\n프로세스 강제 종료\n시스템 재시작\n\n대신 사용하는 방법:\n타임아웃 기반 처리\n애플리케이션 레벨에서 데드락 방지 설계\n데이터베이스: 데드락 탐지 및 트랜잭션 롤백",
    "references": [
      {
        "title": "Operating System Concepts - Silberschatz",
        "url": "https://www.os-book.com/"
      }
    ],
    "keywords": [
      "linux",
      "windows",
      "ostrich",
      "algorithm",
      "banker",
      "현대",
      "채택합니다",
      "데드락",
      "처리를",
      "하지",
      "않는",
      "이유",
      "발생",
      "빈도가",
      "낮음"
    ]
  },
  {
    "id": "OS-056",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Wait Free와 Lock Free를 비교해 주세요.",
    "answer": "둘 다 락 없이 동시성을 보장하는 비차단(non-blocking) 알고리즘입니다.\n\n구분   Lock-Free   Wait-Free\n\n보장   시스템 전체 진행 보장   개별 스레드 진행 보장\n기아   가능   불가능\n구현   상대적으로 쉬움   매우 어려움\n성능   일반적으로 좋음   오버헤드 있을 수 있음\n\nLock-Free:\n최소 하나의 스레드는 항상 진행\n다른 스레드에 의해 지연될 수 있음\nCAS 기반 자료구조에서 흔함\n\nWait-Free:\n모든 스레드가 유한 단계 내 완료 보장\n어떤 스레드도 무한 대기 없음\n실시간 시스템에 적합",
    "references": [
      {
        "title": "The Art of Multiprocessor Programming",
        "url": "https://www.elsevier.com/books/the-art-of-multiprocessor-programming"
      }
    ],
    "keywords": [
      "non-blocking",
      "lock-free",
      "wait-free",
      "cas",
      "없이",
      "동시성을",
      "보장하는",
      "비차단",
      "알고리즘입니다",
      "구분",
      "보장",
      "시스템",
      "전체",
      "진행",
      "개별"
    ]
  },
  {
    "id": "OS-057",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.",
    "answer": "전처리 (Preprocessing)\n매크로 확장 (#define)\n헤더 파일 포함 (#include)\n조건부 컴파일 처리\n출력: .i 파일\n컴파일 (Compilation)\n소스 코드 -> 어셈블리 코드 변환\n문법 검사, 최적화\n출력: .s 파일\n어셈블 (Assembly)\n어셈블리 코드 -> 기계어(오브젝트 코드) 변환\n출력: .o 파일\n링킹 (Linking)\n여러 오브젝트 파일과 라이브러리 결합\n심볼 해결, 주소 결정\n출력: 실행 파일\n로딩 (Loading)\n실행 파일을 메모리에 적재\n주소 재배치 (동적 링킹 시)\n프로세스 생성 및 실행 시작",
    "references": [
      {
        "title": "GCC Compilation Process",
        "url": "https://gcc.gnu.org/onlinedocs/gcc/Overall-Options.html"
      }
    ],
    "keywords": [
      "preprocessing",
      "compilation",
      "assembly",
      "linking",
      "loading",
      "전처리",
      "매크로",
      "확장",
      "헤더",
      "파일",
      "포함",
      "조건부",
      "컴파일",
      "처리",
      "출력"
    ]
  },
  {
    "id": "OS-058",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "링커와, 로더의 차이에 대해 설명해 주세요.",
    "answer": "구분   링커 (Linker)   로더 (Loader)\n\n시점   컴파일 타임   런타임\n입력   오브젝트 파일들 (.o)   실행 파일\n출력   실행 파일   메모리에 적재된 프로세스\n역할   심볼 해결, 파일 결합   메모리 적재, 주소 바인딩\n\n링커의 역할:\n여러 오브젝트 파일을 하나로 결합\n외부 심볼 참조 해결 (함수, 변수)\n라이브러리 연결 (정적/동적)\n재배치 정보 생성\n\n로더의 역할:\n실행 파일을 메모리에 적재\n메모리 주소 할당\n동적 라이브러리 로드 (동적 링킹 시)\n재배치 수행\n프로세스 초기화 및 시작점으로 점프\n\n동적 링커/로더 (ld-linux.so):\n런타임에 공유 라이브러리 로드\n링커와 로더의 역할을 동시에 수행",
    "references": [
      {
        "title": "Linux man-pages: ld-linux(8)",
        "url": "https://man7.org/linux/man-pages/man8/ld-linux.8.html"
      }
    ],
    "keywords": [
      "linker",
      "loader",
      "ld-linux",
      "구분",
      "링커",
      "로더",
      "시점",
      "컴파일",
      "타임",
      "런타임",
      "입력",
      "오브젝트",
      "파일들",
      "실행",
      "파일"
    ]
  },
  {
    "id": "OS-059",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.",
    "answer": "구분   컴파일 언어   인터프리터 언어\n\n변환 시점   실행 전 전체 변환   실행 중 한 줄씩 변환\n실행 속도   빠름   느림\n개발 속도   느림 (컴파일 필요)   빠름 (즉시 실행)\n오류 발견   컴파일 타임   런타임\n이식성   낮음 (플랫폼별 컴파일)   높음\n예시   C, C++, Rust, Go   Python, JavaScript, Ruby\n\n컴파일 언어:\n소스 코드 -> 기계어로 완전 변환\n실행 파일 생성\n최적화 적용 용이\n\n인터프리터 언어:\n실행 시 한 줄씩 해석\n별도 실행 파일 없음\n동적 타이핑, 리플렉션 용이\n\n하이브리드 방식:\nJava: 바이트코드 컴파일 + JVM 인터프리터/JIT\nPython: 바이트코드 컴파일 + PVM 인터프리터",
    "references": [
      {
        "title": "LLVM Documentation",
        "url": "https://llvm.org/docs/"
      }
    ],
    "keywords": [
      "rust",
      "python",
      "javascript",
      "ruby",
      "java",
      "jvm",
      "jit",
      "pvm",
      "구분",
      "컴파일",
      "언어",
      "인터프리터",
      "변환",
      "시점",
      "실행"
    ]
  },
  {
    "id": "OS-060",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "JIT에 대해 설명해 주세요.",
    "answer": "JIT (Just-In-Time) 컴파일은 프로그램 실행 중에 바이트코드를 기계어로 컴파일하는 기술입니다.\n\n동작 방식:\n소스 코드 -> 바이트코드 (사전 컴파일)\n실행 시작: 인터프리터로 바이트코드 실행\n핫스팟 탐지: 자주 실행되는 코드 식별\nJIT 컴파일: 핫스팟을 기계어로 컴파일\n이후 해당 코드는 컴파일된 버전 실행\n\n장점:\n인터프리터보다 빠른 실행 속도\n런타임 정보 기반 최적화 가능\n플랫폼 독립성 유지\n\n단점:\n초기 실행 시 워밍업 시간 필요\n메모리 사용량 증가\n컴파일 오버헤드\n\n사용 예시:\nJava HotSpot VM\nJavaScript V8 엔진\n.NET CLR\nPyPy",
    "references": [
      {
        "title": "JVM JIT Compiler",
        "url": "https://docs.oracle.com/en/java/javase/17/vm/java-hotspot-virtual-machine-performance-enhancements.html"
      }
    ],
    "keywords": [
      "jit",
      "just-in-time",
      "java",
      "hotspot",
      "javascript",
      "net",
      "clr",
      "pypy",
      "컴파일은",
      "프로그램",
      "실행",
      "중에",
      "바이트코드를",
      "기계어로",
      "컴파일하는"
    ]
  },
  {
    "id": "OS-061",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.",
    "answer": "[Java의 경우]\njavac: .java -> .class (바이트코드)\nJVM 로딩: 클래스 로더가 바이트코드 로드\n바이트코드 검증\n인터프리터 실행 + JIT 컴파일 (HotSpot)\nGC가 메모리 관리\n\n[Python의 경우]\n.py -> .pyc (바이트코드, 자동 캐싱)\nPVM(Python Virtual Machine)이 바이트코드 인터프리팅\nGIL(Global Interpreter Lock) 하에서 실행\n\n[C/C++의 경우]\n전처리 -> 컴파일 -> 어셈블 -> 링킹\n네이티브 실행 파일 생성\n로더가 메모리에 적재 후 실행\n\n[JavaScript의 경우]\n파싱: AST 생성\nV8: 바이트코드 생성 (Ignition)\n핫 코드 JIT 컴파일 (TurboFan)\n\n면접 시 본인이 주로 사용하는 언어에 맞게 설명하세요.",
    "references": [
      {
        "title": "JVM Specification",
        "url": "https://docs.oracle.com/javase/specs/jvms/se17/html/"
      }
    ],
    "keywords": [
      "java",
      "jvm",
      "jit",
      "hotspot",
      "python",
      "pvm",
      "virtual",
      "machine",
      "gil",
      "global",
      "interpreter",
      "lock",
      "javascript",
      "ast",
      "ignition"
    ]
  },
  {
    "id": "OS-062",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?",
    "answer": "구현체   구현 언어   실행 환경   특징\n\nCPython   C   자체 PVM   기본 구현체, GIL 존재\nJython   Java   JVM   Java 라이브러리 사용 가능\nPyPy   Python   자체   JIT 컴파일, 빠른 속도\nIronPython   C#   .NET CLR   .NET 통합\n\nCPython:\n.py -> 바이트코드(.pyc) -> PVM 인터프리팅\nC 확장 모듈 지원\nGIL로 인한 멀티스레딩 제한\n\nJython:\n.py -> JVM 바이트코드(.class)\nJVM에서 실행\nJava 클래스 직접 사용 가능\nGIL 없음\n\nPyPy:\n.py -> 바이트코드 -> JIT 컴파일\nRPython으로 작성된 인터프리터\nCPython보다 평균 4~5배 빠름\nC 확장 호환성 제한",
    "references": [
      {
        "title": "PyPy Documentation",
        "url": "https://doc.pypy.org/"
      }
    ],
    "keywords": [
      "cpython",
      "pvm",
      "gil",
      "jython",
      "java",
      "jvm",
      "pypy",
      "python",
      "jit",
      "ironpython",
      "net",
      "clr",
      "rpython",
      "구현체",
      "구현"
    ]
  },
  {
    "id": "OS-063",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?",
    "answer": "로더와 시스템 콜의 관계:\n\nexec() 시스템 콜이 로더 역할을 수행합니다.\n\nexec() 호출 시 커널 내부에서:\n실행 파일 포맷 확인 (ELF)\n현재 프로세스의 주소 공간 해제\n새 프로그램의 코드, 데이터 로드\n스택, 힙 초기화\n동적 링커(ld-linux.so) 로드 (필요시)\n프로그램 진입점(entry point)으로 점프\n\nfork()와 exec()의 역할:\nfork(): 프로세스 복제 (메모리 공간 복사)\nexec(): 새 프로그램 로드 (로더 역할)\n\n로더의 구현 위치:\n\n쉘에서 프로그램 실행 시: fork() -> exec() 조합 사용.",
    "references": [
      {
        "title": "Linux man-pages: execve(2)",
        "url": "https://man7.org/linux/man-pages/man2/execve.2.html"
      }
    ],
    "keywords": [
      "elf",
      "ld-linux",
      "로더와",
      "시스템",
      "콜의",
      "관계",
      "콜이",
      "로더",
      "역할을",
      "수행합니다",
      "호출",
      "커널",
      "내부에서",
      "실행",
      "파일"
    ]
  },
  {
    "id": "OS-064",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.",
    "answer": "IPC (Inter-Process Communication)는 프로세스 간 데이터를 주고받는 메커니즘입니다.\n\n방식   특징   사용 사례\n\nPipe   단방향, 부모-자식 간   쉘 파이프 (\\ )\nNamed Pipe (FIFO)   단방향, 무관계 프로세스   파일 시스템 기반\nMessage Queue   비동기, 메시지 단위   작업 큐\nShared Memory   가장 빠름, 동기화 필요   대용량 데이터 공유\nSemaphore   동기화 도구   자원 접근 제어\nSocket   네트워크 통신 가능   클라이언트-서버\nSignal   비동기 알림   이벤트 통지\nMemory-mapped File   파일 기반 공유 메모리   대용량 파일 처리\n\n선택 기준:\n데이터 크기: 작음(파이프) vs 큼(공유 메모리)\n프로세스 관계: 부모-자식(파이프) vs 무관계(소켓)\n동기/비동기: 동기(파이프) vs 비동기(메시지 큐)",
    "references": [
      {
        "title": "Linux man-pages: ipc(7)",
        "url": "https://man7.org/linux/man-pages/man7/sysvipc.7.html"
      }
    ],
    "keywords": [
      "ipc",
      "inter-process",
      "communication",
      "pipe",
      "named",
      "fifo",
      "message",
      "queue",
      "shared",
      "memory",
      "semaphore",
      "socket",
      "signal",
      "memory-mapped",
      "file"
    ]
  },
  {
    "id": "OS-065",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.",
    "answer": "Shared Memory는 여러 프로세스가 동일한 물리 메모리 영역을 공유하는 IPC 방식입니다.\n\n특징:\n가장 빠른 IPC (커널 개입 최소화)\n데이터 복사 없이 직접 접근\n대용량 데이터 공유에 적합\n\n사용 방법 (POSIX):\n\n유의사항:\n동기화 필수\n여러 프로세스의 동시 접근 -> Race Condition\n세마포어, 뮤텍스로 보호 필요\n메모리 정리\n사용 후 명시적으로 해제 (shm_unlink)\n그렇지 않으면 시스템 재시작까지 유지\n크기 제한\n/proc/sys/kernel/shmmax로 확인\n포인터 주의\n각 프로세스의 가상 주소가 다를 수 있음",
    "references": [
      {
        "title": "Linux man-pages: shm_open(3)",
        "url": "https://man7.org/linux/man-pages/man3/shm_open.3.html"
      }
    ],
    "keywords": [
      "shared",
      "memory",
      "ipc",
      "posix",
      "race",
      "condition",
      "shm_unlink",
      "여러",
      "프로세스가",
      "동일한",
      "물리",
      "메모리",
      "영역을",
      "공유하는",
      "방식입니다"
    ]
  },
  {
    "id": "OS-066",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "메시지 큐는 단방향이라고 할 수 있나요?",
    "answer": "아니요, 메시지 큐는 양방향 통신이 가능합니다.\n\n메시지 큐의 특성:\n하나의 큐로 여러 프로세스가 송수신 가능\n메시지 타입(mtype)으로 선택적 수신 가능\n파이프와 달리 방향 제한 없음\n\n양방향 통신 방법:\n단일 큐 사용:\n메시지 타입으로 구분\n프로세스 A: type 1 송신, type 2 수신\n프로세스 B: type 2 송신, type 1 수신\n두 개의 큐 사용:\n큐 1: A -> B\n큐 2: B -> A\n더 명확한 구조\n\n파이프와의 비교:\n구분   Pipe   Message Queue\n\n방향   단방향   양방향 가능\n데이터   바이트 스트림   메시지 단위\n선택 수신   불가   타입별 가능\n수명   프로세스 종료 시   명시적 삭제까지",
    "references": [
      {
        "title": "Linux man-pages: mq_overview(7)",
        "url": "https://man7.org/linux/man-pages/man7/mq_overview.7.html"
      }
    ],
    "keywords": [
      "pipe",
      "message",
      "queue",
      "아니요",
      "메시지",
      "큐는",
      "양방향",
      "통신이",
      "가능합니다",
      "큐의",
      "특성",
      "하나의",
      "큐로",
      "여러",
      "프로세스가"
    ]
  },
  {
    "id": "OS-067",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Thread Safe 하다는 것은 어떤 의미인가요?",
    "answer": "Thread Safe란 여러 스레드가 동시에 접근해도 프로그램이 올바르게 동작하는 것을 의미합니다.\n\nThread Safe 조건:\n공유 데이터 접근 시 올바른 결과 보장\nRace Condition 없음\n데이터 일관성 유지\n데드락 없음\n\nThread Safe가 아닌 예시:\n\nThread Safe 구현 방법:\n상호 배제: 뮤텍스, 세마포어\n원자적 연산: atomic 변수\n불변 객체: 상태 변경 불가\nThread Local Storage: 스레드별 데이터\nLock-Free 자료구조: CAS 기반\n\nThread Safe한 코드는 멀티스레드 환경에서 안전하게 호출할 수 있습니다.",
    "references": [
      {
        "title": "POSIX Thread Safety",
        "url": "https://pubs.opengroup.org/onlinepubs/9699919799/functions/V2_chap02.html"
      }
    ],
    "keywords": [
      "thread",
      "safe",
      "race",
      "condition",
      "local",
      "storage",
      "lock-free",
      "cas",
      "여러",
      "스레드가",
      "동시에",
      "접근해도",
      "프로그램이",
      "올바르게",
      "동작하는"
    ]
  },
  {
    "id": "OS-068",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?",
    "answer": "상호 배제 (Mutual Exclusion)\n원자적 연산 (Atomic Operations)\nThread Local Storage (TLS)\n불변 객체 (Immutable Objects)\n생성 후 상태 변경 불가\n공유해도 안전\n읽기-쓰기 락 (Read-Write Lock)\n조건 변수 (Condition Variable)\n특정 조건까지 대기/통지\nLock-Free 자료구조\nCAS 기반 구현\n락 없이 동시성 보장\n\n선택 기준: 성능 vs 구현 복잡도 트레이드오프",
    "references": [
      {
        "title": "C11 Atomic Operations",
        "url": "https://en.cppreference.com/w/c/atomic"
      }
    ],
    "keywords": [
      "mutual",
      "exclusion",
      "atomic",
      "operations",
      "thread",
      "local",
      "storage",
      "tls",
      "immutable",
      "objects",
      "read-write",
      "lock",
      "condition",
      "variable",
      "lock-free"
    ]
  },
  {
    "id": "OS-069",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.",
    "answer": "Peterson's Algorithm은 두 프로세스 간 상호 배제를 소프트웨어적으로 구현한 알고리즘입니다.\n\n특징:\n상호 배제, 진행, 한정 대기 모두 만족\n하드웨어 지원 없이 구현\n\n한계점:\n두 프로세스만 가능\nN개로 확장하려면 복잡해짐 (Bakery Algorithm)\nBusy Waiting\nwhile 루프로 CPU 낭비\n현대 CPU에서 동작 안 함\n컴파일러/CPU의 명령어 재배치 (out-of-order)\n메모리 가시성 문제\nMemory Barrier 필요\n캐시 일관성 문제\n멀티코어에서 캐시 동기화 필요",
    "references": [
      {
        "title": "Peterson's Algorithm - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Peterson%27s_algorithm"
      }
    ],
    "keywords": [
      "peterson",
      "algorithm",
      "bakery",
      "busy",
      "waiting",
      "cpu",
      "out-of",
      "memory",
      "barrier",
      "프로세스",
      "상호",
      "배제를",
      "소프트웨어적으로",
      "구현한",
      "알고리즘입니다"
    ]
  },
  {
    "id": "OS-070",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Race Condition 이 무엇인가요?",
    "answer": "Race Condition은 여러 스레드/프로세스가 공유 자원에 동시 접근할 때, 실행 순서에 따라 결과가 달라지는 상황입니다.\n\n예시:\n\n발생 조건:\n공유 자원 존재\n동시 접근 가능\n최소 하나의 쓰기 연산\n동기화 부재\n\n유형:\nRead-Modify-Write: 위 예시\nCheck-Then-Act: if 체크 후 동작 사이 변경\nTOCTOU: Time of Check to Time of Use\n\n해결: 원자적 연산, 락, 동기화 메커니즘",
    "references": [
      {
        "title": "CWE-362: Race Condition",
        "url": "https://cwe.mitre.org/data/definitions/362.html"
      }
    ],
    "keywords": [
      "race",
      "condition",
      "read-modify-write",
      "check-then-act",
      "toctou",
      "time",
      "check",
      "use",
      "여러",
      "스레드",
      "프로세스가",
      "공유",
      "자원에",
      "동시",
      "접근할"
    ]
  },
  {
    "id": "OS-071",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?",
    "answer": "아니요, 락 없이도 Thread Safe를 구현할 수 있습니다.\n\n락 없는 방법들:\n원자적 연산 (Atomic Operations)\nLock-Free 자료구조\n불변 객체 (Immutable)\n생성 후 상태 변경 불가\n읽기만 하므로 동기화 불필요\nThread Local Storage\n메시지 패싱\n공유 상태 대신 메시지로 통신\nActor 모델, CSP\nCopy-on-Write\n쓰기 시에만 복사본 생성\n읽기는 동시 접근 허용\n\n선택 기준: 복잡도, 성능, 확장성 고려",
    "references": [
      {
        "title": "Lock-Free Programming",
        "url": "https://www.1024cores.net/home/lock-free-algorithms"
      }
    ],
    "keywords": [
      "thread",
      "safe",
      "atomic",
      "operations",
      "lock-free",
      "immutable",
      "local",
      "storage",
      "actor",
      "csp",
      "copy-on-write",
      "아니요",
      "없이도",
      "구현할",
      "없는"
    ]
  },
  {
    "id": "OS-072",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.",
    "answer": "Thread Pool:\n미리 생성된 스레드 집합\n작업 큐에서 작업을 가져와 처리\n스레드 생성/소멸 오버헤드 감소\n동시 스레드 수 제한 가능\n\nMonitor:\n상호 배제와 조건 동기화를 결합한 고수준 동기화 도구\n하나의 스레드만 모니터 내부 코드 실행\nwait(), notify(), notifyAll() 제공\nJava의 synchronized 블록이 모니터 구현\n\nFork-Join:\n분할 정복 병렬 처리 프레임워크\nFork: 작업을 작은 단위로 분할\nJoin: 결과를 합침\nWork-Stealing으로 부하 분산",
    "references": [
      {
        "title": "Java Concurrency Utilities",
        "url": "https://docs.oracle.com/javase/tutorial/essential/concurrency/"
      }
    ],
    "keywords": [
      "thread",
      "pool",
      "monitor",
      "java",
      "fork-join",
      "fork",
      "join",
      "work-stealing",
      "미리",
      "생성된",
      "스레드",
      "집합",
      "작업",
      "큐에서",
      "작업을"
    ]
  },
  {
    "id": "OS-073",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Thread Pool을 사용한다고 가정하면, 어떤 기준으로 스레드의 수를 결정할 것인가요?",
    "answer": "작업 유형에 따른 스레드 수 결정:\n\nCPU Bound 작업:\nCPU를 최대한 활용\n너무 많으면 컨텍스트 스위칭 오버헤드\n\nI/O Bound 작업:\nI/O 대기 중 다른 스레드 실행\n대기 시간이 길수록 더 많은 스레드\n\n혼합 작업:\n\n실무 가이드라인:\n시작: 코어 수의 2배로 시작\n측정: 실제 부하 테스트로 튜닝\n모니터링: CPU 사용률, 큐 대기 시간 확인\n동적 조정: 자동 스케일링 고려\n\n주의사항:\n메모리: 스레드당 스택 메모리 (기본 1MB)\n연결 풀: DB 연결 수 제한 고려",
    "references": [
      {
        "title": "Java Concurrency in Practice",
        "url": "https://jcip.net/"
      }
    ],
    "keywords": [
      "cpu",
      "bound",
      "작업",
      "유형에",
      "따른",
      "스레드",
      "결정",
      "최대한",
      "활용",
      "너무",
      "많으면",
      "컨텍스트",
      "스위칭",
      "오버헤드",
      "대기"
    ]
  },
  {
    "id": "OS-074",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "어떤 데이터를 정렬 하려고 합니다. 어떤 방식의 전략을 사용하는 것이 가장 안전하면서도 좋은 성능을 낼 수 있을까요?",
    "answer": "Fork-Join 패턴을 활용한 병렬 정렬이 안전하고 효율적입니다.\n\n권장 전략: 병렬 Merge Sort\n\n안전한 이유:\n공유 상태 최소화: 분할된 영역만 처리\n경쟁 조건 없음: 각 스레드가 독립적인 영역 담당\n락 불필요: 데이터 분할로 동기화 필요 없음\n\n성능 최적화:\n적절한 THRESHOLD 설정 (1000~10000)\nWork-Stealing으로 부하 균형\n캐시 지역성 고려\n\n대안:\nJava: Arrays.parallelSort()\nC++: std::sort with parallel execution policy",
    "references": [
      {
        "title": "Java ForkJoinPool",
        "url": "https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html"
      }
    ],
    "keywords": [
      "fork-join",
      "merge",
      "sort",
      "threshold",
      "work-stealing",
      "java",
      "arrays",
      "패턴을",
      "활용한",
      "병렬",
      "정렬이",
      "안전하고",
      "효율적입니다",
      "권장",
      "전략"
    ]
  },
  {
    "id": "OS-075",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.",
    "answer": "메모리 계층 구조 (위로 갈수록 빠르고 비쌈):\n\n계층   용량   속도   예시\n\n레지스터   ~KB   ~1ns   CPU 내부\nL1 캐시   32-64KB   ~1-2ns   코어당\nL2 캐시   256KB-1MB   ~3-10ns   코어당\nL3 캐시   8-32MB   ~10-20ns   공유\n메인 메모리   GB   ~50-100ns   DRAM\nSSD   TB   ~100us   플래시\nHDD   TB   ~10ms   자기 디스크\n\n캐시 메모리:\nCPU와 메인 메모리 사이의 고속 버퍼\n자주 사용하는 데이터를 임시 저장\n메모리 접근 지연 시간 단축\n\n작동 원리:\n지역성(Locality) 원리 활용\n캐시 히트: 데이터가 캐시에 있음 (빠름)\n캐시 미스: 메인 메모리에서 가져옴 (느림)",
    "references": [
      {
        "title": "Intel Optimization Manual",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "cpu",
      "dram",
      "ssd",
      "hdd",
      "locality",
      "메모리",
      "계층",
      "구조",
      "위로",
      "갈수록",
      "빠르고",
      "비쌈",
      "용량",
      "속도",
      "예시"
    ]
  },
  {
    "id": "OS-076",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "캐시 메모리는 어디에 위치해 있나요?",
    "answer": "캐시 메모리는 CPU 칩 내부에 위치합니다.\n\n물리적 위치:\n\n캐시별 위치:\nL1 캐시: 각 코어 내부, 가장 가까움\nL1I (명령어 캐시)\nL1D (데이터 캐시)\nL2 캐시: 각 코어에 전용 (또는 두 코어 공유)\nL3 캐시: 모든 코어가 공유 (Last Level Cache)\n\nSRAM(Static RAM)으로 구현되어 DRAM보다 빠르지만 비쌈.",
    "references": [
      {
        "title": "CPU Cache Architecture",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "cpu",
      "l1i",
      "l1d",
      "last",
      "level",
      "cache",
      "sram",
      "static",
      "ram",
      "dram",
      "캐시",
      "메모리는",
      "내부에",
      "위치합니다",
      "물리적"
    ]
  },
  {
    "id": "OS-077",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "L1, L2 캐시에 대해 설명해 주세요.",
    "answer": "L1 캐시 (Level 1):\n위치: 각 CPU 코어 내부\n크기: 32-64KB (명령어/데이터 각각)\n속도: 1-2 사이클 (가장 빠름)\n구조:\nL1I (Instruction): 명령어 캐시\nL1D (Data): 데이터 캐시\n특징: Split cache (분리 캐시)\n\nL2 캐시 (Level 2):\n위치: 각 코어에 전용 (현대 CPU)\n크기: 256KB - 1MB\n속도: 3-10 사이클\n구조: Unified (명령어+데이터 통합)\n특징: L1 미스 시 참조\n\nL1 vs L2 비교:\n\n항목   L1   L2\n\n용량   작음   큼\n속도   빠름   느림\n히트율   ~95%   ~80%\n연관도   낮음 (8-way)   높음 (16-way)\n\nL1 미스 -> L2 확인 -> L2 미스 -> L3 확인 -> 메인 메모리",
    "references": [
      {
        "title": "Intel Architecture Optimization",
        "url": "https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html"
      }
    ],
    "keywords": [
      "level",
      "cpu",
      "l1i",
      "instruction",
      "l1d",
      "data",
      "split",
      "unified",
      "캐시",
      "위치",
      "코어",
      "내부",
      "크기",
      "명령어",
      "데이터"
    ]
  },
  {
    "id": "OS-078",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "캐시에 올라오는 데이터는 어떻게 관리되나요?",
    "answer": "캐시 라인 단위로 관리됩니다 (보통 64바이트).\n\n캐시 라인 구조:\n\n캐시 관리 요소:\n태그 (Tag): 메모리 주소 식별\n유효 비트 (Valid bit): 데이터 유효 여부\n더티 비트 (Dirty bit): 수정 여부 (Write-Back용)\nLRU 비트: 교체 정책용\n\n쓰기 정책:\n\n정책   설명\n\nWrite-Through   캐시와 메모리에 동시 기록, 일관성 좋음\nWrite-Back   캐시에만 기록, 교체 시 메모리 기록, 성능 좋음\n\n교체 정책:\nLRU: 가장 오래 사용 안 한 라인 교체\nFIFO: 가장 오래된 라인 교체\nRandom: 무작위 선택\n\n할당 정책:\nWrite-Allocate: 쓰기 미스 시 캐시에 할당\nNo-Write-Allocate: 메모리에만 기록",
    "references": [
      {
        "title": "Computer Architecture: Cache Design",
        "url": "https://csapp.cs.cmu.edu/"
      }
    ],
    "keywords": [
      "tag",
      "valid",
      "dirty",
      "write-back",
      "lru",
      "write-through",
      "fifo",
      "random",
      "write-allocate",
      "no-write-allocate",
      "캐시",
      "라인",
      "단위로",
      "관리됩니다",
      "보통"
    ]
  },
  {
    "id": "OS-079",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "캐시간의 동기화는 어떻게 이루어지나요?",
    "answer": "캐시 일관성 프로토콜을 통해 동기화됩니다.\n\nMESI 프로토콜 (가장 널리 사용):\n\n상태   설명\n\nM (Modified)   수정됨, 이 캐시만 최신, 메모리와 불일치\nE (Exclusive)   독점, 이 캐시만 가지고 있음, 메모리와 일치\nS (Shared)   공유, 다른 캐시에도 있음, 읽기만 가능\nI (Invalid)   무효, 사용 불가\n\n동작 방식:\n코어 A가 데이터 수정 (M 상태)\n코어 B가 같은 데이터 읽기 시도\n스누핑: B의 요청을 A가 감지\nA가 데이터를 B에게 전달, 둘 다 S 상태로 전환\n필요시 메모리 업데이트\n\n캐시 일관성 유지 방법:\n스누핑 (Snooping): 버스 모니터링 (작은 시스템)\n디렉토리 기반: 중앙 디렉토리 관리 (대규모 시스템)",
    "references": [
      {
        "title": "Intel Cache Coherency",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "mesi",
      "modified",
      "exclusive",
      "shared",
      "invalid",
      "snooping",
      "캐시",
      "일관성",
      "프로토콜을",
      "동기화됩니다",
      "프로토콜",
      "가장",
      "널리",
      "사용",
      "상태"
    ]
  },
  {
    "id": "OS-080",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "캐시 메모리의 Mapping 방식에 대해 설명해 주세요.",
    "answer": "직접 매핑 (Direct Mapping)\n각 메모리 블록은 정해진 캐시 위치에만 저장\n구현 단순, 충돌 미스 많음\n완전 연관 매핑 (Fully Associative)\n메모리 블록이 캐시의 어느 위치에나 저장 가능\n충돌 미스 최소, 검색 비용 높음 (모든 라인 비교)\n하드웨어 비용 높음\n집합 연관 매핑 (Set Associative)\nN-way set associative: 각 집합에 N개 라인\n직접 매핑과 완전 연관의 절충\n현대 CPU에서 주로 사용 (8-way, 16-way)\n\n방식   장점   단점\n\n직접   단순, 빠름   충돌 많음\n완전 연관   충돌 적음   비용 높음\n집합 연관   균형   적절한 복잡도",
    "references": [
      {
        "title": "Cache Organization",
        "url": "https://csapp.cs.cmu.edu/"
      }
    ],
    "keywords": [
      "direct",
      "mapping",
      "fully",
      "associative",
      "set",
      "n-way",
      "cpu",
      "직접",
      "매핑",
      "메모리",
      "블록은",
      "정해진",
      "캐시",
      "위치에만",
      "저장"
    ]
  },
  {
    "id": "OS-081",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "캐시의 지역성에 대해 설명해 주세요.",
    "answer": "지역성 (Locality)은 프로그램이 메모리에 접근하는 패턴의 특성입니다.\n시간적 지역성 (Temporal Locality)\n최근 접근한 데이터는 곧 다시 접근될 가능성 높음\n예: 루프 변수, 자주 호출되는 함수\n공간적 지역성 (Spatial Locality)\n접근한 주소 근처의 데이터도 곧 접근될 가능성 높음\n예: 배열 순차 접근, 구조체 멤버 접근\n\n캐시가 지역성을 활용하는 방법:\n시간적 지역성: 접근한 데이터를 캐시에 유지\n공간적 지역성: 캐시 라인 단위(64B)로 가져옴\n\n지역성이 좋은 코드 작성 원칙:\n배열은 순차적으로 접근\n자주 함께 사용하는 데이터는 가깝게 배치",
    "references": [
      {
        "title": "Locality of Reference",
        "url": "https://csapp.cs.cmu.edu/"
      }
    ],
    "keywords": [
      "locality",
      "temporal",
      "spatial",
      "지역성",
      "프로그램이",
      "메모리에",
      "접근하는",
      "패턴의",
      "특성입니다",
      "시간적",
      "최근",
      "접근한",
      "데이터는",
      "다시",
      "접근될"
    ]
  },
  {
    "id": "OS-082",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.",
    "answer": "행 우선(가로) 탐색이 훨씬 빠릅니다.\n\n메모리 레이아웃 (C/C++ 행 우선):\n\n행 우선 탐색 (좋음):\n캐시 라인(64B)에 여러 요소 포함\n높은 캐시 히트율\n공간적 지역성 최대 활용\n\n열 우선 탐색 (나쁨):\n매 접근마다 캐시 미스 가능\n캐시 라인 낭비\n성능 10~100배 차이 가능\n\n성능 차이 원인:\n행: stride-1 접근 (연속)\n열: stride-N 접근 (불연속, 캐시 라인 건너뜀)",
    "references": [
      {
        "title": "Memory Access Patterns",
        "url": "https://csapp.cs.cmu.edu/"
      }
    ],
    "keywords": [
      "우선",
      "가로",
      "탐색이",
      "훨씬",
      "빠릅니다",
      "메모리",
      "레이아웃",
      "탐색",
      "좋음",
      "캐시",
      "라인",
      "여러",
      "요소",
      "포함",
      "높은"
    ]
  },
  {
    "id": "OS-083",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "캐시의 공간 지역성은 어떻게 구현될 수 있을까요? (힌트: 캐시는 어떤 단위로 저장되고 관리될까요?)",
    "answer": "캐시 라인(Cache Line) 단위 저장으로 공간 지역성을 구현합니다.\n\n캐시 라인:\n일반적으로 64바이트 (현대 CPU)\n데이터 접근 시 해당 바이트뿐 아니라 전체 캐시 라인을 가져옴\n\n공간 지역성 구현 원리:\n\n예시:\n\n하드웨어 프리페칭:\nCPU가 접근 패턴 감지\n다음 캐시 라인을 미리 로드\n순차 접근 패턴에서 효과적",
    "references": [
      {
        "title": "Intel Prefetch",
        "url": "https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html"
      }
    ],
    "keywords": [
      "cache",
      "line",
      "cpu",
      "캐시",
      "라인",
      "단위",
      "저장으로",
      "공간",
      "지역성을",
      "구현합니다",
      "일반적으로",
      "바이트",
      "현대",
      "데이터",
      "접근"
    ]
  },
  {
    "id": "OS-084",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)",
    "answer": "가용 메모리 공간(hole)에서 프로세스를 할당할 위치를 결정하는 알고리즘입니다.\n\nFirst-Fit (최초 적합):\n충분한 크기의 첫 번째 가용 공간에 할당\n장점: 탐색 시간 짧음\n단점: 앞쪽에 단편화 집중\n\nBest-Fit (최적 적합):\n요청 크기에 가장 근접한 가용 공간에 할당\n장점: 메모리 낭비 최소화\n단점: 전체 탐색 필요, 작은 조각 많이 생성\n\nWorst-Fit (최악 적합):\n가장 큰 가용 공간에 할당\n장점: 큰 남은 공간 유지\n단점: 전체 탐색 필요, 큰 프로세스 할당 어려움\n\n알고리즘   탐색 시간   메모리 활용   단편화\n\nFirst-Fit   O(n) 최선   보통   앞쪽 집중\nBest-Fit   O(n)   좋음   작은 조각\nWorst-Fit   O(n)   나쁨   큰 조각",
    "references": [
      {
        "title": "Operating System Concepts - Memory Management",
        "url": "https://www.os-book.com/"
      }
    ],
    "keywords": [
      "first-fit",
      "best-fit",
      "worst-fit",
      "가용",
      "메모리",
      "공간",
      "에서",
      "프로세스를",
      "할당할",
      "위치를",
      "결정하는",
      "알고리즘입니다",
      "최초",
      "적합",
      "충분한"
    ]
  },
  {
    "id": "OS-085",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "worst-fit 은 언제 사용할 수 있을까요?",
    "answer": "Worst-Fit이 유용한 상황:\n중간 크기 할당 요청이 많을 때\n큰 hole에서 할당 후에도 충분한 공간 남음\n남은 공간이 다음 요청 수용 가능\n작은 단편화 조각을 피하고 싶을 때\nBest-Fit은 딱 맞는 공간 찾아 작은 조각 생성\nWorst-Fit은 큰 공간 유지로 작은 조각 감소\n할당 크기가 균일할 때\n비슷한 크기의 요청이 반복되면\n큰 공간을 균등하게 분할 가능\n\n실제로는 거의 사용되지 않는 이유:\n큰 프로세스 할당 시 공간 부족\nBest-Fit이나 First-Fit보다 일반적으로 성능 낮음\n시뮬레이션에서 평균 성능 최하위\n\n실무에서:\nglibc malloc: 다양한 전략 조합\nBuddy System, Slab Allocator 등 다른 방식 사용",
    "references": [
      {
        "title": "Memory Allocation Strategies",
        "url": "https://pages.cs.wisc.edu/~remzi/OSTEP/vm-freespace.pdf"
      }
    ],
    "keywords": [
      "worst-fit",
      "best-fit",
      "first-fit",
      "buddy",
      "system",
      "slab",
      "allocator",
      "유용한",
      "상황",
      "중간",
      "크기",
      "할당",
      "요청이",
      "많을",
      "에서"
    ]
  },
  {
    "id": "OS-086",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "성능이 가장 좋은 알고리즘은 무엇일까요?",
    "answer": "일반적으로 First-Fit이 가장 좋은 성능을 보입니다.\n\n시뮬레이션 연구 결과:\nFirst-Fit과 Best-Fit은 비슷한 메모리 활용률\nFirst-Fit은 탐색 시간이 짧아 전체 성능 우수\nWorst-Fit은 대체로 가장 낮은 성능\n\nFirst-Fit의 장점:\n빠른 할당: 첫 번째 적합 공간에서 중단\n단순한 구현: 복잡한 비교 불필요\n합리적인 메모리 활용: Best-Fit과 큰 차이 없음\n\n그러나 \"최고\"는 상황에 따라 다름:\n\n상황   권장 알고리즘\n\n다양한 크기 요청   First-Fit\n메모리 절약 중요   Best-Fit\n실시간 시스템   First-Fit (예측 가능)\n\n현대 시스템:\n단순 연속 할당은 잘 사용하지 않음\n페이징으로 외부 단편화 해결\nSlab, Buddy 등 전문 할당자 사용",
    "references": [
      {
        "title": "OSTEP: Free Space Management",
        "url": "https://pages.cs.wisc.edu/~remzi/OSTEP/vm-freespace.pdf"
      }
    ],
    "keywords": [
      "first-fit",
      "best-fit",
      "worst-fit",
      "slab",
      "buddy",
      "일반적으로",
      "가장",
      "좋은",
      "성능을",
      "보입니다",
      "시뮬레이션",
      "연구",
      "결과",
      "비슷한",
      "메모리"
    ]
  },
  {
    "id": "OS-087",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Thrashing 이란 무엇인가요?",
    "answer": "Thrashing은 시스템이 실제 작업보다 페이지 스왑에 더 많은 시간을 소비하는 상태입니다.\n\n발생 과정:\n메모리 부족 -> 페이지 폴트 증가\n페이지 교체 빈번 -> I/O 대기 증가\nCPU 사용률 감소 -> OS가 더 많은 프로세스 실행\n메모리 경쟁 심화 -> 더 많은 페이지 폴트\n악순환 반복 -> 시스템 거의 멈춤\n\n증상:\n높은 페이지 폴트율\n높은 디스크 I/O\n낮은 CPU 사용률\n시스템 응답 없음\n\n원인:\n물리 메모리 부족\n너무 많은 프로세스 실행\nWorking Set이 메모리보다 큼\n잘못된 페이지 교체 알고리즘\n\n지표:\nPFF(Page Fault Frequency) 급증\n스왑 I/O 급증",
    "references": [
      {
        "title": "Linux Kernel: Memory Overcommit",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/overcommit-accounting.html"
      }
    ],
    "keywords": [
      "thrashing",
      "cpu",
      "working",
      "set",
      "pff",
      "page",
      "fault",
      "frequency",
      "시스템이",
      "실제",
      "작업보다",
      "페이지",
      "스왑에",
      "많은",
      "시간을"
    ]
  },
  {
    "id": "OS-088",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Thrashing 발생 시, 어떻게 완화할 수 있을까요?",
    "answer": "즉각적 대응:\n프로세스 수 감소\n일부 프로세스 중단 (suspend)\n스왑 아웃으로 메모리 확보\n메모리 추가\n물리 메모리 확장\n스왑 공간 확대 (임시 방편)\n\n시스템 레벨 해결책:\nWorking Set 모델\n각 프로세스의 Working Set 크기 추적\nWorking Set을 수용할 수 없으면 프로세스 중단\n지역성 원리 활용\nPFF (Page Fault Frequency) 알고리즘\n페이지 폴트 빈도 모니터링\n높으면: 프레임 추가 할당\n낮으면: 프레임 회수\n프로세스 우선순위 조정\n중요 프로세스에 메모리 우선 할당\n\nLinux 대응책:\nOOM Killer: 메모리 최다 사용 프로세스 종료\nswappiness 조정: 스왑 사용 빈도 제어\ncgroups: 프로세스별 메모리 제한",
    "references": [
      {
        "title": "Linux OOM Killer",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/concepts.html"
      }
    ],
    "keywords": [
      "working",
      "set",
      "pff",
      "page",
      "fault",
      "frequency",
      "linux",
      "oom",
      "killer",
      "즉각적",
      "대응",
      "프로세스",
      "감소",
      "일부",
      "중단"
    ]
  },
  {
    "id": "OS-089",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "가상 메모리란 무엇인가요?",
    "answer": "가상 메모리는 물리 메모리보다 큰 주소 공간을 프로세스에게 제공하는 메모리 관리 기법입니다.\n\n핵심 개념:\n각 프로세스는 독립적인 가상 주소 공간 사용\n가상 주소 -> 물리 주소 변환 (MMU)\n필요한 부분만 물리 메모리에 로드 (Demand Paging)\n나머지는 디스크(스왑 영역)에 저장\n\n장점:\n메모리 추상화: 프로세스는 연속된 주소 공간 인식\n메모리 확장: 물리 메모리보다 큰 프로그램 실행\n프로세스 격리: 다른 프로세스 메모리 접근 차단\n공유 메모리: 같은 물리 페이지를 여러 프로세스가 공유\n효율적 메모리 사용: 실제 필요한 페이지만 로드\n\n구성 요소:\n페이지 테이블: 가상-물리 주소 매핑\nMMU: 하드웨어 주소 변환\n스왑 영역: 디스크 저장 공간",
    "references": [
      {
        "title": "Linux Virtual Memory",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/concepts.html"
      }
    ],
    "keywords": [
      "mmu",
      "demand",
      "paging",
      "가상",
      "메모리는",
      "물리",
      "메모리보다",
      "주소",
      "공간을",
      "프로세스에게",
      "제공하는",
      "메모리",
      "관리",
      "기법입니다",
      "핵심"
    ]
  },
  {
    "id": "OS-090",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "가상 메모리가 가능한 이유가 무엇일까요?",
    "answer": "지역성 원리(Locality of Reference) 때문입니다.\n\n지역성 원리:\n프로그램은 특정 시간에 일부 코드/데이터만 집중적으로 사용\n전체 프로그램이 동시에 필요하지 않음\nWorking Set: 특정 시점에 필요한 페이지 집합\n\n이로 인해 가능한 것:\nDemand Paging: 필요할 때만 페이지 로드\n부분 로딩: 전체 프로그램의 일부만 메모리에 적재\n스왑핑: 안 쓰는 페이지는 디스크로 이동\n\n예시:\n\n기술적 기반:\nMMU (Memory Management Unit): 주소 변환 하드웨어\n페이지 테이블: 매핑 정보 저장\n페이지 폴트 핸들러: 필요 시 페이지 로드\n\n결과적으로 물리 메모리보다 큰 프로그램 실행이 가능합니다.",
    "references": [
      {
        "title": "OSTEP: Beyond Physical Memory",
        "url": "https://pages.cs.wisc.edu/~remzi/OSTEP/vm-beyondphys.pdf"
      }
    ],
    "keywords": [
      "locality",
      "reference",
      "working",
      "set",
      "demand",
      "paging",
      "mmu",
      "memory",
      "management",
      "unit",
      "지역성",
      "원리",
      "때문입니다",
      "프로그램은",
      "특정"
    ]
  },
  {
    "id": "OS-091",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.",
    "answer": "Page Fault 처리 과정:\n페이지 폴트 발생\nCPU가 가상 주소 접근 시도\nMMU가 페이지 테이블 확인\nValid bit = 0 (메모리에 없음) -> 트랩 발생\n커널 모드 전환\n페이지 폴트 핸들러 실행\n프로세스 상태 저장\n주소 유효성 검사\n유효한 가상 주소인가?\n접근 권한이 있는가?\n불법 접근이면 -> Segmentation Fault\n빈 프레임 확보\nFree frame list에서 할당\n없으면 페이지 교체 알고리즘 실행\n페이지 로드\n디스크(스왑)에서 해당 페이지 읽기\n빈 프레임에 적재 (I/O 작업)\n페이지 테이블 업데이트\nValid bit = 1로 설정\n프레임 번호 기록\n프로세스 재개\n폴트 발생 명령어부터 다시 실행",
    "references": [
      {
        "title": "Linux Page Fault Handler",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/"
      }
    ],
    "keywords": [
      "page",
      "fault",
      "cpu",
      "mmu",
      "valid",
      "segmentation",
      "free",
      "처리",
      "과정",
      "페이지",
      "폴트",
      "발생",
      "가상",
      "주소",
      "접근"
    ]
  },
  {
    "id": "OS-092",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "페이지 크기에 대한 Trade-Off를 설명해 주세요.",
    "answer": "작은 페이지 크기:\n장점   단점\n\n내부 단편화 감소   페이지 테이블 크기 증가\n메모리 세밀한 관리   페이지 폴트 빈번\nWorking Set 정확히 반영   TLB 미스 증가\n\n큰 페이지 크기:\n장점   단점\n\n페이지 테이블 크기 감소   내부 단편화 증가\nTLB 히트율 향상   메모리 낭비\nI/O 효율 증가   공유 어려움\n페이지 폴트 감소\n\n일반적인 페이지 크기:\nx86: 4KB (기본), 2MB/1GB (Huge Pages)\nARM: 4KB, 16KB, 64KB\n\nHuge Pages 사용 사례:\n대용량 데이터베이스\n가상화 환경\n메모리 집약적 애플리케이션",
    "references": [
      {
        "title": "Linux Huge Pages",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/hugetlbpage.html"
      }
    ],
    "keywords": [
      "working",
      "set",
      "tlb",
      "huge",
      "pages",
      "arm",
      "작은",
      "페이지",
      "크기",
      "장점",
      "단점",
      "내부",
      "단편화",
      "감소",
      "테이블"
    ]
  },
  {
    "id": "OS-093",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?",
    "answer": "아니요, 일반적으로 페이지 크기가 커지면 페이지 폴트가 감소합니다.\n\n페이지 폴트 감소 이유:\n한 번의 폴트로 더 많은 데이터 로드\n공간적 지역성 활용 증가\n프리페칭 효과 자연 발생\n\n예시:\n\n그러나 예외 상황:\n희소한 접근 패턴: 큰 페이지에서 일부만 사용\n메모리 압박: 큰 페이지는 교체 시 더 많은 데이터 스왑\nWorking Set 초과: 큰 페이지로 가용 프레임 수 감소\n\n결론:\n지역성이 좋은 접근: 큰 페이지 유리 (폴트 감소)\n무작위 접근: 큰 페이지가 불리할 수 있음",
    "references": [
      {
        "title": "Page Size and Performance",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/"
      }
    ],
    "keywords": [
      "working",
      "set",
      "아니요",
      "일반적으로",
      "페이지",
      "크기가",
      "커지면",
      "폴트가",
      "감소합니다",
      "폴트",
      "감소",
      "이유",
      "번의",
      "폴트로",
      "많은"
    ]
  },
  {
    "id": "OS-094",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "세그멘테이션 방식을 사용하고 있다면, 가상 메모리를 사용할 수 없을까요?",
    "answer": "사용할 수 있습니다. 세그멘테이션에서도 가상 메모리 구현이 가능합니다.\n\n세그멘테이션 기반 가상 메모리:\n세그먼트 단위로 스왑 인/아웃\n세그먼트 테이블에 present bit 추가\n메모리에 없는 세그먼트 접근 시 폴트 발생\n\n단점:\n세그먼트 크기가 가변적 -> 스왑 공간 관리 복잡\n외부 단편화 발생\n큰 세그먼트는 스왑 비용 높음\n\n페이지드 세그멘테이션 (Paged Segmentation):\n세그멘테이션 + 페이징 결합\n논리적으로 세그먼트 분리\n물리적으로 페이지 단위 관리\n외부 단편화 해결\n\n현대 시스템:\nx86-64: 세그멘테이션 거의 사용 안 함 (flat memory model)\n페이징이 표준\n보호 기능만 세그멘테이션 활용",
    "references": [
      {
        "title": "Intel Segmentation",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "paged",
      "segmentation",
      "사용할",
      "세그멘테이션에서도",
      "가상",
      "메모리",
      "구현이",
      "가능합니다",
      "세그멘테이션",
      "기반",
      "세그먼트",
      "단위로",
      "스왑",
      "아웃",
      "테이블에"
    ]
  },
  {
    "id": "OS-095",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "세그멘테이션과 페이징의 차이점은 무엇인가요?",
    "answer": "구분   세그멘테이션   페이징\n\n분할 단위   가변 크기 (논리적 단위)   고정 크기 (물리적 단위)\n사용자 관점   인식함 (코드, 데이터, 스택)   투명함\n주소 구조   세그먼트 번호 + 오프셋   페이지 번호 + 오프셋\n단편화   외부 단편화   내부 단편화\n보호   세그먼트별 권한 설정 용이   페이지별 권한 설정\n공유   논리적 단위로 공유   페이지 단위로 공유\n\n세그멘테이션:\n\n페이징:\n\n현대 시스템:\n페이징이 주류 (외부 단편화 없음)\n세그멘테이션은 보호 목적으로만 사용\nx86-64: 사실상 순수 페이징",
    "references": [
      {
        "title": "OSTEP: Segmentation",
        "url": "https://pages.cs.wisc.edu/~remzi/OSTEP/vm-segmentation.pdf"
      }
    ],
    "keywords": [
      "구분",
      "세그멘테이션",
      "페이징",
      "분할",
      "단위",
      "가변",
      "크기",
      "논리적",
      "고정",
      "물리적",
      "사용자",
      "관점",
      "인식함",
      "코드",
      "데이터"
    ]
  },
  {
    "id": "OS-096",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "페이지와 프레임의 차이에 대해 설명해 주세요.",
    "answer": "페이지 (Page):\n가상 메모리의 고정 크기 블록\n논리적 주소 공간의 단위\n프로세스 관점의 메모리 블록\n연속적인 가상 주소\n\n프레임 (Frame):\n물리 메모리의 고정 크기 블록\n물리적 주소 공간의 단위\n실제 RAM의 메모리 블록\n연속적인 물리 주소\n\n관계:\n\n특징:\n페이지와 프레임은 같은 크기 (보통 4KB)\n페이지 테이블: 페이지 -> 프레임 매핑\n연속 페이지가 연속 프레임에 매핑될 필요 없음\n이로 인해 외부 단편화 없음",
    "references": [
      {
        "title": "OSTEP: Paging",
        "url": "https://pages.cs.wisc.edu/~remzi/OSTEP/vm-paging.pdf"
      }
    ],
    "keywords": [
      "page",
      "frame",
      "ram",
      "페이지",
      "가상",
      "메모리의",
      "고정",
      "크기",
      "블록",
      "논리적",
      "주소",
      "공간의",
      "단위",
      "프로세스",
      "관점의"
    ]
  },
  {
    "id": "OS-097",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "내부 단편화와, 외부 단편화에 대해 설명해 주세요.",
    "answer": "내부 단편화 (Internal Fragmentation):\n할당된 메모리 블록 내부에 사용되지 않는 공간\n고정 크기 할당에서 발생\n예: 4KB 페이지에 3KB만 사용 -> 1KB 낭비\n\n외부 단편화 (External Fragmentation):\n메모리 외부에 흩어진 작은 빈 공간들\n가변 크기 할당에서 발생\n총 가용 공간은 충분하나 연속 공간 부족\n\n구분   발생 위치   원인   해결\n\n내부   블록 안   고정 크기 할당   작은 블록 사용\n외부   블록 사이   가변 크기 할당   페이징, 압축\n\n페이징: 외부 단편화 해결, 내부 단편화 존재\n세그멘테이션: 내부 단편화 없음, 외부 단편화 존재",
    "references": [
      {
        "title": "Memory Fragmentation",
        "url": "https://pages.cs.wisc.edu/~remzi/OSTEP/vm-freespace.pdf"
      }
    ],
    "keywords": [
      "internal",
      "fragmentation",
      "external",
      "내부",
      "단편화",
      "할당된",
      "메모리",
      "블록",
      "내부에",
      "사용되지",
      "않는",
      "공간",
      "고정",
      "크기",
      "할당에서"
    ]
  },
  {
    "id": "OS-098",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.",
    "answer": "가상 주소 -> 물리 주소 변환 과정:\n\n변환 단계:\n가상 주소 분리: 페이지 번호 + 오프셋\n페이지 테이블 참조: PTBR + 페이지 번호 * 엔트리 크기\n유효성 검사: Valid bit 확인 (0이면 Page Fault)\n프레임 번호 획득: 페이지 테이블 엔트리에서\n물리 주소 조합: 프레임 번호 + 오프셋\n\n예시 (4KB 페이지, 가상 주소 0x12345678):",
    "references": [
      {
        "title": "x86 Paging",
        "url": "https://wiki.osdev.org/Paging"
      }
    ],
    "keywords": [
      "ptbr",
      "valid",
      "page",
      "fault",
      "가상",
      "주소",
      "물리",
      "변환",
      "과정",
      "단계",
      "분리",
      "페이지",
      "번호",
      "오프셋",
      "테이블"
    ]
  },
  {
    "id": "OS-099",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?",
    "answer": "페이지 테이블 엔트리의 보호 비트로 확인합니다.\n\n페이지 테이블 엔트리 구조:\n\n확인 방법:\n프로그래밍 방식 (Linux):\n명령어:\n하드웨어 수준:\nMMU가 접근 시 권한 검사\n위반 시 Segmentation Fault 발생",
    "references": [
      {
        "title": "Linux man-pages: mprotect(2)",
        "url": "https://man7.org/linux/man-pages/man2/mprotect.2.html"
      }
    ],
    "keywords": [
      "linux",
      "mmu",
      "segmentation",
      "fault",
      "페이지",
      "테이블",
      "엔트리의",
      "보호",
      "비트로",
      "확인합니다",
      "엔트리",
      "구조",
      "확인",
      "방법",
      "프로그래밍"
    ]
  },
  {
    "id": "OS-100",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?",
    "answer": "2^22 = 4,194,304개 (약 400만 개)\n\n계산 과정:\n\n페이지 테이블 크기:\n각 엔트리: 4바이트 (32비트)\n테이블 크기: 2^22 * 4B = 16MB\n\n문제점:\n프로세스마다 16MB 페이지 테이블 필요\n대부분의 주소 공간은 사용되지 않음\n\n해결책:\n다단계 페이지 테이블: 사용하는 영역만 할당\n역 페이지 테이블: 프레임 기준 테이블\n해시 페이지 테이블: 해시로 빠른 검색\n\n실제 시스템에서는 4KB 페이지 사용 -> 2^20 엔트리 (4MB 테이블)",
    "references": [
      {
        "title": "Multi-level Page Tables",
        "url": "https://pages.cs.wisc.edu/~remzi/OSTEP/vm-smalltables.pdf"
      }
    ],
    "keywords": [
      "계산",
      "과정",
      "페이지",
      "테이블",
      "크기",
      "엔트리",
      "바이트",
      "비트",
      "문제점",
      "프로세스마다",
      "필요",
      "대부분의",
      "주소",
      "공간은",
      "사용되지"
    ]
  },
  {
    "id": "OS-101",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "32비트 운영체제는 램을 최대 4G 까지 사용할 수 있습니다. 이 이유를 페이징과 연관 지어서 설명해 주세요.",
    "answer": "32비트 주소 체계의 한계 때문입니다.\n\n이유:\n\n페이징 관점:\n페이지 테이블 엔트리의 프레임 번호: 20비트 (4KB 페이지 기준)\n오프셋: 12비트\n총 주소 가능 물리 메모리: 2^20 * 4KB = 4GB\n\n가상 주소 구조 (4KB 페이지):\n\n물리 주소 한계:\nCPU의 주소 버스: 32비트\n물리 메모리 주소 지정: 최대 4GB\n\n확장 방법:\nPAE (Physical Address Extension): 36비트 물리 주소 (64GB)\n64비트 OS: 이론상 16EB (실제는 수 TB 지원)",
    "references": [
      {
        "title": "x86 PAE",
        "url": "https://en.wikipedia.org/wiki/Physical_Address_Extension"
      }
    ],
    "keywords": [
      "cpu",
      "pae",
      "physical",
      "address",
      "extension",
      "비트",
      "주소",
      "체계의",
      "한계",
      "때문입니다",
      "이유",
      "페이징",
      "관점",
      "페이지",
      "테이블"
    ]
  },
  {
    "id": "OS-102",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "C/C++ 개발을 하게 되면 Segmentation Fault 라는 에러를 접할 수 있을텐데, 이 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요?",
    "answer": "Segmentation Fault는 메모리 보호 위반 시 발생하는 에러입니다. 이름은 세그멘테이션에서 유래했지만, 현대 시스템에서는 페이징 보호 위반에서 주로 발생합니다.\n\n발생 원인:\nNULL 포인터 역참조\n주소 0은 일반적으로 매핑되지 않음\n해제된 메모리 접근 (Use After Free)\n유효하지 않은 페이지 접근\n배열 범위 초과 (Buffer Overflow)\n할당되지 않은 영역 접근\n읽기 전용 메모리에 쓰기\n코드 영역 수정 시도\n\n페이징과의 관계:\n\n역사적 배경:\n과거 세그멘테이션 사용 시 세그먼트 경계 위반에서 유래\n현재는 페이징 기반이지만 이름은 유지",
    "references": [
      {
        "title": "Linux man-pages: signal(7)",
        "url": "https://man7.org/linux/man-pages/man7/signal.7.html"
      }
    ],
    "keywords": [
      "segmentation",
      "fault",
      "null",
      "use",
      "free",
      "buffer",
      "overflow",
      "메모리",
      "보호",
      "위반",
      "발생하는",
      "에러입니다",
      "이름은",
      "세그멘테이션에서",
      "유래했지만"
    ]
  },
  {
    "id": "OS-103",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "TLB는 무엇인가요?",
    "answer": "TLB (Translation Lookaside Buffer)는 페이지 테이블 엔트리를 캐싱하는 고속 하드웨어 캐시입니다.\n\n역할:\n가상 주소 -> 물리 주소 변환 가속\n자주 사용되는 페이지 테이블 엔트리 저장\n메모리 접근 횟수 감소\n\n구조:\n\n특징:\n완전 연관(Fully Associative) 또는 집합 연관 매핑\n크기: 64~1024 엔트리 (작지만 빠름)\n접근 시간: 1 사이클 (매우 빠름)\n히트율: 99% 이상 (지역성 활용)\n\n동작:\nTLB 먼저 검색 (병렬로)\nTLB 히트: 바로 물리 주소 획득\nTLB 미스: 페이지 테이블에서 가져와 TLB에 저장",
    "references": [
      {
        "title": "OSTEP: TLBs",
        "url": "https://pages.cs.wisc.edu/~remzi/OSTEP/vm-tlbs.pdf"
      }
    ],
    "keywords": [
      "tlb",
      "translation",
      "lookaside",
      "buffer",
      "fully",
      "associative",
      "페이지",
      "테이블",
      "엔트리를",
      "캐싱하는",
      "고속",
      "하드웨어",
      "캐시입니다",
      "역할",
      "가상"
    ]
  },
  {
    "id": "OS-104",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "TLB를 쓰면 왜 빨라지나요?",
    "answer": "메모리 접근 횟수를 줄여주기 때문입니다.\n\nTLB 없이 (2단계 페이지 테이블):\n\nTLB 사용 시 (히트):\n\n속도 비교:\n구분   시간\n\nTLB 접근   ~1ns\n메모리 접근   ~100ns\n\n효과:\nTLB 히트 시 100배 이상 빠름\n히트율 99% 이상 (지역성)\n평균 접근 시간 크게 단축\n\n유효 접근 시간 (EAT):",
    "references": [
      {
        "title": "TLB Performance",
        "url": "https://csapp.cs.cmu.edu/"
      }
    ],
    "keywords": [
      "tlb",
      "eat",
      "메모리",
      "접근",
      "횟수를",
      "줄여주기",
      "때문입니다",
      "없이",
      "단계",
      "페이지",
      "테이블",
      "사용",
      "히트",
      "속도",
      "비교"
    ]
  },
  {
    "id": "OS-105",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "MMU가 무엇인가요?",
    "answer": "MMU (Memory Management Unit)는 가상 주소를 물리 주소로 변환하는 하드웨어 장치입니다.\n\n주요 기능:\n주소 변환 (Address Translation)\n가상 주소 -> 물리 주소 매핑\n페이지 테이블 참조\n메모리 보호 (Memory Protection)\n페이지별 접근 권한 검사 (R/W/X)\n불법 접근 시 예외 발생\n캐시 제어\nTLB 관리\n캐시 가능 여부 결정\n\n동작 과정:\n\n구성 요소:\nTLB: 주소 변환 캐시\n페이지 테이블 워커: TLB 미스 시 테이블 탐색\n보호 검사 로직: 권한 검증\n\n예외 발생 상황:\n페이지 폴트: 페이지가 메모리에 없음\n보호 위반: 권한 없는 접근",
    "references": [
      {
        "title": "Intel MMU",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "mmu",
      "memory",
      "management",
      "unit",
      "address",
      "translation",
      "protection",
      "tlb",
      "가상",
      "주소를",
      "물리",
      "주소로",
      "변환하는",
      "하드웨어",
      "장치입니다"
    ]
  },
  {
    "id": "OS-106",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "TLB와 MMU는 어디에 위치해 있나요?",
    "answer": "MMU와 TLB는 CPU 칩 내부에 위치합니다.\n\n물리적 위치:\n\n구조적 특징:\nMMU:\n각 CPU 코어에 통합\nCPU 파이프라인의 일부\n메모리 접근 전 주소 변환\nTLB:\nMMU 내부에 위치\nSRAM으로 구현 (빠른 속도)\n코어별 독립적 TLB 존재\n일부 시스템에서 L2 TLB 공유\n\n계층 구조:\n\nCPU와 메모리 사이의 모든 접근은 MMU를 거칩니다.",
    "references": [
      {
        "title": "x86 CPU Architecture",
        "url": "https://en.wikichip.org/wiki/x86"
      }
    ],
    "keywords": [
      "mmu",
      "tlb",
      "cpu",
      "sram",
      "내부에",
      "위치합니다",
      "물리적",
      "위치",
      "구조적",
      "특징",
      "코어에",
      "통합",
      "파이프라인의",
      "일부",
      "메모리"
    ]
  },
  {
    "id": "OS-107",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "코어가 여러개라면, TLB는 어떻게 동기화 할 수 있을까요?",
    "answer": "TLB Shootdown 메커니즘을 사용합니다.\n\n문제 상황:\n각 코어는 독립적인 TLB 보유\n한 코어에서 페이지 테이블 변경 시 다른 코어 TLB는 오래된 정보 유지\n\nTLB Shootdown 과정:\n코어 A가 페이지 테이블 수정\n코어 A가 다른 코어들에 IPI (Inter-Processor Interrupt) 전송\n각 코어가 인터럽트 받고 해당 TLB 엔트리 무효화\n모든 코어 완료 후 코어 A 진행\n\n최적화 방법:\nPCID/ASID: 프로세스별 TLB 태깅으로 전체 플러시 방지\n지연된 Shootdown: 배치 처리로 IPI 횟수 감소\n범위 지정 무효화: 특정 범위만 무효화\n\n오버헤드:\nIPI는 비용이 높음 (수백~수천 사이클)\n코어 수가 많을수록 증가",
    "references": [
      {
        "title": "Linux TLB Shootdown",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/"
      }
    ],
    "keywords": [
      "tlb",
      "shootdown",
      "ipi",
      "inter-processor",
      "interrupt",
      "pcid",
      "asid",
      "메커니즘을",
      "사용합니다",
      "문제",
      "상황",
      "코어는",
      "독립적인",
      "보유",
      "코어에서"
    ]
  },
  {
    "id": "OS-108",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "TLB 관점에서, Context Switching 발생 시 어떤 변화가 발생하는지 설명해 주세요.",
    "answer": "프로세스 전환 시 TLB를 처리해야 합니다.\n\n문제점:\n각 프로세스는 독립적인 가상 주소 공간\nTLB에는 이전 프로세스의 매핑 정보\n새 프로세스가 같은 가상 주소 사용 시 잘못된 물리 주소 참조\n\n해결 방법:\nTLB 전체 플러시 (Flush)\n모든 TLB 엔트리 무효화\n단순하지만 비용 높음\n새 프로세스는 모두 TLB 미스 발생\nASID/PCID 사용 (Address Space ID)\n각 TLB 엔트리에 프로세스 ID 태깅\n컨텍스트 스위칭 시 ASID만 변경\nTLB 플러시 불필요\n   \n\n성능 영향:\n\n방법   장점   단점\n\n플러시   구현 단순   TLB 미스 증가, 성능 저하\nASID   캐시 유지, 빠름   하드웨어 지원 필요\n\n현대 CPU(x86 PCID, ARM ASID)는 프로세스 식별자를 지원합니다.",
    "references": [
      {
        "title": "Intel PCID",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "tlb",
      "flush",
      "asid",
      "pcid",
      "address",
      "space",
      "cpu",
      "arm",
      "프로세스",
      "전환",
      "처리해야",
      "문제점",
      "프로세스는",
      "독립적인",
      "가상"
    ]
  },
  {
    "id": "OS-109",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.",
    "answer": "원자적 명령어 (Atomic Instructions)를 사용합니다.\nTest-And-Set (TAS)\nCompare-And-Swap (CAS)\nFetch-And-Add\nLoad-Link / Store-Conditional (LL/SC)\nARM, MIPS에서 사용\nLL로 값 읽고, SC로 조건부 쓰기\n\nx86 명령어:\nLOCK prefix: 버스 락 또는 캐시 락\nXCHG, CMPXCHG, XADD",
    "references": [
      {
        "title": "Intel Atomic Operations",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "keywords": [
      "atomic",
      "instructions",
      "test-and-set",
      "tas",
      "compare-and-swap",
      "cas",
      "fetch-and-add",
      "load-link",
      "store-conditional",
      "arm",
      "mips",
      "lock",
      "xchg",
      "cmpxchg",
      "xadd"
    ]
  },
  {
    "id": "OS-110",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "volatile 키워드는 어떤 의미가 있나요?",
    "answer": "volatile은 컴파일러에게 해당 변수에 대한 최적화를 하지 말라고 지시합니다.\n\n의미:\n매번 메모리에서 값을 읽음 (레지스터 캐싱 X)\n쓰기 연산을 생략하지 않음\n접근 순서 재배치 방지 (해당 변수에 한해)\n\n사용 사례:\n\n주의: volatile은 동기화를 보장하지 않음:\n\n언어별 차이:\n\n언어   의미\n\nC/C++   컴파일러 최적화 방지만\nJava   가시성 + happens-before 보장\n\nC++11 이후: std::atomic 사용 권장",
    "references": [
      {
        "title": "C++ volatile",
        "url": "https://en.cppreference.com/w/cpp/language/cv"
      }
    ],
    "keywords": [
      "java",
      "happens-before",
      "컴파일러에게",
      "해당",
      "변수에",
      "대한",
      "최적화를",
      "하지",
      "말라고",
      "지시합니다",
      "의미",
      "매번",
      "메모리에서",
      "값을",
      "읽음"
    ]
  },
  {
    "id": "OS-111",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "싱글코어가 아니라 멀티코어라면, 어떻게 동기화가 이뤄질까요?",
    "answer": "멀티코어 환경에서는 캐시 일관성 프로토콜과 메모리 배리어가 필요합니다.\n캐시 일관성 (Cache Coherence)\nMESI 프로토콜로 캐시 간 데이터 동기화\n한 코어가 쓰기 시 다른 코어 캐시 무효화\n하드웨어가 자동으로 처리\n원자적 연산 + 버스/캐시 락\nLOCK: 캐시 라인 독점 또는 버스 락\n다른 코어의 접근 차단\n메모리 배리어 (Memory Barrier/Fence)\n명령어 재배치 방지\n메모리 가시성 보장\n하드웨어 동기화 프리미티브\nCAS, LL/SC 등 원자적 명령어\n멀티코어에서도 원자성 보장\n\n요약:\n계층   메커니즘\n\n캐시   MESI 프로토콜\n명령어   원자적 연산 + LOCK\n메모리   메모리 배리어",
    "references": [
      {
        "title": "Memory Barriers",
        "url": "https://www.kernel.org/doc/html/latest/core-api/wrappers/memory-barriers.html"
      }
    ],
    "keywords": [
      "cache",
      "coherence",
      "mesi",
      "lock",
      "memory",
      "barrier",
      "fence",
      "cas",
      "멀티코어",
      "환경에서는",
      "캐시",
      "일관성",
      "프로토콜과",
      "메모리",
      "배리어가"
    ]
  },
  {
    "id": "OS-112",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "페이지 교체 알고리즘에 대해 설명해 주세요.",
    "answer": "페이지 폴트 시 빈 프레임이 없을 때, 어떤 페이지를 교체할지 결정하는 알고리즘입니다.\n\n주요 알고리즘:\n\n알고리즘   설명   특징\n\nOPT   가장 나중에 사용될 페이지 교체   이론적 최적, 실현 불가\nFIFO   가장 먼저 들어온 페이지 교체   단순, Belady's Anomaly\nLRU   가장 오래 사용 안 한 페이지 교체   좋은 성능, 구현 비용\nLFU   가장 적게 사용된 페이지 교체   빈도 기반\nClock   LRU 근사, 순환 리스트   효율적 구현\nNRU   Not Recently Used, 참조/수정 비트   단순한 근사\n\n목표:\n페이지 폴트율 최소화\n낮은 구현 오버헤드\n\n선택 기준:\n구현 복잡도\n하드웨어 지원 (참조 비트, 수정 비트)\n성능 vs 오버헤드 트레이드오프\n\nLinux는 LRU 근사 알고리즘 (Active/Inactive 리스트)을 사용합니다.",
    "references": [
      {
        "title": "OSTEP: Page Replacement",
        "url": "https://pages.cs.wisc.edu/~remzi/OSTEP/vm-beyondphys-policy.pdf"
      }
    ],
    "keywords": [
      "opt",
      "fifo",
      "belady",
      "anomaly",
      "lru",
      "lfu",
      "clock",
      "nru",
      "recently",
      "linux",
      "active",
      "inactive",
      "페이지",
      "폴트",
      "프레임이"
    ]
  },
  {
    "id": "OS-113",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?",
    "answer": "시간적 지역성 (Temporal Locality)을 이용합니다.\n\n시간적 지역성:\n최근에 사용된 데이터는 곧 다시 사용될 가능성이 높음\n오래 사용되지 않은 데이터는 앞으로도 사용 가능성 낮음\n\nLRU의 가정:\n\nOPT와의 관계:\nOPT: 미래에 가장 늦게 사용될 페이지 교체 (이상적)\nLRU: 과거에 가장 오래 안 쓴 페이지 교체 (OPT 근사)\n\n효과적인 상황:\n루프에서 같은 데이터 반복 접근\n최근 참조 = 곧 다시 참조\n\n비효과적인 상황:\n순차적 스캔 (한 번만 접근)\nWorking Set > 프레임 수 (스래싱)\n\nLRU는 지역성이 있는 대부분의 워크로드에서 좋은 성능을 보입니다.",
    "references": [
      {
        "title": "Locality of Reference",
        "url": "https://csapp.cs.cmu.edu/"
      }
    ],
    "keywords": [
      "temporal",
      "locality",
      "lru",
      "opt",
      "working",
      "set",
      "시간적",
      "지역성",
      "이용합니다",
      "최근에",
      "사용된",
      "데이터는",
      "다시",
      "사용될",
      "가능성이"
    ]
  },
  {
    "id": "OS-114",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?",
    "answer": "카운터 기반 (Counter)\n매 접근마다 타임스탬프 갱신\n교체 시 전체 탐색 필요\n스택 기반 (Stack)\n이중 연결 리스트로 구현\n매 접근마다 리스트 재구성\n해시맵 + 이중 연결 리스트 (최적)\nClock 알고리즘 (LRU 근사)\n\nLinux는 Active/Inactive 리스트 기반 LRU 근사를 사용합니다.",
    "references": [
      {
        "title": "Linux Page Reclaim",
        "url": "https://www.kernel.org/doc/html/latest/admin-guide/mm/"
      }
    ],
    "keywords": [
      "counter",
      "stack",
      "clock",
      "lru",
      "linux",
      "active",
      "inactive",
      "카운터",
      "기반",
      "접근마다",
      "타임스탬프",
      "갱신",
      "교체",
      "전체",
      "탐색"
    ]
  },
  {
    "id": "OS-115",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "LRU 알고리즘의 단점을 설명해 주세요. 이를 해결할 수 있는 대안에 대해서도 설명해 주세요.",
    "answer": "LRU의 단점:\n순차 스캔 문제 (Scan Resistant)\n대량 순차 읽기 시 캐시 오염\n한 번만 사용될 페이지가 최근 사용으로 표시\n구현 오버헤드\n매 접근마다 순서 갱신 필요\n하드웨어 지원 없이 정확한 LRU 구현 어려움\n빈도 무시\n자주 사용되는 페이지도 최근 안 쓰면 교체\n최근성만 고려, 빈도는 무시\n\n대안 알고리즘:\n\n알고리즘   해결하는 문제\n\nLRU-K   최근 K번의 접근 이력 고려\n2Q   새 페이지와 오래된 페이지 분리 관리\nARC   빈도와 최근성 동시 고려\nCLOCK-Pro   Clock + 빈도 정보\nLFU   빈도 기반 (시간 무시 문제)\n\nLinux 접근법:\nActive/Inactive 리스트 분리\n두 번 접근된 페이지만 Active로 승격\n순차 스캔 저항성 확보",
    "references": [
      {
        "title": "ARC Algorithm",
        "url": "https://www.usenix.org/conference/fast-03/arc-self-tuning-low-overhead-replacement-cache"
      }
    ],
    "keywords": [
      "lru",
      "scan",
      "resistant",
      "lru-k",
      "arc",
      "clock-pro",
      "clock",
      "lfu",
      "linux",
      "active",
      "inactive",
      "단점",
      "순차",
      "스캔",
      "문제"
    ]
  },
  {
    "id": "OS-116",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "File Descriptor와, File System에 에 대해 설명해 주세요.",
    "answer": "File Descriptor (파일 디스크립터):\n프로세스가 열린 파일을 참조하는 정수 식별자\n프로세스별 파일 디스크립터 테이블에 저장\n기본값: 0(stdin), 1(stdout), 2(stderr)\n\n파일 디스크립터 구조:\n\nFile System (파일 시스템):\n저장 장치에 파일을 조직하고 관리하는 방법\n파일 저장, 검색, 접근 방식 정의\n\n주요 파일 시스템:\n이름   운영체제   특징\n\next4   Linux   저널링, 대용량 지원\nNTFS   Windows   권한, 암호화\nAPFS   macOS   스냅샷, 암호화\nFAT32   범용   단순, 호환성",
    "references": [
      {
        "title": "Linux man-pages: open(2)",
        "url": "https://man7.org/linux/man-pages/man2/open.2.html"
      }
    ],
    "keywords": [
      "file",
      "descriptor",
      "system",
      "linux",
      "ntfs",
      "windows",
      "apfs",
      "fat32",
      "파일",
      "디스크립터",
      "프로세스가",
      "열린",
      "파일을",
      "참조하는",
      "정수"
    ]
  },
  {
    "id": "OS-117",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "I-Node가 무엇인가요?",
    "answer": "I-Node (Index Node)는 Unix/Linux 파일 시스템에서 파일의 메타데이터를 저장하는 자료구조입니다.\n\n저장 정보:\n파일 타입 (일반, 디렉토리, 심볼릭 링크 등)\n파일 크기\n소유자 (UID, GID)\n권한 (rwxrwxrwx)\n타임스탬프 (생성, 수정, 접근 시간)\n링크 카운트 (하드 링크 수)\n데이터 블록 포인터 (실제 데이터 위치)\n\n데이터 블록 포인터 구조:\n\n특징:\n파일 이름은 inode에 저장되지 않음 (디렉토리에 저장)\ninode 번호로 파일 식별\n하드 링크: 같은 inode를 가리키는 여러 이름",
    "references": [
      {
        "title": "Linux man-pages: inode(7)",
        "url": "https://man7.org/linux/man-pages/man7/inode.7.html"
      }
    ],
    "keywords": [
      "i-node",
      "index",
      "node",
      "unix",
      "linux",
      "uid",
      "gid",
      "파일",
      "시스템에서",
      "파일의",
      "메타데이터를",
      "저장하는",
      "자료구조입니다",
      "저장",
      "정보"
    ]
  },
  {
    "id": "OS-118",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "프로그래밍 언어 상에서 제공하는 파일 관련 함수 (Python - open(), Java - BufferedReader/Writer 등)은, 파일을 어떤 방식으로 읽어들이나요?",
    "answer": "버퍼링을 통한 시스템 콜 최소화 방식을 사용합니다.\n\n동작 과정:\n\n버퍼링의 이점:\n시스템 콜 횟수 감소: 한 번에 많은 데이터 읽기\nI/O 효율화: 블록 단위로 읽기/쓰기\n성능 향상: 디스크 접근 최소화\n\n예시:\n\n버퍼 크기:\n보통 4KB ~ 64KB\n페이지 크기의 배수가 효율적",
    "references": [
      {
        "title": "Python I/O",
        "url": "https://docs.python.org/3/library/io.html"
      }
    ],
    "keywords": [
      "버퍼링을",
      "통한",
      "시스템",
      "최소화",
      "방식을",
      "사용합니다",
      "동작",
      "과정",
      "버퍼링의",
      "이점",
      "횟수",
      "감소",
      "번에",
      "많은",
      "데이터"
    ]
  },
  {
    "id": "OS-119",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.",
    "answer": "동기(Synchronous) vs 비동기(Asynchronous): 작업 완료를 누가 확인하는가\n\n구분   동기   비동기\n\n완료 확인   호출자가 확인   피호출자가 알림\n결과 수신   직접 반환   콜백/이벤트\n\n블로킹(Blocking) vs 논블로킹(Non-blocking): 작업 완료 전 제어권을 어떻게 하는가\n\n구분   블로킹   논블로킹\n\n제어권   완료까지 대기   즉시 반환\n다른 작업   불가   가능\n\n조합 예시:\n\n조합   예시\n\n동기 + 블로킹   일반 read()\n동기 + 논블로킹   ONONBLOCK + 폴링\n비동기 + 블로킹   select()에서 대기\n비동기 + 논블로킹   iouring, IOCP",
    "references": [
      {
        "title": "Linux AIO",
        "url": "https://man7.org/linux/man-pages/man7/aio.7.html"
      }
    ],
    "keywords": [
      "synchronous",
      "asynchronous",
      "blocking",
      "non-blocking",
      "ononblock",
      "iocp",
      "동기",
      "비동기",
      "작업",
      "완료를",
      "누가",
      "확인하는가",
      "구분",
      "완료",
      "확인"
    ]
  },
  {
    "id": "OS-120",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "그렇다면, 동기이면서 논블로킹이고, 비동기이면서 블로킹인 경우는 의미가 있다고 할 수 있나요?",
    "answer": "두 경우 모두 실제로 사용됩니다.\n\n동기 + 논블로킹:\n직접 결과 확인 (동기)\n즉시 반환 (논블로킹)\n바쁜 대기(busy waiting) 가능\n\n비동기 + 블로킹:\n여러 작업을 대기하며 블로킹\n어느 것이 완료되든 알림받음\nI/O 멀티플렉싱의 핵심\n\n의미:\n조합   사용 사례\n\n동기 + 논블로킹   폴링, 게임 루프\n비동기 + 블로킹   select, epoll",
    "references": [
      {
        "title": "Linux select(2)",
        "url": "https://man7.org/linux/man-pages/man2/select.2.html"
      }
    ],
    "keywords": [
      "모두",
      "실제로",
      "사용됩니다",
      "동기",
      "논블로킹",
      "직접",
      "결과",
      "확인",
      "즉시",
      "반환",
      "바쁜",
      "대기",
      "가능",
      "비동기",
      "블로킹"
    ]
  },
  {
    "id": "OS-121",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "I/O 멀티플렉싱에 대해 설명해 주세요.",
    "answer": "I/O 멀티플렉싱은 하나의 스레드가 여러 I/O 채널을 동시에 감시하는 기법입니다.\n\n필요성:\n수천 개의 연결을 처리해야 하는 서버\n스레드/프로세스 생성 오버헤드 방지\nC10K 문제 해결\n\n메커니즘:\n\n주요 구현:\n\n함수   특징\n\nselect   최대 1024개 fd, O(n)\npoll   fd 수 제한 없음, O(n)\nepoll (Linux)   O(1), 대규모 연결에 효율적\nkqueue (BSD)   epoll과 유사\nIOCP (Windows)   비동기 완료 포트\n\nepoll 예시:",
    "references": [
      {
        "title": "Linux man-pages: epoll(7)",
        "url": "https://man7.org/linux/man-pages/man7/epoll.7.html"
      }
    ],
    "keywords": [
      "c10k",
      "linux",
      "bsd",
      "iocp",
      "windows",
      "멀티플렉싱은",
      "하나의",
      "스레드가",
      "여러",
      "채널을",
      "동시에",
      "감시하는",
      "기법입니다",
      "필요성",
      "수천"
    ]
  },
  {
    "id": "OS-122",
    "category": "os",
    "categoryName": "OS",
    "priority": "P1",
    "question": "논블로킹 I/O를 수행한다고 하면, 그 결과를 어떻게 수신할 수 있나요?",
    "answer": "논블로킹 I/O 결과 수신 방법:\n폴링 (Polling)\n단순하지만 CPU 낭비\nI/O 멀티플렉싱\n여러 fd를 효율적으로 감시\n시그널 기반 (Signal-Driven)\n인터럽트 기반\n비동기 I/O (AIO)\niouring (최신 Linux)\n높은 성능, 시스템 콜 최소화",
    "references": [
      {
        "title": "Linux io_uring",
        "url": "https://man7.org/linux/man-pages/man7/io_uring.7.html"
      }
    ],
    "keywords": [
      "polling",
      "cpu",
      "signal-driven",
      "aio",
      "linux",
      "논블로킹",
      "결과",
      "수신",
      "방법",
      "폴링",
      "단순하지만",
      "낭비",
      "멀티플렉싱",
      "여러",
      "효율적으로"
    ]
  },
  {
    "id": "ES-001",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Elasticsearch의 기본 아키텍처와 주요 컴포넌트(Cluster, Node, Index, Document 등)에 대해 설명해주세요.",
    "answer": "Elasticsearch는 분산 검색 및 분석 엔진으로, 다음과 같은 주요 컴포넌트로 구성됩니다:\nCluster: 하나 이상의 노드로 구성된 집합으로, 모든 데이터를 저장하고 통합 인덱싱 및 검색 기능을 제공합니다. 고유한 이름으로 식별됩니다.\nNode: 클러스터의 일부로서 데이터를 저장하고 인덱싱 및 검색에 참여하는 단일 서버입니다. Master, Data, Ingest 등 역할별로 구분됩니다.\nIndex: 유사한 특성을 가진 도큐먼트의 모음입니다. RDBMS의 데이터베이스와 유사한 개념입니다.\nDocument: 인덱스에 저장되는 기본 정보 단위로, JSON 형식으로 표현됩니다. RDBMS의 행(row)과 유사합니다.\nShard: 인덱스를 수평 분할한 조각으로, 데이터 분산 저장과 병렬 처리를 가능하게 합니다.",
    "references": [
      {
        "title": "Elasticsearch Basic Concepts",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/elasticsearch-intro.html"
      }
    ],
    "keywords": [
      "elasticsearch",
      "cluster",
      "node",
      "master",
      "data",
      "ingest",
      "index",
      "rdbms",
      "document",
      "json",
      "shard",
      "분산",
      "검색",
      "분석",
      "엔진으로"
    ]
  },
  {
    "id": "ES-002",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Elasticsearch에서 인덱스와 도큐먼트의 개념과 관계는 무엇인가요?",
    "answer": "Index(인덱스)는 도큐먼트의 논리적 컨테이너로, 관련된 데이터를 그룹화합니다. RDBMS의 테이블과 유사하지만 더 유연한 스키마를 가집니다.\n\nDocument(도큐먼트)는 검색 가능한 데이터의 최소 단위로, JSON 객체 형태로 저장됩니다. 각 도큐먼트는 고유한 _id를 가지며, 필드(field)들의 집합으로 구성됩니다.\n\n관계:\n하나의 인덱스는 여러 도큐먼트를 포함할 수 있습니다\n도큐먼트는 반드시 하나의 인덱스에 속해야 합니다\n인덱스의 매핑(mapping)은 도큐먼트 필드의 데이터 타입을 정의합니다",
    "references": [
      {
        "title": "Data in: documents and indices",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/documents-indices.html"
      }
    ],
    "keywords": [
      "index",
      "rdbms",
      "document",
      "json",
      "인덱스",
      "도큐먼트의",
      "논리적",
      "컨테이너로",
      "관련된",
      "데이터를",
      "그룹화합니다",
      "테이블과",
      "유사하지만",
      "유연한",
      "스키마를"
    ]
  },
  {
    "id": "ES-003",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Shard와 Replica의 역할 및 차이점은 무엇인가요?",
    "answer": "Primary Shard(프라이머리 샤드):\n인덱스의 데이터를 수평 분할한 단위입니다\n인덱스 생성 시 샤드 수가 결정되며, 이후 변경이 어렵습니다\n각 도큐먼트는 하나의 프라이머리 샤드에만 저장됩니다\n\nReplica Shard(레플리카 샤드):\n프라이머리 샤드의 복사본입니다\n고가용성 제공: 프라이머리 샤드 장애 시 레플리카가 승격됩니다\n검색 성능 향상: 검색 요청을 분산 처리할 수 있습니다\n동적으로 개수 조정이 가능합니다\n\n주요 차이점:\n구분   Primary Shard   Replica Shard\n\n역할   데이터 저장/쓰기   복제/읽기 분산\n변경   인덱스 생성 시 고정   동적 변경 가능\n필수 여부   필수   선택",
    "references": [
      {
        "title": "Scalability and resilience",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/scalability.html"
      }
    ],
    "keywords": [
      "primary",
      "shard",
      "replica",
      "프라이머리",
      "샤드",
      "인덱스의",
      "데이터를",
      "수평",
      "분할한",
      "단위입니다",
      "인덱스",
      "생성",
      "수가",
      "결정되며",
      "이후"
    ]
  },
  {
    "id": "ES-004",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Elasticsearch에서 클러스터와 노드 간의 관계와 역할에 대해 설명해주세요.",
    "answer": "클러스터(Cluster)는 하나 이상의 노드로 구성된 집합으로, 동일한 cluster.name을 공유합니다.\n\n노드(Node)는 클러스터를 구성하는 개별 서버로, 역할에 따라 다음과 같이 구분됩니다:\nMaster Node: 클러스터 상태 관리, 인덱스 생성/삭제, 샤드 할당 결정\nData Node: 실제 데이터 저장, 검색 및 집계 수행\nCoordinating Node: 검색 요청 라우팅 및 결과 병합\nIngest Node: 인덱싱 전 데이터 전처리\n\n관계:\n노드는 클러스터에 참여하여 데이터와 워크로드를 분산합니다\nMaster-eligible 노드 중 하나가 마스터로 선출됩니다\n노드 간 통신은 Transport 계층(기본 9300 포트)을 통해 이루어집니다",
    "references": [
      {
        "title": "Node roles",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html"
      }
    ],
    "keywords": [
      "cluster",
      "node",
      "master",
      "data",
      "coordinating",
      "ingest",
      "master-eligible",
      "transport",
      "클러스터",
      "하나",
      "이상의",
      "노드로",
      "구성된",
      "집합으로",
      "동일한"
    ]
  },
  {
    "id": "ES-005",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Query DSL의 기본 구조와 사용 방법에 대해 설명해주세요.",
    "answer": "Query DSL(Domain Specific Language)은 JSON 기반의 쿼리 언어로, Elasticsearch에서 검색을 수행하는 표준 방법입니다.\n\n기본 구조:\n\n주요 컨텍스트:\nQuery Context: 관련성 점수(score)를 계산합니다\nFilter Context: 조건 일치 여부만 판단하며 캐싱됩니다\n\n기본 사용 예시:",
    "references": [
      {
        "title": "Query DSL",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html"
      }
    ],
    "keywords": [
      "query",
      "dsl",
      "domain",
      "specific",
      "language",
      "json",
      "elasticsearch",
      "context",
      "filter",
      "기반의",
      "쿼리",
      "언어로",
      "에서",
      "검색을",
      "수행하는"
    ]
  },
  {
    "id": "ES-006",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Match 쿼리와 Term 쿼리의 차이점은 무엇인가요?",
    "answer": "Match Query:\n전문 검색(Full-text search)에 사용됩니다\n검색어를 분석기(Analyzer)를 통해 토큰화합니다\n분석된 토큰으로 검색하여 유연한 매칭이 가능합니다\n\nTerm Query:\n정확한 값 매칭(Exact match)에 사용됩니다\n분석기를 거치지 않고 원본 그대로 검색합니다\nkeyword 필드, 숫자, 날짜 등에 적합합니다\n\n핵심 차이: Match는 분석기 적용 O, Term은 분석기 적용 X",
    "references": [
      {
        "title": "Match query",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query.html"
      },
      {
        "title": "Term query",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-term-query.html"
      }
    ],
    "keywords": [
      "match",
      "query",
      "full-text",
      "analyzer",
      "term",
      "exact",
      "전문",
      "검색",
      "사용됩니다",
      "검색어를",
      "분석기",
      "토큰화합니다",
      "분석된",
      "토큰으로",
      "검색하여"
    ]
  },
  {
    "id": "ES-007",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Range 쿼리의 활용 사례와 주의사항에 대해 설명해주세요.",
    "answer": "Range Query는 숫자, 날짜, 문자열 필드에서 특정 범위 내의 값을 검색합니다.\n\n주요 연산자:\ngt: 초과, gte: 이상\nlt: 미만, lte: 이하\n\n활용 사례:\n\n주의사항:\n날짜 형식: 인덱스 매핑의 날짜 형식과 일치해야 합니다\n타임존: timezone 파라미터로 시간대를 명시하는 것이 좋습니다\n성능: 넓은 범위 쿼리는 많은 도큐먼트를 스캔할 수 있어 Filter Context 사용 권장\n문자열 범위: 사전순 비교이므로 의도한 결과와 다를 수 있습니다",
    "references": [
      {
        "title": "Range query",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-range-query.html"
      }
    ],
    "keywords": [
      "range",
      "query",
      "filter",
      "context",
      "숫자",
      "날짜",
      "문자열",
      "필드에서",
      "특정",
      "범위",
      "내의",
      "값을",
      "검색합니다",
      "주요",
      "연산자"
    ]
  },
  {
    "id": "ES-008",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Bool 쿼리의 구성 요소(Must, Should, Must Not, Filter)에 대해 설명해주세요.",
    "answer": "Bool Query는 여러 쿼리를 논리적으로 조합하는 복합 쿼리입니다.\n\n구성 요소:\n\n절   설명   점수 영향   캐싱\n\nmust   반드시 일치해야 함 (AND)   O   X\nshould   일치하면 점수 증가 (OR)   O   X\nmustnot   일치하면 제외 (NOT)   X   O\nfilter   반드시 일치해야 함 (필터링)   X   O\n\n예시:\n\n성능 팁: 점수 계산이 필요 없는 조건은 filter를 사용하여 캐싱 이점을 활용하세요.",
    "references": [
      {
        "title": "Boolean query",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html"
      }
    ],
    "keywords": [
      "bool",
      "query",
      "여러",
      "쿼리를",
      "논리적으로",
      "조합하는",
      "복합",
      "쿼리입니다",
      "구성",
      "요소",
      "설명",
      "점수",
      "영향",
      "캐싱",
      "반드시"
    ]
  },
  {
    "id": "ES-009",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Aggregation의 개념과 Bucket Aggregation, Metric Aggregation의 차이에 대해 설명해주세요.",
    "answer": "Aggregation은 데이터를 그룹화하고 통계를 계산하는 기능으로, SQL의 GROUP BY와 유사합니다.\n\nBucket Aggregation:\n도큐먼트를 기준에 따라 그룹(버킷)으로 분류합니다\n예: terms, datehistogram, range, filters\n\nMetric Aggregation:\n숫자 값에 대한 통계를 계산합니다\n예: sum, avg, min, max, cardinality, stats\n\nPipeline Aggregation:\n다른 집계 결과를 입력으로 사용합니다\n예: derivative, movingavg, bucketsort\n\n중첩 사용 예시:",
    "references": [
      {
        "title": "Aggregations",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html"
      }
    ],
    "keywords": [
      "aggregation",
      "sql",
      "group",
      "bucket",
      "metric",
      "pipeline",
      "데이터를",
      "그룹화하고",
      "통계를",
      "계산하는",
      "기능으로",
      "유사합니다",
      "도큐먼트를",
      "기준에",
      "따라"
    ]
  },
  {
    "id": "ES-010",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Analyzers, Tokenizers, Filters의 역할과 설정 방법에 대해 설명해주세요.",
    "answer": "Analyzer(분석기)는 텍스트를 검색 가능한 토큰으로 변환하는 파이프라인입니다.\n\n구성 요소:\nCharacter Filters: 텍스트 전처리 (HTML 태그 제거 등)\nTokenizer: 텍스트를 토큰으로 분리\nToken Filters: 토큰 후처리 (소문자 변환, 불용어 제거 등)\n\n처리 순서: Character Filters → Tokenizer → Token Filters\n\n내장 Analyzer:\nstandard: 기본 분석기, 유니코드 텍스트 분할\nsimple: 문자가 아닌 곳에서 분할, 소문자 변환\nwhitespace: 공백 기준 분할\nkeyword: 전체 텍스트를 하나의 토큰으로\n\n커스텀 Analyzer 설정:",
    "references": [
      {
        "title": "Text analysis",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html"
      }
    ],
    "keywords": [
      "analyzer",
      "character",
      "filters",
      "html",
      "tokenizer",
      "token",
      "분석기",
      "텍스트를",
      "검색",
      "가능한",
      "토큰으로",
      "변환하는",
      "파이프라인입니다",
      "구성",
      "요소"
    ]
  },
  {
    "id": "ES-011",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Mapping의 개념과 동적 매핑(Dynamic Mapping) 및 명시적 매핑(Explicit Mapping)의 차이점은 무엇인가요?",
    "answer": "Mapping은 인덱스에 저장되는 도큐먼트의 구조와 필드 타입을 정의하는 스키마입니다.\n\nDynamic Mapping (동적 매핑):\n도큐먼트 인덱싱 시 자동으로 필드 타입을 추론합니다\n빠른 프로토타이핑에 유용하지만, 의도치 않은 타입 할당 가능성이 있습니다\n\nExplicit Mapping (명시적 매핑):\n인덱스 생성 시 명확하게 필드 타입을 정의합니다\n프로덕션 환경에서 권장됩니다\n\n주요 차이점:\n구분   Dynamic   Explicit\n\n정의 시점   자동 (인덱싱 시)   수동 (인덱스 생성 시)\n타입 정확성   추론 기반   명시적\n유연성   높음   낮음\n권장 환경   개발   프로덕션",
    "references": [
      {
        "title": "Mapping",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html"
      }
    ],
    "keywords": [
      "mapping",
      "dynamic",
      "explicit",
      "인덱스에",
      "저장되는",
      "도큐먼트의",
      "구조와",
      "필드",
      "타입을",
      "정의하는",
      "스키마입니다",
      "동적",
      "매핑",
      "도큐먼트",
      "인덱싱"
    ]
  },
  {
    "id": "ES-012",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Elasticsearch에서 Relevance Scoring의 원리와 개선 방법에 대해 설명해주세요.",
    "answer": "Relevance Scoring은 검색 쿼리와 도큐먼트의 관련성을 수치화한 점수(score)입니다.\n\n점수 계산 알고리즘 (BM25):\nElasticsearch 5.0부터 기본 알고리즘으로, 다음 요소를 고려합니다:\nTF (Term Frequency): 검색어가 도큐먼트에 등장하는 빈도\nIDF (Inverse Document Frequency): 전체 도큐먼트 대비 검색어의 희소성\nField Length: 필드 길이가 짧을수록 높은 점수\n\n점수 개선 방법:\nField Boosting: 특정 필드에 가중치 부여\nFunction Score Query: 커스텀 점수 함수 적용\nExplain API: 점수 계산 과정 분석",
    "references": [
      {
        "title": "Relevance tuning",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/search-relevance.html"
      }
    ],
    "keywords": [
      "relevance",
      "scoring",
      "bm25",
      "elasticsearch",
      "term",
      "frequency",
      "idf",
      "inverse",
      "document",
      "field",
      "length",
      "boosting",
      "function",
      "score",
      "query"
    ]
  },
  {
    "id": "ES-013",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Boosting을 통한 검색 결과 가중치 조정 방법에 대해 설명해주세요.",
    "answer": "Boosting은 특정 조건에 따라 검색 점수를 높이거나 낮추는 기법입니다.\nQuery-time Boosting (쿼리 시점):\nBoosting Query:\npositive: 일치하면 점수 계산\nnegative: 일치하면 점수 감소\nFunction Score Query:",
    "references": [
      {
        "title": "Boosting query",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-boosting-query.html"
      }
    ],
    "keywords": [
      "boosting",
      "query-time",
      "query",
      "function",
      "score",
      "특정",
      "조건에",
      "따라",
      "검색",
      "점수를",
      "높이거나",
      "낮추는",
      "기법입니다",
      "쿼리",
      "시점"
    ]
  },
  {
    "id": "ES-014",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Multi-match 쿼리와 Cross-field 검색의 차이점은 무엇인가요?",
    "answer": "Multi-match Query는 여러 필드에서 동시에 검색을 수행합니다.\n\n타입별 차이:\n\n타입   설명   사용 사례\n\nbestfields   가장 높은 점수의 필드 사용 (기본값)   동일 필드 내 매칭 중요\nmostfields   모든 필드 점수 합산   동의어가 여러 필드에 있을 때\ncrossfields   모든 필드를 하나로 취급   이름 검색 (firstname + lastname)\nphrase   구문 매칭   정확한 문구 검색\nphraseprefix   접두어 구문 매칭   자동완성\n\nCross-field 검색 예시:\n\"홍\"이 firstname에, \"길동\"이 lastname에 있어도 매칭됩니다\n\nbestfields와의 차이:\nbestfields: 각 필드를 독립적으로 검색하여 최고 점수 선택\ncross_fields: 여러 필드를 하나의 큰 필드처럼 취급",
    "references": [
      {
        "title": "Multi-match query",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-multi-match-query.html"
      }
    ],
    "keywords": [
      "multi-match",
      "query",
      "cross-field",
      "cross_fields",
      "여러",
      "필드에서",
      "동시에",
      "검색을",
      "수행합니다",
      "타입별",
      "차이",
      "타입",
      "설명",
      "사용",
      "사례"
    ]
  },
  {
    "id": "ES-015",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Nested 타입과 Object 타입의 차이점 및 사용 시 주의사항에 대해 설명해주세요.",
    "answer": "Object 타입:\n기본 JSON 객체 매핑 방식입니다\n내부적으로 필드가 평탄화(flatten)되어 저장됩니다\n배열 내 객체 간 관계가 손실됩니다\n\nNested 타입:\n각 객체를 별도의 숨겨진 도큐먼트로 저장합니다\n객체 간 관계가 유지됩니다\nNested Query로 검색해야 합니다\n\n주요 차이점:\n구분   Object   Nested\n\n관계 유지   X   O\n저장 방식   평탄화   별도 도큐먼트\n검색 방식   일반 쿼리   Nested Query\n성능   빠름   상대적으로 느림\n\n주의사항:\nNested 객체 수 제한: 기본 10,000개 (index.mapping.nested_objects.limit)\n많은 Nested 객체는 힙 메모리와 검색 성능에 영향",
    "references": [
      {
        "title": "Nested field type",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html"
      }
    ],
    "keywords": [
      "object",
      "json",
      "nested",
      "query",
      "nested_objects",
      "타입",
      "기본",
      "객체",
      "매핑",
      "방식입니다",
      "내부적으로",
      "필드가",
      "평탄화",
      "되어",
      "저장됩니다"
    ]
  },
  {
    "id": "ES-016",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Elasticsearch의 인덱스 설정(Index Settings)과 매핑 설정(Mapping Settings)의 차이점은 무엇인가요?",
    "answer": "Index Settings (인덱스 설정):\n인덱스의 동작 방식과 물리적 구성을 정의합니다.\nStatic Settings: 인덱스 생성 시에만 설정 가능\nnumberofshards: 프라이머리 샤드 수\ncodec: 압축 알고리즘\nDynamic Settings: 런타임에 변경 가능\nnumberofreplicas: 레플리카 수\nrefreshinterval: 인덱스 갱신 주기\n\nMapping Settings (매핑 설정):\n도큐먼트 필드의 데이터 타입과 처리 방식을 정의합니다.\n\n핵심 차이:\n구분   Index Settings   Mapping Settings\n\n대상   인덱스 자체   필드\n내용   샤드, 복제본, 분석기   필드 타입, 분석기 적용\n변경   일부 동적 변경 가능   기존 필드 타입 변경 불가",
    "references": [
      {
        "title": "Index settings",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html"
      }
    ],
    "keywords": [
      "index",
      "settings",
      "static",
      "dynamic",
      "mapping",
      "인덱스",
      "설정",
      "인덱스의",
      "동작",
      "방식과",
      "물리적",
      "구성을",
      "정의합니다",
      "생성",
      "시에만"
    ]
  },
  {
    "id": "ES-017",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "검색 성능 튜닝을 위한 주요 고려사항은 무엇인가요?",
    "answer": "매핑 최적화:\n불필요한 필드 인덱싱 비활성화 (index: false)\ndocvalues 비활성화 (집계/정렬 불필요 시)\n적절한 데이터 타입 선택 (keyword vs text)\n쿼리 최적화:\nFilter Context 활용 (캐싱 이점)\nbool 쿼리에서 filter 절 적극 사용\nsize: 0으로 집계 전용 쿼리 실행\n샤드 전략:\n샤드 크기: 10-50GB 권장\n노드당 샤드 수: 힙 1GB당 20개 이하\n과도한 샤드 분산 방지\n하드웨어/설정:\n충분한 힙 메모리 (최대 32GB, 전체 메모리의 50%)\nSSD 사용 권장\nrefreshinterval 조정 (인덱싱 성능 vs 검색 최신성)\n캐싱 활용:\nNode Query Cache: Filter 결과 캐싱\nShard Request Cache: 집계 결과 캐싱\nField Data Cache: 정렬/집계용 필드 데이터",
    "references": [
      {
        "title": "Tune for search speed",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html"
      }
    ],
    "keywords": [
      "filter",
      "context",
      "ssd",
      "node",
      "query",
      "cache",
      "shard",
      "request",
      "field",
      "data",
      "매핑",
      "최적화",
      "불필요한",
      "필드",
      "인덱싱"
    ]
  },
  {
    "id": "ES-018",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Elasticsearch의 분산 시스템 특성과 데이터 복제 메커니즘에 대해 설명해주세요.",
    "answer": "분산 시스템 특성:\n수평 확장성: 노드 추가로 용량과 처리량 증가\n고가용성: 레플리카를 통한 장애 대응\n자동 샤드 밸런싱: 클러스터 내 샤드 자동 분배\n분산 검색: 모든 샤드에서 병렬 검색 후 결과 병합\n\n데이터 복제 메커니즘:\nPrimary-Replica 모델:\n쓰기 요청은 Primary Shard에서 처리\nPrimary가 Replica로 복제 전파\n모든 Replica 복제 완료 시 응답 반환 (기본값)\n복제 프로세스:\n일관성 설정 (waitforactive_shards):\n1: Primary만 확인 (빠름, 덜 안전)\nall: 모든 복제본 확인 (느림, 안전)\nquorum: 과반수 확인 (균형)\n장애 복구:\nPrimary 장애 시 Replica가 자동 승격\n새 노드 추가 시 자동 샤드 재배치",
    "references": [
      {
        "title": "Reading and writing documents",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html"
      }
    ],
    "keywords": [
      "primary-replica",
      "primary",
      "shard",
      "replica",
      "waitforactive_shards",
      "분산",
      "시스템",
      "특성",
      "수평",
      "확장성",
      "노드",
      "추가로",
      "용량과",
      "처리량",
      "증가"
    ]
  },
  {
    "id": "ES-019",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "클러스터 상태를 모니터링하기 위한 도구와 주요 지표에는 무엇이 있나요?",
    "answer": "모니터링 도구:\nKibana Stack Monitoring: 시각적 대시보드 제공\nCluster APIs:\nGET cluster/health: 클러스터 상태\nGET cluster/stats: 클러스터 통계\nGET nodes/stats: 노드별 통계\nCat APIs: 사람이 읽기 쉬운 형식\nGET cat/health, GET cat/nodes, GET cat/indices\n\n주요 지표:\n\n카테고리   지표   설명\n\n클러스터   status   green/yellow/red\nactiveshards   활성 샤드 수\nunassignedshards   미할당 샤드 수\n노드   heapusedpercent   힙 메모리 사용률\ncpupercent   CPU 사용률\ndiskusedpercent   디스크 사용률\n인덱싱   indexingrate   초당 인덱싱 문서 수\nrefreshtime   리프레시 소요 시간\n검색   querylatency   쿼리 지연 시간\nfetch_latency   결과 가져오기 지연\n\n클러스터 상태:\nGreen: 모든 샤드 할당 완료\nYellow: Primary는 할당, Replica 미할당\nRed: 일부 Primary 미할당",
    "references": [
      {
        "title": "Monitor a cluster",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/monitor-elasticsearch-cluster.html"
      }
    ],
    "keywords": [
      "kibana",
      "stack",
      "monitoring",
      "cluster",
      "apis",
      "get",
      "cat",
      "cpu",
      "fetch_latency",
      "green",
      "yellow",
      "primary",
      "replica",
      "red",
      "모니터링"
    ]
  },
  {
    "id": "ES-020",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Replica가 부족할 때 발생할 수 있는 문제와 해결 방법은 무엇인가요?",
    "answer": "발생 가능한 문제:\n가용성 저하: 노드 장애 시 데이터 손실 위험\nYellow 상태: Replica 미할당으로 클러스터 상태 저하\n검색 성능 저하: 검색 부하 분산 불가\n복구 지연: 장애 발생 시 복구 시간 증가\n\n원인 파악:\n\n일반적인 원인과 해결 방법:\n\n원인   해결 방법\n\n노드 부족   노드 추가 또는 replica 수 감소\n디스크 용량 부족   디스크 확보 또는 watermark 설정 조정\n할당 필터   allocation 설정 검토\n노드 장애   장애 노드 복구 또는 제거\n\n해결 명령어:",
    "references": [
      {
        "title": "Cluster allocation explain",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-allocation-explain.html"
      }
    ],
    "keywords": [
      "yellow",
      "replica",
      "발생",
      "가능한",
      "문제",
      "가용성",
      "저하",
      "노드",
      "장애",
      "데이터",
      "손실",
      "위험",
      "상태",
      "미할당으로",
      "클러스터"
    ]
  },
  {
    "id": "ES-021",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Data Node, Master Node, Client Node의 역할과 차이점에 대해 설명해주세요.",
    "answer": "Master Node (마스터 노드):\n클러스터 전체 관리 담당\n인덱스 생성/삭제, 샤드 할당 결정\n클러스터 상태 관리 및 전파\n최소 3개의 master-eligible 노드 권장 (split-brain 방지)\n\nData Node (데이터 노드):\n실제 데이터 저장 및 CRUD 작업 수행\n검색 및 집계 쿼리 실행\nCPU, 메모리, I/O 집약적 작업\n\nCoordinating Node (코디네이팅 노드):\n클라이언트 요청을 받아 적절한 노드로 라우팅\n검색 결과 병합 (scatter-gather)\n전용 설정 시 \"Client Node\"라고도 불림\n\nIngest Node (인제스트 노드):\n인덱싱 전 데이터 전처리 파이프라인 실행\n\n역할 비교:\n역할   Master   Data   Coordinating\n\n클러스터 관리   O   X   X\n데이터 저장   X   O   X\n쿼리 라우팅   X   X   O\n리소스 요구   낮음   높음   중간",
    "references": [
      {
        "title": "Node roles",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html"
      }
    ],
    "keywords": [
      "master",
      "node",
      "master-eligible",
      "split-brain",
      "data",
      "crud",
      "cpu",
      "coordinating",
      "scatter-gather",
      "client",
      "ingest",
      "마스터",
      "노드",
      "클러스터",
      "전체"
    ]
  },
  {
    "id": "ES-022",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Kibana와 Elasticsearch의 관계 및 연동 방법에 대해 설명해주세요.",
    "answer": "관계:\nKibana는 Elasticsearch 데이터를 시각화하고 관리하는 공식 UI 도구입니다.\n\n주요 기능:\nDiscover: 데이터 탐색 및 검색\nVisualize: 차트, 그래프 등 시각화 생성\nDashboard: 여러 시각화를 조합한 대시보드\nDev Tools: Query DSL 직접 실행\nManagement: 인덱스 패턴, 사용자 관리\n\n연동 방법:\n기본 설정 (kibana.yml):\n다중 노드 연결:\nSSL/TLS 설정:\n\n인덱스 패턴 생성:\nKibana > Stack Management > Index Patterns\n패턴 입력 (예: logs-*)\n타임스탬프 필드 선택",
    "references": [
      {
        "title": "Kibana configuration",
        "url": "https://www.elastic.co/guide/en/kibana/current/settings.html"
      }
    ],
    "keywords": [
      "kibana",
      "elasticsearch",
      "discover",
      "visualize",
      "dashboard",
      "dev",
      "tools",
      "query",
      "dsl",
      "management",
      "ssl",
      "tls",
      "stack",
      "index",
      "patterns"
    ]
  },
  {
    "id": "ES-023",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Elasticsearch의 스케일링(Scale-out) 전략에는 어떤 것들이 있나요?",
    "answer": "수평 확장 (Scale-out):\n노드 추가: 새 노드 추가 시 자동으로 샤드 재분배\n샤드 분산: 데이터와 쿼리 부하 분산\n샤드 전략:\n초기 샤드 수 적절히 설정 (이후 변경 어려움)\n샤드 크기 권장: 10-50GB\n노드당 샤드 수: 힙 1GB당 20개 이하\n인덱스 분할 전략:\n시간 기반 인덱스: logs-2024.01, logs-2024.02\n롤오버: 조건 충족 시 새 인덱스 자동 생성\n역할 기반 노드 분리:\nMaster, Data, Ingest, Coordinating 노드 분리\nHot-Warm-Cold 아키텍처 적용\nCross-Cluster Replication (CCR):\n지역 간 데이터 복제\n재해 복구 및 지역별 검색 성능 향상\nFrozen Tier:\n자주 접근하지 않는 데이터를 저비용 스토리지로 이동",
    "references": [
      {
        "title": "Scalability and resilience",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/scalability.html"
      }
    ],
    "keywords": [
      "scale-out",
      "master",
      "data",
      "ingest",
      "coordinating",
      "hot-warm-cold",
      "cross-cluster",
      "replication",
      "ccr",
      "frozen",
      "tier",
      "수평",
      "확장",
      "노드",
      "추가"
    ]
  },
  {
    "id": "ES-024",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "인덱스 템플릿(Index Template)의 역할과 구성 방법에 대해 설명해주세요.",
    "answer": "역할:\n인덱스 템플릿은 새 인덱스 생성 시 자동으로 적용되는 설정과 매핑을 정의합니다. 시간 기반 인덱스나 동일한 구조의 여러 인덱스 관리에 유용합니다.\n\n구성 요소:\nindexpatterns: 템플릿이 적용될 인덱스 패턴\ntemplate: settings, mappings, aliases 정의\npriority: 여러 템플릿 중 우선순위\ncomposedof: 재사용 가능한 컴포넌트 템플릿\n\n컴포넌트 템플릿 생성:\n\n인덱스 템플릿 생성:\n\n레거시 템플릿과 차이:\n레거시: template API (deprecated)\n현재: indextemplate + component_template",
    "references": [
      {
        "title": "Index templates",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/index-templates.html"
      }
    ],
    "keywords": [
      "api",
      "component_template",
      "역할",
      "인덱스",
      "템플릿은",
      "생성",
      "자동으로",
      "적용되는",
      "설정과",
      "매핑을",
      "정의합니다",
      "시간",
      "기반",
      "인덱스나",
      "동일한"
    ]
  },
  {
    "id": "ES-025",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "인덱스 롤오버(Rollover) 전략과 사용 사례에 대해 설명해주세요.",
    "answer": "롤오버(Rollover)는 인덱스가 특정 조건을 충족하면 자동으로 새 인덱스를 생성하고 alias를 전환하는 기능입니다.\n\n롤오버 조건:\nmaxage: 인덱스 생성 후 경과 시간\nmaxdocs: 최대 도큐먼트 수\nmaxsize: 프라이머리 샤드 최대 크기\nmaxprimaryshardsize: 개별 프라이머리 샤드 크기\n\n설정 방법:\n초기 인덱스 및 Alias 생성:\n롤오버 실행:\nILM과 연동 (권장):\n\n사용 사례:\n로그 데이터 관리 (일별/주별 인덱스)\n시계열 데이터 (메트릭, 이벤트)\n대용량 데이터셋 분할 관리",
    "references": [
      {
        "title": "Rollover API",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-rollover-index.html"
      }
    ],
    "keywords": [
      "rollover",
      "alias",
      "ilm",
      "롤오버",
      "인덱스가",
      "특정",
      "조건을",
      "충족하면",
      "자동으로",
      "인덱스를",
      "생성하고",
      "전환하는",
      "기능입니다",
      "조건",
      "인덱스"
    ]
  },
  {
    "id": "ES-026",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Suggester 기능의 동작 원리와 활용 방법은 무엇인가요?",
    "answer": "Suggester는 검색어 자동완성, 오타 수정, 유사어 제안 등의 기능을 제공합니다.\n\nSuggester 유형:\nTerm Suggester: 개별 단어 오타 수정\nPhrase Suggester: 전체 구문 수정 (단어 간 관계 고려)\nCompletion Suggester: 빠른 자동완성 (별도 데이터 구조)\n\n동작 원리:\nTerm/Phrase: Edit distance 기반 유사도 계산\nCompletion: FST(Finite State Transducer) 자료구조로 메모리에 로드하여 빠른 검색\n\n활용 사례:\n검색창 자동완성\n\"이것을 찾으셨나요?\" 기능\n철자 교정",
    "references": [
      {
        "title": "Suggesters",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters.html"
      }
    ],
    "keywords": [
      "suggester",
      "term",
      "phrase",
      "completion",
      "edit",
      "fst",
      "finite",
      "state",
      "transducer",
      "검색어",
      "자동완성",
      "오타",
      "수정",
      "유사어",
      "제안"
    ]
  },
  {
    "id": "ES-027",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Scroll API와 Search After의 차이점 및 각각의 사용 시나리오는 무엇인가요?",
    "answer": "기본 페이징 (from + size):\n10,000건 제한 (index.maxresultwindow)\n깊은 페이지에서 성능 저하\n\nScroll API:\n대량 데이터 추출용 (export)\n스냅샷 시점의 결과 유지\n컨텍스트 유지로 리소스 소모\n\nSearch After:\n실시간 페이징용\n이전 결과의 정렬 값을 기준으로 다음 페이지 조회\n무한 스크롤, 라이브 데이터에 적합\n\n비교:\n구분   Scroll   Search After\n\n용도   데이터 추출   실시간 페이징\n일관성   스냅샷   실시간\n리소스   높음 (컨텍스트 유지)   낮음\n정렬 변경   불가   가능\n무작위 접근   불가   불가\n\nPoint in Time (PIT) + Search After: 일관된 스냅샷 + 효율적 페이징",
    "references": [
      {
        "title": "Paginate search results",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html"
      }
    ],
    "keywords": [
      "scroll",
      "api",
      "search",
      "point",
      "time",
      "pit",
      "기본",
      "페이징",
      "제한",
      "깊은",
      "페이지에서",
      "성능",
      "저하",
      "대량",
      "데이터"
    ]
  },
  {
    "id": "ES-028",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Time-based index의 개념과 활용 방안에 대해 설명해주세요.",
    "answer": "Time-based Index는 시간을 기준으로 분할된 인덱스로, 시계열 데이터 관리에 최적화되어 있습니다.\n\n구조 예시:\n\n장점:\n효율적인 삭제: 오래된 인덱스 전체 삭제 (도큐먼트 삭제보다 빠름)\n검색 범위 제한: 특정 기간만 검색하여 성능 향상\nHot-Warm-Cold 적용: 시간에 따른 스토리지 티어링\n샤드 크기 관리: 예측 가능한 인덱스 크기\n\n활용 방안:\n인덱스 템플릿 + 롤오버:\nILM 정책 연동:\nAlias를 통한 검색:",
    "references": [
      {
        "title": "Data streams",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/data-streams.html"
      }
    ],
    "keywords": [
      "time-based",
      "index",
      "hot-warm-cold",
      "ilm",
      "alias",
      "시간을",
      "기준으로",
      "분할된",
      "인덱스로",
      "시계열",
      "데이터",
      "관리에",
      "최적화되어",
      "구조",
      "예시"
    ]
  },
  {
    "id": "ES-029",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "데이터 삭제 시 발생할 수 있는 이슈와 그 해결 방법은 무엇인가요?",
    "answer": "삭제 방식:\nDocument Delete: DELETE /index/doc/id\nDelete by Query: POST /index/deletebyquery\nIndex Delete: DELETE /index\n\n발생 가능한 이슈:\n성능 저하:\nDelete by Query는 내부적으로 검색 + 삭제 수행\n대량 삭제 시 클러스터 부하 증가\n해결: scrollsize, slices 파라미터로 조절\n디스크 공간 미해제:\n삭제된 문서는 세그먼트에 \"삭제 표시\"만 됨\n실제 공간은 세그먼트 병합 시 회수\n해결: Force Merge 실행\n버전 충돌:\n삭제 중 해당 문서 업데이트 시 충돌\n해결: conflicts=proceed 옵션\n인덱스 전체 삭제 실수:\n예방: action.destructiverequires_name: true 설정\n와일드카드 삭제 방지\n\n권장 사항:\n대량 삭제: Time-based Index + 인덱스 삭제\n개별 삭제: Document Delete API\n조건 삭제: Delete by Query (off-peak 시간)",
    "references": [
      {
        "title": "Delete by query API",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete-by-query.html"
      }
    ],
    "keywords": [
      "document",
      "delete",
      "query",
      "post",
      "index",
      "force",
      "merge",
      "destructiverequires_name",
      "time-based",
      "api",
      "off-peak",
      "삭제",
      "방식",
      "발생",
      "가능한"
    ]
  },
  {
    "id": "ES-030",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Snapshot과 Restore 기능을 통한 백업 전략에 대해 설명해주세요.",
    "answer": "Snapshot은 클러스터 또는 특정 인덱스의 백업을 생성하는 기능입니다.\n\nRepository 설정:\n\n지원 저장소: 파일시스템, S3, GCS, Azure Blob, HDFS\n\n스냅샷 생성:\n\n복원:\n\n백업 전략:\n증분 백업: 스냅샷은 자동으로 증분 방식 (변경분만 저장)\n스케줄링: SLM(Snapshot Lifecycle Management) 사용\n권장 사항:\n정기적인 전체 클러스터 스냅샷\n중요 인덱스는 별도 스냅샷\n복원 테스트 주기적 수행",
    "references": [
      {
        "title": "Snapshot and restore",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshot-restore.html"
      }
    ],
    "keywords": [
      "snapshot",
      "repository",
      "gcs",
      "azure",
      "blob",
      "hdfs",
      "slm",
      "lifecycle",
      "management",
      "클러스터",
      "특정",
      "인덱스의",
      "백업을",
      "생성하는",
      "기능입니다"
    ]
  },
  {
    "id": "ES-031",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "분산 트랜잭션과 관련하여 Elasticsearch는 어떤 접근 방식을 취하나요?",
    "answer": "Elasticsearch의 트랜잭션 특성:\n\nElasticsearch는 ACID 트랜잭션을 지원하지 않습니다. 대신 다음과 같은 접근 방식을 취합니다:\n단일 문서 수준 원자성:\n개별 문서의 인덱싱, 업데이트, 삭제는 원자적\n하나의 문서 작업은 완전히 성공하거나 실패\nOptimistic Concurrency Control:\nversion 또는 ifseqno + ifprimaryterm으로 동시성 제어\nEventual Consistency:\nPrimary 복제 후 Replica에 비동기 전파\nrefresh_interval 후 검색 가능\n즉각적인 일관성이 필요하면 ?refresh=true\nBulk 작업:\n개별 작업은 독립적으로 성공/실패\n전체 롤백 없음 (부분 실패 가능)\n\nRDBMS 트랜잭션이 필요한 경우:\n애플리케이션 레벨에서 보상 트랜잭션 구현\nRDBMS를 Source of Truth로, ES는 검색용으로 분리\n2PC(Two-Phase Commit) 패턴 직접 구현",
    "references": [
      {
        "title": "Reading and writing documents",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html"
      }
    ],
    "keywords": [
      "elasticsearch",
      "acid",
      "optimistic",
      "concurrency",
      "control",
      "eventual",
      "consistency",
      "primary",
      "replica",
      "refresh_interval",
      "bulk",
      "rdbms",
      "source",
      "truth",
      "two-phase"
    ]
  },
  {
    "id": "ES-032",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Elasticsearch 버전 업그레이드 시 고려해야 할 사항은 무엇인가요?",
    "answer": "업그레이드 전 확인사항:\n호환성 검토:\n지원 업그레이드 경로 확인 (예: 7.x → 8.x)\nBreaking Changes 문서 검토\n플러그인, 클라이언트 라이브러리 호환성\nDeprecation 확인:\n백업 필수:\n\n업그레이드 방식:\n\n방식   설명   다운타임\n\nRolling Upgrade   노드별 순차 업그레이드   없음\nFull Cluster Restart   전체 클러스터 중지 후 업그레이드   있음\nReindex from Remote   새 클러스터로 데이터 마이그레이션   없음\n\nRolling Upgrade 절차:\n샤드 할당 비활성화\n동기화 플러시 실행\n노드 중지 → 업그레이드 → 재시작\n클러스터 green 상태 확인\n다음 노드 반복\n\n주의사항:\n인덱스 호환성 (N-1 버전까지만 지원)\n매핑/설정 변경사항 확인\n충분한 테스트 환경에서 사전 검증",
    "references": [
      {
        "title": "Upgrade Elasticsearch",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-upgrade.html"
      }
    ],
    "keywords": [
      "breaking",
      "changes",
      "deprecation",
      "rolling",
      "upgrade",
      "full",
      "cluster",
      "restart",
      "reindex",
      "remote",
      "n-1",
      "업그레이드",
      "확인사항",
      "호환성",
      "검토"
    ]
  },
  {
    "id": "ES-033",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Index Lifecycle Management(ILM)의 기능과 필요성에 대해 설명해주세요.",
    "answer": "ILM(Index Lifecycle Management)은 인덱스의 생명주기를 자동으로 관리하는 기능입니다.\n\n필요성:\n시간에 따른 데이터 접근 패턴 변화 대응\n스토리지 비용 최적화\n수동 관리 작업 자동화\n데이터 보존 정책 일관성 유지\n\n생명주기 단계 (Phases):\n\n단계   설명   주요 액션\n\nHot   활발한 쓰기/읽기   rollover, setpriority\nWarm   읽기 전용, 덜 빈번한 접근   shrink, forcemerge, readonly\nCold   드문 검색, 저비용 스토리지   searchablesnapshot\nFrozen   거의 접근 없음   partial searchablesnapshot\nDelete   삭제   delete\n\n정책 예시:\n\n인덱스에 정책 적용:",
    "references": [
      {
        "title": "ILM: Manage the index lifecycle",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/index-lifecycle-management.html"
      }
    ],
    "keywords": [
      "ilm",
      "index",
      "lifecycle",
      "management",
      "phases",
      "hot",
      "warm",
      "cold",
      "frozen",
      "delete",
      "인덱스의",
      "생명주기를",
      "자동으로",
      "관리하는",
      "기능입니다"
    ]
  },
  {
    "id": "ES-034",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Logstash, Beats 등과의 연동을 통한 데이터 수집 및 처리 방식에 대해 설명해주세요.",
    "answer": "Elastic Stack 데이터 수집 컴포넌트:\nBeats (경량 데이터 수집기):\nFilebeat: 로그 파일 수집\nMetricbeat: 시스템/서비스 메트릭\nPacketbeat: 네트워크 패킷 분석\nHeartbeat: 업타임 모니터링\nAuditbeat: 감사 데이터\nLogstash (데이터 처리 파이프라인):\nInput → Filter → Output 구조\n복잡한 데이터 변환, 정제, 보강\nIngest Pipeline (ES 내장):\n인덱싱 전 경량 데이터 처리\nLogstash 없이 간단한 변환 수행\n\n아키텍처 패턴:\n간단: Beats → Elasticsearch\n표준: Beats → Logstash → Elasticsearch\n버퍼: Beats → Kafka → Logstash → Elasticsearch",
    "references": [
      {
        "title": "Ingest pipelines",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/ingest.html"
      }
    ],
    "keywords": [
      "elastic",
      "stack",
      "beats",
      "filebeat",
      "metricbeat",
      "packetbeat",
      "heartbeat",
      "auditbeat",
      "logstash",
      "input",
      "filter",
      "output",
      "ingest",
      "pipeline",
      "elasticsearch"
    ]
  },
  {
    "id": "ES-035",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Elasticsearch의 보안 기능(예: X-Pack Security)과 설정 방법에 대해 설명해주세요.",
    "answer": "Elasticsearch Security (기본 라이선스에 포함)는 클러스터 보안을 위한 핵심 기능을 제공합니다.\n\n주요 보안 기능:\n인증 (Authentication):\nNative realm (내장 사용자)\nLDAP, Active Directory\nSAML, OpenID Connect\nAPI Key, Token\n권한 부여 (Authorization):\nRole-Based Access Control (RBAC)\n인덱스, 문서, 필드 수준 권한\n암호화:\nTLS/SSL (노드 간, 클라이언트-클러스터)\n저장 데이터 암호화\n\n기본 설정 (elasticsearch.yml):\n\n사용자 생성:\n\n역할 생성:\n\nAPI Key 생성:",
    "references": [
      {
        "title": "Secure the Elastic Stack",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/secure-cluster.html"
      }
    ],
    "keywords": [
      "elasticsearch",
      "security",
      "authentication",
      "native",
      "ldap",
      "active",
      "directory",
      "saml",
      "openid",
      "connect",
      "api",
      "key",
      "token",
      "authorization",
      "role-based"
    ]
  },
  {
    "id": "ES-036",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Role-Based Access Control(RBAC)과 Document Level Security의 차이에 대해 설명해주세요.",
    "answer": "RBAC (Role-Based Access Control):\n역할 기반으로 클러스터, 인덱스, 필드 수준의 접근 권한을 제어합니다.\n\nDocument Level Security (DLS):\n역할 내에서 특정 조건에 맞는 문서만 접근할 수 있도록 제한합니다.\n\n→ team: teama인 문서만 조회 가능\n\nField Level Security (FLS):\n특정 필드만 접근 가능하도록 제한합니다.\n\n비교:\n\n구분   RBAC   DLS   FLS\n\n제어 수준   클러스터/인덱스   문서   필드\n적용 방식   privileges   query   field_security\n사용 사례   기본 권한 관리   멀티테넌시   민감정보 보호",
    "references": [
      {
        "title": "Document level security",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/document-level-security.html"
      },
      {
        "title": "Field level security",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/field-level-security.html"
      }
    ],
    "keywords": [
      "rbac",
      "role-based",
      "access",
      "control",
      "document",
      "level",
      "security",
      "dls",
      "field",
      "fls",
      "field_security",
      "역할",
      "기반으로",
      "클러스터",
      "인덱스"
    ]
  },
  {
    "id": "ES-037",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "커스텀 분석기(Custom Analyzer)를 생성하고 적용하는 방법은 무엇인가요?",
    "answer": "커스텀 분석기는 Character Filter, Tokenizer, Token Filter를 조합하여 만듭니다.\n\n생성 방법:\n\n매핑에 적용:\n\n분석 테스트:\n\n한글 분석기 예시 (nori):",
    "references": [
      {
        "title": "Create a custom analyzer",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-custom-analyzer.html"
      }
    ],
    "keywords": [
      "character",
      "filter",
      "tokenizer",
      "token",
      "커스텀",
      "분석기는",
      "조합하여",
      "만듭니다",
      "생성",
      "방법",
      "매핑에",
      "적용",
      "분석",
      "테스트",
      "한글"
    ]
  },
  {
    "id": "ES-038",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "멀티테넌시를 지원하기 위한 Elasticsearch의 접근 방식은 무엇인가요?",
    "answer": "멀티테넌시는 여러 테넌트(사용자/조직)가 동일한 Elasticsearch 클러스터를 공유하면서 데이터를 격리하는 방식입니다.\n\n접근 방식:\n테넌트별 인덱스:\n장점: 완전한 격리, 독립적 매핑/설정\n단점: 인덱스 수 증가, 관리 복잡성\n테넌트 필드 + DLS:\n장점: 인덱스 관리 단순화\n단점: 잘못된 쿼리로 데이터 노출 위험\n인덱스 Alias + 필터:\n별도 클러스터:\n장점: 완전한 격리, 성능 영향 없음\n단점: 운영 비용 증가\n\n선택 기준:\n요구사항   권장 방식\n\n강력한 격리   별도 클러스터\n많은 테넌트   DLS + 단일 인덱스\n독립적 설정 필요   테넌트별 인덱스",
    "references": [
      {
        "title": "Document level security",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/document-level-security.html"
      }
    ],
    "keywords": [
      "elasticsearch",
      "dls",
      "alias",
      "멀티테넌시는",
      "여러",
      "테넌트",
      "사용자",
      "조직",
      "동일한",
      "클러스터를",
      "공유하면서",
      "데이터를",
      "격리하는",
      "방식입니다",
      "접근"
    ]
  },
  {
    "id": "ES-039",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Bulk API 사용 시 성능 최적화 및 주의사항은 무엇인가요?",
    "answer": "Bulk API는 여러 인덱싱/삭제/업데이트 작업을 단일 요청으로 처리합니다.\n\n기본 구조:\n\n성능 최적화:\n적절한 배치 크기:\n권장: 5-15MB per request\n문서 수보다 바이트 크기 기준\n테스트로 최적값 찾기\n병렬 처리:\n여러 스레드에서 동시 Bulk 요청\n노드 수 × 2 정도의 병렬 요청\nRefresh 비활성화:\nReplica 비활성화 (초기 로딩 시):\n\n주의사항:\n응답 확인: 부분 실패 가능, errors: true 체크\n재시도 로직: 429 (Too Many Requests) 시 백오프\n메모리 관리: 너무 큰 배치는 OOM 위험\n순서 보장: 동일 문서 작업은 순서대로 처리",
    "references": [
      {
        "title": "Bulk API",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html"
      }
    ],
    "keywords": [
      "bulk",
      "api",
      "refresh",
      "replica",
      "many",
      "requests",
      "oom",
      "여러",
      "인덱싱",
      "삭제",
      "업데이트",
      "작업을",
      "단일",
      "요청으로",
      "처리합니다"
    ]
  },
  {
    "id": "ES-040",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Latency와 Throughput 튜닝을 위한 Elasticsearch 설정 방법에 대해 설명해주세요.",
    "answer": "Latency (지연시간) 최적화:\n검색 성능:\n힙 메모리 설정:\nThread Pool 조정:\n\nThroughput (처리량) 최적화:\n인덱싱 성능:\nBulk 처리:\n적절한 배치 크기 (5-15MB)\n병렬 요청 활용\nMerge 설정:\n\n모니터링 지표:\n지표   확인 방법\n\n검색 지연   nodes/stats/indices/search\n인덱싱 속도   nodes/stats/indices/indexing\nGC 시간   nodes/stats/jvm\n큐 대기   nodes/stats/threadpool",
    "references": [
      {
        "title": "Tune for indexing speed",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html"
      }
    ],
    "keywords": [
      "latency",
      "thread",
      "pool",
      "throughput",
      "bulk",
      "merge",
      "지연시간",
      "최적화",
      "검색",
      "성능",
      "메모리",
      "설정",
      "조정",
      "처리량",
      "인덱싱"
    ]
  },
  {
    "id": "ES-041",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "복잡한 검색 조건을 구현하기 위한 Query DSL 활용 사례를 설명해주세요.",
    "answer": "복합 검색 예시:\n다중 조건 검색 (AND, OR, NOT 조합):\nNested 객체 검색:\n다중 필드 + 가중치:\nFunction Score (커스텀 점수):\nAggregation + 필터:",
    "references": [
      {
        "title": "Compound queries",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/compound-queries.html"
      }
    ],
    "keywords": [
      "nested",
      "function",
      "score",
      "aggregation",
      "복합",
      "검색",
      "예시",
      "다중",
      "조건",
      "조합",
      "객체",
      "필드",
      "가중치",
      "커스텀",
      "점수"
    ]
  },
  {
    "id": "ES-042",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Reindex API의 사용 목적과 동작 방식에 대해 설명해주세요.",
    "answer": "Reindex API는 한 인덱스의 데이터를 다른 인덱스로 복사합니다.\n\n사용 목적:\n매핑 변경 (기존 필드 타입 변경 불가하므로)\n샤드 수 변경\n분석기 변경\n인덱스 분할/병합\n데이터 마이그레이션\n\n기본 사용법:\n\n고급 옵션:\n선택적 복사 (쿼리 적용):\n필드 변환 (스크립트):\n원격 클러스터에서 복사:\n비동기 실행:\n\n성능 최적화:\nslices: auto - 병렬 처리\nrefresh: false - 완료 후 수동 refresh\nrequestsper_second - 스로틀링",
    "references": [
      {
        "title": "Reindex API",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html"
      }
    ],
    "keywords": [
      "reindex",
      "api",
      "requestsper_second",
      "인덱스의",
      "데이터를",
      "다른",
      "인덱스로",
      "복사합니다",
      "사용",
      "목적",
      "매핑",
      "변경",
      "기존",
      "필드",
      "타입"
    ]
  },
  {
    "id": "ES-043",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Snapshot Repository 구성 및 관리 방법에 대해 설명해주세요.",
    "answer": "Snapshot Repository는 스냅샷을 저장하는 위치입니다.\n\n지원 저장소 유형:\nShared File System (fs)\nAWS S3 (s3)\nGoogle Cloud Storage (gcs)\nAzure Blob Storage (azure)\nHDFS (hdfs)\n\n파일시스템 Repository 구성:\n경로 설정 (elasticsearch.yml):\nRepository 생성:\n\nS3 Repository 구성:\n\n관리 작업:\n\nRepository 확인:\n\nRepository 검증:\n\n스냅샷 목록:\n\n스냅샷 상태:\n\nRepository 삭제:\n\n주의사항:\n여러 클러스터가 같은 repository 공유 시 읽기 전용 설정 필요\nRepository 삭제 전 스냅샷 먼저 삭제\n충분한 저장 공간 확보",
    "references": [
      {
        "title": "Register a snapshot repository",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshots-register-repository.html"
      }
    ],
    "keywords": [
      "snapshot",
      "repository",
      "shared",
      "file",
      "system",
      "aws",
      "google",
      "cloud",
      "storage",
      "azure",
      "blob",
      "hdfs",
      "스냅샷을",
      "저장하는",
      "위치입니다"
    ]
  },
  {
    "id": "ES-044",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "데이터 정합성(consistency) 모델과 Elasticsearch의 eventual consistency 특성에 대해 설명해주세요.",
    "answer": "Elasticsearch의 일관성 모델:\n\nElasticsearch는 Eventual Consistency (최종 일관성) 모델을 따릅니다.\n\n쓰기 일관성:\nPrimary-Replica 복제:\n쓰기는 Primary Shard에서 먼저 처리\n이후 Replica에 복제\n기본적으로 모든 in-sync replica 복제 완료 후 응답\nwaitforactiveshards 설정:\n1: Primary만\nall: 모든 복제본\n숫자: 지정된 수의 샤드\n\n읽기 일관성:\nRefresh 간격:\n기본 1초마다 refresh\nrefresh 전에는 새 데이터 검색 불가\n실시간 읽기:\n\n일관성 보장 수준:\n\n작업   일관성\n\nGET (by ID)   강한 일관성\nSearch   Eventual (refresh 후)\nWrite   설정에 따라 조절 가능\n\nEventual Consistency 영향:\n쓰기 직후 검색 시 결과에 포함 안 될 수 있음\nRead-after-Write 보장 필요 시 refresh=true 사용\n\nACID와의 비교:\nElasticsearch는 단일 문서 수준의 원자성만 보장\n다중 문서 트랜잭션 미지원\n분산 환경에서 가용성과 성능 우선",
    "references": [
      {
        "title": "Near real-time search",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/near-real-time.html"
      }
    ],
    "keywords": [
      "elasticsearch",
      "eventual",
      "consistency",
      "primary-replica",
      "primary",
      "shard",
      "replica",
      "in-sync",
      "refresh",
      "get",
      "search",
      "write",
      "read-after-write",
      "acid",
      "일관성"
    ]
  },
  {
    "id": "ES-045",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "인덱스 및 도큐먼트 크기 최적화를 위한 전략은 무엇인가요?",
    "answer": "인덱스 크기 최적화:\n불필요한 필드 제거:\ndocvalues 비활성화 (정렬/집계 불필요 시):\nsource 필드 관리:\n적절한 데이터 타입:\nkeyword vs text 선택\ninteger vs long vs short\nscaledfloat 사용 (정밀도 조절)\n\n도큐먼트 크기 최적화:\n정규화 vs 비정규화:\n자주 변경되는 데이터: 정규화 (별도 인덱스)\n검색 성능 중요: 비정규화 (임베딩)\n배열 크기 제한:\nNested 객체 제한:\n과도한 nested 객체는 성능 저하\n가능하면 flattened 타입 고려\n\nForce Merge:\n읽기 전용 인덱스에 적용\n세그먼트 수 감소로 검색 성능 향상",
    "references": [
      {
        "title": "Tune for disk usage",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-disk-usage.html"
      }
    ],
    "keywords": [
      "nested",
      "force",
      "merge",
      "인덱스",
      "크기",
      "최적화",
      "불필요한",
      "필드",
      "제거",
      "비활성화",
      "정렬",
      "집계",
      "불필요",
      "관리",
      "적절한"
    ]
  },
  {
    "id": "ES-046",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "파이프라인(pipeline) 처리 기능과 Ingest Node의 역할에 대해 설명해주세요.",
    "answer": "Ingest Pipeline은 인덱싱 전 데이터를 변환, 보강, 정제하는 기능입니다.\n\nIngest Node 역할:\n파이프라인 프로세서 실행\n인덱싱 전 데이터 전처리\nLogstash 대체 가능 (간단한 변환)\n\n파이프라인 구성요소:\nProcessors: 데이터 변환 단위\nonfailure: 오류 처리\n\n파이프라인 생성:\n\n주요 프로세서:\n프로세서   기능\n\ngrok   정규식 패턴 추출\ndate   날짜 파싱\nset   필드 값 설정\nremove   필드 삭제\nrename   필드명 변경\nconvert   타입 변환\nscript   커스텀 스크립트\nenrich   외부 데이터 보강\n\n파이프라인 적용:",
    "references": [
      {
        "title": "Ingest pipelines",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/ingest.html"
      }
    ],
    "keywords": [
      "ingest",
      "pipeline",
      "node",
      "logstash",
      "processors",
      "인덱싱",
      "데이터를",
      "변환",
      "보강",
      "정제하는",
      "기능입니다",
      "역할",
      "파이프라인",
      "프로세서",
      "실행"
    ]
  },
  {
    "id": "ES-047",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Hot-Warm-Cold 아키텍처의 개념과 구현 방법에 대해 설명해주세요.",
    "answer": "Hot-Warm-Cold 아키텍처는 데이터 접근 패턴에 따라 스토리지 티어를 분리하여 비용과 성능을 최적화합니다.\n\n티어별 특성:\n\n티어   데이터 특성   하드웨어   접근 빈도\n\nHot   최신, 활발한 쓰기/읽기   SSD, 고성능   높음\nWarm   과거, 읽기 전용   HDD, 중간   중간\nCold   오래된, 드문 접근   대용량 HDD   낮음\nFrozen   아카이브   오브젝트 스토리지   매우 낮음\n\n구현 방법:\n노드 역할 설정 (elasticsearch.yml):\nILM 정책 설정:\n인덱스 템플릿 연결:",
    "references": [
      {
        "title": "Data tiers",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/data-tiers.html"
      }
    ],
    "keywords": [
      "hot-warm-cold",
      "hot",
      "ssd",
      "warm",
      "hdd",
      "cold",
      "frozen",
      "ilm",
      "아키텍처는",
      "데이터",
      "접근",
      "패턴에",
      "따라",
      "스토리지",
      "티어를"
    ]
  },
  {
    "id": "ES-048",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "커스텀 스크립팅의 활용과 성능에 미치는 영향에 대해 설명해주세요.",
    "answer": "Painless는 Elasticsearch의 기본 스크립팅 언어로, 안전하고 빠른 스크립트 실행을 지원합니다.\n\n활용 사례:\n스크립트 필드:\n스크립트 업데이트:\n스크립트 쿼리:\nIngest Pipeline:\n\n성능 영향:\n\n요소   영향   권장 사항\n\n컴파일   초기 비용 발생   파라미터화로 재사용\ndocvalues   빠른 필드 접근   doc['field'].value 사용\nsource   느린 접근   가능하면 피하기\n복잡한 로직   CPU 부하   단순화, 인덱싱 시 계산\n\n최적화 방법:\n\n컴파일 캐시 설정:",
    "references": [
      {
        "title": "Painless scripting language",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-painless.html"
      }
    ],
    "keywords": [
      "painless",
      "elasticsearch",
      "ingest",
      "pipeline",
      "cpu",
      "기본",
      "스크립팅",
      "언어로",
      "안전하고",
      "빠른",
      "스크립트",
      "실행을",
      "지원합니다",
      "활용",
      "사례"
    ]
  },
  {
    "id": "ES-049",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "Elasticsearch 클러스터에서 발생할 수 있는 장애와 복구 전략은 무엇인가요?",
    "answer": "주요 장애 유형과 복구 전략:\n노드 장애:\n증상: 클러스터 Yellow/Red 상태\n자동 복구: Replica가 Primary로 승격\n수동 복구: 노드 재시작 또는 교체\n마스터 노드 장애:\n증상: 클러스터 작업 불가\n자동 복구: Master-eligible 노드 중 새 마스터 선출\n예방: 최소 3개 Master-eligible 노드\n디스크 용량 부족:\n증상: 인덱싱 차단, Read-only 전환\n복구:\n데이터 손상:\n복구: 스냅샷에서 복원\nSplit-Brain:\n예방: discovery.zen.minimummasternodes (7.x 이전)\n7.x 이후 자동 quorum 관리\n\n모니터링 및 예방:",
    "references": [
      {
        "title": "Fix common cluster issues",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/fix-common-cluster-issues.html"
      }
    ],
    "keywords": [
      "yellow",
      "red",
      "replica",
      "primary",
      "master-eligible",
      "read-only",
      "split-brain",
      "주요",
      "장애",
      "유형과",
      "복구",
      "전략",
      "노드",
      "증상",
      "클러스터"
    ]
  },
  {
    "id": "ES-050",
    "category": "elasticsearch",
    "categoryName": "Elasticsearch",
    "priority": "P3",
    "question": "최근 Elasticsearch의 업데이트 및 새로운 기능에 대해 알고 있는 내용을 공유해주세요.",
    "answer": "Elasticsearch 8.x 주요 기능:\n보안 기본 활성화:\nTLS, 인증이 기본으로 활성화\n설치 시 자동 인증서 생성\nelastic 사용자 비밀번호 자동 생성\nkNN (k-Nearest Neighbor) 검색:\n벡터 유사도 검색 네이티브 지원\n시맨틱 검색, 추천 시스템에 활용\nESQL (ES|QL):\n새로운 파이프 기반 쿼리 언어\nServerless Elasticsearch:\n완전 관리형 서버리스 배포 옵션\n자동 스케일링, 운영 부담 감소\n향상된 머신러닝:\nTransformer 모델 통합\nNLP 작업 (텍스트 분류, NER, 감정 분석)\nELSER (Elastic Learned Sparse EncodeR)\n성능 개선:\n더 빠른 집계\n향상된 인덱싱 속도\n메모리 사용 최적화\nFrozen Tier 개선:\nSearchable Snapshots\n비용 효율적인 장기 데이터 보관\nData Streams 개선:\nTSDS (Time Series Data Streams)\n시계열 데이터 최적화 저장",
    "references": [
      {
        "title": "What's new in Elasticsearch",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/release-highlights.html"
      }
    ],
    "keywords": [
      "elasticsearch",
      "tls",
      "nearest",
      "neighbor",
      "esql",
      "serverless",
      "transformer",
      "nlp",
      "ner",
      "elser",
      "elastic",
      "learned",
      "sparse",
      "encoder",
      "frozen"
    ]
  },
  {
    "id": "MONGO-001",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB란 무엇이며, RDBMS와 어떤 차이가 있나요?",
    "answer": "MongoDB는 문서 지향(Document-Oriented) NoSQL 데이터베이스입니다.\n\nRDBMS와의 주요 차이점:\n데이터 모델: RDBMS는 테이블(행/열), MongoDB는 Document(BSON)\n스키마: RDBMS는 고정 스키마, MongoDB는 유연한 스키마\n관계: RDBMS는 JOIN, MongoDB는 Embedding 또는 Reference\n확장: RDBMS는 수직 확장, MongoDB는 수평 확장(Sharding)",
    "references": [
      {
        "title": "SQL to MongoDB Mapping",
        "url": "https://www.mongodb.com/docs/manual/reference/sql-comparison/"
      }
    ],
    "keywords": [
      "mongodb",
      "document-oriented",
      "nosql",
      "rdbms",
      "document",
      "bson",
      "join",
      "embedding",
      "reference",
      "sharding",
      "문서",
      "지향",
      "데이터베이스입니다",
      "와의",
      "주요"
    ]
  },
  {
    "id": "MONGO-002",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "NoSQL 데이터베이스의 종류와 MongoDB가 속한 유형은 무엇인가요?",
    "answer": "NoSQL 데이터베이스 4가지 유형:\nDocument Store: MongoDB, CouchDB - JSON/BSON 문서 저장\nKey-Value Store: Redis, DynamoDB - 키-값 쌍 저장\nColumn-Family Store: Cassandra, HBase - 컬럼 기반 저장\nGraph Database: Neo4j - 노드와 관계 저장\n\nMongoDB는 Document Store 유형에 속하며, 데이터를 BSON 형식의 문서로 저장합니다.",
    "references": [
      {
        "title": "MongoDB Introduction",
        "url": "https://www.mongodb.com/docs/manual/introduction/"
      }
    ],
    "keywords": [
      "nosql",
      "document",
      "store",
      "mongodb",
      "couchdb",
      "json",
      "bson",
      "key-value",
      "redis",
      "dynamodb",
      "column-family",
      "cassandra",
      "hbase",
      "graph",
      "database"
    ]
  },
  {
    "id": "MONGO-003",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB를 사용하는 이유와 장단점은 무엇인가요?",
    "answer": "장점:\n유연한 스키마로 빠른 개발 가능\n수평 확장(Sharding)이 용이\n높은 읽기/쓰기 성능\n풍부한 쿼리 언어와 Aggregation Framework\n내장 복제(Replica Set)로 고가용성\n\n단점:\n복잡한 JOIN 연산에 비효율적\n메모리 사용량이 높음\n트랜잭션 오버헤드(Multi-Document)",
    "references": [
      {
        "title": "MongoDB Introduction",
        "url": "https://www.mongodb.com/docs/manual/introduction/"
      }
    ],
    "keywords": [
      "sharding",
      "aggregation",
      "framework",
      "replica",
      "set",
      "join",
      "multi-document",
      "장점",
      "유연한",
      "스키마로",
      "빠른",
      "개발",
      "가능",
      "수평",
      "확장"
    ]
  },
  {
    "id": "MONGO-004",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "BSON이란 무엇이며, JSON과의 차이점은 무엇인가요?",
    "answer": "BSON(Binary JSON)은 JSON의 바이너리 인코딩 형식입니다.\n\nJSON과의 차이점:\n형식: JSON은 텍스트, BSON은 바이너리\n데이터 타입: BSON은 Date, ObjectId, Binary 등 추가 타입 지원\n크기: BSON은 길이 정보 포함으로 순회가 빠름\n효율성: BSON이 인코딩/디코딩 속도가 빠름",
    "references": [
      {
        "title": "BSON Types",
        "url": "https://www.mongodb.com/docs/manual/reference/bson-types/"
      }
    ],
    "keywords": [
      "bson",
      "binary",
      "json",
      "date",
      "objectid",
      "바이너리",
      "인코딩",
      "형식입니다",
      "과의",
      "차이점",
      "형식",
      "텍스트",
      "데이터",
      "타입",
      "추가"
    ]
  },
  {
    "id": "MONGO-005",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Collection과 Document의 개념을 설명해주세요.",
    "answer": "Document:\nMongoDB의 기본 데이터 단위 (RDBMS의 행에 해당)\nBSON 형식으로 저장되는 필드-값 쌍의 집합\n최대 크기 16MB\n\nCollection:\nDocument들의 그룹 (RDBMS의 테이블에 해당)\n동적 스키마로 다른 구조의 Document 포함 가능",
    "references": [
      {
        "title": "Documents",
        "url": "https://www.mongodb.com/docs/manual/core/document/"
      }
    ],
    "keywords": [
      "document",
      "mongodb",
      "rdbms",
      "bson",
      "collection",
      "기본",
      "데이터",
      "단위",
      "행에",
      "해당",
      "형식으로",
      "저장되는",
      "필드",
      "쌍의",
      "집합"
    ]
  },
  {
    "id": "MONGO-006",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB의 스키마리스(Schema-less) 특성은 무엇을 의미하나요?",
    "answer": "스키마리스란 컬렉션 내 Document들이 동일한 필드 구조를 가질 필요가 없다는 의미입니다.\n\n특징:\n같은 컬렉션에 다른 필드를 가진 Document 저장 가능\n필드 추가/삭제 시 스키마 변경 불필요\n빠른 개발과 반복이 가능\n\n주의점:\nSchema Validation으로 유효성 검증 가능\n애플리케이션 레벨에서 스키마 관리 필요",
    "references": [
      {
        "title": "Data Modeling",
        "url": "https://www.mongodb.com/docs/manual/data-modeling/"
      }
    ],
    "keywords": [
      "document",
      "schema",
      "validation",
      "스키마리스란",
      "컬렉션",
      "들이",
      "동일한",
      "필드",
      "구조를",
      "가질",
      "필요가",
      "없다는",
      "의미입니다",
      "특징",
      "같은"
    ]
  },
  {
    "id": "MONGO-007",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB에서 Schema Design의 중요한 원칙은 무엇인가요?",
    "answer": "주요 설계 원칙:\n함께 조회되는 데이터는 함께 저장 - Embedding 활용\n애플리케이션의 접근 패턴 기반 설계 - 읽기/쓰기 비율 고려\nDocument 크기 제한(16MB) 고려\n인덱싱 전략 수립\n데이터 중복 vs 참조 트레이드오프 판단\n\nAnti-patterns 피하기:\n무한 성장하는 배열\n과도한 Embedding\n불필요한 Normalization",
    "references": [
      {
        "title": "Data Modeling Introduction",
        "url": "https://www.mongodb.com/docs/manual/core/data-modeling-introduction/"
      }
    ],
    "keywords": [
      "embedding",
      "document",
      "anti-patterns",
      "normalization",
      "주요",
      "설계",
      "원칙",
      "함께",
      "조회되는",
      "데이터는",
      "저장",
      "활용",
      "애플리케이션의",
      "접근",
      "패턴"
    ]
  },
  {
    "id": "MONGO-008",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Embedding(내장)과 Referencing(참조) 방식의 차이와 각각 언제 사용하나요?",
    "answer": "Embedding (내장):\n한 번의 쿼리로 모든 데이터 조회\n1:1, 1:Few 관계에 적합\n데이터가 함께 조회될 때 사용\n\nReferencing (참조):\n데이터 중복 방지\n1:Many, Many:Many 관계에 적합\n독립적으로 접근하는 데이터에 사용",
    "references": [
      {
        "title": "Data Model Design",
        "url": "https://www.mongodb.com/docs/manual/core/data-model-design/"
      }
    ],
    "keywords": [
      "embedding",
      "few",
      "referencing",
      "many",
      "내장",
      "번의",
      "쿼리로",
      "모든",
      "데이터",
      "조회",
      "관계에",
      "적합",
      "데이터가",
      "함께",
      "조회될"
    ]
  },
  {
    "id": "MONGO-009",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "One-to-Many 관계를 MongoDB에서 어떻게 설계하나요?",
    "answer": "Embedding (1:Few):\nChild Reference (1:Many):\nParent Reference (1:Squillions):",
    "references": [
      {
        "title": "Model One-to-Many Relationships",
        "url": "https://www.mongodb.com/docs/manual/tutorial/model-embedded-one-to-many-relationships-between-documents/"
      }
    ],
    "keywords": [
      "embedding",
      "few",
      "child",
      "reference",
      "many",
      "parent",
      "squillions"
    ]
  },
  {
    "id": "MONGO-010",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Many-to-Many 관계를 MongoDB에서 어떻게 설계하나요?",
    "answer": "양쪽 Document에 참조 배열 저장:\n\n$lookup으로 조인:\n\n고려사항: 배열 크기가 커지면 별도 Junction Collection 사용",
    "references": [
      {
        "title": "Model Many-to-Many Relationships",
        "url": "https://www.mongodb.com/docs/manual/tutorial/model-embedded-many-to-many-relationships-between-documents/"
      }
    ],
    "keywords": [
      "document",
      "junction",
      "collection",
      "양쪽",
      "참조",
      "배열",
      "저장",
      "으로",
      "조인",
      "고려사항",
      "크기가",
      "커지면",
      "별도",
      "사용"
    ]
  },
  {
    "id": "MONGO-011",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Document의 크기 제한은 얼마이며, 큰 데이터는 어떻게 처리하나요?",
    "answer": "Document 크기 제한: 16MB\n\n큰 데이터 처리 방법:\nGridFS 사용 - 16MB 초과 파일을 청크로 분할 저장\n데이터 분리 - 큰 필드를 별도 Collection으로 분리\n참조 사용 - Embedding 대신 Reference 활용\n압축 - 바이너리 데이터 압축 후 저장",
    "references": [
      {
        "title": "Document Size Limit",
        "url": "https://www.mongodb.com/docs/manual/reference/limits/#bson-document-size"
      }
    ],
    "keywords": [
      "document",
      "gridfs",
      "collection",
      "embedding",
      "reference",
      "크기",
      "제한",
      "데이터",
      "처리",
      "방법",
      "사용",
      "초과",
      "파일을",
      "청크로",
      "분할"
    ]
  },
  {
    "id": "MONGO-012",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "GridFS란 무엇이며 언제 사용하나요?",
    "answer": "GridFS는 16MB를 초과하는 대용량 파일을 저장하기 위한 MongoDB 스펙입니다.\n\n작동 방식:\n파일을 255KB 청크로 분할\nfs.files: 파일 메타데이터 저장\nfs.chunks: 실제 데이터 청크 저장\n\n사용 사례:\n이미지, 비디오, 오디오 파일 저장\n대용량 문서 저장\n파일 시스템 제한 우회",
    "references": [
      {
        "title": "GridFS",
        "url": "https://www.mongodb.com/docs/manual/core/gridfs/"
      }
    ],
    "keywords": [
      "gridfs",
      "mongodb",
      "초과하는",
      "대용량",
      "파일을",
      "저장하기",
      "위한",
      "스펙입니다",
      "작동",
      "방식",
      "청크로",
      "분할",
      "파일",
      "메타데이터",
      "저장"
    ]
  },
  {
    "id": "MONGO-013",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB의 기본 CRUD 작업을 설명해주세요.",
    "answer": "Create:\n\nRead:\n\nUpdate:\n\nDelete:",
    "references": [
      {
        "title": "CRUD Operations",
        "url": "https://www.mongodb.com/docs/manual/crud/"
      }
    ],
    "keywords": [
      "create",
      "read",
      "update",
      "delete"
    ]
  },
  {
    "id": "MONGO-014",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "find()와 findOne()의 차이는 무엇인가요?",
    "answer": "구분   find()   findOne()\n\n반환   Cursor (여러 Document)   단일 Document 또는 null\n용도   복수 결과 조회   단일 결과 조회\n성능   limit 없으면 전체 스캔   첫 번째 매칭 후 중단",
    "references": [
      {
        "title": "find()",
        "url": "https://www.mongodb.com/docs/manual/reference/method/db.collection.find/"
      }
    ],
    "keywords": [
      "cursor",
      "document",
      "구분",
      "반환",
      "여러",
      "단일",
      "용도",
      "복수",
      "결과",
      "조회",
      "성능",
      "없으면",
      "전체",
      "스캔",
      "번째"
    ]
  },
  {
    "id": "MONGO-015",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB의 쿼리 연산자($eq, $gt, $in, $and, $or 등)를 설명해주세요.",
    "answer": "비교 연산자:\n$eq: 같음 / $ne: 같지 않음\n$gt: 초과 / $gte: 이상\n$lt: 미만 / $lte: 이하\n$in: 배열 내 포함 / $nin: 포함되지 않음\n\n논리 연산자:\n$and: AND 조건\n$or: OR 조건\n$not: 부정\n$nor: 모든 조건 불만족",
    "references": [
      {
        "title": "Query Operators",
        "url": "https://www.mongodb.com/docs/manual/reference/operator/query/"
      }
    ],
    "keywords": [
      "비교",
      "연산자",
      "같음",
      "같지",
      "않음",
      "초과",
      "이상",
      "미만",
      "이하",
      "배열",
      "포함",
      "포함되지",
      "논리",
      "조건",
      "부정"
    ]
  },
  {
    "id": "MONGO-016",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Projection이란 무엇이며 어떻게 사용하나요?",
    "answer": "Projection은 쿼리 결과에서 반환할 필드를 지정하는 기능입니다.\n\n주의사항:\n포함(1)과 제외(0)를 혼용할 수 없음 (id 제외)\n네트워크 대역폭과 메모리 절약에 효과적",
    "references": [
      {
        "title": "Project Fields",
        "url": "https://www.mongodb.com/docs/manual/tutorial/project-fields-from-query-results/"
      }
    ],
    "keywords": [
      "projection",
      "쿼리",
      "결과에서",
      "반환할",
      "필드를",
      "지정하는",
      "기능입니다",
      "주의사항",
      "포함",
      "제외",
      "혼용할",
      "없음",
      "네트워크",
      "대역폭과",
      "메모리"
    ]
  },
  {
    "id": "MONGO-017",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB의 인덱스 종류와 각각의 특징을 설명해주세요.",
    "answer": "주요 인덱스 종류:\nSingle Field Index: 단일 필드 인덱스\nCompound Index: 복합 필드 인덱스\nMultikey Index: 배열 필드 인덱스\nText Index: 텍스트 검색용 인덱스\nGeospatial Index: 지리 데이터용 (2d, 2dsphere)\nHashed Index: 해시 기반 Sharding용\nTTL Index: 자동 문서 만료",
    "references": [
      {
        "title": "Index Types",
        "url": "https://www.mongodb.com/docs/manual/indexes/"
      }
    ],
    "keywords": [
      "single",
      "field",
      "index",
      "compound",
      "multikey",
      "text",
      "geospatial",
      "hashed",
      "sharding",
      "ttl",
      "주요",
      "인덱스",
      "종류",
      "단일",
      "필드"
    ]
  },
  {
    "id": "MONGO-018",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Compound Index(복합 인덱스)란 무엇이며 언제 사용하나요?",
    "answer": "복합 인덱스는 여러 필드를 조합한 인덱스입니다.\n\n사용 시점:\n여러 필드로 자주 검색/정렬할 때\n복합 조건 쿼리 최적화 시\n\nESR 규칙 (권장 순서):\nEquality: 등가 조건 필드 먼저\nSort: 정렬 필드\nRange: 범위 조건 필드 마지막",
    "references": [
      {
        "title": "Compound Indexes",
        "url": "https://www.mongodb.com/docs/manual/core/index-compound/"
      }
    ],
    "keywords": [
      "esr",
      "equality",
      "sort",
      "range",
      "복합",
      "인덱스는",
      "여러",
      "필드를",
      "조합한",
      "인덱스입니다",
      "사용",
      "시점",
      "필드로",
      "자주",
      "검색"
    ]
  },
  {
    "id": "MONGO-019",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "인덱스의 순서가 쿼리 성능에 어떤 영향을 미치나요?",
    "answer": "복합 인덱스에서 필드 순서가 중요한 이유:\n\n인덱스 { a: 1, b: 1, c: 1 }의 경우:\n{ a: 1 } 쿼리: 사용 가능\n{ a: 1, b: 1 } 쿼리: 사용 가능\n{ b: 1 } 쿼리: 사용 불가 (prefix 없음)\n{ a: 1, c: 1 } 쿼리: a만 인덱스 활용\n\nPrefix Rule:\n복합 인덱스는 왼쪽부터 순서대로 사용됩니다.\n\n정렬 방향:",
    "references": [
      {
        "title": "Index Prefix",
        "url": "https://www.mongodb.com/docs/manual/core/index-compound/#prefixes"
      }
    ],
    "keywords": [
      "prefix",
      "rule",
      "복합",
      "인덱스에서",
      "필드",
      "순서가",
      "중요한",
      "이유",
      "인덱스",
      "쿼리",
      "사용",
      "가능",
      "불가",
      "없음",
      "활용"
    ]
  },
  {
    "id": "MONGO-020",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Text Index와 Geospatial Index는 무엇인가요?",
    "answer": "Text Index:\n텍스트 검색을 위한 인덱스로, 문자열 필드에서 단어 검색 지원\n\nGeospatial Index:\n지리적 데이터 쿼리를 위한 인덱스\n2dsphere: 구형 지구 기반 (GeoJSON)\n2d: 평면 좌표 기반",
    "references": [
      {
        "title": "Text Indexes",
        "url": "https://www.mongodb.com/docs/manual/core/index-text/"
      }
    ],
    "keywords": [
      "text",
      "index",
      "geospatial",
      "geojson",
      "텍스트",
      "검색을",
      "위한",
      "인덱스로",
      "문자열",
      "필드에서",
      "단어",
      "검색",
      "지원",
      "지리적",
      "데이터"
    ]
  },
  {
    "id": "MONGO-021",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "explain()을 사용하여 쿼리 성능을 분석하는 방법은?",
    "answer": "주요 확인 항목:\nqueryPlanner.winningPlan: 선택된 실행 계획\nstage: COLLSCAN(전체 스캔) vs IXSCAN(인덱스 스캔)\nexecutionStats.totalDocsExamined: 검사한 문서 수\nexecutionStats.executionTimeMillis: 실행 시간\n\n좋은 쿼리의 지표:\nstage가 IXSCAN\ntotalDocsExamined ≈ nReturned\nindexOnly: true (Covered Query)",
    "references": [
      {
        "title": "Explain Results",
        "url": "https://www.mongodb.com/docs/manual/reference/explain-results/"
      }
    ],
    "keywords": [
      "collscan",
      "ixscan",
      "covered",
      "query",
      "주요",
      "확인",
      "항목",
      "선택된",
      "실행",
      "계획",
      "전체",
      "스캔",
      "인덱스",
      "검사한",
      "문서"
    ]
  },
  {
    "id": "MONGO-022",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Covered Query란 무엇이며 어떻게 활용하나요?",
    "answer": "Covered Query는 인덱스만으로 쿼리를 완료할 수 있어 Document에 접근하지 않는 쿼리입니다.\n\n조건:\n모든 쿼리 필드가 인덱스에 포함\n모든 반환 필드가 인덱스에 포함\nid 필드가 projection에서 제외\n\nexplain()에서 확인:\ntotalDocsExamined: 0\nstage: IXSCAN (FETCH 없음)",
    "references": [
      {
        "title": "Covered Query",
        "url": "https://www.mongodb.com/docs/manual/core/query-optimization/#covered-query"
      }
    ],
    "keywords": [
      "covered",
      "query",
      "document",
      "ixscan",
      "fetch",
      "인덱스만으로",
      "쿼리를",
      "완료할",
      "있어",
      "접근하지",
      "않는",
      "쿼리입니다",
      "조건",
      "모든",
      "쿼리"
    ]
  },
  {
    "id": "MONGO-023",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Aggregation Pipeline이란 무엇인가요?",
    "answer": "Aggregation Pipeline은 문서를 여러 단계(Stage)를 거쳐 처리하는 데이터 처리 프레임워크입니다.\n\n특징:\n각 Stage의 출력이 다음 Stage의 입력\nSQL의 GROUP BY, JOIN 등의 기능 제공\n복잡한 데이터 변환 및 분석 가능",
    "references": [
      {
        "title": "Aggregation Pipeline",
        "url": "https://www.mongodb.com/docs/manual/core/aggregation-pipeline/"
      }
    ],
    "keywords": [
      "aggregation",
      "pipeline",
      "stage",
      "sql",
      "group",
      "join",
      "문서를",
      "여러",
      "단계",
      "거쳐",
      "처리하는",
      "데이터",
      "처리",
      "프레임워크입니다",
      "특징"
    ]
  },
  {
    "id": "MONGO-024",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Aggregation의 주요 Stage($match, $group, $project, $sort 등)를 설명해주세요.",
    "answer": "주요 Stage:\n\nStage   설명   SQL 대응\n\n$match   조건 필터링   WHERE\n$group   그룹화 및 집계   GROUP BY\n$project   필드 선택/변환   SELECT\n$sort   정렬   ORDER BY\n$limit   결과 제한   LIMIT\n$skip   결과 건너뛰기   OFFSET\n$lookup   다른 Collection 조인   JOIN\n$unwind   배열 펼치기   -",
    "references": [
      {
        "title": "Aggregation Stages",
        "url": "https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/"
      }
    ],
    "keywords": [
      "stage",
      "sql",
      "where",
      "group",
      "select",
      "order",
      "limit",
      "offset",
      "collection",
      "join",
      "주요",
      "설명",
      "대응",
      "조건",
      "필터링"
    ]
  },
  {
    "id": "MONGO-025",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "$lookup을 사용한 Join 작업을 설명해주세요.",
    "answer": "$lookup은 다른 Collection과 LEFT OUTER JOIN을 수행합니다.\n\n기본 문법:\n\nPipeline 사용 (5.0+):",
    "references": [
      {
        "title": "$lookup",
        "url": "https://www.mongodb.com/docs/manual/reference/operator/aggregation/lookup/"
      }
    ],
    "keywords": [
      "collection",
      "left",
      "outer",
      "join",
      "pipeline",
      "다른",
      "수행합니다",
      "기본",
      "문법",
      "사용"
    ]
  },
  {
    "id": "MONGO-026",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "$unwind는 언제 사용하며 어떤 역할을 하나요?",
    "answer": "$unwind는 배열 필드를 펼쳐서 각 요소마다 별도의 문서를 생성합니다.\n\n사용 시점:\n배열 요소별 집계가 필요할 때\n$lookup 결과 배열 처리 시\n배열 요소 기준 그룹화 시\n\n옵션:",
    "references": [
      {
        "title": "$unwind",
        "url": "https://www.mongodb.com/docs/manual/reference/operator/aggregation/unwind/"
      }
    ],
    "keywords": [
      "배열",
      "필드를",
      "펼쳐서",
      "요소마다",
      "별도의",
      "문서를",
      "생성합니다",
      "사용",
      "시점",
      "요소별",
      "집계가",
      "필요할",
      "결과",
      "처리",
      "요소"
    ]
  },
  {
    "id": "MONGO-027",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "$facet을 사용하여 여러 Aggregation을 동시에 실행하는 방법은?",
    "answer": "$facet은 동일한 입력 데이터에 여러 파이프라인을 병렬로 실행합니다.\n\n사용 사례:\n대시보드 데이터 조회\n페이지네이션 + 총 개수 동시 조회",
    "references": [
      {
        "title": "$facet",
        "url": "https://www.mongodb.com/docs/manual/reference/operator/aggregation/facet/"
      }
    ],
    "keywords": [
      "동일한",
      "입력",
      "데이터에",
      "여러",
      "파이프라인을",
      "병렬로",
      "실행합니다",
      "사용",
      "사례",
      "대시보드",
      "데이터",
      "조회",
      "페이지네이션",
      "개수",
      "동시"
    ]
  },
  {
    "id": "MONGO-028",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Aggregation Pipeline과 MapReduce의 차이는 무엇인가요?",
    "answer": "구분   Aggregation Pipeline   MapReduce\n\n성능   빠름 (네이티브 C++)   느림 (JavaScript)\n유연성   제한적 (Stage 기반)   높음 (임의 JS 코드)\n사용성   쉬움   복잡함\n권장   대부분의 경우 권장   5.0부터 Deprecated\n\nMongoDB 5.0+:\nMapReduce는 deprecated되었으며, Aggregation Pipeline 사용을 권장합니다. 복잡한 로직은 $accumulator나 $function으로 JavaScript 사용 가능합니다.",
    "references": [
      {
        "title": "Map-Reduce to Aggregation",
        "url": "https://www.mongodb.com/docs/manual/reference/map-reduce-to-aggregation-pipeline/"
      }
    ],
    "keywords": [
      "aggregation",
      "pipeline",
      "mapreduce",
      "javascript",
      "stage",
      "deprecated",
      "mongodb",
      "구분",
      "성능",
      "빠름",
      "네이티브",
      "느림",
      "유연성",
      "제한적",
      "기반"
    ]
  },
  {
    "id": "MONGO-029",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB의 Replication이란 무엇인가요?",
    "answer": "Replication은 여러 서버에 동일한 데이터를 복제하여 고가용성과 데이터 중복성을 제공하는 기능입니다.\n\n목적:\n고가용성: Primary 장애 시 자동 Failover\n데이터 보호: 데이터 손실 방지\n읽기 분산: Secondary에서 읽기 가능\n재해 복구: 지리적 분산 배치 가능\n\n작동 방식:\nPrimary가 모든 쓰기 처리\nOplog를 통해 Secondary에 변경사항 복제\nPrimary 장애 시 투표로 새 Primary 선출",
    "references": [
      {
        "title": "Replication",
        "url": "https://www.mongodb.com/docs/manual/replication/"
      }
    ],
    "keywords": [
      "replication",
      "primary",
      "failover",
      "secondary",
      "oplog",
      "여러",
      "서버에",
      "동일한",
      "데이터를",
      "복제하여",
      "고가용성과",
      "데이터",
      "중복성을",
      "제공하는",
      "기능입니다"
    ]
  },
  {
    "id": "MONGO-030",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Replica Set의 구조와 역할을 설명해주세요.",
    "answer": "Replica Set은 동일한 데이터를 가진 MongoDB 인스턴스 그룹입니다.\n\n구조:\n\n권장 구성:\n최소 3개 노드 (홀수 권장)\nPrimary 1개 + Secondary 2개\n또는 Primary 1개 + Secondary 1개 + Arbiter 1개",
    "references": [
      {
        "title": "Replica Set Members",
        "url": "https://www.mongodb.com/docs/manual/core/replica-set-members/"
      }
    ],
    "keywords": [
      "replica",
      "set",
      "mongodb",
      "primary",
      "secondary",
      "arbiter",
      "동일한",
      "데이터를",
      "가진",
      "인스턴스",
      "그룹입니다",
      "구조",
      "권장",
      "구성",
      "최소"
    ]
  },
  {
    "id": "MONGO-031",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Primary, Secondary, Arbiter 노드의 역할은 무엇인가요?",
    "answer": "Primary:\n모든 쓰기 작업 처리\n기본 읽기 작업 처리\nOplog에 작업 기록\n\nSecondary:\nPrimary의 Oplog를 복제하여 데이터 동기화\nRead Preference 설정 시 읽기 가능\nPrimary 장애 시 선출 후보\n\nArbiter:\n데이터를 저장하지 않음\n선거에 투표만 참여\n짝수 노드일 때 과반수 확보용\n리소스 최소화 목적",
    "references": [
      {
        "title": "Replica Set Arbiter",
        "url": "https://www.mongodb.com/docs/manual/core/replica-set-arbiter/"
      }
    ],
    "keywords": [
      "primary",
      "oplog",
      "secondary",
      "read",
      "preference",
      "arbiter",
      "모든",
      "쓰기",
      "작업",
      "처리",
      "기본",
      "읽기",
      "기록",
      "복제하여",
      "데이터"
    ]
  },
  {
    "id": "MONGO-032",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Read Preference란 무엇이며 종류는 무엇인가요?",
    "answer": "Read Preference는 읽기 작업을 어느 노드에서 수행할지 지정합니다.\n\n종류:\n모드   설명\n\nprimary   Primary에서만 읽기 (기본값)\nprimaryPreferred   Primary 우선, 불가시 Secondary\nsecondary   Secondary에서만 읽기\nsecondaryPreferred   Secondary 우선, 불가시 Primary\nnearest   네트워크 지연 최소 노드\n\n주의: Secondary 읽기는 약간의 지연(Replication Lag) 가능",
    "references": [
      {
        "title": "Read Preference",
        "url": "https://www.mongodb.com/docs/manual/core/read-preference/"
      }
    ],
    "keywords": [
      "read",
      "preference",
      "primary",
      "secondary",
      "replication",
      "lag",
      "읽기",
      "작업을",
      "어느",
      "노드에서",
      "수행할지",
      "지정합니다",
      "종류",
      "모드",
      "설명"
    ]
  },
  {
    "id": "MONGO-033",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Write Concern이란 무엇이며 어떻게 설정하나요?",
    "answer": "Write Concern은 쓰기 작업의 확인 수준을 지정합니다.\n\n주요 옵션:\nw 값   설명\n\n0   확인 안 함 (Fire-and-forget)\n1   Primary 확인 (기본값)\n\"majority\"   과반수 노드 확인\nn   n개 노드 확인\n\nj 옵션: journal 기록 여부\nwtimeout: 타임아웃 설정\n\n트레이드오프: w 값이 높을수록 안전하지만 지연 증가",
    "references": [
      {
        "title": "Write Concern",
        "url": "https://www.mongodb.com/docs/manual/reference/write-concern/"
      }
    ],
    "keywords": [
      "write",
      "concern",
      "fire-and-forget",
      "primary",
      "쓰기",
      "작업의",
      "확인",
      "수준을",
      "지정합니다",
      "주요",
      "옵션",
      "설명",
      "기본값",
      "과반수",
      "노드"
    ]
  },
  {
    "id": "MONGO-034",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Replica Set의 자동 Failover 과정을 설명해주세요.",
    "answer": "Failover 과정:\n장애 감지: Heartbeat(2초 간격)로 Primary 상태 확인\n선거 시작: electionTimeoutMillis(기본 10초) 후 선거 개시\n투표: 과반수 투표로 새 Primary 선출\n승격: 가장 최신 데이터를 가진 Secondary가 Primary로 승격\n연결 재설정: 드라이버가 새 Primary로 연결\n\n선출 기준:\n가장 최신 oplog\npriority 값 (높을수록 우선)\n과반수 투표 획득",
    "references": [
      {
        "title": "Replica Set Elections",
        "url": "https://www.mongodb.com/docs/manual/core/replica-set-elections/"
      }
    ],
    "keywords": [
      "failover",
      "heartbeat",
      "primary",
      "secondary",
      "과정",
      "장애",
      "감지",
      "간격",
      "상태",
      "확인",
      "선거",
      "시작",
      "기본",
      "개시",
      "투표"
    ]
  },
  {
    "id": "MONGO-035",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Oplog란 무엇이며 어떤 역할을 하나요?",
    "answer": "Oplog(Operation Log)는 Primary의 모든 쓰기 작업을 기록하는 Capped Collection입니다.\n\n역할:\nSecondary가 Oplog를 읽어 데이터 동기화\nPoint-in-Time Recovery 지원\nChange Streams의 기반\n\n특징:\nlocal.oplog.rs Collection에 저장\nCapped Collection (고정 크기, 오래된 것 자동 삭제)\nIdempotent 연산으로 저장\n\n크기 설정:\n기본: 디스크의 5% 또는 50GB 중 작은 값\noplogSizeMB 옵션으로 조정",
    "references": [
      {
        "title": "Replica Set Oplog",
        "url": "https://www.mongodb.com/docs/manual/core/replica-set-oplog/"
      }
    ],
    "keywords": [
      "oplog",
      "operation",
      "log",
      "primary",
      "capped",
      "collection",
      "secondary",
      "point-in-time",
      "recovery",
      "change",
      "streams",
      "idempotent",
      "모든",
      "쓰기",
      "작업을"
    ]
  },
  {
    "id": "MONGO-036",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Secondary 노드에서 읽기 작업을 수행할 때 주의할 점은?",
    "answer": "주의사항:\nReplication Lag: Primary와 데이터 불일치 가능\n최신 데이터가 필요한 경우 Primary 읽기 권장\nStale Read: 오래된 데이터 읽기 가능\n쓰기 후 읽기 일관성 문제\n쓰기 직후 Secondary 읽기 시 반영 안 될 수 있음\nFailover 시 연결 끊김\n드라이버 재연결 로직 필요\n\n권장 사용 사례:\n분석/리포팅 쿼리\n지연 허용 가능한 읽기\n지리적으로 분산된 읽기",
    "references": [
      {
        "title": "Read Preference Use Cases",
        "url": "https://www.mongodb.com/docs/manual/core/read-preference-use-cases/"
      }
    ],
    "keywords": [
      "replication",
      "lag",
      "primary",
      "stale",
      "read",
      "secondary",
      "failover",
      "주의사항",
      "데이터",
      "불일치",
      "가능",
      "최신",
      "데이터가",
      "필요한",
      "읽기"
    ]
  },
  {
    "id": "MONGO-037",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Sharding이란 무엇이며 왜 필요한가요?",
    "answer": "Sharding은 데이터를 여러 서버에 분산 저장하는 수평 확장(Scale-out) 방식입니다.\n\n필요한 이유:\n단일 서버 저장 용량 한계 극복\n높은 처리량(throughput) 요구\nWorking Set이 RAM을 초과할 때\n지리적 데이터 분산 필요 시\n\nSharding vs Replication:\n구분   Sharding   Replication\n\n목적   용량/성능 확장   고가용성/읽기 분산\n데이터   분산 저장   복제 저장\n확장 방향   수평 (Scale-out)   -",
    "references": [
      {
        "title": "Sharding",
        "url": "https://www.mongodb.com/docs/manual/sharding/"
      }
    ],
    "keywords": [
      "sharding",
      "scale-out",
      "working",
      "set",
      "ram",
      "replication",
      "데이터를",
      "여러",
      "서버에",
      "분산",
      "저장하는",
      "수평",
      "확장",
      "방식입니다",
      "필요한"
    ]
  },
  {
    "id": "MONGO-038",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB의 Sharding 아키텍처(Shard, Config Server, mongos)를 설명해주세요.",
    "answer": "구성요소:\nShard: 실제 데이터 저장 (Replica Set으로 구성)\nConfig Server: 샤드 메타데이터, 청크 위치 정보 저장\nmongos: 쿼리 라우터, 클라이언트 연결점",
    "references": [
      {
        "title": "Sharded Cluster Components",
        "url": "https://www.mongodb.com/docs/manual/core/sharded-cluster-components/"
      }
    ],
    "keywords": [
      "shard",
      "replica",
      "set",
      "config",
      "server",
      "구성요소",
      "실제",
      "데이터",
      "저장",
      "으로",
      "구성",
      "샤드",
      "메타데이터",
      "청크",
      "위치"
    ]
  },
  {
    "id": "MONGO-039",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Shard Key란 무엇이며 선택 시 고려사항은?",
    "answer": "Shard Key는 데이터를 여러 Shard에 분배하는 기준 필드입니다.\n\n선택 시 고려사항:\n높은 Cardinality: 다양한 값이 많아야 균등 분배\n균등한 분포: 특정 값에 쏠리지 않아야 함\n쿼리 패턴: 자주 사용하는 쿼리 필드 포함\n변경 불가: 한 번 설정 후 변경 어려움 (5.0부터 가능)\n\n좋은 Shard Key 예시:\n\n피해야 할 패턴:\n단조 증가 값 (ObjectId, 타임스탬프) → Hot Shard 발생\n낮은 Cardinality (boolean, status)",
    "references": [
      {
        "title": "Shard Key Selection",
        "url": "https://www.mongodb.com/docs/manual/core/sharding-shard-key/"
      }
    ],
    "keywords": [
      "shard",
      "key",
      "cardinality",
      "objectid",
      "hot",
      "데이터를",
      "여러",
      "분배하는",
      "기준",
      "필드입니다",
      "선택",
      "고려사항",
      "높은",
      "다양한",
      "값이"
    ]
  },
  {
    "id": "MONGO-040",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Range-based Sharding과 Hash-based Sharding의 차이는?",
    "answer": "구분   Range Sharding   Hash Sharding\n\n분배 방식   값 범위별 분배   해시값 기반 분배\n장점   범위 쿼리 효율적   균등 분배 보장\n단점   불균등 분배 가능   범위 쿼리 비효율\n적합   날짜, 지역 기반 데이터   랜덤 접근 패턴\n\n선택 기준:\n범위 쿼리가 많으면 → Range\n균등 분배가 중요하면 → Hash\n단조 증가 키 사용 시 → Hash 권장",
    "references": [
      {
        "title": "Hashed Sharding",
        "url": "https://www.mongodb.com/docs/manual/core/hashed-sharding/"
      }
    ],
    "keywords": [
      "range",
      "sharding",
      "hash",
      "구분",
      "분배",
      "방식",
      "범위별",
      "해시값",
      "기반",
      "장점",
      "범위",
      "쿼리",
      "효율적",
      "균등",
      "보장"
    ]
  },
  {
    "id": "MONGO-041",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Zone Sharding이란 무엇인가요?",
    "answer": "Zone Sharding은 특정 데이터를 특정 Shard에 저장하도록 규칙을 정의하는 기능입니다.\n\n사용 사례:\n지리적 데이터 분산 (유럽 데이터는 유럽 DC에)\n테넌트별 데이터 격리\n하드웨어 계층화 (핫 데이터는 SSD Shard에)\n\n구성:\nShard에 태그 할당\nShard Key 범위에 태그 연결\nBalancer가 규칙에 따라 Chunk 이동",
    "references": [
      {
        "title": "Zone Sharding",
        "url": "https://www.mongodb.com/docs/manual/core/zone-sharding/"
      }
    ],
    "keywords": [
      "zone",
      "sharding",
      "shard",
      "ssd",
      "key",
      "balancer",
      "chunk",
      "특정",
      "데이터를",
      "저장하도록",
      "규칙을",
      "정의하는",
      "기능입니다",
      "사용",
      "사례"
    ]
  },
  {
    "id": "MONGO-042",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Chunk란 무엇이며 어떻게 분할되나요?",
    "answer": "Chunk는 Shard Key 범위에 따라 분할된 데이터 그룹입니다.\n\n특징:\n기본 크기: 128MB (설정 가능)\n연속된 Shard Key 범위의 Document 포함\nShard 간 데이터 이동의 단위\n\n분할 과정:\nChunk가 chunkSize 초과 시 분할 트리거\n중간 값을 기준으로 두 Chunk로 분할\nBalancer가 Chunk를 다른 Shard로 이동",
    "references": [
      {
        "title": "Data Partitioning with Chunks",
        "url": "https://www.mongodb.com/docs/manual/core/sharding-data-partitioning/"
      }
    ],
    "keywords": [
      "chunk",
      "shard",
      "key",
      "document",
      "balancer",
      "범위에",
      "따라",
      "분할된",
      "데이터",
      "그룹입니다",
      "특징",
      "기본",
      "크기",
      "설정",
      "가능"
    ]
  },
  {
    "id": "MONGO-043",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Balancer의 역할은 무엇인가요?",
    "answer": "Balancer는 Shard 간 Chunk를 자동으로 재분배하여 데이터 균형을 유지합니다.\n\n역할:\nChunk 분포 모니터링\n불균형 감지 시 Chunk 마이그레이션\nZone 규칙에 따른 Chunk 이동\n\n작동 방식:\nConfig Server에서 실행\nShard 간 Chunk 수 차이가 임계값 초과 시 동작\n백그라운드에서 Chunk 이동",
    "references": [
      {
        "title": "Sharded Cluster Balancer",
        "url": "https://www.mongodb.com/docs/manual/core/sharding-balancer-administration/"
      }
    ],
    "keywords": [
      "balancer",
      "shard",
      "chunk",
      "zone",
      "config",
      "server",
      "자동으로",
      "재분배하여",
      "데이터",
      "균형을",
      "유지합니다",
      "역할",
      "분포",
      "모니터링",
      "불균형"
    ]
  },
  {
    "id": "MONGO-044",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Sharding 환경에서 발생할 수 있는 문제점과 해결 방법은?",
    "answer": "Hot Shard (Jumbo Chunk)\n문제: 특정 Shard에 트래픽 집중\n해결: Hash Sharding 사용, 복합 Shard Key\nScatter-Gather 쿼리\n문제: Shard Key 미포함 쿼리가 모든 Shard 조회\n해결: 쿼리에 Shard Key 포함, 적절한 Key 선택\nChunk 마이그레이션 오버헤드\n문제: 대량 데이터 이동 시 성능 저하\n해결: 피크 시간 외 Balancer 실행\n분산 트랜잭션 복잡성\n문제: 여러 Shard 걸친 트랜잭션 어려움\n해결: 관련 데이터 같은 Shard에 배치\nShard Key 변경 불가\n문제: 잘못된 Key 선택 시 수정 어려움\n해결: 5.0+ reshardCollection 사용",
    "references": [
      {
        "title": "Sharding Troubleshooting",
        "url": "https://www.mongodb.com/docs/manual/reference/command/reshardCollection/"
      }
    ],
    "keywords": [
      "hot",
      "shard",
      "jumbo",
      "chunk",
      "hash",
      "sharding",
      "key",
      "scatter-gather",
      "balancer",
      "문제",
      "특정",
      "트래픽",
      "집중",
      "해결",
      "사용"
    ]
  },
  {
    "id": "MONGO-045",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB의 Transaction 지원에 대해 설명해주세요.",
    "answer": "버전별 Transaction 지원:\n4.0: Replica Set에서 Multi-Document Transaction\n4.2: Sharded Cluster에서 분산 Transaction\n4.4+: 성능 개선 및 제한 완화\n\n제한사항:\n기본 60초 타임아웃\n16MB 크기 제한",
    "references": [
      {
        "title": "Transactions",
        "url": "https://www.mongodb.com/docs/manual/core/transactions/"
      }
    ],
    "keywords": [
      "transaction",
      "replica",
      "set",
      "multi-document",
      "sharded",
      "cluster",
      "버전별",
      "지원",
      "에서",
      "분산",
      "성능",
      "개선",
      "제한",
      "완화",
      "제한사항"
    ]
  },
  {
    "id": "MONGO-046",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Multi-Document Transaction은 언제 사용하나요?",
    "answer": "사용 시점:\n여러 Document를 원자적으로 업데이트해야 할 때\n계좌 이체처럼 All-or-Nothing이 필요한 경우\n정규화된 데이터 모델에서 일관성 유지\n\n사용 예시:\n\n대안 고려:\nEmbedding으로 단일 Document 작업으로 변경\n단일 Document 업데이트는 자동 원자성\n\n주의: 트랜잭션은 오버헤드가 있으므로 필요한 경우만 사용",
    "references": [
      {
        "title": "Transactions in Applications",
        "url": "https://www.mongodb.com/docs/manual/core/transactions-in-applications/"
      }
    ],
    "keywords": [
      "document",
      "all-or-nothing",
      "embedding",
      "사용",
      "시점",
      "여러",
      "원자적으로",
      "업데이트해야",
      "계좌",
      "이체처럼",
      "필요한",
      "정규화된",
      "데이터",
      "모델에서",
      "일관성"
    ]
  },
  {
    "id": "MONGO-047",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB의 ACID 특성을 설명해주세요.",
    "answer": "단일 Document 작업:\n항상 ACID 보장 (원자적 작업)\n\nMulti-Document Transaction (4.0+):\n\n속성   MongoDB 지원\n\nAtomicity   트랜잭션 내 모든 작업이 성공하거나 모두 롤백\nConsistency   트랜잭션 완료 후 데이터 일관성 유지\nIsolation   Snapshot Isolation 제공\nDurability   writeConcern: majority + j:true로 보장",
    "references": [
      {
        "title": "Transactions and Atomicity",
        "url": "https://www.mongodb.com/docs/manual/core/write-operations-atomicity/"
      }
    ],
    "keywords": [
      "document",
      "acid",
      "multi-document",
      "transaction",
      "mongodb",
      "atomicity",
      "consistency",
      "isolation",
      "snapshot",
      "durability",
      "단일",
      "작업",
      "항상",
      "보장",
      "원자적"
    ]
  },
  {
    "id": "MONGO-048",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Read Isolation과 Snapshot Isolation에 대해 설명해주세요.",
    "answer": "Read Concern 레벨:\n\n레벨   설명\n\nlocal   로컬 데이터 읽기 (기본값)\navailable   Sharding에서 가장 빠른 응답\nmajority   과반수 복제 확인된 데이터\nlinearizable   가장 최신 데이터 보장\nsnapshot   트랜잭션 시작 시점 스냅샷\n\nSnapshot Isolation:\n트랜잭션 시작 시점의 일관된 데이터 뷰 제공\n다른 트랜잭션의 변경이 보이지 않음\nPhantom Read 방지",
    "references": [
      {
        "title": "Read Concern",
        "url": "https://www.mongodb.com/docs/manual/reference/read-concern/"
      }
    ],
    "keywords": [
      "read",
      "concern",
      "sharding",
      "snapshot",
      "isolation",
      "phantom",
      "레벨",
      "설명",
      "로컬",
      "데이터",
      "읽기",
      "기본값",
      "에서",
      "가장",
      "빠른"
    ]
  },
  {
    "id": "MONGO-049",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Atomicity는 Document 레벨과 Multi-Document 레벨에서 어떻게 다르게 동작하나요?",
    "answer": "Document 레벨 Atomicity:\n모든 MongoDB 버전에서 자동 지원\n단일 Document 내 모든 필드 업데이트가 원자적\n트랜잭션 없이도 보장\n\nMulti-Document Atomicity:\n4.0+ 트랜잭션 필요\n명시적 session 사용\n성능 오버헤드 존재",
    "references": [
      {
        "title": "Atomicity and Transactions",
        "url": "https://www.mongodb.com/docs/manual/core/write-operations-atomicity/"
      }
    ],
    "keywords": [
      "document",
      "atomicity",
      "mongodb",
      "multi-document",
      "레벨",
      "모든",
      "버전에서",
      "자동",
      "지원",
      "단일",
      "필드",
      "업데이트가",
      "원자적",
      "트랜잭션",
      "없이도"
    ]
  },
  {
    "id": "MONGO-050",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Eventual Consistency란 무엇이며 MongoDB에서 어떻게 관리되나요?",
    "answer": "Eventual Consistency는 시간이 지나면 모든 노드가 동일한 데이터를 갖게 되는 모델입니다.\n\nMongoDB에서의 적용:\nSecondary는 Primary와 약간의 지연(Replication Lag) 존재\nSecondary 읽기 시 최신 데이터가 아닐 수 있음\n\n일관성 제어 방법:\nWrite Concern:\nRead Concern:\nRead Preference:\n\nStrong Consistency 필요 시:\nPrimary 읽기 + writeConcern: majority 사용",
    "references": [
      {
        "title": "Causal Consistency",
        "url": "https://www.mongodb.com/docs/manual/core/causal-consistency-read-write-concerns/"
      }
    ],
    "keywords": [
      "eventual",
      "consistency",
      "mongodb",
      "secondary",
      "primary",
      "replication",
      "lag",
      "write",
      "concern",
      "read",
      "preference",
      "strong",
      "시간이",
      "지나면",
      "모든"
    ]
  },
  {
    "id": "MONGO-051",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB 쿼리 성능을 개선하는 방법은?",
    "answer": "인덱스 최적화:\n자주 쿼리하는 필드에 인덱스 생성\nCovered Query 활용\n불필요한 인덱스 제거\n쿼리 최적화:\n데이터 모델링:\n자주 함께 조회되는 데이터 Embedding\n적절한 정규화/비정규화\nexplain() 분석:\nCOLLSCAN 제거\ntotalDocsExamined 최소화\n하드웨어:\nWorking Set이 RAM에 맞도록 메모리 확보\nSSD 사용",
    "references": [
      {
        "title": "Query Optimization",
        "url": "https://www.mongodb.com/docs/manual/core/query-optimization/"
      }
    ],
    "keywords": [
      "covered",
      "query",
      "embedding",
      "collscan",
      "working",
      "set",
      "ram",
      "ssd",
      "인덱스",
      "최적화",
      "자주",
      "쿼리하는",
      "필드에",
      "생성",
      "활용"
    ]
  },
  {
    "id": "MONGO-052",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Working Set이란 무엇이며 메모리와의 관계는?",
    "answer": "Working Set은 자주 접근하는 데이터와 인덱스의 집합입니다.\n\n메모리와의 관계:\nWorking Set이 RAM에 맞으면 → 빠른 성능\nWorking Set > RAM → 디스크 I/O 발생 (Page Fault)\n\n모니터링:\n\n최적화 방법:\nRAM 증설: Working Set이 맞도록\n인덱스 최적화: 불필요한 인덱스 제거\n데이터 아카이빙: 오래된 데이터 분리\nProjection 사용: 필요한 필드만 조회\n\n권장:\nWorking Set은 가용 RAM의 50-80% 이내 유지\nPage Fault 비율 모니터링",
    "references": [
      {
        "title": "WiredTiger Storage Engine",
        "url": "https://www.mongodb.com/docs/manual/core/wiredtiger/"
      }
    ],
    "keywords": [
      "working",
      "set",
      "ram",
      "page",
      "fault",
      "projection",
      "자주",
      "접근하는",
      "데이터와",
      "인덱스의",
      "집합입니다",
      "메모리와의",
      "관계",
      "맞으면",
      "빠른"
    ]
  },
  {
    "id": "MONGO-053",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Connection Pool의 개념과 적절한 크기 설정 방법은?",
    "answer": "Connection Pool은 미리 생성된 DB 연결을 재사용하는 메커니즘입니다.\n\n장점:\n연결 생성/해제 오버헤드 감소\n응답 시간 단축\n리소스 효율적 사용\n\n설정 방법:\n\n적절한 크기 산정:\n기본값: 100\n계산: 동시 요청 수 / 애플리케이션 인스턴스 수\nMongoDB 최대: 65,536 연결\n\n주의:\n너무 크면 서버 리소스 낭비\n너무 작으면 연결 대기 발생",
    "references": [
      {
        "title": "Connection Pool",
        "url": "https://www.mongodb.com/docs/drivers/node/current/fundamentals/connection/connection-options/"
      }
    ],
    "keywords": [
      "connection",
      "pool",
      "mongodb",
      "미리",
      "생성된",
      "연결을",
      "재사용하는",
      "메커니즘입니다",
      "장점",
      "연결",
      "생성",
      "해제",
      "오버헤드",
      "감소",
      "응답"
    ]
  },
  {
    "id": "MONGO-054",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "WiredTiger Storage Engine의 특징은 무엇인가요?",
    "answer": "WiredTiger는 MongoDB 3.2부터 기본 스토리지 엔진입니다.\n\n주요 특징:\nDocument-level Locking: 동시성 향상\n압축 지원: snappy(기본), zlib, zstd\nCheckpointing: 60초마다 일관된 스냅샷 저장\n캐시 관리: 내부 캐시로 성능 최적화\n저널링: 장애 복구 보장\n\nMMAPv1과 비교:\n구분   WiredTiger   MMAPv1\n\n락   Document   Collection\n압축   지원   미지원\n캐시   내부 캐시   OS 캐시\n\n캐시 설정:",
    "references": [
      {
        "title": "WiredTiger",
        "url": "https://www.mongodb.com/docs/manual/core/wiredtiger/"
      }
    ],
    "keywords": [
      "wiredtiger",
      "mongodb",
      "document-level",
      "locking",
      "checkpointing",
      "mmapv1",
      "document",
      "collection",
      "부터",
      "기본",
      "스토리지",
      "엔진입니다",
      "주요",
      "특징",
      "동시성"
    ]
  },
  {
    "id": "MONGO-055",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Cache 크기 설정과 메모리 관리 전략은?",
    "answer": "WiredTiger Cache 기본값:\nmax(256MB, (RAM - 1GB) × 50%)\n\n설정 방법:\n\n메모리 관리 전략:\nCache 크기 산정:\nWorking Set 크기 파악\n다른 프로세스 고려 (OS, 애플리케이션)\nRAM의 50-60% 권장\n모니터링 지표:\n최적화:\n높은 eviction → 캐시 증설 필요\n인덱스 메모리 사용량 확인\n불필요한 인덱스 제거",
    "references": [
      {
        "title": "WiredTiger Memory Use",
        "url": "https://www.mongodb.com/docs/manual/core/wiredtiger/#memory-use"
      }
    ],
    "keywords": [
      "wiredtiger",
      "cache",
      "ram",
      "working",
      "set",
      "기본값",
      "설정",
      "방법",
      "메모리",
      "관리",
      "전략",
      "크기",
      "산정",
      "파악",
      "다른"
    ]
  },
  {
    "id": "MONGO-056",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Profiler를 사용하여 느린 쿼리를 찾는 방법은?",
    "answer": "Database Profiler는 쿼리 실행 정보를 system.profile 컬렉션에 기록합니다.\n\n프로파일링 레벨:\n0: Off (기본)\n1: 느린 쿼리만 (slowms 초과)\n2: 모든 쿼리\n\n분석 항목:\nmillis: 실행 시간\nnscanned: 스캔한 Document 수\nquery: 쿼리 내용\nplanSummary: 실행 계획\n\n대안: Atlas에서는 Performance Advisor 사용",
    "references": [
      {
        "title": "Database Profiler",
        "url": "https://www.mongodb.com/docs/manual/tutorial/manage-the-database-profiler/"
      }
    ],
    "keywords": [
      "database",
      "profiler",
      "off",
      "document",
      "atlas",
      "performance",
      "advisor",
      "쿼리",
      "실행",
      "정보를",
      "컬렉션에",
      "기록합니다",
      "프로파일링",
      "레벨",
      "기본"
    ]
  },
  {
    "id": "MONGO-057",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Bulk Write Operation의 장점과 사용 방법은?",
    "answer": "Bulk Write는 여러 쓰기 작업을 하나의 요청으로 배치 처리합니다.\n\n장점:\n네트워크 왕복 감소\n처리량 향상\n서버 부하 감소\n\n옵션:\nordered: true (기본): 순서대로 실행, 오류 시 중단\nordered: false: 병렬 실행, 오류 무시하고 계속\n\n사용 사례:\n대량 데이터 마이그레이션\n배치 업데이트\n초기 데이터 로딩",
    "references": [
      {
        "title": "Bulk Write Operations",
        "url": "https://www.mongodb.com/docs/manual/core/bulk-write-operations/"
      }
    ],
    "keywords": [
      "bulk",
      "write",
      "여러",
      "쓰기",
      "작업을",
      "하나의",
      "요청으로",
      "배치",
      "처리합니다",
      "장점",
      "네트워크",
      "왕복",
      "감소",
      "처리량",
      "향상"
    ]
  },
  {
    "id": "MONGO-058",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Read/Write 성능을 향상시키기 위한 Best Practice는?",
    "answer": "Read 성능:\n적절한 인덱스 생성 및 Covered Query 활용\nProjection으로 필요한 필드만 조회\nRead Preference로 읽기 분산\n캐싱 레이어(Redis) 활용\n\nWrite 성능:\nBulk Write 사용\nWrite Concern 적절히 조정 (w:1 vs majority)\n불필요한 인덱스 제거 (쓰기 시 업데이트 필요)\nSharding으로 쓰기 분산\n\n공통:\n\n모니터링:\ndb.serverStatus() 정기 확인\nSlow Query 로깅 활성화",
    "references": [
      {
        "title": "Performance Best Practices",
        "url": "https://www.mongodb.com/docs/manual/administration/analyzing-mongodb-performance/"
      }
    ],
    "keywords": [
      "read",
      "covered",
      "query",
      "projection",
      "preference",
      "redis",
      "write",
      "bulk",
      "concern",
      "sharding",
      "slow",
      "성능",
      "적절한",
      "인덱스",
      "생성"
    ]
  },
  {
    "id": "MONGO-059",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB의 인증과 권한 관리 방법은?",
    "answer": "인증 (Authentication):\nSCRAM (기본): 사용자명/비밀번호\nx.509: 인증서 기반\nLDAP: 외부 LDAP 서버 연동\nKerberos: 엔터프라이즈 인증\n\n권한 부여 활성화:\n\n연결:\n\n주의: 프로덕션에서는 반드시 인증 활성화",
    "references": [
      {
        "title": "Authentication",
        "url": "https://www.mongodb.com/docs/manual/core/authentication/"
      }
    ],
    "keywords": [
      "authentication",
      "scram",
      "ldap",
      "kerberos",
      "인증",
      "기본",
      "사용자명",
      "비밀번호",
      "인증서",
      "기반",
      "외부",
      "서버",
      "연동",
      "엔터프라이즈",
      "권한"
    ]
  },
  {
    "id": "MONGO-060",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Role-Based Access Control(RBAC)이란 무엇인가요?",
    "answer": "RBAC는 역할(Role)을 통해 사용자 권한을 관리하는 방식입니다.\n\nBuilt-in Roles:\n역할   권한\n\nread   읽기 전용\nreadWrite   읽기/쓰기\ndbAdmin   DB 관리 (인덱스, 통계)\nuserAdmin   사용자 관리\nclusterAdmin   클러스터 관리\nroot   모든 권한\n\nCustom Role 생성:\n\n최소 권한 원칙: 필요한 권한만 부여",
    "references": [
      {
        "title": "Role-Based Access Control",
        "url": "https://www.mongodb.com/docs/manual/core/authorization/"
      }
    ],
    "keywords": [
      "rbac",
      "role",
      "built-in",
      "roles",
      "custom",
      "역할",
      "사용자",
      "권한을",
      "관리하는",
      "방식입니다",
      "권한",
      "읽기",
      "전용",
      "쓰기",
      "관리"
    ]
  },
  {
    "id": "MONGO-061",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB에서 데이터 암호화 방법은?",
    "answer": "전송 중 암호화 (In-Transit):\nTLS/SSL로 클라이언트-서버 간 통신 암호화\n저장 중 암호화 (At-Rest):\nWiredTiger의 네이티브 암호화 (Enterprise)\n필드 레벨 암호화 (Client-Side):\n특정 필드만 클라이언트에서 암호화 (4.2+)",
    "references": [
      {
        "title": "Encryption at Rest",
        "url": "https://www.mongodb.com/docs/manual/core/security-encryption-at-rest/"
      }
    ],
    "keywords": [
      "in-transit",
      "tls",
      "ssl",
      "at-rest",
      "wiredtiger",
      "enterprise",
      "client-side",
      "전송",
      "암호화",
      "클라이언트",
      "서버",
      "통신",
      "저장",
      "네이티브",
      "필드"
    ]
  },
  {
    "id": "MONGO-062",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Backup과 Restore 전략을 설명해주세요.",
    "answer": "백업 방법:\nmongodump/mongorestore: 논리적 백업\n작은 데이터셋에 적합\n컬렉션별 선택적 백업 가능\n파일 시스템 스냅샷: 물리적 백업\n대용량에 빠름\nLVM, EBS 스냅샷 활용\nMongoDB Atlas: 자동 백업\n연속 백업, Point-in-Time Recovery\n\n백업 전략:\n\n복구 테스트:\n정기적인 복구 훈련 필수\nRTO/RPO 목표 설정",
    "references": [
      {
        "title": "Backup Methods",
        "url": "https://www.mongodb.com/docs/manual/core/backups/"
      }
    ],
    "keywords": [
      "lvm",
      "ebs",
      "mongodb",
      "atlas",
      "point-in-time",
      "recovery",
      "rto",
      "rpo",
      "백업",
      "방법",
      "논리적",
      "작은",
      "데이터셋에",
      "적합",
      "컬렉션별"
    ]
  },
  {
    "id": "MONGO-063",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "mongodump와 mongorestore의 차이점과 사용 방법은?",
    "answer": "mongodump: 데이터를 BSON 파일로 내보내기\nmongorestore: BSON 파일을 MongoDB로 복원\n\n옵션:\n--gzip: 압축\n--oplog: 일관된 스냅샷 (Replica Set)\n--drop: 복원 전 기존 데이터 삭제\n--numParallelCollections: 병렬 처리\n\n주의: 대용량 데이터는 파일 시스템 스냅샷 권장",
    "references": [
      {
        "title": "mongodump",
        "url": "https://www.mongodb.com/docs/database-tools/mongodump/"
      }
    ],
    "keywords": [
      "bson",
      "mongodb",
      "replica",
      "set",
      "데이터를",
      "파일로",
      "내보내기",
      "파일을",
      "복원",
      "옵션",
      "압축",
      "일관된",
      "스냅샷",
      "기존",
      "데이터"
    ]
  },
  {
    "id": "MONGO-064",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Point-in-Time Recovery가 가능한가요?",
    "answer": "네, Replica Set에서 Oplog를 활용하여 Point-in-Time Recovery가 가능합니다.\n\n방법:\nmongodump + oplog:\nMongoDB Atlas:\n자동 연속 백업\nUI에서 원하는 시점 선택 가능\n\n제한사항:\nReplica Set 또는 Sharded Cluster 필요\nOplog 보존 기간 내의 시점만 복구 가능\nOplog 크기에 따라 복구 가능 기간 결정\n\nOplog 보존 기간 설정:",
    "references": [
      {
        "title": "Point in Time Recovery",
        "url": "https://www.mongodb.com/docs/manual/tutorial/restore-replica-set-from-backup/"
      }
    ],
    "keywords": [
      "replica",
      "set",
      "oplog",
      "point-in-time",
      "recovery",
      "mongodb",
      "atlas",
      "sharded",
      "cluster",
      "에서",
      "활용하여",
      "가능합니다",
      "방법",
      "자동",
      "연속"
    ]
  },
  {
    "id": "MONGO-065",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB 모니터링 시 중요한 메트릭은 무엇인가요?",
    "answer": "핵심 메트릭:\n\n카테고리   메트릭   확인 명령\n\n연결   current connections   db.serverStatus().connections\n쿼리   opcounters (query, insert, update, delete)   db.serverStatus().opcounters\n복제   replication lag   rs.printSecondaryReplicationInfo()\n메모리   cache usage, page faults   db.serverStatus().wiredTiger.cache\n잠금   lock wait time   db.serverStatus().locks\n저장   disk space, data size   db.stats()\n\n알람 설정 권장:\n연결 수 > 80% 한도\nReplication Lag > 10초\nCache Eviction 급증\nPage Faults 증가\n\n모니터링 도구:\nMongoDB Atlas (내장 모니터링)\nPrometheus + Grafana\nDatadog, New Relic",
    "references": [
      {
        "title": "Monitoring",
        "url": "https://www.mongodb.com/docs/manual/administration/monitoring/"
      }
    ],
    "keywords": [
      "replication",
      "lag",
      "cache",
      "eviction",
      "page",
      "faults",
      "mongodb",
      "atlas",
      "prometheus",
      "grafana",
      "datadog",
      "new",
      "relic",
      "핵심",
      "메트릭"
    ]
  },
  {
    "id": "MONGO-066",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Change Streams란 무엇이며 어떻게 활용하나요?",
    "answer": "Change Streams는 실시간으로 데이터 변경을 감지하는 기능입니다.\n\n특징:\nOplog 기반 실시간 이벤트 스트림\nReplica Set 또는 Sharded Cluster 필요\nResumable (재시작 시 이어서 처리)\n\n활용 사례:\n실시간 알림/푸시\n캐시 무효화\n데이터 동기화 (CDC)\n감사 로깅\n\n이벤트 타입:\ninsert, update, replace, delete, invalidate, drop",
    "references": [
      {
        "title": "Change Streams",
        "url": "https://www.mongodb.com/docs/manual/changeStreams/"
      }
    ],
    "keywords": [
      "change",
      "streams",
      "oplog",
      "replica",
      "set",
      "sharded",
      "cluster",
      "resumable",
      "cdc",
      "실시간으로",
      "데이터",
      "변경을",
      "감지하는",
      "기능입니다",
      "특징"
    ]
  },
  {
    "id": "MONGO-067",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Time Series Collection은 무엇이며 언제 사용하나요?",
    "answer": "Time Series Collection은 시계열 데이터를 효율적으로 저장하고 쿼리하기 위한 특수 컬렉션입니다 (5.0+).\n\n특징:\n자동 버킷팅으로 저장 공간 절약\n시계열 쿼리 최적화\n자동 압축\n\n사용 사례:\nIoT 센서 데이터\n메트릭/로그 수집\n주가/거래 데이터",
    "references": [
      {
        "title": "Time Series Collections",
        "url": "https://www.mongodb.com/docs/manual/core/timeseries-collections/"
      }
    ],
    "keywords": [
      "time",
      "series",
      "collection",
      "iot",
      "시계열",
      "데이터를",
      "효율적으로",
      "저장하고",
      "쿼리하기",
      "위한",
      "특수",
      "컬렉션입니다",
      "특징",
      "자동",
      "버킷팅으로"
    ]
  },
  {
    "id": "MONGO-068",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Capped Collection의 특징과 사용 사례는?",
    "answer": "Capped Collection은 고정 크기의 순환 버퍼 방식 컬렉션입니다.\n\n특징:\n크기 또는 문서 수 제한\n삽입 순서 보장\n가장 오래된 문서 자동 삭제\n높은 삽입 처리량\nDocument 삭제/크기 증가 업데이트 불가\n\n사용 사례:\n로그 저장 (최근 N개만 유지)\n캐싱\n실시간 스트림 버퍼\n\n주의사항:\nSharding 불가\nTTL 인덱스 대신 사용 가능\nOplog가 대표적인 Capped Collection",
    "references": [
      {
        "title": "Capped Collections",
        "url": "https://www.mongodb.com/docs/manual/core/capped-collections/"
      }
    ],
    "keywords": [
      "capped",
      "collection",
      "document",
      "sharding",
      "ttl",
      "oplog",
      "고정",
      "크기의",
      "순환",
      "버퍼",
      "방식",
      "컬렉션입니다",
      "특징",
      "크기",
      "문서"
    ]
  },
  {
    "id": "MONGO-069",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "TTL Index를 사용한 자동 데이터 만료 처리 방법은?",
    "answer": "TTL(Time-To-Live) Index는 지정된 시간 후 Document를 자동 삭제합니다.\n\n동작 방식:\n백그라운드 스레드가 60초마다 확인\n정확한 삭제 시점은 보장되지 않음\n\n사용 사례:\n세션 데이터, 임시 토큰\n로그 데이터 보관 기간 설정\n캐시 자동 정리",
    "references": [
      {
        "title": "TTL Indexes",
        "url": "https://www.mongodb.com/docs/manual/core/index-ttl/"
      }
    ],
    "keywords": [
      "ttl",
      "time-to-live",
      "index",
      "document",
      "지정된",
      "시간",
      "자동",
      "삭제합니다",
      "동작",
      "방식",
      "백그라운드",
      "스레드가",
      "초마다",
      "확인",
      "정확한"
    ]
  },
  {
    "id": "MONGO-070",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB Atlas의 주요 기능과 장점은?",
    "answer": "MongoDB Atlas는 공식 완전 관리형 클라우드 데이터베이스 서비스입니다.\n\n주요 기능:\n자동화: 프로비저닝, 패치, 업그레이드 자동화\n고가용성: 자동 Replica Set, Multi-Region\nSharding: 클릭으로 Sharded Cluster 구성\n백업: 연속 백업, Point-in-Time Recovery\n보안: VPC Peering, 암호화, LDAP 통합\n\n추가 서비스:\nAtlas Search: 전문 검색\nAtlas Charts: 데이터 시각화\nAtlas Data Lake: S3 데이터 쿼리\nAtlas Functions: 서버리스 함수\nAtlas Triggers: 이벤트 기반 로직\n\n장점:\n운영 부담 감소\n글로벌 분산 쉬움\nFree Tier 제공",
    "references": [
      {
        "title": "MongoDB Atlas",
        "url": "https://www.mongodb.com/docs/atlas/"
      }
    ],
    "keywords": [
      "mongodb",
      "atlas",
      "replica",
      "set",
      "multi-region",
      "sharding",
      "sharded",
      "cluster",
      "point-in-time",
      "recovery",
      "vpc",
      "peering",
      "ldap",
      "search",
      "charts"
    ]
  },
  {
    "id": "MONGO-071",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB Compass란 무엇인가요?",
    "answer": "MongoDB Compass는 공식 GUI 클라이언트입니다.\n\n주요 기능:\n시각적 탐색: 스키마 구조, 데이터 분포 시각화\n쿼리 빌더: GUI로 쿼리 작성\nAggregation Builder: 파이프라인 시각적 구성\n인덱스 관리: 인덱스 생성/삭제, 사용량 분석\n성능 분석: explain plan 시각화\n스키마 분석: 필드 타입, 분포 통계\n\n버전:\nCompass (Full): 모든 기능\nCompass Readonly: 읽기 전용\nCompass Isolated: 네트워크 요청 없음\n\n사용 사례:\n개발 중 데이터 탐색\n쿼리 디버깅\n비개발자 데이터 조회",
    "references": [
      {
        "title": "MongoDB Compass",
        "url": "https://www.mongodb.com/docs/compass/current/"
      }
    ],
    "keywords": [
      "mongodb",
      "compass",
      "gui",
      "aggregation",
      "builder",
      "full",
      "readonly",
      "isolated",
      "공식",
      "클라이언트입니다",
      "주요",
      "기능",
      "시각적",
      "탐색",
      "스키마"
    ]
  },
  {
    "id": "MONGO-072",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB와 Elasticsearch를 함께 사용하는 아키텍처는?",
    "answer": "MongoDB를 Primary DB로, Elasticsearch를 검색 엔진으로 사용하는 패턴입니다.\n\n동기화 방법:\nChange Streams + Application\nMongoDB Connector for BI / Kafka\nDebezium + Kafka Connect\nMonstache (오픈소스 동기화 도구)\n\n사용 사례:\n복잡한 전문 검색 (MongoDB Text Index 한계 극복)\n로그 분석\n실시간 대시보드",
    "references": [
      {
        "title": "Atlas Search",
        "url": "https://www.mongodb.com/docs/atlas/atlas-search/"
      }
    ],
    "keywords": [
      "mongodb",
      "primary",
      "elasticsearch",
      "change",
      "streams",
      "application",
      "connector",
      "kafka",
      "debezium",
      "connect",
      "monstache",
      "text",
      "index",
      "검색",
      "엔진으로"
    ]
  },
  {
    "id": "MONGO-073",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB와 Redis를 함께 사용하는 캐싱 전략은?",
    "answer": "Cache-Aside (Lazy Loading) 패턴:\n\nWrite-Through 패턴:\n\n캐시 무효화:\nTTL 설정으로 자동 만료\nChange Streams로 실시간 무효화\n\n사용 사례:\n세션 저장 (Redis)\n자주 조회되는 데이터 캐싱\nRate Limiting",
    "references": [
      {
        "title": "Caching Patterns",
        "url": "https://www.mongodb.com/docs/manual/tutorial/model-data-for-atomic-operations/"
      }
    ],
    "keywords": [
      "cache-aside",
      "lazy",
      "loading",
      "write-through",
      "ttl",
      "change",
      "streams",
      "redis",
      "rate",
      "limiting",
      "패턴",
      "캐시",
      "무효화",
      "설정으로",
      "자동"
    ]
  },
  {
    "id": "MONGO-074",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "CDC(Change Data Capture)를 MongoDB에서 구현하는 방법은?",
    "answer": "Change Streams 활용 (권장):\n\nResume Token으로 재시작:\n\nDebezium + Kafka 활용:\nDebezium MongoDB Connector\n대규모 분산 환경에 적합\n\n사용 사례:\n데이터 웨어하우스 동기화\n이벤트 기반 아키텍처\n실시간 분석 파이프라인",
    "references": [
      {
        "title": "Change Streams",
        "url": "https://www.mongodb.com/docs/manual/changeStreams/"
      }
    ],
    "keywords": [
      "change",
      "streams",
      "resume",
      "token",
      "debezium",
      "kafka",
      "mongodb",
      "connector",
      "활용",
      "권장",
      "으로",
      "재시작",
      "대규모",
      "분산",
      "환경에"
    ]
  },
  {
    "id": "MONGO-075",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "MongoDB의 버전별 주요 변경사항과 개선점은?",
    "answer": "버전   주요 기능\n\n3.6   Change Streams, JSON Schema Validation\n4.0   Multi-Document ACID Transactions (Replica Set)\n4.2   Distributed Transactions (Sharded Cluster), Wildcard Index\n4.4   Hedged Reads, Compound Hashed Index\n5.0   Time Series Collection, Versioned API, Resharding\n6.0   Queryable Encryption, Cluster-to-Cluster Sync\n7.0   Sharding 개선, Compound Wildcard Index\n\n주요 트렌드:\n점점 강화되는 Transaction 지원\n보안 기능 강화 (암호화, 감사)\n운영 편의성 개선\n분석 기능 내장 (Atlas Search, Charts)\n\n버전 업그레이드 시:\nCompatibility Mode 확인\nFeature Compatibility Version 설정\n롤링 업그레이드 권장",
    "references": [
      {
        "title": "Release Notes",
        "url": "https://www.mongodb.com/docs/manual/release-notes/"
      }
    ],
    "keywords": [
      "change",
      "streams",
      "json",
      "schema",
      "validation",
      "multi-document",
      "acid",
      "transactions",
      "replica",
      "set",
      "distributed",
      "sharded",
      "cluster",
      "wildcard",
      "index"
    ]
  },
  {
    "id": "MONGO-076",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "대량의 데이터 마이그레이션 시 고려사항은?",
    "answer": "사전 준비:\n데이터 크기/구조 분석\n다운타임 허용 범위 결정\n롤백 계획 수립\n\n마이그레이션 방법:\nmongodump/mongorestore:\nmongoimport (JSON/CSV):\nBulk Write API:\n\n최적화:\n인덱스 나중에 생성 (삽입 속도 향상)\nordered: false로 병렬 처리\nBalancer 일시 중지 (Sharded)\n\n주의사항:\n네트워크 대역폭 확인\n대상 서버 리소스 모니터링\n증분 마이그레이션 고려",
    "references": [
      {
        "title": "mongoimport",
        "url": "https://www.mongodb.com/docs/database-tools/mongoimport/"
      }
    ],
    "keywords": [
      "json",
      "csv",
      "bulk",
      "write",
      "api",
      "balancer",
      "sharded",
      "사전",
      "준비",
      "데이터",
      "크기",
      "구조",
      "분석",
      "다운타임",
      "허용"
    ]
  },
  {
    "id": "MONGO-077",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Hot Shard 문제를 어떻게 해결하나요?",
    "answer": "Hot Shard는 특정 Shard에 읽기/쓰기가 집중되는 현상입니다.\n\n원인:\n단조 증가 Shard Key (ObjectId, 타임스탬프)\n낮은 Cardinality Shard Key\n불균등한 데이터 분포\n\n해결 방법:\nHash Sharding 사용:\n복합 Shard Key:\nShard Key 변경 (5.0+):\nZone Sharding으로 분산:\n\n모니터링:",
    "references": [
      {
        "title": "Shard Key Selection",
        "url": "https://www.mongodb.com/docs/manual/core/sharding-choose-a-shard-key/"
      }
    ],
    "keywords": [
      "hot",
      "shard",
      "key",
      "objectid",
      "cardinality",
      "hash",
      "sharding",
      "zone",
      "특정",
      "읽기",
      "쓰기가",
      "집중되는",
      "현상입니다",
      "원인",
      "단조"
    ]
  },
  {
    "id": "MONGO-078",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "N+1 문제가 MongoDB에서도 발생하나요? 해결 방법은?",
    "answer": "네, Reference 방식 사용 시 N+1 문제가 발생할 수 있습니다.\n\nN+1 문제 예시:\n\n해결 방법:\n$lookup 사용:\nEmbedding (비정규화):\nBatch 조회:",
    "references": [
      {
        "title": "$lookup",
        "url": "https://www.mongodb.com/docs/manual/reference/operator/aggregation/lookup/"
      }
    ],
    "keywords": [
      "reference",
      "embedding",
      "batch",
      "방식",
      "사용",
      "문제가",
      "발생할",
      "문제",
      "예시",
      "해결",
      "방법",
      "비정규화",
      "조회"
    ]
  },
  {
    "id": "MONGO-079",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "실시간 분석을 위한 MongoDB 설계 방법은?",
    "answer": "사전 집계 (Pre-aggregation):\nTime Series Collection (5.0+):\nChange Streams + 스트리밍:\n읽기 분산:\nSecondary에서 분석 쿼리 실행\nAnalytics Node 설정\nAtlas Charts:\n내장 실시간 시각화\n\n아키텍처:",
    "references": [
      {
        "title": "Time Series Best Practices",
        "url": "https://www.mongodb.com/docs/manual/core/timeseries/timeseries-best-practices/"
      }
    ],
    "keywords": [
      "pre-aggregation",
      "time",
      "series",
      "collection",
      "change",
      "streams",
      "secondary",
      "analytics",
      "node",
      "atlas",
      "charts",
      "사전",
      "집계",
      "스트리밍",
      "읽기"
    ]
  },
  {
    "id": "MONGO-080",
    "category": "mongodb",
    "categoryName": "MongoDB",
    "priority": "P3",
    "question": "Multi-tenancy 아키텍처를 MongoDB로 구현하는 방법은?",
    "answer": "컬렉션 내 테넌트 필드:\n테넌트별 컬렉션:\n테넌트별 데이터베이스:\n\n비교:\n방식   격리 수준   관리 복잡도   확장성\n\n필드   낮음   쉬움   높음\n컬렉션   중간   중간   중간\n데이터베이스   높음   어려움   낮음\n\nZone Sharding 활용:",
    "references": [
      {
        "title": "Multi-tenant Data",
        "url": "https://www.mongodb.com/docs/manual/tutorial/model-data-for-keyword-search/"
      }
    ],
    "keywords": [
      "zone",
      "sharding",
      "컬렉션",
      "테넌트",
      "필드",
      "테넌트별",
      "데이터베이스",
      "비교",
      "방식",
      "격리",
      "수준",
      "관리",
      "복잡도",
      "확장성",
      "낮음"
    ]
  },
  {
    "id": "REDIS-001",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 기본 개념과 주요 특징은 무엇인가요?",
    "answer": "Redis(Remote Dictionary Server)는 오픈소스 인메모리 데이터 구조 저장소입니다.\n\n주요 특징:\n인메모리 저장: 모든 데이터를 메모리에 저장하여 매우 빠른 읽기/쓰기 성능 제공\n다양한 데이터 구조: String, List, Set, Sorted Set, Hash, Stream 등 지원\n싱글 스레드: 단일 스레드로 명령을 처리하여 원자성 보장\nPersistence: RDB 스냅샷과 AOF 로그를 통한 데이터 영속성 지원\n복제 및 클러스터링: Master-Replica 복제와 Redis Cluster를 통한 고가용성 및 확장성\nPub/Sub: 실시간 메시징 기능 제공",
    "references": [
      {
        "title": "Redis Introduction",
        "url": "https://redis.io/docs/about/"
      }
    ],
    "keywords": [
      "redis",
      "remote",
      "dictionary",
      "server",
      "string",
      "list",
      "set",
      "sorted",
      "hash",
      "stream",
      "persistence",
      "rdb",
      "aof",
      "master-replica",
      "cluster"
    ]
  },
  {
    "id": "REDIS-002",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis가 메모리 기반 데이터 저장소로서 제공하는 장점은 무엇이며, 이로 인한 단점은 무엇인가요?",
    "answer": "장점:\n초고속 성능: 디스크 I/O 없이 메모리에서 직접 데이터 접근 (읽기/쓰기 지연시간 마이크로초 단위)\n높은 처리량: 초당 수십만 건의 연산 처리 가능\n낮은 지연시간: 실시간 애플리케이션에 적합\n예측 가능한 성능: 디스크 기반 DB의 캐시 미스로 인한 성능 변동 없음\n\n단점:\n메모리 비용: RAM은 디스크보다 비싸므로 대용량 데이터 저장 시 비용 증가\n데이터 용량 제한: 물리적 메모리 크기에 제한됨\n휘발성 위험: 서버 장애 시 메모리 데이터 손실 가능 (Persistence 설정으로 완화)\n메모리 단편화: 장시간 운영 시 메모리 단편화 발생 가능",
    "references": [
      {
        "title": "Redis Persistence",
        "url": "https://redis.io/docs/management/persistence/"
      }
    ],
    "keywords": [
      "ram",
      "persistence",
      "장점",
      "초고속",
      "성능",
      "디스크",
      "없이",
      "메모리에서",
      "직접",
      "데이터",
      "접근",
      "읽기",
      "쓰기",
      "지연시간",
      "마이크로초"
    ]
  },
  {
    "id": "REDIS-003",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis에서 제공하는 데이터 타입(스트링, 리스트, 셋, 정렬된 셋, 해시 등)에 대해 설명해주세요.",
    "answer": "String\n가장 기본적인 타입, 최대 512MB 저장\n텍스트, 숫자, 바이너리 데이터 저장 가능\n사용 예: 캐싱, 세션 저장, 카운터\n\nList\n순서가 있는 문자열 리스트 (양방향 연결 리스트)\n앞/뒤에서 삽입/삭제 O(1)\n사용 예: 메시지 큐, 최근 항목 목록\n\nSet\n중복 없는 문자열 집합\n합집합, 교집합, 차집합 연산 지원\n사용 예: 태그, 고유 방문자 추적\n\nSorted Set (ZSet)\n점수(score)로 정렬된 고유 문자열 집합\n범위 조회, 순위 조회 효율적\n사용 예: 리더보드, 우선순위 큐\n\nHash\n필드-값 쌍의 컬렉션 (객체 표현에 적합)\n개별 필드 접근/수정 가능\n사용 예: 사용자 프로필, 설정 정보\n\nStream\n로그 형태의 데이터 구조, 시간순 메시지 저장\nConsumer Group 지원으로 메시지 큐 구현\n사용 예: 이벤트 소싱, 메시지 스트리밍",
    "references": [
      {
        "title": "Redis Data Types",
        "url": "https://redis.io/docs/data-types/"
      }
    ],
    "keywords": [
      "string",
      "list",
      "set",
      "sorted",
      "zset",
      "hash",
      "stream",
      "consumer",
      "group",
      "가장",
      "기본적인",
      "타입",
      "최대",
      "저장",
      "텍스트"
    ]
  },
  {
    "id": "REDIS-004",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 키-값 구조와 다른 NoSQL 데이터베이스와의 차이점은 무엇인가요?",
    "answer": "Redis의 키-값 구조 특징:\n키는 바이너리 세이프 문자열 (최대 512MB)\n값은 단순 문자열이 아닌 다양한 데이터 구조 지원 (Rich Data Structures)\n\n다른 NoSQL과의 차이점:\n\n구분   Redis   Document DB (MongoDB)   Wide-Column (Cassandra)\n\n데이터 모델   Key-Value + 데이터 구조   JSON Document   Column Family\n저장 위치   인메모리 (선택적 디스크)   디스크   디스크\n쿼리   키 기반 + 제한적 검색   풍부한 쿼리 언어   CQL\n주 용도   캐시, 세션, 실시간 처리   범용   대규모 분산 저장\n일관성   강한 일관성 (단일)   튜너블   튜너블\n\nRedis만의 강점:\n원자적 연산 보장 (싱글 스레드)\n밀리초 이하의 지연시간\n풍부한 데이터 구조로 복잡한 연산 지원",
    "references": [
      {
        "title": "Redis Keys",
        "url": "https://redis.io/docs/data-types/tutorial/"
      }
    ],
    "keywords": [
      "redis",
      "rich",
      "data",
      "structures",
      "nosql",
      "document",
      "mongodb",
      "wide-column",
      "cassandra",
      "key-value",
      "json",
      "column",
      "family",
      "cql",
      "구조"
    ]
  },
  {
    "id": "REDIS-005",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis에서 Persistence를 위해 지원하는 RDB와 AOF 방식의 차이점과 각각의 장단점은 무엇인가요?",
    "answer": "RDB (Redis Database Backup)\n특정 시점의 메모리 스냅샷을 바이너리 파일로 저장\nSAVE (동기) 또는 BGSAVE (비동기) 명령으로 생성\n\n장점   단점\n\n컴팩트한 단일 파일로 백업 용이   스냅샷 간 데이터 손실 가능\n복구 속도 빠름   대용량 데이터 시 fork() 부하\nAOF보다 빠른 재시작\n\nAOF (Append Only File)\n모든 쓰기 명령을 로그로 기록\nappendfsync 옵션: always, everysec, no\n\n장점   단점\n\n데이터 손실 최소화 (최대 1초)   파일 크기가 RDB보다 큼\n사람이 읽을 수 있는 로그   복구 시간이 더 길 수 있음\nRewrite로 파일 크기 최적화   쓰기 성능 약간 저하\n\n권장 설정:\n둘 다 활성화하여 상호 보완\nAOF로 내구성 확보, RDB로 빠른 복구 및 백업",
    "references": [
      {
        "title": "Redis Persistence",
        "url": "https://redis.io/docs/management/persistence/"
      }
    ],
    "keywords": [
      "rdb",
      "redis",
      "database",
      "backup",
      "save",
      "bgsave",
      "aof",
      "append",
      "file",
      "rewrite",
      "특정",
      "시점의",
      "메모리",
      "스냅샷을",
      "바이너리"
    ]
  },
  {
    "id": "REDIS-006",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 Pub/Sub 기능은 어떻게 동작하며, 이를 활용한 메시징 시스템 구현 사례에 대해 설명해주세요.",
    "answer": "동작 방식:\nPublisher: PUBLISH channel message 명령으로 채널에 메시지 발행\nSubscriber: SUBSCRIBE channel 명령으로 채널 구독\n메시지는 구독 중인 모든 클라이언트에게 실시간으로 전달 (Fire-and-forget)\n\n특징:\n채널은 사전 생성 불필요 (동적 생성)\n패턴 구독 지원 (PSUBSCRIBE news.*)\n메시지 저장 없음 (구독자 없으면 메시지 손실)\nAt-most-once 전달 보장\n\n활용 사례:\n실시간 알림 시스템\n채팅 애플리케이션\n캐시 무효화 브로드캐스트\n마이크로서비스 이벤트 전파\n서비스 간 느슨한 결합 유지\n이벤트 기반 아키텍처 구현\n\n주의사항:\n메시지 영속성 필요 시 Redis Streams 권장\n대규모 시스템에서는 Kafka 등 전용 메시지 브로커 고려",
    "references": [
      {
        "title": "Redis Pub/Sub",
        "url": "https://redis.io/docs/interact/pubsub/"
      }
    ],
    "keywords": [
      "publisher",
      "publish",
      "subscriber",
      "subscribe",
      "fire-and-forget",
      "psubscribe",
      "at-most-once",
      "redis",
      "streams",
      "kafka",
      "동작",
      "방식",
      "명령으로",
      "채널에",
      "메시지"
    ]
  },
  {
    "id": "REDIS-007",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis Cluster의 기본 아키텍처와 데이터 샤딩(sharding) 방식에 대해 설명해주세요.",
    "answer": "기본 아키텍처:\n최소 3개의 마스터 노드로 구성\n각 마스터는 1개 이상의 레플리카 보유 권장\n노드 간 Gossip 프로토콜로 상태 공유\n클라이언트는 어떤 노드에 연결해도 올바른 노드로 리다이렉트\n\n데이터 샤딩 방식 (Hash Slot):\n총 16,384개의 해시 슬롯 사용\n키의 CRC16 해시값 % 16384로 슬롯 결정\n각 마스터 노드가 슬롯의 일부를 담당\n\nHash Tag:\n{user}:profile, {user}:settings처럼 중괄호 사용\n같은 태그의 키는 동일 슬롯에 저장 (멀티키 연산 가능)\n\n장점:\n수평적 확장성 (노드 추가로 용량/처리량 증가)\n자동 페일오버로 고가용성 확보\n데이터 자동 재분배",
    "references": [
      {
        "title": "Redis Cluster Specification",
        "url": "https://redis.io/docs/reference/cluster-spec/"
      }
    ],
    "keywords": [
      "gossip",
      "hash",
      "slot",
      "crc16",
      "tag",
      "기본",
      "아키텍처",
      "최소",
      "개의",
      "마스터",
      "노드로",
      "구성",
      "마스터는",
      "이상의",
      "레플리카"
    ]
  },
  {
    "id": "REDIS-008",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis Sentinel의 역할은 무엇이며, 이를 통해 어떻게 고가용성을 보장할 수 있나요?",
    "answer": "Redis Sentinel의 역할:\n모니터링 (Monitoring)\nMaster와 Replica 인스턴스 상태 지속 확인\n노드의 정상 동작 여부 감시\n알림 (Notification)\n장애 발생 시 관리자/시스템에 알림\nAPI를 통한 이벤트 전달\n자동 페일오버 (Automatic Failover)\nMaster 장애 감지 시 Replica를 새 Master로 승격\n다른 Replica들을 새 Master에 연결\n클라이언트에게 새 Master 주소 제공\n구성 제공자 (Configuration Provider)\n클라이언트가 현재 Master 주소를 Sentinel에 질의\n\n동작 방식:\n\n권장 구성:\n최소 3개의 Sentinel 인스턴스 (홀수 권장)\n서로 다른 물리 서버/가용 영역에 배치\nquorum 설정으로 페일오버 결정 기준 지정",
    "references": [
      {
        "title": "Redis Sentinel",
        "url": "https://redis.io/docs/management/sentinel/"
      }
    ],
    "keywords": [
      "redis",
      "sentinel",
      "monitoring",
      "master",
      "replica",
      "notification",
      "api",
      "automatic",
      "failover",
      "configuration",
      "provider",
      "역할",
      "모니터링",
      "인스턴스",
      "상태"
    ]
  },
  {
    "id": "REDIS-009",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 캐시 만료(expiration) 정책 설정 방법과, 실제 운영 시 고려해야 할 점은 무엇인가요?",
    "answer": "만료 시간 설정 방법:\n\n운영 시 고려사항:\nCache Stampede (Thundering Herd)\n동시에 많은 키 만료 시 DB 부하 급증\n해결: 만료 시간에 랜덤 지터(jitter) 추가\n메모리 관리\n만료된 키는 즉시 삭제되지 않음 (lazy + 주기적 삭제)\nmaxmemory 설정과 함께 eviction 정책 설정 필요\nTTL 설계\n데이터 특성에 맞는 적절한 TTL 설정\n너무 짧으면 캐시 효율 저하, 너무 길면 데이터 불일치\n만료 이벤트 모니터링\nKeyspace notifications로 만료 이벤트 구독 가능\nCONFIG SET notify-keyspace-events Ex",
    "references": [
      {
        "title": "Redis EXPIRE",
        "url": "https://redis.io/commands/expire/"
      }
    ],
    "keywords": [
      "cache",
      "stampede",
      "thundering",
      "herd",
      "ttl",
      "keyspace",
      "config",
      "set",
      "notify-keyspace",
      "만료",
      "시간",
      "설정",
      "방법",
      "운영",
      "고려사항"
    ]
  },
  {
    "id": "REDIS-010",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 캐시 eviction 정책(LRU, LFU, TTL 등) 간의 차이점과 선택 기준에 대해 설명해주세요.",
    "answer": "Eviction 정책 종류:\n\n정책   설명\n\nnoeviction   메모리 초과 시 쓰기 명령 에러 반환\nallkeys-lru   모든 키 중 가장 오래 사용되지 않은 키 제거\nvolatile-lru   만료 설정된 키 중 LRU 제거\nallkeys-lfu   모든 키 중 가장 적게 사용된 키 제거\nvolatile-lfu   만료 설정된 키 중 LFU 제거\nallkeys-random   모든 키 중 무작위 제거\nvolatile-random   만료 설정된 키 중 무작위 제거\nvolatile-ttl   만료 시간이 가장 짧은 키 제거\n\nLRU vs LFU 비교:\nLRU (Least Recently Used): 최근 접근 시간 기준\n최근 사용된 데이터가 다시 사용될 확률 높음 가정\n일반적인 캐시 워크로드에 적합\nLFU (Least Frequently Used): 접근 빈도 기준\n자주 사용되는 데이터 유지\n인기 콘텐츠 캐싱에 적합 (Redis 4.0+)\n\n선택 기준:\n\n사용 사례   권장 정책\n\n일반 캐시   allkeys-lru\n세션 저장소   volatile-lru 또는 volatile-ttl\n인기 콘텐츠 캐시   allkeys-lfu\n데이터 손실 불가   noeviction\n\n설정 방법:",
    "references": [
      {
        "title": "Redis Eviction",
        "url": "https://redis.io/docs/reference/eviction/"
      }
    ],
    "keywords": [
      "eviction",
      "allkeys-lru",
      "volatile-lru",
      "lru",
      "allkeys-lfu",
      "volatile-lfu",
      "lfu",
      "allkeys-random",
      "volatile-random",
      "volatile-ttl",
      "least",
      "recently",
      "frequently",
      "redis",
      "정책"
    ]
  },
  {
    "id": "REDIS-011",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 트랜잭션 기능(MULTI, EXEC, WATCH 등)을 활용하여 동시성 문제를 어떻게 해결할 수 있는지 설명해주세요.",
    "answer": "기본 트랜잭션 (MULTI/EXEC):\n큐에 쌓인 명령들이 순차적으로 원자적 실행\n중간에 다른 클라이언트 명령 끼어들지 않음\n\nWATCH를 활용한 Optimistic Locking:\n\n동시성 문제 해결 예시 (재고 차감):\n\n주의사항:\nRedis 트랜잭션은 롤백 없음 (에러 발생해도 다른 명령 실행됨)\nWATCH는 트랜잭션 전 키 변경 감지용 (낙관적 잠금)\n복잡한 원자적 연산은 Lua 스크립트 권장",
    "references": [
      {
        "title": "Redis Transactions",
        "url": "https://redis.io/docs/interact/transactions/"
      }
    ],
    "keywords": [
      "multi",
      "exec",
      "watch",
      "optimistic",
      "locking",
      "redis",
      "lua",
      "기본",
      "트랜잭션",
      "큐에",
      "쌓인",
      "명령들이",
      "순차적으로",
      "원자적",
      "실행"
    ]
  },
  {
    "id": "REDIS-012",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis에서 Lua 스크립트를 사용하는 이유와, 스크립팅 기능이 주는 이점은 무엇인가요?",
    "answer": "Lua 스크립트 사용 이유:\n원자성 보장\n스크립트 전체가 단일 명령처럼 원자적 실행\n중간에 다른 명령 끼어들지 않음\n네트워크 왕복 감소\n여러 명령을 한 번의 호출로 실행\n클라이언트-서버 간 통신 오버헤드 감소\n복잡한 로직 구현\n조건문, 반복문 등 프로그래밍 로직 사용 가능\nMULTI/EXEC로 불가능한 연산 구현\n\n사용 예시 - Rate Limiter:\n\n실행 방법:\n\n이점 정리:\n장점   설명\n\n원자성   경쟁 상태 방지\n성능   네트워크 RTT 최소화\n재사용성   EVALSHA로 캐싱된 스크립트 재사용\n유연성   복잡한 비즈니스 로직 서버사이드 실행",
    "references": [
      {
        "title": "Redis Scripting",
        "url": "https://redis.io/docs/interact/programmability/eval-intro/"
      }
    ],
    "keywords": [
      "lua",
      "multi",
      "exec",
      "rate",
      "limiter",
      "rtt",
      "evalsha",
      "스크립트",
      "사용",
      "이유",
      "원자성",
      "보장",
      "전체가",
      "단일",
      "명령처럼"
    ]
  },
  {
    "id": "REDIS-013",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 메모리 관리 전략과, 메모리 부족 시 발생할 수 있는 문제 및 해결 방법에 대해 설명해주세요.",
    "answer": "메모리 관리 전략:\nmaxmemory 설정\nmaxmemory-policy 설정\n메모리 한계 도달 시 동작 정의\nallkeys-lru, volatile-lru, noeviction 등\n데이터 구조 최적화\n짧은 키 이름 사용\nHash로 작은 객체들 그룹화\n적절한 데이터 타입 선택\n\n메모리 부족 시 문제:\n\n문제   설명\n\n쓰기 실패   noeviction 정책 시 OOM 에러\n성능 저하   빈번한 eviction으로 캐시 히트율 하락\n스왑 사용   OS 스왑 발생 시 심각한 지연\n복제 지연   메모리 부족으로 복제 버퍼 오버플로우\n서비스 중단   OOM Killer에 의해 프로세스 종료\n\n해결 방법:\n설정 최적화\n모니터링 및 알림\n아키텍처 개선\nRedis Cluster로 수평 확장\n데이터 TTL 적절히 설정\n대용량 데이터는 다른 저장소 사용",
    "references": [
      {
        "title": "Redis Memory Optimization",
        "url": "https://redis.io/docs/management/optimization/memory-optimization/"
      }
    ],
    "keywords": [
      "maxmemory-policy",
      "allkeys-lru",
      "volatile-lru",
      "hash",
      "oom",
      "killer",
      "redis",
      "cluster",
      "ttl",
      "메모리",
      "관리",
      "전략",
      "설정",
      "한계",
      "도달"
    ]
  },
  {
    "id": "REDIS-014",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis에서 Key 네임스페이스(예: Key prefix)를 사용하는 이유와 장점은 무엇인가요?",
    "answer": "Key Prefix 사용 이유:\n\nRedis는 단일 키 공간(flat namespace)을 사용하므로, 논리적 그룹화를 위해 프리픽스 컨벤션 사용\n\n네이밍 컨벤션 예시:\n\n장점:\n논리적 분리\n데이터 유형별, 서비스별 키 구분\n멀티테넌트 환경에서 테넌트별 분리\n관리 용이성\nKEYS user:* 또는 SCAN으로 그룹 조회\n특정 프리픽스 일괄 삭제 가능\nRedis Cluster 최적화\nHash Tag {user:1234}:profile로 관련 키 같은 슬롯 배치\n멀티키 연산 가능하게 함\n충돌 방지\n여러 애플리케이션이 같은 Redis 사용 시 네임스페이스 분리\n환경별 구분 (dev:, staging:, prod:)\n모니터링 및 분석\n프리픽스별 메모리 사용량 분석\n키 패턴별 접근 통계",
    "references": [
      {
        "title": "Redis Key Patterns",
        "url": "https://redis.io/docs/data-types/tutorial/"
      }
    ],
    "keywords": [
      "key",
      "prefix",
      "redis",
      "keys",
      "scan",
      "cluster",
      "hash",
      "tag",
      "사용",
      "이유",
      "단일",
      "공간",
      "사용하므로",
      "논리적",
      "그룹화를"
    ]
  },
  {
    "id": "REDIS-015",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis를 활용한 세션 관리 구현의 장점과 고려해야 할 단점은 무엇인가요?",
    "answer": "장점:\n빠른 성능\n인메모리 저장으로 밀리초 이하 세션 조회\n높은 동시 접속자 처리 가능\n분산 환경 지원\n여러 애플리케이션 서버가 세션 공유\n로드 밸런서 뒤에서 Sticky Session 불필요\n자동 만료\nTTL 설정으로 세션 자동 정리\n메모리 관리 용이\n확장성\nRedis Cluster로 수평 확장\n수백만 세션 처리 가능\n\n구현 예시:\n\n고려해야 할 단점:\n데이터 손실 위험\n메모리 기반으로 서버 장애 시 세션 손실\n해결: AOF 활성화, Replica 구성\n추가 인프라\nRedis 서버 별도 운영 필요\n네트워크 홉 추가\n직렬화 오버헤드\n세션 객체 직렬화/역직렬화 필요\n보안 고려사항\nRedis 접근 제어 필요\n민감 정보 암호화 권장\n네트워크 의존성\nRedis 연결 실패 시 서비스 영향\n해결: 연결 풀링, 회로 차단기 패턴",
    "references": [
      {
        "title": "Redis as Session Store",
        "url": "https://redis.io/docs/latest/develop/use/patterns/"
      }
    ],
    "keywords": [
      "sticky",
      "session",
      "ttl",
      "redis",
      "cluster",
      "aof",
      "replica",
      "장점",
      "빠른",
      "성능",
      "인메모리",
      "저장으로",
      "밀리초",
      "이하",
      "세션"
    ]
  },
  {
    "id": "REDIS-016",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 데이터 복제(replication) 메커니즘과 이를 통한 데이터 가용성 확보 방법에 대해 설명해주세요.",
    "answer": "복제 메커니즘:\n초기 동기화 (Full Sync)\nReplica가 Master에 연결 시 RDB 스냅샷 전송\n스냅샷 생성 중 발생한 쓰기는 버퍼에 저장 후 전송\n지속적 복제 (Incremental Sync)\nMaster의 모든 쓰기 명령을 Replica에 전파\n비동기 방식으로 동작 (기본)\n부분 재동기화 (Partial Resync)\n연결 끊김 후 재연결 시 변경분만 동기화\nReplication Backlog 버퍼 활용\n\n설정 방법:\n\n가용성 확보 방법:\n읽기 부하 분산\nReplica에서 읽기 처리로 Master 부하 감소\n장애 대응\nMaster 장애 시 Replica를 Master로 승격\n자동: Redis Sentinel 사용\n데이터 안전성",
    "references": [
      {
        "title": "Redis Replication",
        "url": "https://redis.io/docs/management/replication/"
      }
    ],
    "keywords": [
      "full",
      "sync",
      "replica",
      "master",
      "rdb",
      "incremental",
      "partial",
      "resync",
      "replication",
      "backlog",
      "redis",
      "sentinel",
      "복제",
      "메커니즘",
      "초기"
    ]
  },
  {
    "id": "REDIS-017",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis에서 데이터 정합성을 보장하기 위한 방법에는 어떤 것들이 있으며, 각각의 한계는 무엇인가요?",
    "answer": "데이터 정합성 보장 방법:\n동기 복제 설정\n한계: 지연시간 증가, Replica 장애 시 쓰기 차단 가능\n최소 Replica 요구사항\n한계: Replica 부족 시 쓰기 불가\nLua 스크립트 활용\n복잡한 연산을 원자적으로 실행\n한계: 스크립트 실행 중 전체 Redis 블로킹\nWATCH/MULTI 트랜잭션\nOptimistic Locking으로 동시성 제어\n한계: 충돌 시 재시도 필요\n\nRedis의 근본적 한계:\n\n한계   설명\n\n비동기 복제   기본적으로 Master 쓰기 후 응답, Replica 복제는 비동기\n최종 일관성   강한 일관성 보장 불가 (CAP에서 AP 성향)\n페일오버 데이터 손실   Master 장애 시 미복제 데이터 손실 가능",
    "references": [
      {
        "title": "Redis Consistency",
        "url": "https://redis.io/docs/management/replication/"
      }
    ],
    "keywords": [
      "replica",
      "lua",
      "redis",
      "watch",
      "multi",
      "optimistic",
      "locking",
      "master",
      "cap",
      "데이터",
      "정합성",
      "보장",
      "방법",
      "동기",
      "복제"
    ]
  },
  {
    "id": "REDIS-018",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis 성능 최적화를 위해 고려해야 할 주요 설정과 모니터링 도구에는 어떤 것들이 있나요?",
    "answer": "주요 성능 최적화 설정:\n메모리 관련\nPersistence 튜닝\n클라이언트 최적화\n연결 풀링 사용\n파이프라이닝으로 RTT 감소\n\n모니터링 도구 및 명령:\n\n도구/명령   용도\n\nINFO   전체 서버 통계\nINFO memory   메모리 상세 정보\nSLOWLOG GET   느린 명령 로그\nLATENCY DOCTOR   지연 진단\nMEMORY DOCTOR   메모리 문제 진단\n\n외부 모니터링 도구:\nRedis Insight: 공식 GUI 모니터링 도구\nPrometheus + Grafana: redis_exporter 연동\n\n최적화 체크리스트:\n적절한 maxmemory 및 eviction 정책\nKEYS 명령 대신 SCAN 사용\n큰 컬렉션 분할 (Big Key 방지)\n파이프라이닝 활용",
    "references": [
      {
        "title": "Redis Administration",
        "url": "https://redis.io/docs/management/admin/"
      }
    ],
    "keywords": [
      "persistence",
      "rtt",
      "info",
      "slowlog",
      "get",
      "latency",
      "doctor",
      "memory",
      "redis",
      "insight",
      "gui",
      "prometheus",
      "grafana",
      "redis_exporter",
      "keys"
    ]
  },
  {
    "id": "REDIS-019",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis와 Memcached의 차이점 및 각 솔루션의 장단점에 대해 설명해주세요.",
    "answer": "주요 차이점 비교:\n\n항목   Redis   Memcached\n\n데이터 타입   String, List, Set, Hash 등   String만\n데이터 영속성   RDB, AOF 지원   없음\n복제   Master-Replica 지원   없음\n클러스터링   Redis Cluster   클라이언트 샤딩\nPub/Sub   지원   미지원\n멀티스레드   싱글 (I/O는 6.0+ 멀티)   멀티스레드\n메모리 효율   상대적으로 낮음   높음\n\nRedis 장점:\n다양한 데이터 구조로 복잡한 연산 가능\n데이터 영속성으로 재시작 후 복구\n복제 및 고가용성 내장\n\nMemcached 장점:\n단순하고 가벼움\n멀티스레드로 멀티코어 활용\n메모리 효율적\n\n선택 기준:\n\n요구사항   권장\n\n단순 키-값 캐시   Memcached\n복잡한 데이터 구조   Redis\n데이터 영속성 필요   Redis\n고가용성 필요   Redis",
    "references": [
      {
        "title": "Redis vs Others",
        "url": "https://redis.io/docs/getting-started/faq/"
      }
    ],
    "keywords": [
      "redis",
      "memcached",
      "string",
      "list",
      "set",
      "hash",
      "rdb",
      "aof",
      "master-replica",
      "cluster",
      "pub",
      "sub",
      "주요",
      "차이점",
      "비교"
    ]
  },
  {
    "id": "REDIS-020",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis를 운영할 때 데이터 보안 및 접근 제어는 어떻게 구현할 수 있나요?",
    "answer": "접근 제어 방법:\n인증 (Authentication)\nACL (Access Control Lists)\n네트워크 보안\nTLS/SSL 암호화\n\n보안 체크리스트:\n\n항목   설정\n\n인증 활성화   requirepass 또는 ACL\n바인딩 제한   bind 127.0.0.1\n위험 명령 비활성화   FLUSHALL, CONFIG 등\nTLS 암호화   프로덕션 환경 필수\n방화벽   신뢰된 IP만 허용",
    "references": [
      {
        "title": "Redis Security",
        "url": "https://redis.io/docs/management/security/"
      }
    ],
    "keywords": [
      "authentication",
      "acl",
      "access",
      "control",
      "lists",
      "tls",
      "ssl",
      "flushall",
      "config",
      "접근",
      "제어",
      "방법",
      "인증",
      "네트워크",
      "보안"
    ]
  },
  {
    "id": "REDIS-021",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis 사용 시 발생할 수 있는 메모리 단편화 문제와 이를 완화하기 위한 전략은 무엇인가요?",
    "answer": "메모리 단편화란?\n할당된 메모리와 실제 사용 메모리 간 차이\nmemfragmentationratio로 확인 (1.0-1.5 정상, 1.5 이상 주의)\n\n발생 원인:\n다양한 크기의 키/값 반복 생성/삭제\n긴 시간 운영으로 메모리 공간 분산\n\n확인 방법:\n\n완화 전략:\nActive Defragmentation (Redis 4.0+)\nJemalloc 사용\nRedis 기본 메모리 할당자\n단편화 최소화에 최적화\n재시작을 통한 해결\nReplica 승격 방식으로 무중단 재시작\n데이터 구조 최적화\n비슷한 크기의 키/값 사용\nHash의 ziplist 인코딩 활용",
    "references": [
      {
        "title": "Redis Memory Optimization",
        "url": "https://redis.io/docs/management/optimization/memory-optimization/"
      }
    ],
    "keywords": [
      "active",
      "defragmentation",
      "redis",
      "jemalloc",
      "replica",
      "hash",
      "메모리",
      "단편화란",
      "할당된",
      "메모리와",
      "실제",
      "사용",
      "차이",
      "확인",
      "정상"
    ]
  },
  {
    "id": "REDIS-022",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 키 만료(expire) 기능이 내부적으로 어떻게 구현되는지, 그리고 만료된 데이터를 효율적으로 처리하는 방법은 무엇인가요?",
    "answer": "내부 구현 방식:\n\nRedis는 Lazy Expiration + Active Expiration 두 가지 방식 조합 사용\nLazy Expiration (수동적)\n클라이언트가 키에 접근할 때 만료 여부 확인\n만료되었으면 삭제 후 nil 반환\nActive Expiration (능동적)\n백그라운드에서 주기적으로 실행 (초당 10회)\n만료 설정된 키 중 무작위 20개 샘플링\n만료된 키 삭제, 25% 이상이면 반복\n\n효율적인 만료 처리 전략:\n만료 시간 분산\nKeyspace Notifications\n\n주의사항:\n만료 키가 많으면 Active Expiration에 CPU 사용\nReplica에서는 Master의 DEL 명령 수신 시 삭제",
    "references": [
      {
        "title": "Redis EXPIRE",
        "url": "https://redis.io/commands/expire/"
      }
    ],
    "keywords": [
      "redis",
      "lazy",
      "expiration",
      "active",
      "keyspace",
      "notifications",
      "cpu",
      "replica",
      "master",
      "del",
      "내부",
      "구현",
      "방식",
      "가지",
      "조합"
    ]
  },
  {
    "id": "REDIS-023",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 비동기 복제와 동기 복제 방식의 차이점, 그리고 각 방식의 선택 기준에 대해 설명해주세요.",
    "answer": "비동기 복제 (기본값):\nMaster가 쓰기 완료 후 즉시 클라이언트에 응답\nReplica로 전파는 백그라운드에서 진행\n지연시간 최소화, 데이터 손실 가능성 있음\n\n동기 복제 (WAIT 명령):\n\n차이점 비교:\n\n항목   비동기 복제   동기 복제 (WAIT)\n\n응답 시점   즉시   Replica 확인 후\n지연시간   낮음   높음\n데이터 손실 위험   있음   감소\n\n선택 기준:\n\n상황   권장 방식\n\n캐시 용도, 성능 중시   비동기 (기본)\n데이터 손실 허용 불가   WAIT 사용\n금융/결제 시스템   WAIT + 최소 1~2 Replica",
    "references": [
      {
        "title": "Redis Replication",
        "url": "https://redis.io/docs/management/replication/"
      }
    ],
    "keywords": [
      "master",
      "replica",
      "wait",
      "비동기",
      "복제",
      "기본값",
      "쓰기",
      "완료",
      "즉시",
      "클라이언트에",
      "응답",
      "전파는",
      "백그라운드에서",
      "진행",
      "지연시간"
    ]
  },
  {
    "id": "REDIS-024",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 WATCH 명령어를 활용한 Optimistic Locking 메커니즘은 어떻게 동작하나요?",
    "answer": "Optimistic Locking 개념:\n데이터 충돌이 드물다고 가정\n락을 미리 잡지 않고 커밋 시점에 충돌 검사\n충돌 발생 시 재시도\n\nWATCH 동작 방식:\n\n구현 예시:\n\n주요 명령어:\n\n명령   설명\n\nWATCH key   키 감시 시작\nUNWATCH   감시 해제\nMULTI   트랜잭션 시작\nEXEC   실행 (WATCH 키 변경 시 nil)",
    "references": [
      {
        "title": "Redis Transactions",
        "url": "https://redis.io/docs/interact/transactions/"
      }
    ],
    "keywords": [
      "optimistic",
      "locking",
      "watch",
      "unwatch",
      "multi",
      "exec",
      "개념",
      "데이터",
      "충돌이",
      "드물다고",
      "가정",
      "락을",
      "미리",
      "잡지",
      "않고"
    ]
  },
  {
    "id": "REDIS-025",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis Cluster에서 데이터 재분배(Resharding)를 수행할 때의 절차와 주의할 점은 무엇인가요?",
    "answer": "Resharding이란?\n해시 슬롯을 노드 간 이동하여 데이터 재분배\n노드 추가/제거, 부하 분산 시 필요\n\n절차:\n클러스터 상태 확인\n새 노드 추가 (필요 시)\n슬롯 재분배\n\n주의사항:\n\n주의점   설명\n\n서비스 영향   슬롯 이동 중 리다이렉트 발생\n대역폭   대량 데이터 이동 시 네트워크 부하\nBig Key   큰 키 이동 시 블로킹 가능\n점진적 수행   한 번에 많은 슬롯 이동 피하기\n\n모범 사례:\n트래픽 낮은 시간에 수행\n소량씩 점진적 이동\n각 단계 후 상태 확인",
    "references": [
      {
        "title": "Redis Cluster Tutorial",
        "url": "https://redis.io/docs/management/scaling/"
      }
    ],
    "keywords": [
      "resharding",
      "big",
      "key",
      "이란",
      "해시",
      "슬롯을",
      "노드",
      "이동하여",
      "데이터",
      "재분배",
      "추가",
      "제거",
      "부하",
      "분산",
      "필요"
    ]
  },
  {
    "id": "REDIS-026",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 Multi/Exec 트랜잭션이 ACID 특성을 어떻게 보장하는지 설명해주세요.",
    "answer": "ACID 특성별 분석:\nAtomicity (원자성) - 부분적 보장\n트랜잭션 내 명령들은 연속적으로 실행됨\n주의: 개별 명령 실패해도 나머지 명령 계속 실행 (롤백 없음)\nConsistency (일관성) - 부분적 보장\n단일 명령은 항상 일관성 유지\n트랜잭션 중 에러 발생 시 부분 적용 가능\nIsolation (격리성) - 보장\n싱글 스레드로 명령 처리\nMULTI/EXEC 블록은 완전히 격리\nDurability (지속성) - 설정에 따라\n설정   지속성\n\nAOF always   모든 명령 기록\nAOF everysec   최대 1초 손실\n\nRDBMS 트랜잭션과 비교:\n\n특성   Redis   RDBMS\n\n원자성   부분적 (롤백 없음)   완전\n격리성   완전   레벨 선택 가능\n롤백   불가   가능\n\n결론:\nRedis 트랜잭션은 전통적 ACID 완전 보장하지 않음\n강한 트랜잭션 필요 시 Lua 스크립트 또는 RDBMS 고려",
    "references": [
      {
        "title": "Redis Transactions",
        "url": "https://redis.io/docs/interact/transactions/"
      }
    ],
    "keywords": [
      "acid",
      "atomicity",
      "consistency",
      "isolation",
      "multi",
      "exec",
      "durability",
      "aof",
      "rdbms",
      "redis",
      "lua",
      "특성별",
      "분석",
      "원자성",
      "부분적"
    ]
  },
  {
    "id": "REDIS-027",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "정렬된 셋(sorted set)의 내부 구현 방식과, 이를 활용한 대표적인 활용 사례에 대해 설명해주세요.",
    "answer": "내부 구현 방식:\n작은 데이터: Listpack\n조건: 원소 128개 이하 & 각 원소 64바이트 이하\n연속된 메모리 블록에 저장\n큰 데이터: Skip List + Hash Table\nSkip List: 점수 기반 정렬 및 범위 검색 O(log N)\nHash Table: 멤버-점수 O(1) 조회\n\n시간 복잡도:\n\n연산   복잡도\n\nZADD   O(log N)\nZSCORE   O(1)\nZRANGE   O(log N + M)\n\n대표 활용 사례:\n리더보드\n시간 기반 이벤트\n레이트 리미터",
    "references": [
      {
        "title": "Redis Sorted Sets",
        "url": "https://redis.io/docs/data-types/sorted-sets/"
      }
    ],
    "keywords": [
      "listpack",
      "skip",
      "list",
      "hash",
      "table",
      "zadd",
      "zscore",
      "zrange",
      "내부",
      "구현",
      "방식",
      "작은",
      "데이터",
      "조건",
      "원소"
    ]
  },
  {
    "id": "REDIS-028",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis의 해시(Hash) 자료구조를 활용하여 메모리 사용량을 최적화하는 방법은 무엇인가요?",
    "answer": "Hash의 메모리 최적화 원리:\n\n작은 Hash는 listpack 인코딩 사용\n연속된 메모리 블록에 필드-값 저장\n개별 키-값 대비 메모리 오버헤드 감소\n\n최적화 전략:\n객체 저장 시 Hash 사용\n작은 객체 버킷팅\n\n주의사항:\n\n항목   고려사항\n\nlistpack 한계 초과   hashtable로 변환되어 메모리 증가\n필드 독립적 TTL   Hash 필드별 만료 불가\n\n메모리 분석:",
    "references": [
      {
        "title": "Redis Hashes",
        "url": "https://redis.io/docs/data-types/hashes/"
      }
    ],
    "keywords": [
      "hash",
      "ttl",
      "메모리",
      "최적화",
      "원리",
      "작은",
      "인코딩",
      "사용",
      "연속된",
      "블록에",
      "필드",
      "저장",
      "개별",
      "대비",
      "오버헤드"
    ]
  },
  {
    "id": "REDIS-029",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis에서 메모리 사용 현황을 모니터링하기 위한 주요 명령어(redis-cli info memory 등)와 그 활용법에 대해 설명해주세요.",
    "answer": "INFO memory 명령:\n\n주요 지표:\n\n지표   설명\n\nusedmemory   Redis가 할당한 메모리\nusedmemoryrss   OS가 할당한 실제 메모리\nmemfragmentationratio   RSS/usedmemory (1.5 이상 주의)\n\nMEMORY 명령어:\n\n실시간 모니터링:\n\n외부 도구 연동:\nRedis Insight: 공식 GUI\nPrometheus + Grafana: redis_exporter 연동\n\n모니터링 체크리스트:\n메모리 사용률\n단편화율\n캐시 히트율\n연결 수\n느린 쿼리",
    "references": [
      {
        "title": "Redis INFO",
        "url": "https://redis.io/commands/info/"
      }
    ],
    "keywords": [
      "info",
      "redis",
      "rss",
      "memory",
      "insight",
      "gui",
      "prometheus",
      "grafana",
      "redis_exporter",
      "명령",
      "주요",
      "지표",
      "설명",
      "할당한",
      "메모리"
    ]
  },
  {
    "id": "REDIS-030",
    "category": "redis",
    "categoryName": "Redis",
    "priority": "P2",
    "question": "Redis Modules나 Redis Streams와 같은 최신 기능들이 백엔드 시스템에서 어떻게 활용될 수 있는지, 그리고 이들이 기존 기능과 비교해 갖는 장점은 무엇인지 설명해주세요.",
    "answer": "Redis Streams:\n로그 형태의 추가 전용 데이터 구조\nConsumer Group으로 분산 처리 지원\n\nvs Pub/Sub:\n\n항목   Streams   Pub/Sub\n\n메시지 저장   영구 저장   저장 안 됨\n재처리   가능   불가능\nConsumer Group   지원   미지원\n\nRedis Modules:\n\n모듈   기능\n\nRediSearch   전문 검색\nRedisJSON   JSON 문서 저장/쿼리\nRedisTimeSeries   시계열 데이터\nRedisBloom   Bloom Filter\n\n기존 기능 대비 장점:\nRediSearch: 서버사이드 검색\nRedisJSON: 부분 쿼리/수정\nRedisTimeSeries: 다운샘플링, 집계",
    "references": [
      {
        "title": "Redis Streams",
        "url": "https://redis.io/docs/data-types/streams/"
      },
      {
        "title": "Redis Modules",
        "url": "https://redis.io/modules"
      }
    ],
    "keywords": [
      "redis",
      "streams",
      "consumer",
      "group",
      "pub",
      "sub",
      "modules",
      "redisearch",
      "redisjson",
      "json",
      "redistimeseries",
      "redisbloom",
      "bloom",
      "filter",
      "로그"
    ]
  },
  {
    "id": "CRDT-001",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "CRDT(Conflict-free Replicated Data Type)의 기본 개념과 사용 목적은 무엇인가요?",
    "answer": "CRDT는 분산 시스템에서 여러 복제본(replica)이 독립적으로 수정되더라도 충돌 없이 자동으로 병합될 수 있도록 설계된 데이터 구조입니다.\n\n핵심 특징:\n중앙 서버 불필요: 각 클라이언트가 독립적으로 데이터를 수정하고, 최종적으로 모든 복제본이 동일한 상태로 수렴\nEventual Consistency 보장: 동일한 업데이트를 받은 모든 복제본은 결정론적으로 같은 상태에 도달\n오프라인 지원: 네트워크 연결 없이도 로컬 편집이 가능하며, 나중에 동기화\n\n사용 목적:\n실시간 협업 애플리케이션 (Google Docs, Figma 등)\n오프라인-퍼스트 애플리케이션\nP2P 분산 시스템",
    "references": [
      {
        "title": "CRDT.tech - About CRDTs",
        "url": "https://crdt.tech/"
      },
      {
        "title": "Shapiro et al., \"Conflict-free Replicated Data Types\"",
        "url": "https://pages.lip6.fr/Marc.Shapiro/papers/RR-7687.pdf"
      }
    ],
    "keywords": [
      "crdt",
      "eventual",
      "consistency",
      "google",
      "docs",
      "figma",
      "p2p",
      "분산",
      "시스템에서",
      "여러",
      "복제본",
      "독립적으로",
      "수정되더라도",
      "충돌",
      "없이"
    ]
  },
  {
    "id": "CRDT-002",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs 라이브러리의 주요 기능과 특징에 대해 설명해주세요.",
    "answer": "Yjs는 고성능 CRDT 라이브러리로, 실시간 협업 애플리케이션 구축에 최적화되어 있습니다.\n\n주요 기능:\n공유 데이터 타입: Y.Array, Y.Map, Y.Text, Y.XmlFragment 등 다양한 CRDT 데이터 타입 제공\n네트워크 독립적: WebSocket, WebRTC, Hyper 등 다양한 네트워크 기술과 연동 가능\n풍부한 에디터 통합: ProseMirror, Quill, Monaco, CodeMirror 등 주요 에디터 바인딩 지원\n\n특징:\n최고 수준의 성능: 벤치마크에서 가장 빠른 CRDT 구현체로 평가\nYATA 알고리즘: 효율적인 텍스트 편집을 위한 최적화된 알고리즘 사용\n바이너리 인코딩: 메모리 효율적인 바이너리 형식으로 데이터 저장\n모듈화 구조: 필요한 기능만 선택적으로 사용 가능",
    "references": [
      {
        "title": "Yjs 공식 문서",
        "url": "https://docs.yjs.dev/"
      },
      {
        "title": "Yjs GitHub",
        "url": "https://github.com/yjs/yjs"
      }
    ],
    "keywords": [
      "yjs",
      "crdt",
      "array",
      "map",
      "text",
      "xmlfragment",
      "websocket",
      "webrtc",
      "hyper",
      "prosemirror",
      "quill",
      "monaco",
      "codemirror",
      "yata",
      "고성능"
    ]
  },
  {
    "id": "CRDT-003",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs를 사용하여 분산 환경에서 데이터 동기화를 구현하는 방법은 무엇인가요?",
    "answer": "Yjs에서 분산 데이터 동기화는 Provider와 Y.Doc을 통해 구현됩니다.\n\n기본 구현 단계:\n\n동기화 메커니즘:\n업데이트 전파: 로컬 변경사항이 자동으로 연결된 모든 피어에게 전파\n순서 독립적: 업데이트가 도착하는 순서와 관계없이 동일한 결과 보장\n증분 동기화: 전체 문서가 아닌 변경된 부분만 전송\n\n주요 Provider:\ny-websocket: WebSocket 기반 동기화\ny-webrtc: P2P WebRTC 동기화\ny-indexeddb: 브라우저 로컬 저장소",
    "references": [
      {
        "title": "Yjs Providers",
        "url": "https://docs.yjs.dev/ecosystem/connection-provider"
      }
    ],
    "keywords": [
      "yjs",
      "provider",
      "doc",
      "y-websocket",
      "websocket",
      "y-webrtc",
      "p2p",
      "webrtc",
      "y-indexeddb",
      "에서",
      "분산",
      "데이터",
      "동기화는",
      "구현됩니다",
      "기본"
    ]
  },
  {
    "id": "CRDT-004",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "CRDT와 OT(Operational Transformation)의 차이점은 무엇인가요?",
    "answer": "CRDT와 OT는 모두 분산 환경에서 협업 편집을 가능하게 하지만, 근본적인 접근 방식이 다릅니다.\n\n구분   OT   CRDT\n\n충돌 해결 위치   변환 함수에서 중앙 집중화   데이터 구조 자체에 분산\n서버 의존성   중앙 서버 필요 (일반적)   완전한 P2P 가능\n오프라인 지원   제한적   우수함\n메모리 사용   낮음   높음 (메타데이터 오버헤드)\n의도 보존   우수함   제한적\n\nOT 동작 방식:\n편집을 연산(operation) 시퀀스로 처리\n동시 연산 발생 시 서버에서 변환(transform)하여 적용\n예: \"위치 5에 삽입\" → 다른 편집으로 인해 \"위치 3에 삽입\"으로 변환\n\nCRDT 동작 방식:\n데이터 구조 자체에 충분한 메타데이터 포함\n각 요소에 고유 ID 부여하여 위치 대신 ID 기반 참조\n예: \"문자 ID 'a1b2' 뒤에 삽입\"\n\n실제 사용 사례:\nOT: Google Docs\nCRDT: Figma, Notion (일부)",
    "references": [
      {
        "title": "Real Differences between OT and CRDT",
        "url": "https://arxiv.org/abs/1905.01518"
      },
      {
        "title": "Building real-time collaboration: OT vs CRDT",
        "url": "https://www.tiny.cloud/blog/real-time-collaboration-ot-vs-crdt/"
      }
    ],
    "keywords": [
      "crdt",
      "p2p",
      "google",
      "docs",
      "figma",
      "notion",
      "모두",
      "분산",
      "환경에서",
      "협업",
      "편집을",
      "가능하게",
      "근본적인",
      "접근",
      "방식이"
    ]
  },
  {
    "id": "CRDT-005",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs에서 제공하는 데이터 타입(Y.Array, Y.Map 등)의 역할과 사용 사례는 무엇인가요?",
    "answer": "Yjs는 다양한 공유 데이터 타입을 제공하며, 각각 특정 사용 사례에 최적화되어 있습니다.\n\n주요 데이터 타입:\n\n타입   설명   사용 사례\n\nY.Text   협업 텍스트 편집   문서 편집기, 코드 에디터\nY.Array   순서가 있는 리스트   할 일 목록, 슬라이드 순서\nY.Map   키-값 저장소   설정, 사용자 정보\nY.XmlFragment   XML/HTML 구조   리치 텍스트, DOM 구조\nY.XmlElement   XML 요소   계층적 문서 구조\n\n코드 예시:\n\n중첩 구조:\nY.Map과 Y.Array는 다른 공유 타입을 포함할 수 있어 복잡한 데이터 구조 표현 가능",
    "references": [
      {
        "title": "Yjs Shared Types",
        "url": "https://docs.yjs.dev/api/shared-types"
      }
    ],
    "keywords": [
      "yjs",
      "text",
      "array",
      "map",
      "xmlfragment",
      "xml",
      "html",
      "dom",
      "xmlelement",
      "다양한",
      "공유",
      "데이터",
      "타입을",
      "제공하며",
      "각각"
    ]
  },
  {
    "id": "CRDT-006",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs의 업데이트 전파 및 문서 병합 방식은 어떻게 동작하나요?",
    "answer": "Yjs는 효율적인 바이너리 인코딩과 증분 업데이트를 통해 변경사항을 전파합니다.\n\n업데이트 전파 과정:\n로컬 변경 감지: 공유 타입에 변경 발생\n업데이트 인코딩: 변경사항을 Uint8Array로 인코딩\n전파: Provider를 통해 다른 피어에게 전송\n적용: 수신 측에서 업데이트 디코딩 및 적용\n\n문서 병합:\nState Vector: 각 클라이언트의 현재 상태를 벡터로 표현\n차이점만 전송: 두 문서의 State Vector를 비교하여 누락된 업데이트만 전송",
    "references": [
      {
        "title": "Yjs Document Updates",
        "url": "https://docs.yjs.dev/api/document-updates"
      }
    ],
    "keywords": [
      "yjs",
      "uint8array",
      "provider",
      "state",
      "vector",
      "효율적인",
      "바이너리",
      "인코딩과",
      "증분",
      "업데이트를",
      "변경사항을",
      "전파합니다",
      "업데이트",
      "전파",
      "과정"
    ]
  },
  {
    "id": "CRDT-007",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs에서 문서의 버전 관리와 업데이트 충돌 해결 방법에 대해 설명해주세요.",
    "answer": "Yjs는 고유한 클라이언트 ID와 논리적 시계를 사용하여 버전을 관리하고 충돌을 해결합니다.\n\n버전 관리 메커니즘:\nClient ID: 각 Y.Doc 인스턴스에 고유한 ID 할당\nClock: 각 클라이언트별로 단조 증가하는 논리적 시계\nState Vector: Map<clientID, clock> 형태로 문서 상태 표현\n\n충돌 해결:\n\nYATA 알고리즘에 기반한 결정론적 규칙:\n삽입 위치 결정: 동일 위치 삽입 시 클라이언트 ID로 순서 결정\n삭제 처리: 삭제된 항목은 tombstone으로 마킹 (실제 제거 대신)\n자동 병합: 모든 클라이언트가 동일한 규칙을 적용하므로 최종 상태 수렴 보장",
    "references": [
      {
        "title": "Yjs Internals",
        "url": "https://docs.yjs.dev/api/internals"
      }
    ],
    "keywords": [
      "yjs",
      "client",
      "doc",
      "clock",
      "state",
      "vector",
      "map",
      "yata",
      "고유한",
      "클라이언트",
      "논리적",
      "시계를",
      "사용하여",
      "버전을",
      "관리하고"
    ]
  },
  {
    "id": "CRDT-008",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs의 Awareness 프로토콜이란 무엇이며, 어떤 기능을 제공하나요?",
    "answer": "Awareness는 사용자 존재 정보(presence)와 커서 위치 등 일시적인 상태를 공유하는 프로토콜입니다.\n\n주요 기능:\n온라인 상태 추적: 누가 현재 접속 중인지 확인\n커서 위치 공유: 다른 사용자의 편집 위치 표시\n사용자 정보 전파: 이름, 색상, 아바타 등\n\n구현 방식:\n\n동작 원리:\n각 클라이언트는 고유한 clientID를 가짐\n상태 변경 시 증가하는 clock과 함께 JSON 객체 전파\n30초 타임아웃: 업데이트 없으면 오프라인으로 간주\nheartbeat 필요: 정기적인 상태 브로드캐스트 권장",
    "references": [
      {
        "title": "Yjs Awareness",
        "url": "https://docs.yjs.dev/api/about-awareness"
      },
      {
        "title": "y-protocols GitHub",
        "url": "https://github.com/yjs/y-protocols"
      }
    ],
    "keywords": [
      "awareness",
      "json",
      "사용자",
      "존재",
      "정보",
      "커서",
      "위치",
      "일시적인",
      "상태를",
      "공유하는",
      "프로토콜입니다",
      "주요",
      "기능",
      "온라인",
      "상태"
    ]
  },
  {
    "id": "CRDT-009",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs의 상대적 버전 관리(relative versioning) 메커니즘은 어떻게 작동하나요?",
    "answer": "Relative Position은 절대적인 인덱스 대신 다른 요소와의 관계로 위치를 표현하는 메커니즘입니다.\n\n필요성:\nCRDT에서 절대 인덱스는 동시 편집 시 무효화될 수 있음\n커서 위치, 선택 영역 등을 안정적으로 유지해야 함\n\nRelative Position 원리:\n\n내부 구조:\ntype: 참조하는 공유 타입\nitem: 기준이 되는 항목의 ID (clientID + clock)\nassoc: 항목의 앞(-1) 또는 뒤(1)를 가리킴\n\n활용 사례:\n커서 위치 저장 및 복원\n주석/코멘트의 텍스트 범위 추적\nUndo/Redo 구현",
    "references": [
      {
        "title": "Yjs Relative Positions",
        "url": "https://docs.yjs.dev/api/relative-positions"
      }
    ],
    "keywords": [
      "relative",
      "position",
      "crdt",
      "undo",
      "redo",
      "절대적인",
      "인덱스",
      "대신",
      "다른",
      "요소와의",
      "관계로",
      "위치를",
      "표현하는",
      "메커니즘입니다",
      "필요성"
    ]
  },
  {
    "id": "CRDT-010",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs와 다른 CRDT 라이브러리(예: Automerge) 간의 주요 차이점은 무엇인가요?",
    "answer": "Yjs와 Automerge는 모두 인기 있는 CRDT 라이브러리이지만 설계 철학과 특성이 다릅니다.\n\n구분   Yjs   Automerge\n\n알고리즘   YATA   RGA\n데이터 모델   타입별 전용 구조   JSON 문서\n인코딩   바이너리   JSON (WASM 버전은 바이너리)\n언어   JavaScript   Rust + WASM 바인딩\n성능   매우 빠름   상대적으로 느림\n메모리   효율적   더 많은 메모리 사용\nGC   지원   제한적\n\nYjs 강점:\n텍스트 협업에 최적화된 성능\n다양한 에디터 바인딩 생태계\n네트워크 Provider 선택의 유연성\n가비지 컬렉션으로 문서 크기 관리\n\nAutomerge 강점:\nJSON 친화적 데이터 모델\n다국어 지원 (Rust, Python, Go 등)\nautomerge-repo로 end-to-end 동기화 제공\n오프라인-퍼스트 설계\n\n선택 기준:\n텍스트 에디터 중심 → Yjs\nJSON 데이터 구조 중심 → Automerge\n성능이 최우선 → Yjs",
    "references": [
      {
        "title": "CRDT Implementations",
        "url": "https://crdt.tech/implementations"
      },
      {
        "title": "CRDT Benchmarks",
        "url": "https://github.com/dmonad/crdt-benchmarks"
      }
    ],
    "keywords": [
      "yjs",
      "automerge",
      "crdt",
      "yata",
      "rga",
      "json",
      "wasm",
      "javascript",
      "rust",
      "provider",
      "python",
      "automerge-repo",
      "end-to",
      "모두",
      "인기"
    ]
  },
  {
    "id": "CRDT-011",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs를 통한 실시간 협업 애플리케이션 구현 시 고려해야 할 사항은 무엇인가요?",
    "answer": "실시간 협업 애플리케이션 구현 시 여러 측면을 고려해야 합니다.\n네트워크 아키텍처:\n중앙 서버 (y-websocket): 구현 단순, 권한 관리 용이\nP2P (y-webrtc): 서버 비용 절감, 지연 시간 단축\n하이브리드: 둘을 조합하여 장점 활용\n데이터 영속성:\n인증 및 권한:\nWebSocket 연결 시 토큰 검증\n문서별 읽기/쓰기 권한 분리\n민감한 작업에 대한 서버 측 검증\n성능 최적화:\n큰 문서는 하위 문서(subdoc)로 분할\n불필요한 히스토리는 GC로 정리\n적절한 debounce로 업데이트 빈도 조절\nUX 고려사항:\nAwareness로 다른 사용자 커서 표시\n연결 상태 표시 (온라인/오프라인)\n충돌 해결 결과에 대한 시각적 피드백",
    "references": [
      {
        "title": "Yjs Getting Started",
        "url": "https://docs.yjs.dev/getting-started"
      }
    ],
    "keywords": [
      "y-websocket",
      "p2p",
      "y-webrtc",
      "websocket",
      "awareness",
      "실시간",
      "협업",
      "애플리케이션",
      "구현",
      "여러",
      "측면을",
      "고려해야",
      "네트워크",
      "아키텍처",
      "중앙"
    ]
  },
  {
    "id": "CRDT-012",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs에서 업데이트를 옵저빙(observing)하는 방법과 이벤트 핸들링은 어떻게 이루어지나요?",
    "answer": "Yjs는 Observer 패턴을 사용하여 데이터 변경을 감지하고 반응할 수 있습니다.\n\n문서 레벨 이벤트:\n\n타입별 Observer:\n\n옵저버 해제:",
    "references": [
      {
        "title": "Yjs Events",
        "url": "https://docs.yjs.dev/api/shared-types/y.text#observing-changes-y.textevent"
      }
    ],
    "keywords": [
      "yjs",
      "observer",
      "패턴을",
      "사용하여",
      "데이터",
      "변경을",
      "감지하고",
      "반응할",
      "문서",
      "레벨",
      "이벤트",
      "타입별",
      "옵저버",
      "해제"
    ]
  },
  {
    "id": "CRDT-013",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs의 Delta 업데이트 방식과 그 장점에 대해 설명해주세요.",
    "answer": "Yjs의 Delta는 Quill Delta 형식을 기반으로 텍스트 변경을 표현하는 방식입니다.\n\nDelta 구조:\n\nY.Text와 Delta:\n\n장점:\n직관적 표현: 변경 사항을 명확하게 표현\n서식 지원: 속성(attributes)으로 리치 텍스트 지원\n효율적 전송: 전체 문서 대신 변경분만 전송\n에디터 호환: Quill, ProseMirror 등과 쉽게 연동",
    "references": [
      {
        "title": "Quill Delta",
        "url": "https://quilljs.com/docs/delta/"
      },
      {
        "title": "Y.Text API",
        "url": "https://docs.yjs.dev/api/shared-types/y.text"
      }
    ],
    "keywords": [
      "yjs",
      "delta",
      "quill",
      "text",
      "prosemirror",
      "형식을",
      "기반으로",
      "텍스트",
      "변경을",
      "표현하는",
      "방식입니다",
      "구조",
      "장점",
      "직관적",
      "표현"
    ]
  },
  {
    "id": "CRDT-014",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs 문서 병합 과정에서 발생할 수 있는 충돌 상황은 어떤 것이며, 이를 어떻게 해결하나요?",
    "answer": "CRDT 특성상 Yjs에서는 \"충돌\"이 자동으로 해결되지만, 의도하지 않은 결과가 발생할 수 있는 상황이 있습니다.\n동시 삽입 충돌:\n상황: 두 사용자가 같은 위치에 동시에 텍스트 삽입\n해결: 클라이언트 ID를 기준으로 결정론적 순서 적용\n동시 삭제와 수정:\n상황: 한 사용자가 삭제하는 동안 다른 사용자가 수정\n해결: 삭제 우선 (tombstone으로 마킹)\n동시 속성 변경:\n상황: 같은 텍스트에 다른 서식 적용\n해결: Last-Write-Wins (마지막 변경 적용)\nInterleaving 문제:\n상황: \"foo\"와 \"bar\" 동시 입력 시 \"fboaor\" 같은 결과\n해결: YATA 알고리즘이 이 문제를 최소화\n\n의도 보존을 위한 전략:",
    "references": [
      {
        "title": "YATA Algorithm",
        "url": "https://docs.yjs.dev/api/internals"
      }
    ],
    "keywords": [
      "crdt",
      "yjs",
      "last-write-wins",
      "interleaving",
      "yata",
      "특성상",
      "에서는",
      "충돌",
      "자동으로",
      "해결되지만",
      "의도하지",
      "않은",
      "결과가",
      "발생할",
      "있는"
    ]
  },
  {
    "id": "CRDT-015",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs의 메모리 사용 최적화 및 성능 개선 방안은 무엇인가요?",
    "answer": "Yjs 애플리케이션의 성능을 최적화하기 위한 여러 전략이 있습니다.\n가비지 컬렉션 (GC):\nSubdocuments (하위 문서):\n업데이트 압축:\n트랜잭션 활용:\n효율적인 초기 동기화:\n메모리 모니터링:\n대용량 문서에서는 정기적으로 문서 크기 확인\n필요시 오래된 히스토리 정리",
    "references": [
      {
        "title": "Yjs Performance Tips",
        "url": "https://docs.yjs.dev/api/document-updates"
      }
    ],
    "keywords": [
      "yjs",
      "subdocuments",
      "애플리케이션의",
      "성능을",
      "최적화하기",
      "위한",
      "여러",
      "전략이",
      "가비지",
      "컬렉션",
      "하위",
      "문서",
      "업데이트",
      "압축",
      "트랜잭션"
    ]
  },
  {
    "id": "CRDT-016",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs의 저장소(storage) 모듈과 데이터를 영구 저장하는 전략은 무엇인가요?",
    "answer": "Yjs는 다양한 영속성 Provider를 통해 문서를 저장할 수 있습니다.\n\n클라이언트 측 저장:\n\n서버 측 저장:\n\n저장 전략:\n전체 문서 저장:\n증분 업데이트 저장:\n스냅샷 + 증분:\n\n고려사항:\n업데이트 로그가 커지면 주기적으로 병합\n동시성 제어를 위한 적절한 락 메커니즘\n백업 및 복구 전략",
    "references": [
      {
        "title": "y-indexeddb",
        "url": "https://github.com/yjs/y-indexeddb"
      },
      {
        "title": "y-leveldb",
        "url": "https://github.com/yjs/y-leveldb"
      }
    ],
    "keywords": [
      "yjs",
      "provider",
      "다양한",
      "영속성",
      "문서를",
      "저장할",
      "클라이언트",
      "저장",
      "서버",
      "전략",
      "전체",
      "문서",
      "증분",
      "업데이트",
      "스냅샷"
    ]
  },
  {
    "id": "CRDT-017",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "네트워크 지연(latency) 환경에서 Yjs의 동기화 성능을 개선하는 방법은 무엇인가요?",
    "answer": "네트워크 지연 환경에서도 Yjs는 로컬 우선 동작으로 좋은 사용자 경험을 제공합니다.\n낙관적 업데이트 (기본 동작):\n로컬 변경은 즉시 반영\n네트워크 응답을 기다리지 않음\n나중에 동기화되어도 결과 수렴 보장\n로컬 영속성 활용:\n재연결 전략:\n업데이트 배칭:\n압축 전송:\nYjs 업데이트는 이미 바이너리로 효율적\n필요시 gzip 추가 압축 적용",
    "references": [
      {
        "title": "Yjs Offline Support",
        "url": "https://docs.yjs.dev/getting-started/allowing-offline-editing"
      }
    ],
    "keywords": [
      "yjs",
      "네트워크",
      "지연",
      "환경에서도",
      "로컬",
      "우선",
      "동작으로",
      "좋은",
      "사용자",
      "경험을",
      "제공합니다",
      "낙관적",
      "업데이트",
      "기본",
      "동작"
    ]
  },
  {
    "id": "CRDT-018",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs와 WebSocket, WebRTC 등 다른 실시간 통신 프로토콜 연동 방안에 대해 설명해주세요.",
    "answer": "Yjs는 네트워크 프로토콜에 독립적이며, 다양한 Provider를 통해 연동합니다.\nWebSocket (y-websocket):\nWebRTC (y-webrtc):\n커스텀 Provider 구현:\n\n프로토콜 선택 기준:\n\n프로토콜   장점   단점\n\nWebSocket   안정적, 권한 제어 용이   서버 비용\nWebRTC   P2P, 낮은 지연   연결 설정 복잡\n하이브리드   장점 조합   구현 복잡도",
    "references": [
      {
        "title": "y-websocket",
        "url": "https://github.com/yjs/y-websocket"
      },
      {
        "title": "y-webrtc",
        "url": "https://github.com/yjs/y-webrtc"
      }
    ],
    "keywords": [
      "yjs",
      "provider",
      "websocket",
      "y-websocket",
      "webrtc",
      "y-webrtc",
      "p2p",
      "네트워크",
      "프로토콜에",
      "독립적이며",
      "다양한",
      "연동합니다",
      "커스텀",
      "구현",
      "프로토콜"
    ]
  },
  {
    "id": "CRDT-019",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "CRDT를 이용한 분산 시스템에서 eventual consistency와 strong consistency의 차이는 무엇인가요?",
    "answer": "분산 시스템에서 일관성 모델은 데이터 동기화의 보장 수준을 정의합니다.\n\nStrong Consistency (강한 일관성):\n모든 읽기는 가장 최근 쓰기 결과를 반환\n모든 노드가 동일한 순서로 업데이트 확인\n예: 전통적인 RDBMS, Raft/Paxos 기반 시스템\n\nEventual Consistency (최종 일관성):\n충분한 시간이 지나면 모든 노드가 같은 상태에 도달\n중간 상태에서는 노드별로 다른 값을 볼 수 있음\nCRDT가 보장하는 일관성 모델\n\nCRDT의 강점 - Strong Eventual Consistency:\n\nCRDT는 일반적인 Eventual Consistency보다 강한 보장을 제공:\n수렴 보장: 같은 업데이트를 받은 복제본은 반드시 같은 상태\n충돌 없음: 병합 시 충돌 해결이 자동으로 결정론적\n순서 독립: 업데이트 적용 순서가 최종 결과에 영향 없음\n\n트레이드오프 (CAP 정리):\n\n속성   Strong   Eventual\n\n가용성   낮음   높음\n지연 시간   높음   낮음\n네트워크 분할 허용   불가   가능\n오프라인 작업   불가   가능",
    "references": [
      {
        "title": "CRDT.tech - About CRDTs",
        "url": "https://crdt.tech/"
      }
    ],
    "keywords": [
      "strong",
      "consistency",
      "rdbms",
      "raft",
      "paxos",
      "eventual",
      "crdt",
      "cap",
      "분산",
      "시스템에서",
      "일관성",
      "모델은",
      "데이터",
      "동기화의",
      "보장"
    ]
  },
  {
    "id": "CRDT-020",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs 문서 크기가 커질 때 발생할 수 있는 성능 이슈와 대응 방법은 무엇인가요?",
    "answer": "대용량 Yjs 문서는 메모리, 네트워크, 초기 로드 시간에 영향을 줄 수 있습니다.\n\n성능 이슈:\n메모리 사용량 증가\n각 문자에 메타데이터 (ID, 참조) 포함\n삭제된 항목도 tombstone으로 유지\n초기 동기화 지연\n전체 문서 상태를 전송해야 함\n새 클라이언트 연결 시 병목\n업데이트 처리 시간\n큰 문서에서 변경 적용이 느려질 수 있음\n\n대응 방법:\nSubdocuments 활용:\n가비지 컬렉션:\n스냅샷 기반 압축:\nLazy Loading:\n모니터링:",
    "references": [
      {
        "title": "Yjs Subdocuments",
        "url": "https://docs.yjs.dev/api/subdocuments"
      }
    ],
    "keywords": [
      "yjs",
      "subdocuments",
      "lazy",
      "loading",
      "대용량",
      "문서는",
      "메모리",
      "네트워크",
      "초기",
      "로드",
      "시간에",
      "영향을",
      "성능",
      "이슈",
      "사용량"
    ]
  },
  {
    "id": "CRDT-021",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs의 모듈화 구조와 플러그인 확장 기능에 대해 설명해주세요.",
    "answer": "Yjs는 핵심 라이브러리와 확장 모듈로 구성된 모듈화된 아키텍처를 가집니다.\n\n핵심 패키지 (yjs):\nY.Doc, Y.Array, Y.Map, Y.Text 등 기본 CRDT 타입\n인코딩/디코딩, 동기화 프로토콜\n\n네트워크 Provider:\n\n영속성 Provider:\n\n에디터 바인딩:\n\n프로토콜 모듈 (y-protocols):\n\n커스텀 Provider 구현:\n\n생태계 장점:\n필요한 기능만 선택적 사용\n새로운 백엔드/에디터 쉽게 추가\n커뮤니티 확장 활발",
    "references": [
      {
        "title": "Yjs Ecosystem",
        "url": "https://docs.yjs.dev/ecosystem"
      }
    ],
    "keywords": [
      "yjs",
      "doc",
      "array",
      "map",
      "text",
      "crdt",
      "provider",
      "y-protocols",
      "핵심",
      "라이브러리와",
      "확장",
      "모듈로",
      "구성된",
      "모듈화된",
      "아키텍처를"
    ]
  },
  {
    "id": "CRDT-022",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs에서 데이터 업데이트 시 네트워크 트래픽 최적화를 위한 기법은 무엇인가요?",
    "answer": "Yjs는 효율적인 바이너리 인코딩을 사용하지만, 추가 최적화 기법을 적용할 수 있습니다.\n업데이트 병합:\nDebouncing:\n차등 동기화:\n압축:\n선택적 동기화:\n대역폭 제한:",
    "references": [
      {
        "title": "Yjs Performance",
        "url": "https://docs.yjs.dev/api/document-updates"
      }
    ],
    "keywords": [
      "yjs",
      "debouncing",
      "효율적인",
      "바이너리",
      "인코딩을",
      "사용하지만",
      "추가",
      "최적화",
      "기법을",
      "적용할",
      "업데이트",
      "병합",
      "차등",
      "동기화",
      "압축"
    ]
  },
  {
    "id": "CRDT-023",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs 업데이트 메시지의 크기를 최소화하는 방법에 대해 설명해주세요.",
    "answer": "Yjs 업데이트 메시지 크기 최소화는 네트워크 효율성과 성능에 직접적인 영향을 줍니다.\n\nYjs 기본 최적화:\n바이너리 인코딩: JSON 대비 훨씬 컴팩트\n변수 길이 정수: 작은 숫자에 적은 바이트 사용\n참조 기반 구조: 중복 데이터 최소화\n\n추가 최적화 기법:\n트랜잭션 그룹화:\n업데이트 병합:\nOrigin 필터링:\n압축 적용:\nDiff 기반 전송:\n\n메시지 크기 측정:",
    "references": [
      {
        "title": "Yjs Internals",
        "url": "https://docs.yjs.dev/api/internals"
      }
    ],
    "keywords": [
      "yjs",
      "json",
      "origin",
      "diff",
      "업데이트",
      "메시지",
      "크기",
      "최소화는",
      "네트워크",
      "효율성과",
      "성능에",
      "직접적인",
      "영향을",
      "줍니다",
      "기본"
    ]
  },
  {
    "id": "CRDT-024",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs 기반 협업 도구에서 사용되는 이벤트(event) 처리 패턴은 무엇인가요?",
    "answer": "Yjs는 다양한 수준에서 이벤트를 제공하며, 효과적인 패턴을 통해 처리합니다.\n\n이벤트 계층:\n\n일반적인 처리 패턴:\nOrigin 기반 분기:\n배치 처리:\nDeep Observer 패턴:\n멱등성 보장:\n이벤트 정리:",
    "references": [
      {
        "title": "Yjs Events",
        "url": "https://docs.yjs.dev/api/y.doc"
      }
    ],
    "keywords": [
      "yjs",
      "origin",
      "deep",
      "observer",
      "다양한",
      "수준에서",
      "이벤트를",
      "제공하며",
      "효과적인",
      "패턴을",
      "처리합니다",
      "이벤트",
      "계층",
      "일반적인",
      "처리"
    ]
  },
  {
    "id": "CRDT-025",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "CRDT를 활용한 오프라인 편집 및 동기화 시나리오는 어떻게 구성되나요?",
    "answer": "CRDT의 가장 큰 장점 중 하나는 오프라인 편집을 자연스럽게 지원한다는 것입니다.\n\n오프라인 시나리오 구성:\n로컬 영속성 설정:\n연결 상태 관리:\n동기화 흐름:\n충돌 없는 병합:\n사용자 경험:\n오프라인 상태 표시\n동기화 진행률\n마지막 동기화 시간",
    "references": [
      {
        "title": "Yjs Offline Support",
        "url": "https://docs.yjs.dev/getting-started/allowing-offline-editing"
      }
    ],
    "keywords": [
      "crdt",
      "가장",
      "장점",
      "하나는",
      "오프라인",
      "편집을",
      "자연스럽게",
      "지원한다는",
      "것입니다",
      "시나리오",
      "구성",
      "로컬",
      "영속성",
      "설정",
      "연결"
    ]
  },
  {
    "id": "CRDT-026",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs에서 스키마 변경(schema evolution)을 처리하는 방식은 무엇인가요?",
    "answer": "Yjs는 스키마리스(schemaless) 특성을 가지지만, 애플리케이션 레벨에서 스키마 진화를 관리해야 합니다.\n\nYjs의 유연성:\n\n스키마 버전 관리 패턴:\n버전 필드 사용:\n점진적 마이그레이션:\n기본값 처리:\n타입 검증 레이어:\n\n주의사항:\n삭제된 필드도 tombstone으로 남음\n구 버전 클라이언트와의 호환성 고려\n마이그레이션은 모든 클라이언트에서 동일하게 동작해야 함",
    "references": [
      {
        "title": "Yjs Shared Types",
        "url": "https://docs.yjs.dev/api/shared-types"
      }
    ],
    "keywords": [
      "yjs",
      "스키마리스",
      "특성을",
      "가지지만",
      "애플리케이션",
      "레벨에서",
      "스키마",
      "진화를",
      "관리해야",
      "유연성",
      "버전",
      "관리",
      "패턴",
      "필드",
      "사용"
    ]
  },
  {
    "id": "CRDT-027",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs 문서의 데이터 정합성을 보장하기 위한 전략은 무엇인가요?",
    "answer": "Yjs는 CRDT 특성으로 수렴을 보장하지만, 애플리케이션 레벨 정합성은 추가 전략이 필요합니다.\n\nCRDT가 보장하는 것:\nStrong Eventual Consistency: 같은 업데이트 → 같은 상태\n충돌 없는 병합\n순서 독립적 적용\n\n애플리케이션 레벨 정합성 전략:\n트랜잭션 활용:\n유효성 검증:\n서버 측 검증:\n낙관적 락킹:\n체크섬 기반 검증:",
    "references": [
      {
        "title": "Yjs Transactions",
        "url": "https://docs.yjs.dev/api/y.doc#transact"
      }
    ],
    "keywords": [
      "yjs",
      "crdt",
      "strong",
      "eventual",
      "consistency",
      "특성으로",
      "수렴을",
      "보장하지만",
      "애플리케이션",
      "레벨",
      "정합성은",
      "추가",
      "전략이",
      "필요합니다",
      "보장하는"
    ]
  },
  {
    "id": "CRDT-028",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs의 업데이트 충돌 해결 알고리즘에 대해 설명해주세요.",
    "answer": "Yjs는 YATA (Yet Another Transformation Approach) 알고리즘을 기반으로 충돌을 해결합니다.\n\nYATA 알고리즘 핵심:\n고유 식별자:\n위치 참조:\n삽입 규칙:\n동일 위치에 동시 삽입 시:\n삭제 처리:\n\n예시 시나리오:\n\nYATA vs RGA:\nRGA: 전역 카운터 사용\nYATA: 클라이언트별 카운터 (더 효율적)\n\n장점:\nO(log n) 삽입 복잡도\n인터리빙 문제 최소화\n메모리 효율적",
    "references": [
      {
        "title": "YATA Paper",
        "url": "https://www.researchgate.net/publication/310212186_Near_Real-Time_Peer-to-Peer_Shared_Editing_on_Extensible_Data_Types"
      },
      {
        "title": "Yjs Internals",
        "url": "https://docs.yjs.dev/api/internals"
      }
    ],
    "keywords": [
      "yjs",
      "yata",
      "another",
      "transformation",
      "approach",
      "rga",
      "알고리즘을",
      "기반으로",
      "충돌을",
      "해결합니다",
      "알고리즘",
      "핵심",
      "고유",
      "식별자",
      "위치"
    ]
  },
  {
    "id": "CRDT-029",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs를 실제 프로덕션 환경에 적용할 때 고려해야 할 주요 이슈는 무엇인가요?",
    "answer": "프로덕션 환경에서 Yjs를 운영하려면 여러 측면을 고려해야 합니다.\n확장성 (Scalability):\n모니터링:\n에러 처리:\n백업 및 복구:\n보안:\n성능 최적화:\n문서 분할 (Subdocuments)\n연결 풀링\n로드 밸런싱\n버전 관리:\n클라이언트/서버 Yjs 버전 호환성\n점진적 업그레이드 전략",
    "references": [
      {
        "title": "Yjs Production Tips",
        "url": "https://docs.yjs.dev/"
      }
    ],
    "keywords": [
      "yjs",
      "scalability",
      "subdocuments",
      "프로덕션",
      "환경에서",
      "운영하려면",
      "여러",
      "측면을",
      "고려해야",
      "확장성",
      "모니터링",
      "에러",
      "처리",
      "백업",
      "복구"
    ]
  },
  {
    "id": "CRDT-030",
    "category": "crdt",
    "categoryName": "CRDT",
    "priority": "P3",
    "question": "Yjs를 활용한 협업 시스템에서 보안 및 접근 제어를 구현하는 방법은 무엇인가요?",
    "answer": "Yjs 자체는 보안 기능을 제공하지 않으므로, 애플리케이션 레벨에서 구현해야 합니다.\n인증 (Authentication):\n권한 부여 (Authorization):\n전송 암호화:\n데이터 검증:\nRate Limiting:\n감사 로깅:",
    "references": [
      {
        "title": "y-websocket Security",
        "url": "https://github.com/yjs/y-websocket"
      },
      {
        "title": "y-protocols Auth",
        "url": "https://github.com/yjs/y-protocols"
      }
    ],
    "keywords": [
      "yjs",
      "authentication",
      "authorization",
      "rate",
      "limiting",
      "자체는",
      "보안",
      "기능을",
      "제공하지",
      "않으므로",
      "애플리케이션",
      "레벨에서",
      "구현해야",
      "인증",
      "권한"
    ]
  },
  {
    "id": "JAVA-001",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "JVM의 구조와 동작 원리에 대해 설명해주세요.",
    "answer": "JVM(Java Virtual Machine)은 자바 바이트코드를 실행하는 가상 머신입니다.\n\n주요 구성 요소:\nClass Loader: 클래스 파일 로드, 링크, 초기화\nRuntime Data Area: Heap, Stack, Method Area, PC Register, Native Method Stack\nExecution Engine: Interpreter + JIT Compiler로 바이트코드 실행\nGarbage Collector: 미사용 객체 메모리 자동 해제\n\n동작 과정: .java → javac → .class(바이트코드) → Class Loader → Execution Engine 실행",
    "references": [
      {
        "title": "JVM Specification",
        "url": "https://docs.oracle.com/javase/specs/jvms/se17/html/index.html"
      }
    ],
    "keywords": [
      "jvm",
      "java",
      "virtual",
      "machine",
      "class",
      "loader",
      "runtime",
      "data",
      "area",
      "heap",
      "stack",
      "method",
      "register",
      "native",
      "execution"
    ]
  },
  {
    "id": "JAVA-002",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "JVM의 메모리 구조(Heap, Stack, Method Area 등)를 설명해주세요.",
    "answer": "Method Area (메서드 영역)\n클래스 정보, static 변수, 상수 풀 저장\n모든 스레드가 공유\nHeap (힙)\n객체 인스턴스와 배열 저장\nGC의 대상, 모든 스레드가 공유\nYoung Generation(Eden, Survivor)과 Old Generation으로 구분\nStack (스택)\n스레드별 독립적, 메서드 호출 시 프레임 생성\n지역 변수, 매개변수, 리턴 값 저장\nPC Register\n스레드별 현재 실행 중인 명령어 주소 저장\nNative Method Stack\n네이티브 메서드(C/C++) 실행을 위한 스택",
    "references": [
      {
        "title": "JVM Runtime Data Areas",
        "url": "https://docs.oracle.com/javase/specs/jvms/se17/html/jvms-2.html#jvms-2.5"
      }
    ],
    "keywords": [
      "method",
      "area",
      "heap",
      "young",
      "generation",
      "eden",
      "survivor",
      "old",
      "stack",
      "register",
      "native",
      "메서드",
      "영역",
      "클래스",
      "정보"
    ]
  },
  {
    "id": "JAVA-003",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Garbage Collection의 동작 원리와 종류에 대해 설명해주세요.",
    "answer": "동작 원리:\nMark: 루트에서 참조되는 객체를 마킹\nSweep: 마킹되지 않은 객체 제거\nCompact: 메모리 단편화 방지를 위해 압축 (선택적)\n\n세대별 GC (Generational GC):\nYoung Generation: 새 객체 할당, Minor GC 발생 (빈번, 빠름)\nOld Generation: 오래 살아남은 객체, Major/Full GC 발생\n\nGC 종류:\nSerial GC: 단일 스레드, 소규모 애플리케이션용\nParallel GC: 멀티 스레드로 처리량 최적화\nCMS GC: 낮은 지연시간, Concurrent Mark-Sweep\nG1 GC: Region 기반, 대용량 힙에 적합 (Java 9+ 기본)\nZGC/Shenandoah: 초저지연 GC (Java 11+)",
    "references": [
      {
        "title": "Java Garbage Collection",
        "url": "https://docs.oracle.com/en/java/javase/17/gctuning/introduction-garbage-collection-tuning.html"
      }
    ],
    "keywords": [
      "mark",
      "sweep",
      "compact",
      "generational",
      "young",
      "generation",
      "minor",
      "old",
      "major",
      "full",
      "serial",
      "parallel",
      "cms",
      "concurrent",
      "mark-sweep"
    ]
  },
  {
    "id": "JAVA-004",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "G1 GC와 다른 GC 알고리즘의 차이점은 무엇인가요?",
    "answer": "G1 GC 특징:\n힙을 동일 크기의 Region으로 분할 (1MB~32MB)\nRegion 단위로 GC 수행, 가비지가 많은 영역 우선 수집 (Garbage First)\n목표 중단 시간(Pause Time Goal) 설정 가능 (-XX:MaxGCPauseMillis)\n\n다른 GC와 비교:\n\n구분   G1 GC   Parallel GC   CMS GC\n\n구조   Region 기반   전통적 세대별   전통적 세대별\n목표   균형(처리량+지연)   처리량 최대화   지연시간 최소화\n압축   Incremental   Full GC 시   압축 없음(단편화)\nSTW   예측 가능   길 수 있음   짧지만 불규칙\n\nG1 GC 권장 상황: 힙 크기 4GB 이상, 지연시간과 처리량 균형 필요 시",
    "references": [
      {
        "title": "G1 Garbage Collector",
        "url": "https://docs.oracle.com/en/java/javase/17/gctuning/garbage-first-g1-garbage-collector1.html"
      }
    ],
    "keywords": [
      "region",
      "garbage",
      "first",
      "pause",
      "time",
      "goal",
      "maxgcpausemillis",
      "parallel",
      "cms",
      "incremental",
      "full",
      "stw",
      "특징",
      "힙을",
      "동일"
    ]
  },
  {
    "id": "JAVA-005",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java의 클래스 로딩 과정을 설명해주세요.",
    "answer": "3단계 클래스 로딩 과정:\nLoading (로딩)\n.class 파일을 읽어 바이트코드를 Method Area에 저장\nClass 객체 생성\nLinking (링킹)\nVerification: 바이트코드 유효성 검증\nPreparation: static 변수 메모리 할당 및 기본값 초기화\nResolution: 심볼릭 참조를 실제 참조로 변환\nInitialization (초기화)\nstatic 블록 실행, static 변수에 명시적 값 할당\n\n클래스 로더 계층 (위임 모델):\nBootstrap ClassLoader → Extension ClassLoader → Application ClassLoader\n상위 로더에 먼저 위임 후, 못 찾으면 하위에서 로드",
    "references": [
      {
        "title": "Class Loading",
        "url": "https://docs.oracle.com/javase/specs/jvms/se17/html/jvms-5.html"
      }
    ],
    "keywords": [
      "loading",
      "method",
      "area",
      "class",
      "linking",
      "verification",
      "preparation",
      "resolution",
      "initialization",
      "bootstrap",
      "classloader",
      "extension",
      "application",
      "단계",
      "클래스"
    ]
  },
  {
    "id": "JAVA-006",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "static 키워드의 의미와 사용 시 주의사항은 무엇인가요?",
    "answer": "의미:\n클래스 레벨에 속하며, 인스턴스 생성 없이 접근 가능\nMethod Area에 저장, 모든 인스턴스가 공유\n\n사용처:\nstatic 변수: 클래스 전체에서 공유하는 값 (예: 카운터)\nstatic 메서드: 유틸리티 메서드 (예: Math.max())\nstatic 블록: 클래스 로딩 시 한 번 실행\nstatic 내부 클래스: 외부 클래스 인스턴스 없이 생성 가능\n\n주의사항:\nstatic 메서드에서 인스턴스 멤버 직접 접근 불가\n멀티스레드 환경에서 동기화 필요 (공유 자원)\n메모리 누수 주의 (GC 대상이 아님, 클래스 언로드 시까지 유지)\n테스트 어려움 (상태 공유로 인한 부작용)\n과도한 사용은 OOP 원칙 위반",
    "references": [
      {
        "title": "Understanding Class Members",
        "url": "https://docs.oracle.com/javase/tutorial/java/javaOO/classvars.html"
      }
    ],
    "keywords": [
      "method",
      "area",
      "math",
      "oop",
      "의미",
      "클래스",
      "레벨에",
      "속하며",
      "인스턴스",
      "생성",
      "없이",
      "접근",
      "가능",
      "저장",
      "모든"
    ]
  },
  {
    "id": "JAVA-007",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "final, finally, finalize의 차이점을 설명해주세요.",
    "answer": "final (키워드)\n변수: 재할당 불가 (상수화)\n메서드: 오버라이딩 불가\n클래스: 상속 불가 (예: String, Integer)\n\nfinally (예외 처리)\ntry-catch-finally 블록에서 항상 실행되는 블록\n리소스 정리에 사용 (try-with-resources 권장)\nreturn이 있어도 실행됨 (System.exit() 제외)\n\nfinalize() (메서드) - Deprecated\nObject 클래스의 메서드, GC 전 호출\nJava 9부터 deprecated, 사용 권장하지 않음\n대안: try-with-resources, Cleaner API",
    "references": [
      {
        "title": "Java Language Keywords",
        "url": "https://docs.oracle.com/javase/tutorial/java/nutsandbolts/_keywords.html"
      }
    ],
    "keywords": [
      "string",
      "integer",
      "try-catch",
      "try-with",
      "system",
      "deprecated",
      "object",
      "java",
      "cleaner",
      "api",
      "키워드",
      "변수",
      "재할당",
      "불가",
      "상수화"
    ]
  },
  {
    "id": "JAVA-008",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "추상 클래스와 인터페이스의 차이점과 사용 시나리오를 설명해주세요.",
    "answer": "구분   추상 클래스   인터페이스\n\n상속   단일 상속   다중 구현 가능\n생성자   가질 수 있음   없음\n필드   인스턴스 변수 가능   public static final만\n메서드   모든 종류   public abstract (+ default, static)\n접근제어자   모두 가능   public만\n\n사용 시나리오:\n\n추상 클래스:\n\"is-a\" 관계, 공통 구현 코드 공유 시\n상태(필드)를 공유해야 할 때\n예: Animal → Dog, Cat\n\n인터페이스:\n\"can-do\" 관계, 행위 계약 정의\n다중 타입 역할 부여 시\n예: Comparable, Serializable, Runnable",
    "references": [
      {
        "title": "Abstract Methods and Classes",
        "url": "https://docs.oracle.com/javase/tutorial/java/IandI/abstract.html"
      }
    ],
    "keywords": [
      "is-a",
      "animal",
      "dog",
      "cat",
      "can-do",
      "comparable",
      "serializable",
      "runnable",
      "구분",
      "추상",
      "클래스",
      "인터페이스",
      "상속",
      "단일",
      "다중"
    ]
  },
  {
    "id": "JAVA-009",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java 8 이후 인터페이스의 default 메서드와 static 메서드에 대해 설명해주세요.",
    "answer": "default 메서드:\n인터페이스에 기본 구현을 제공\n하위 호환성 유지하며 인터페이스 확장 가능\n구현 클래스에서 오버라이딩 가능\n\nstatic 메서드:\n인터페이스에 유틸리티 메서드 정의\n인터페이스명으로 직접 호출 (상속/오버라이딩 불가)\n\n다이아몬드 문제 해결:\n동일 시그니처의 default 메서드 충돌 시, 구현 클래스에서 명시적 오버라이딩 필요\nInterfaceName.super.method() 로 특정 인터페이스 메서드 호출",
    "references": [
      {
        "title": "Default Methods",
        "url": "https://docs.oracle.com/javase/tutorial/java/IandI/defaultmethods.html"
      }
    ],
    "keywords": [
      "interfacename",
      "메서드",
      "인터페이스에",
      "기본",
      "구현을",
      "제공",
      "하위",
      "호환성",
      "유지하며",
      "인터페이스",
      "확장",
      "가능",
      "구현",
      "클래스에서",
      "오버라이딩"
    ]
  },
  {
    "id": "JAVA-010",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Checked Exception과 Unchecked Exception의 차이점은 무엇인가요?",
    "answer": "구분   Checked Exception   Unchecked Exception\n\n상속   Exception 상속   RuntimeException 상속\n처리   반드시 처리 (try-catch/throws)   선택적 처리\n컴파일   미처리 시 컴파일 에러   컴파일 에러 없음\n시점   예측 가능한 외부 요인   프로그래밍 오류\n\nChecked Exception 예시:\nIOException, SQLException, FileNotFoundException\n복구 가능한 상황, 호출자에게 처리 강제\n\nUnchecked Exception 예시:\nNullPointerException, IllegalArgumentException, IndexOutOfBoundsException\n프로그래밍 버그, 방어 코딩으로 예방\n\n현대적 관점:\nSpring/JPA 등은 Unchecked 선호 (보일러플레이트 감소)\nChecked는 과도한 try-catch로 코드 가독성 저하 우려",
    "references": [
      {
        "title": "Exceptions",
        "url": "https://docs.oracle.com/javase/tutorial/essential/exceptions/index.html"
      }
    ],
    "keywords": [
      "checked",
      "exception",
      "unchecked",
      "runtimeexception",
      "try-catch",
      "ioexception",
      "sqlexception",
      "filenotfoundexception",
      "nullpointerexception",
      "illegalargumentexception",
      "indexoutofboundsexception",
      "spring",
      "jpa",
      "구분",
      "상속"
    ]
  },
  {
    "id": "JAVA-011",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "try-with-resources 구문의 동작 원리를 설명해주세요.",
    "answer": "개념:\nJava 7에서 도입된 자동 리소스 관리 구문으로, AutoCloseable 인터페이스를 구현한 리소스를 자동으로 닫아줍니다.\n\n동작 원리:\ntry 블록 종료 시 close() 자동 호출\n선언 역순으로 close() 실행\nclose()에서 발생한 예외는 suppressed exception으로 처리\n\n장점:\nfinally 블록 불필요, 코드 간결\n리소스 누수 방지\n예외 안전한 리소스 해제\n\nSuppressed Exception:",
    "references": [
      {
        "title": "Try-with-resources",
        "url": "https://docs.oracle.com/javase/tutorial/essential/exceptions/tryResourceClose.html"
      }
    ],
    "keywords": [
      "java",
      "autocloseable",
      "suppressed",
      "exception",
      "개념",
      "에서",
      "도입된",
      "자동",
      "리소스",
      "관리",
      "구문으로",
      "인터페이스를",
      "구현한",
      "리소스를",
      "자동으로"
    ]
  },
  {
    "id": "JAVA-012",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "equals()와 hashCode()의 관계와 오버라이딩 시 주의사항은 무엇인가요?",
    "answer": "계약 (Contract):\nequals()가 true인 두 객체는 반드시 같은 hashCode() 반환\nhashCode()가 같아도 equals()는 false일 수 있음\n\n위반 시 문제:\nHashMap, HashSet 등 해시 기반 컬렉션에서 오작동\n객체를 찾지 못하거나 중복 저장되는 버그\n\nequals() 오버라이딩 규칙:\n반사성: x.equals(x) == true\n대칭성: x.equals(y) == y.equals(x)\n추이성: x.equals(y), y.equals(z) → x.equals(z)\n일관성: 값 불변 시 항상 동일 결과\nnull 비교: x.equals(null) == false\n\n구현 팁:",
    "references": [
      {
        "title": "Object.equals()",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#equals(java.lang.Object"
      }
    ],
    "keywords": [
      "contract",
      "hashmap",
      "hashset",
      "계약",
      "객체는",
      "반드시",
      "같은",
      "반환",
      "같아도",
      "있음",
      "위반",
      "문제",
      "해시",
      "기반",
      "컬렉션에서"
    ]
  },
  {
    "id": "JAVA-013",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "String, StringBuilder, StringBuffer의 차이점을 설명해주세요.",
    "answer": "구분   String   StringBuilder   StringBuffer\n\n가변성   불변 (Immutable)   가변 (Mutable)   가변 (Mutable)\n스레드 안전   O (불변)   X   O (synchronized)\n성능   문자열 연산 시 느림   가장 빠름   StringBuilder보다 느림\n메모리   연산마다 새 객체 생성   내부 버퍼 재사용   내부 버퍼 재사용\n\n사용 시나리오:\nString: 문자열 변경이 적을 때, 리터럴 사용\nStringBuilder: 단일 스레드에서 문자열 조작 (권장)\nStringBuffer: 멀티스레드에서 문자열 조작\n\nString Pool:\nString 리터럴은 힙의 String Pool에 저장되어 재사용\nnew String()은 별도 객체 생성",
    "references": [
      {
        "title": "String",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html"
      }
    ],
    "keywords": [
      "string",
      "stringbuilder",
      "stringbuffer",
      "immutable",
      "mutable",
      "pool",
      "구분",
      "가변성",
      "불변",
      "가변",
      "스레드",
      "안전",
      "성능",
      "문자열",
      "연산"
    ]
  },
  {
    "id": "JAVA-014",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java의 Generic에 대해 설명하고, Type Erasure란 무엇인가요?",
    "answer": "Generic:\n컴파일 타임에 타입 안전성을 보장하고, 캐스팅 제거하는 기능 (Java 5+)\n\nType Erasure:\n컴파일 후 제네릭 타입 정보가 제거되어 런타임에는 존재하지 않음\nList<String> → List (Raw Type)\n하위 호환성을 위해 도입\n\n제약사항:\nnew T(), new T[] 불가\ninstanceof T 불가\nstatic 컨텍스트에서 타입 파라미터 사용 불가\n기본 타입 사용 불가 (List<int> X → List<Integer> O)\n\n와일드카드:\n?: 모든 타입\n? extends T: 상한 경계 (읽기 전용)\n? super T: 하한 경계 (쓰기 용)\nPECS: Producer-Extends, Consumer-Super",
    "references": [
      {
        "title": "Generics",
        "url": "https://docs.oracle.com/javase/tutorial/java/generics/index.html"
      }
    ],
    "keywords": [
      "generic",
      "java",
      "type",
      "erasure",
      "list",
      "string",
      "raw",
      "integer",
      "pecs",
      "producer-extends",
      "consumer-super",
      "컴파일",
      "타임에",
      "타입",
      "안전성을"
    ]
  },
  {
    "id": "JAVA-015",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Comparable과 Comparator의 차이점을 설명해주세요.",
    "answer": "구분   Comparable   Comparator\n\n패키지   java.lang   java.util\n메서드   compareTo(T o)   compare(T o1, T o2)\n구현 위치   비교 대상 클래스 내부   별도 클래스/람다\n정렬 기준   자연 순서 (단일)   다양한 기준 가능\n\nComparable:\n\nComparator:\n\n사용 시나리오:\nComparable: 클래스의 기본 정렬 기준 정의\nComparator: 여러 정렬 기준 필요 시, 기존 클래스 수정 불가 시",
    "references": [
      {
        "title": "Comparable",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Comparable.html"
      }
    ],
    "keywords": [
      "comparable",
      "comparator",
      "구분",
      "패키지",
      "메서드",
      "구현",
      "위치",
      "비교",
      "대상",
      "클래스",
      "내부",
      "별도",
      "람다",
      "정렬",
      "기준"
    ]
  },
  {
    "id": "JAVA-016",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java의 Collection Framework 구조를 설명해주세요.",
    "answer": "계층 구조:\n\n주요 인터페이스:\nList: 인덱스 기반 접근, 순서 보장\nSet: 중복 불허, 집합 연산\nQueue/Deque: FIFO/양방향 큐\nMap: 키-값 매핑\n\n선택 기준:\n순서/중복 필요 → List\n고유값 보장 → Set\n키로 검색 → Map\n선입선출 → Queue",
    "references": [
      {
        "title": "Collections Framework",
        "url": "https://docs.oracle.com/javase/tutorial/collections/index.html"
      }
    ],
    "keywords": [
      "list",
      "set",
      "queue",
      "deque",
      "fifo",
      "map",
      "계층",
      "구조",
      "주요",
      "인터페이스",
      "인덱스",
      "기반",
      "접근",
      "순서",
      "보장"
    ]
  },
  {
    "id": "JAVA-017",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "ArrayList와 LinkedList의 차이점과 사용 시나리오는 무엇인가요?",
    "answer": "구분   ArrayList   LinkedList\n\n내부 구조   동적 배열   이중 연결 리스트\n인덱스 접근   O(1)   O(n)\n삽입/삭제 (중간)   O(n)   O(1) (노드 접근 후)\n삽입/삭제 (끝)   O(1) 평균   O(1)\n메모리   연속, 적음   노드별 포인터, 많음\n캐시 효율   높음   낮음\n\nArrayList 권장:\n읽기/조회가 빈번한 경우\n인덱스 기반 접근이 많은 경우\n대부분의 일반적인 상황 (기본 선택)\n\nLinkedList 권장:\n앞/뒤 삽입/삭제가 빈번한 경우\nQueue/Deque 용도로 사용 시\nIterator를 통한 순회 중 삭제가 많을 때\n\n실무 팁:\n실제로는 ArrayList가 대부분 더 좋은 성능을 보임 (CPU 캐시 효율)",
    "references": [
      {
        "title": "ArrayList",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/ArrayList.html"
      }
    ],
    "keywords": [
      "arraylist",
      "linkedlist",
      "queue",
      "deque",
      "iterator",
      "cpu",
      "구분",
      "내부",
      "구조",
      "동적",
      "배열",
      "이중",
      "연결",
      "리스트",
      "인덱스"
    ]
  },
  {
    "id": "JAVA-018",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "HashMap의 동작 원리와 해시 충돌 해결 방법을 설명해주세요.",
    "answer": "동작 원리:\nkey.hashCode()로 해시값 계산\n해시값을 배열 인덱스로 변환 (hash & (n-1))\n해당 버킷에 Entry(key, value) 저장\n\n해시 충돌 해결 (Separate Chaining):\n같은 버킷에 여러 Entry가 저장될 때\nJava 7: 연결 리스트로 체이닝\nJava 8+: 버킷 내 8개 초과 시 Red-Black Tree로 변환 (O(n) → O(log n))\n\n주요 특징:\n초기 용량: 16, 로드팩터: 0.75\n로드팩터 초과 시 2배 리사이징 (rehashing)\nnull key 1개, null value 다수 허용\n순서 보장 X (LinkedHashMap은 보장)\n\n성능:\n평균: get/put O(1)\n최악 (충돌 많을 때): O(log n) - Java 8+",
    "references": [
      {
        "title": "HashMap",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/HashMap.html"
      }
    ],
    "keywords": [
      "entry",
      "separate",
      "chaining",
      "java",
      "red-black",
      "tree",
      "linkedhashmap",
      "동작",
      "원리",
      "해시값",
      "계산",
      "해시값을",
      "배열",
      "인덱스로",
      "변환"
    ]
  },
  {
    "id": "JAVA-019",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "ConcurrentHashMap의 동작 원리와 HashMap과의 차이점은 무엇인가요?",
    "answer": "구분   HashMap   ConcurrentHashMap\n\n스레드 안전   X   O\nnull 허용   key/value 가능   불가\n동기화 방식   없음   세그먼트/노드 락\n성능   단일 스레드 최고   멀티스레드 최적화\nIterator   fail-fast   weakly consistent\n\nConcurrentHashMap 동작 원리:\n\nJava 7:\nSegment 기반 분할 잠금 (기본 16개)\n각 세그먼트별 독립적 락\n\nJava 8+:\n세그먼트 대신 노드 단위 CAS + synchronized\n버킷이 비어있으면 CAS로 삽입\n충돌 시 해당 노드만 synchronized\n읽기는 락 없이 수행 (volatile)\n\n사용 시나리오:\n멀티스레드 환경에서 Map 공유 시\nCollections.synchronizedMap()보다 높은 동시성 필요 시",
    "references": [
      {
        "title": "ConcurrentHashMap",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/concurrent/ConcurrentHashMap.html"
      }
    ],
    "keywords": [
      "hashmap",
      "concurrenthashmap",
      "iterator",
      "fail-fast",
      "java",
      "segment",
      "cas",
      "map",
      "collections",
      "구분",
      "스레드",
      "안전",
      "허용",
      "가능",
      "불가"
    ]
  },
  {
    "id": "JAVA-020",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java의 동기화 방법(synchronized, volatile, Atomic 클래스 등)을 설명해주세요.",
    "answer": "synchronized\n임계 영역에 하나의 스레드만 진입\n메서드 또는 블록 레벨 적용\n모니터 락 기반, 상호 배제 보장\nvolatile\n변수의 가시성(visibility) 보장\n메인 메모리에서 직접 읽기/쓰기\n원자성 보장 안 함 (읽기/쓰기만 원자적)\nAtomic 클래스\nCAS(Compare-And-Swap) 기반 락-프리 연산\nAtomicInteger, AtomicLong, AtomicReference 등\n단일 변수의 원자적 연산\njava.util.concurrent.locks\nReentrantLock: 명시적 락, tryLock() 지원\nReadWriteLock: 읽기/쓰기 분리 락",
    "references": [
      {
        "title": "Concurrency",
        "url": "https://docs.oracle.com/javase/tutorial/essential/concurrency/index.html"
      }
    ],
    "keywords": [
      "atomic",
      "cas",
      "compare-and-swap",
      "atomicinteger",
      "atomiclong",
      "atomicreference",
      "reentrantlock",
      "readwritelock",
      "임계",
      "영역에",
      "하나의",
      "스레드만",
      "진입",
      "메서드",
      "블록"
    ]
  },
  {
    "id": "JAVA-021",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "volatile 키워드의 의미와 사용 시나리오는 무엇인가요?",
    "answer": "의미:\n변수를 CPU 캐시가 아닌 메인 메모리에서 직접 읽고 씀\n가시성(Visibility) 보장: 한 스레드의 변경이 다른 스레드에 즉시 보임\nHappens-Before 관계 보장\n\n보장하지 않는 것:\n원자성: count++ 같은 복합 연산은 원자적이지 않음\n상호 배제: 여러 스레드의 동시 접근 차단 안 함\n\n사용 시나리오:\n\n주의:\n복합 연산에는 synchronized나 Atomic 클래스 사용\n불필요한 volatile은 성능 저하 유발",
    "references": [
      {
        "title": "Atomic Access",
        "url": "https://docs.oracle.com/javase/tutorial/essential/concurrency/atomic.html"
      }
    ],
    "keywords": [
      "cpu",
      "visibility",
      "happens-before",
      "atomic",
      "의미",
      "변수를",
      "캐시가",
      "아닌",
      "메인",
      "메모리에서",
      "직접",
      "읽고",
      "가시성",
      "보장",
      "스레드의"
    ]
  },
  {
    "id": "JAVA-022",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java Memory Model에 대해 설명해주세요.",
    "answer": "JMM (Java Memory Model):\n멀티스레드 환경에서 메모리 접근 규칙을 정의한 명세 (JSR-133, Java 5+)\n\n핵심 개념:\n가시성 (Visibility)\n한 스레드의 변경이 다른 스레드에 보이는지\nCPU 캐시로 인해 보장 안 될 수 있음\n재정렬 (Reordering)\n컴파일러/CPU가 성능 최적화를 위해 명령어 순서 변경\n단일 스레드에서는 결과 동일 보장\nHappens-Before 관계\n연산 A가 B 전에 발생함을 보장하는 규칙\nsynchronized, volatile, Thread.start(), join() 등이 보장\n\n주요 규칙:\n같은 락의 unlock → lock\nvolatile 쓰기 → 읽기\nThread.start() → 해당 스레드의 모든 동작\n스레드의 모든 동작 → join() 리턴\n\n실무 영향:\n동기화 없이 공유 변수 접근 시 예기치 않은 결과\nsynchronized, volatile, Atomic으로 해결",
    "references": [
      {
        "title": "JLS Chapter 17",
        "url": "https://docs.oracle.com/javase/specs/jls/se17/html/jls-17.html"
      }
    ],
    "keywords": [
      "jmm",
      "java",
      "memory",
      "model",
      "jsr-133",
      "visibility",
      "cpu",
      "reordering",
      "happens-before",
      "thread",
      "atomic",
      "멀티스레드",
      "환경에서",
      "메모리",
      "접근"
    ]
  },
  {
    "id": "JAVA-023",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "ThreadLocal의 동작 원리와 주의사항은 무엇인가요?",
    "answer": "개념:\n각 스레드가 독립적인 변수 복사본을 가지게 하는 클래스\n\n동작 원리:\n각 Thread 객체 내부에 ThreadLocalMap 존재\nThreadLocal을 키로, 값을 저장\n스레드별 격리된 저장 공간 제공\n\n사용 시나리오:\n사용자 세션/인증 정보 전달\n트랜잭션 컨텍스트\nSimpleDateFormat 등 스레드 안전하지 않은 객체\n\n주의사항:\n메모리 누수: 스레드 풀 환경에서 remove() 미호출 시 누수\n스레드 재사용 시 이전 값이 남아있을 수 있음\ntry-finally로 항상 정리",
    "references": [
      {
        "title": "ThreadLocal",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/ThreadLocal.html"
      }
    ],
    "keywords": [
      "thread",
      "threadlocalmap",
      "threadlocal",
      "simpledateformat",
      "try-finally",
      "개념",
      "스레드가",
      "독립적인",
      "변수",
      "복사본을",
      "가지게",
      "하는",
      "클래스",
      "동작",
      "원리"
    ]
  },
  {
    "id": "JAVA-024",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Executor Framework와 Thread Pool에 대해 설명해주세요.",
    "answer": "Executor Framework:\n스레드 생성과 작업 실행을 분리한 추상화 계층 (Java 5+)\n\n주요 인터페이스:\nExecutor: 단순 실행 (execute)\nExecutorService: 라이프사이클 관리, Future 반환\nScheduledExecutorService: 지연/주기적 실행\n\nThread Pool 종류 (Executors 팩토리):\n\nThreadPoolExecutor 파라미터:\ncorePoolSize, maximumPoolSize\nkeepAliveTime, workQueue\nRejectedExecutionHandler\n\n실무 권장:\nExecutors 대신 ThreadPoolExecutor 직접 설정\n적절한 큐 크기와 거부 정책 설정",
    "references": [
      {
        "title": "Executors",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/concurrent/Executors.html"
      }
    ],
    "keywords": [
      "executor",
      "framework",
      "java",
      "executorservice",
      "future",
      "scheduledexecutorservice",
      "thread",
      "pool",
      "executors",
      "threadpoolexecutor",
      "rejectedexecutionhandler",
      "스레드",
      "생성과",
      "작업",
      "실행을"
    ]
  },
  {
    "id": "JAVA-025",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Fork/Join Framework의 동작 원리를 설명해주세요.",
    "answer": "개념:\n분할 정복(Divide and Conquer) 알고리즘을 병렬로 실행하기 위한 프레임워크 (Java 7+)\n\n핵심 구성:\nForkJoinPool: 작업 실행 풀\nForkJoinTask: 분할 가능한 작업 (RecursiveTask/RecursiveAction)\nWork-Stealing: 유휴 스레드가 다른 스레드의 큐에서 작업을 훔쳐옴\n\n동작 원리:\n작업을 작은 단위로 분할 (fork)\n각 서브태스크를 병렬 실행\n결과를 결합 (join)\n\nWork-Stealing:\n각 스레드가 자체 Deque 보유\n자신의 큐가 비면 다른 스레드 큐의 tail에서 작업 훔침\n부하 균형 자동 조절",
    "references": [
      {
        "title": "ForkJoinPool",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/concurrent/ForkJoinPool.html"
      }
    ],
    "keywords": [
      "divide",
      "conquer",
      "java",
      "forkjoinpool",
      "forkjointask",
      "recursivetask",
      "recursiveaction",
      "work-stealing",
      "deque",
      "개념",
      "분할",
      "정복",
      "알고리즘을",
      "병렬로",
      "실행하기"
    ]
  },
  {
    "id": "JAVA-026",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java의 Stream API 동작 원리와 병렬 처리 방법을 설명해주세요.",
    "answer": "Stream API:\n컬렉션 데이터를 선언적으로 처리하는 추상화 (Java 8+)\n\n동작 원리:\n소스: 컬렉션, 배열, 파일 등\n중간 연산: filter, map, sorted (지연 평가, Lazy)\n최종 연산: collect, forEach, reduce (실행 트리거)\n\n지연 평가 (Lazy Evaluation):\n최종 연산 호출 전까지 중간 연산 실행 안 함\n파이프라인 최적화 가능 (short-circuit 등)\n\n병렬 처리:\n\n병렬 스트림 주의사항:\n공유 가변 상태 피하기\n작은 데이터셋은 오히려 오버헤드\n순서 의존 연산 주의 (forEachOrdered)\nForkJoinPool.commonPool() 사용",
    "references": [
      {
        "title": "Stream",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/stream/Stream.html"
      }
    ],
    "keywords": [
      "stream",
      "api",
      "java",
      "lazy",
      "evaluation",
      "short-circuit",
      "forkjoinpool",
      "컬렉션",
      "데이터를",
      "선언적으로",
      "처리하는",
      "추상화",
      "동작",
      "원리",
      "소스"
    ]
  },
  {
    "id": "JAVA-027",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Optional 클래스의 필요성과 올바른 사용 방법은 무엇인가요?",
    "answer": "필요성:\nNullPointerException 방지\nnull 가능성을 명시적으로 표현\n함수형 스타일의 null 처리\n\n올바른 사용:\n\n안티패턴 (피해야 할 것):\nopt.get() 직접 호출 (NoSuchElementException 위험)\nopt.isPresent() + opt.get() 조합\n필드 타입으로 Optional 사용\n메서드 파라미터로 Optional 사용\n컬렉션을 Optional로 감싸기\n\n권장:\n메서드 반환 타입으로만 사용\n빈 컬렉션은 Optional 대신 빈 컬렉션 반환",
    "references": [
      {
        "title": "Optional",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Optional.html"
      }
    ],
    "keywords": [
      "nullpointerexception",
      "nosuchelementexception",
      "optional",
      "필요성",
      "방지",
      "가능성을",
      "명시적으로",
      "표현",
      "함수형",
      "스타일의",
      "처리",
      "올바른",
      "사용",
      "안티패턴",
      "피해야"
    ]
  },
  {
    "id": "JAVA-028",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Functional Interface와 Lambda Expression에 대해 설명해주세요.",
    "answer": "Functional Interface:\n추상 메서드가 정확히 1개인 인터페이스\n@FunctionalInterface로 명시 (선택)\n람다/메서드 참조의 타겟 타입\n\n주요 함수형 인터페이스:\n인터페이스   메서드   용도\n\nFunction<T,R>   R apply(T)   변환\nConsumer<T>   void accept(T)   소비\nSupplier<T>   T get()   생성\nPredicate<T>   boolean test(T)   조건 검사\nBiFunction<T,U,R>   R apply(T,U)   이항 변환\n\nLambda Expression:\n익명 함수의 간결한 표현 (Java 8+)\n\n특징:\neffectively final 변수만 캡처 가능\nthis는 람다를 감싸는 클래스 참조",
    "references": [
      {
        "title": "Lambda Expressions",
        "url": "https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html"
      }
    ],
    "keywords": [
      "functional",
      "interface",
      "functionalinterface",
      "function",
      "consumer",
      "supplier",
      "predicate",
      "bifunction",
      "lambda",
      "expression",
      "java",
      "추상",
      "메서드가",
      "정확히",
      "개인"
    ]
  },
  {
    "id": "JAVA-029",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Method Reference의 종류와 사용 방법을 설명해주세요.",
    "answer": "Method Reference:\n기존 메서드를 람다 대신 참조하는 간결한 문법 (::)\n\n4가지 종류:\n정적 메서드 참조\n특정 객체의 인스턴스 메서드\n임의 객체의 인스턴스 메서드\n생성자 참조\n\n사용 시점:\n람다가 단순히 기존 메서드를 호출할 때 사용하면 가독성 향상",
    "references": [
      {
        "title": "Method References",
        "url": "https://docs.oracle.com/javase/tutorial/java/javaOO/methodreferences.html"
      }
    ],
    "keywords": [
      "method",
      "reference",
      "기존",
      "메서드를",
      "람다",
      "대신",
      "참조하는",
      "간결한",
      "문법",
      "가지",
      "종류",
      "정적",
      "메서드",
      "참조",
      "특정"
    ]
  },
  {
    "id": "JAVA-030",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "CompletableFuture의 동작 원리와 사용 방법을 설명해주세요.",
    "answer": "개념:\n비동기 프로그래밍을 위한 Future의 확장 (Java 8+)\n\n기본 사용:\n\n주요 메서드:\n메서드   설명\n\nsupplyAsync   값 반환 비동기 실행\nrunAsync   값 없이 비동기 실행\nthenApply   결과 변환 (map)\nthenCompose   결과로 새 Future 생성 (flatMap)\nthenCombine   두 Future 결과 결합\nexceptionally   예외 처리\nhandle   결과/예외 모두 처리\n\n병렬 처리:\n\n실행 스레드:\n기본: ForkJoinPool.commonPool()\n커스텀 Executor 지정 가능 (supplyAsync(task, executor))",
    "references": [
      {
        "title": "CompletableFuture",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/concurrent/CompletableFuture.html"
      }
    ],
    "keywords": [
      "future",
      "java",
      "forkjoinpool",
      "executor",
      "개념",
      "비동기",
      "프로그래밍을",
      "위한",
      "확장",
      "기본",
      "사용",
      "주요",
      "메서드",
      "설명",
      "반환"
    ]
  },
  {
    "id": "JAVA-031",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java의 리플렉션(Reflection)이란 무엇이고 언제 사용하나요?",
    "answer": "개념:\n런타임에 클래스의 메타정보를 조회하고 조작하는 API\n\n주요 기능:\n\n사용 사례:\n프레임워크: Spring DI, JPA, JUnit\n직렬화/역직렬화: Jackson, Gson\n동적 프록시 생성\nIDE 자동완성, 디버거\n\n단점:\n성능 오버헤드 (캐싱으로 완화)\n컴파일 타임 타입 체크 불가\n캡슐화 위반 가능",
    "references": [
      {
        "title": "Reflection API",
        "url": "https://docs.oracle.com/javase/tutorial/reflect/index.html"
      }
    ],
    "keywords": [
      "api",
      "spring",
      "jpa",
      "junit",
      "jackson",
      "gson",
      "ide",
      "개념",
      "런타임에",
      "클래스의",
      "메타정보를",
      "조회하고",
      "조작하는",
      "주요",
      "기능"
    ]
  },
  {
    "id": "JAVA-032",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "동적 프록시(Dynamic Proxy)의 동작 원리를 설명해주세요.",
    "answer": "개념:\n런타임에 인터페이스를 구현하는 프록시 객체를 동적으로 생성\n\nJDK Dynamic Proxy:\n\n동작 원리:\n런타임에 $Proxy0 클래스 동적 생성\n지정된 인터페이스 구현\n모든 메서드 호출을 InvocationHandler.invoke()로 위임\n\nJDK Proxy vs CGLIB:\n구분   JDK Proxy   CGLIB\n\n대상   인터페이스만   클래스도 가능\n방식   인터페이스 구현   클래스 상속\n제약   인터페이스 필요   final 클래스 불가\n\n사용 사례:\nSpring AOP\n트랜잭션 관리\n로깅, 보안, 캐싱",
    "references": [
      {
        "title": "Dynamic Proxy",
        "url": "https://docs.oracle.com/javase/8/docs/technotes/guides/reflection/proxy.html"
      }
    ],
    "keywords": [
      "jdk",
      "dynamic",
      "proxy",
      "proxy0",
      "invocationhandler",
      "cglib",
      "spring",
      "aop",
      "개념",
      "런타임에",
      "인터페이스를",
      "구현하는",
      "프록시",
      "객체를",
      "동적으로"
    ]
  },
  {
    "id": "JAVA-033",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Annotation의 동작 원리와 커스텀 Annotation 작성 방법은 무엇인가요?",
    "answer": "Annotation:\n코드에 메타데이터를 부여하는 선언적 방법\n\n동작 원리:\n컴파일 시 또는 런타임에 리플렉션으로 읽음\nRetention 정책에 따라 유지 범위 결정\nAnnotation Processor 또는 리플렉션으로 처리\n\n커스텀 Annotation 작성:\n\n메타 어노테이션:\n어노테이션   설명\n\n@Target   적용 위치 (TYPE, METHOD, FIELD 등)\n@Retention   SOURCE, CLASS, RUNTIME\n@Inherited   상속 시 어노테이션 상속\n@Documented   Javadoc에 포함\n@Repeatable   반복 적용 가능\n\n처리 방법:",
    "references": [
      {
        "title": "Annotations",
        "url": "https://docs.oracle.com/javase/tutorial/java/annotations/index.html"
      }
    ],
    "keywords": [
      "annotation",
      "retention",
      "processor",
      "target",
      "type",
      "method",
      "field",
      "source",
      "class",
      "runtime",
      "inherited",
      "documented",
      "javadoc",
      "repeatable",
      "코드에"
    ]
  },
  {
    "id": "JAVA-034",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java의 직렬화(Serialization)와 역직렬화에 대해 설명해주세요.",
    "answer": "개념:\n직렬화: 객체를 바이트 스트림으로 변환\n역직렬화: 바이트 스트림을 객체로 복원\n\n사용 방법:\n\ntransient 키워드:\n직렬화에서 제외할 필드에 사용\n역직렬화 시 기본값으로 초기화\n\n주의사항:\n보안 취약점 (원격 코드 실행 위험)\n버전 호환성 (serialVersionUID 필수)\n성능 이슈\n\n대안:\nJSON (Jackson, Gson)\nProtocol Buffers, Avro\nRecord serialization (Java 16+)",
    "references": [
      {
        "title": "Object Serialization",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/specs/serialization/index.html"
      }
    ],
    "keywords": [
      "json",
      "jackson",
      "gson",
      "protocol",
      "buffers",
      "avro",
      "record",
      "java",
      "개념",
      "직렬화",
      "객체를",
      "바이트",
      "스트림으로",
      "변환",
      "역직렬화"
    ]
  },
  {
    "id": "JAVA-035",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "serialVersionUID의 역할은 무엇인가요?",
    "answer": "역할:\n직렬화된 객체의 버전을 식별하여 역직렬화 시 클래스 호환성 검증\n\n동작 방식:\n직렬화 시 클래스의 serialVersionUID 저장\n역직렬화 시 현재 클래스의 serialVersionUID와 비교\n불일치 시 InvalidClassException 발생\n\n명시적 선언의 중요성:\n선언 안 하면 컴파일러가 자동 생성 (클래스 구조 기반)\n작은 변경에도 UID가 달라져 역직렬화 실패 위험\nIDE 경고: \"serializable class does not declare a static final serialVersionUID\"\n\n호환성 관리:\n필드 추가: 기본값으로 초기화 (호환)\n필드 삭제: 무시됨 (호환)\n필드 타입 변경: 비호환 (새 UID 필요)\n클래스 계층 변경: 비호환\n\n생성 방법:\nserialver 유틸리티\nIDE 자동 생성\n임의의 long 값 (1L 권장)",
    "references": [
      {
        "title": "Serializable",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/io/Serializable.html"
      }
    ],
    "keywords": [
      "invalidclassexception",
      "uid",
      "ide",
      "역할",
      "직렬화된",
      "객체의",
      "버전을",
      "식별하여",
      "역직렬화",
      "클래스",
      "호환성",
      "검증",
      "동작",
      "방식",
      "직렬화"
    ]
  },
  {
    "id": "JAVA-036",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java의 모듈 시스템(Java 9+)에 대해 설명해주세요.",
    "answer": "개념:\nJava 9에서 도입된 JPMS(Java Platform Module System), 프로젝트 Jigsaw\n\n목적:\n강력한 캡슐화 (public이어도 export 안 하면 접근 불가)\n명시적 의존성 선언\nJDK 모듈화 (필요한 것만 포함)\n런타임 이미지 최적화\n\nmodule-info.java:\n\n주요 키워드:\n키워드   설명\n\nrequires   모듈 의존성\nexports   패키지 공개\nopens   리플렉션 접근 허용\nprovides/uses   서비스 로더\n\n장점:\n더 작은 런타임 (jlink로 커스텀 JRE)\n빠른 시작 시간\n보안 강화",
    "references": [
      {
        "title": "Java Module System",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/module/package-summary.html"
      }
    ],
    "keywords": [
      "java",
      "jpms",
      "platform",
      "module",
      "system",
      "jigsaw",
      "jdk",
      "module-info",
      "jre",
      "개념",
      "에서",
      "도입된",
      "프로젝트",
      "목적",
      "강력한"
    ]
  },
  {
    "id": "JAVA-037",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "var 키워드(Java 10+)의 사용과 제한사항은 무엇인가요?",
    "answer": "개념:\n지역 변수 타입 추론 (Local Variable Type Inference)\n\n사용 예시:\n\n제한사항:\n\n가이드라인:\n타입이 명확할 때 사용 (생성자, 리터럴)\n가독성 저하 시 명시적 타입 선언\n변수명으로 의미 전달",
    "references": [
      {
        "title": "Local Variable Type Inference",
        "url": "https://docs.oracle.com/en/java/javase/17/language/local-variable-type-inference.html"
      }
    ],
    "keywords": [
      "local",
      "variable",
      "type",
      "inference",
      "개념",
      "지역",
      "변수",
      "타입",
      "추론",
      "사용",
      "예시",
      "제한사항",
      "가이드라인",
      "타입이",
      "명확할"
    ]
  },
  {
    "id": "JAVA-038",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Record 클래스(Java 14+)의 특징과 사용 시나리오를 설명해주세요.",
    "answer": "개념:\n불변 데이터 캐리어를 간결하게 선언하는 클래스 (Java 16 정식)\n\n기본 문법:\n\n특징:\n암묵적으로 final (상속 불가)\n모든 필드 final (불변)\njava.lang.Record 상속\n인터페이스 구현 가능\n\n커스터마이징:\n\n사용 시나리오:\nDTO (Data Transfer Object)\n값 객체 (Value Object)\n다중 반환값\n패턴 매칭과 함께 사용",
    "references": [
      {
        "title": "Record Classes",
        "url": "https://docs.oracle.com/en/java/javase/17/language/records.html"
      }
    ],
    "keywords": [
      "java",
      "record",
      "dto",
      "data",
      "transfer",
      "object",
      "value",
      "개념",
      "불변",
      "데이터",
      "캐리어를",
      "간결하게",
      "선언하는",
      "클래스",
      "정식"
    ]
  },
  {
    "id": "JAVA-039",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Sealed Class(Java 17+)란 무엇이고 왜 필요한가요?",
    "answer": "개념:\n상속 가능한 클래스를 명시적으로 제한하는 기능 (Java 17 정식)\n\n문법:\n\n하위 클래스 제한자:\n제한자   의미\n\nfinal   더 이상 상속 불가\nsealed   추가 permits로 제한된 상속\nnon-sealed   제한 없이 상속 허용\n\n필요성:\n도메인 모델링: 타입 계층을 완전히 제어\n패턴 매칭: 컴파일러가 모든 케이스 검증 가능 (exhaustiveness)\nAPI 설계: 의도된 확장만 허용\n\n패턴 매칭과 함께:\n\nvs enum:\nSealed: 각 타입이 다른 필드/메서드 가질 수 있음\nEnum: 모든 값이 같은 구조",
    "references": [
      {
        "title": "Sealed Classes",
        "url": "https://docs.oracle.com/en/java/javase/17/language/sealed-classes-and-interfaces.html"
      }
    ],
    "keywords": [
      "java",
      "non-sealed",
      "api",
      "sealed",
      "enum",
      "개념",
      "상속",
      "가능한",
      "클래스를",
      "명시적으로",
      "제한하는",
      "기능",
      "정식",
      "문법",
      "하위"
    ]
  },
  {
    "id": "JAVA-040",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Pattern Matching(Java 14+)의 개선사항을 설명해주세요.",
    "answer": "Pattern Matching for instanceof (Java 16)\nPattern Matching for switch (Java 21)\nRecord Pattern (Java 21)\nGuarded Pattern (when 절)\n\n장점:\n보일러플레이트 코드 감소\n타입 안전성 향상\n함수형 스타일 지원",
    "references": [
      {
        "title": "Pattern Matching",
        "url": "https://docs.oracle.com/en/java/javase/17/language/pattern-matching.html"
      }
    ],
    "keywords": [
      "pattern",
      "matching",
      "java",
      "record",
      "guarded",
      "장점",
      "보일러플레이트",
      "코드",
      "감소",
      "타입",
      "안전성",
      "향상",
      "함수형",
      "스타일",
      "지원"
    ]
  },
  {
    "id": "JAVA-041",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "JVM이 정확히 무엇이고, 어떤 기능을 하는지 설명해 주세요.",
    "answer": "JVM (Java Virtual Machine):\n자바 바이트코드를 해석하고 실행하는 가상 머신\n\n주요 기능:\n플랫폼 독립성: \"Write Once, Run Anywhere\" - OS별 JVM이 바이트코드 실행\n메모리 관리: 자동 메모리 할당 및 GC로 해제\n보안: 바이트코드 검증, 샌드박스 실행\n최적화: JIT 컴파일러로 핫스팟 코드 네이티브 변환\n스레드 관리: 멀티스레딩 지원 및 동기화\n\n실행 흐름:\n\nJVM 구현체:\nOracle HotSpot (가장 널리 사용)\nOpenJ9 (IBM)\nGraalVM (다국어 지원)\nAzul Zulu, Amazon Corretto",
    "references": [
      {
        "title": "JVM Specification",
        "url": "https://docs.oracle.com/javase/specs/jvms/se17/html/index.html"
      }
    ],
    "keywords": [
      "jvm",
      "java",
      "virtual",
      "machine",
      "write",
      "once",
      "run",
      "anywhere",
      "jit",
      "oracle",
      "hotspot",
      "openj9",
      "ibm",
      "graalvm",
      "azul"
    ]
  },
  {
    "id": "JAVA-042",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "그럼, 자바 말고 다른 언어는 JVM 위에 올릴 수 없나요?",
    "answer": "가능합니다. JVM은 바이트코드를 실행하므로, 바이트코드로 컴파일되는 언어면 모두 실행 가능합니다.\n\nJVM 언어들:\n언어   특징\n\nKotlin   안드로이드 공식 언어, Java 상호운용\nScala   함수형 + 객체지향, 대용량 데이터 처리\nGroovy   동적 타이핑, 스크립팅, Gradle\nClojure   Lisp 계열 함수형 언어\nJRuby   Ruby의 JVM 구현\nJython   Python의 JVM 구현\n\n장점:\nJVM 생태계(라이브러리, 도구) 활용\nJava 클래스와 상호 호출 가능\n성숙한 GC, JIT 최적화 혜택\n크로스 플랫폼\n\n상호운용 예시:",
    "references": [
      {
        "title": "JVM Languages",
        "url": "https://en.wikipedia.org/wiki/List_of_JVM_languages"
      }
    ],
    "keywords": [
      "jvm",
      "kotlin",
      "java",
      "scala",
      "groovy",
      "gradle",
      "clojure",
      "lisp",
      "jruby",
      "ruby",
      "jython",
      "python",
      "jit",
      "가능합니다",
      "바이트코드를"
    ]
  },
  {
    "id": "JAVA-043",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "반대로 JVM 계열 언어를 일반적으로 컴파일해서 사용할 순 없나요?",
    "answer": "가능합니다. AOT(Ahead-Of-Time) 컴파일을 통해 네이티브 실행 파일로 변환할 수 있습니다.\n\n방법들:\nGraalVM Native Image\n빠른 시작 시간 (밀리초)\n적은 메모리 사용\n단, 빌드 시간 길고 리플렉션 제약\nKotlin Native\nLLVM 기반 네이티브 컴파일\niOS, macOS, Windows, Linux 지원\nJVM 없이 독립 실행\nScala Native\nLLVM 백엔드로 네이티브 컴파일\n\n장점:\nJVM 워밍업 시간 제거\n컨테이너/서버리스에 적합\n배포 크기 감소\n\n단점:\n리플렉션, 동적 기능 제약\n빌드 시간 증가\n일부 라이브러리 호환성 이슈",
    "references": [
      {
        "title": "GraalVM Native Image",
        "url": "https://www.graalvm.org/latest/reference-manual/native-image/"
      }
    ],
    "keywords": [
      "aot",
      "ahead-of-time",
      "graalvm",
      "native",
      "image",
      "kotlin",
      "llvm",
      "windows",
      "linux",
      "jvm",
      "scala",
      "가능합니다",
      "컴파일을",
      "네이티브",
      "실행"
    ]
  },
  {
    "id": "JAVA-044",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "VM을 사용함으로써 얻을 수 있는 장점과 단점에 대해 설명해 주세요.",
    "answer": "장점:\n플랫폼 독립성\n한 번 컴파일, 어디서나 실행\nOS별 코드 수정 불필요\n메모리 관리\n자동 GC로 메모리 누수 감소\n개발자가 메모리 직접 관리 불필요\n보안\n바이트코드 검증\n샌드박스 실행 환경\n런타임 최적화\nJIT 컴파일러가 핫스팟 최적화\n프로파일링 기반 동적 최적화\n풍부한 생태계\n표준 라이브러리, 모니터링 도구\n\n단점:\n성능 오버헤드\n네이티브 코드 대비 느릴 수 있음\n해석 실행 비용\n시작 시간\nJVM 워밍업, 클래스 로딩 시간\n서버리스/CLI에 불리\n메모리 사용량\nJVM 자체 메모리 소비\n객체 헤더 등 오버헤드\nGC 중단 (STW)\n예측 불가능한 지연",
    "references": [
      {
        "title": "JVM Architecture",
        "url": "https://docs.oracle.com/javase/specs/jvms/se17/html/jvms-1.html"
      }
    ],
    "keywords": [
      "jit",
      "jvm",
      "cli",
      "stw",
      "장점",
      "플랫폼",
      "독립성",
      "컴파일",
      "어디서나",
      "실행",
      "코드",
      "수정",
      "불필요",
      "메모리",
      "관리"
    ]
  },
  {
    "id": "JAVA-045",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "JVM과 내부에서 실행되고 있는 프로그램은 부모 프로세스 - 자식 프로세스 관계를 갖고 있다고 봐도 무방한가요?",
    "answer": "아닙니다. JVM과 Java 프로그램은 부모-자식 프로세스 관계가 아닙니다.\n\n실제 관계:\nJVM은 하나의 프로세스\nJava 프로그램은 그 프로세스 내에서 실행되는 스레드\n즉, 동일 프로세스 내에서 실행됨\n\n프로세스 구조:\n\n부모-자식 프로세스와의 차이:\n구분   부모-자식 프로세스   JVM-Java 프로그램\n\n메모리   독립 (IPC 필요)   공유 (힙, 메서드 영역)\n생명주기   독립적   JVM 종료 시 함께 종료\n관계   fork()   동일 프로세스 내 스레드\n\nRuntime.exec()로 자식 프로세스 생성은 가능:",
    "references": [
      {
        "title": "Process and Thread",
        "url": "https://docs.oracle.com/javase/tutorial/essential/concurrency/procthread.html"
      }
    ],
    "keywords": [
      "jvm",
      "java",
      "jvm-java",
      "ipc",
      "runtime",
      "아닙니다",
      "프로그램은",
      "부모",
      "자식",
      "프로세스",
      "관계가",
      "실제",
      "관계",
      "하나의",
      "내에서"
    ]
  },
  {
    "id": "JAVA-046",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "final 키워드를 사용하면, 어떤 이점이 있나요?",
    "answer": "불변성 보장\n변수: 재할당 방지로 실수 예방\n안전한 공유 (멀티스레드에서 동기화 불필요)\n설계 의도 명확화\n클래스: 상속 금지 (예: String, 보안/설계상 이유)\n메서드: 오버라이딩 금지 (템플릿 메서드 패턴)\n성능 최적화 가능성\n컴파일러/JIT 최적화 힌트\n인라이닝 가능성 증가\n람다/익명 클래스 캡처\n지역 변수 캡처 시 effectively final 필요\n\n사용 예:\n\n가이드라인:\n불변 객체 설계 시 적극 활용\n상수는 static final 조합\n변경 의도 없는 지역 변수에 습관적 사용 권장",
    "references": [
      {
        "title": "final Keyword",
        "url": "https://docs.oracle.com/javase/tutorial/java/IandI/final.html"
      }
    ],
    "keywords": [
      "string",
      "jit",
      "불변성",
      "보장",
      "변수",
      "재할당",
      "방지로",
      "실수",
      "예방",
      "안전한",
      "공유",
      "멀티스레드에서",
      "동기화",
      "불필요",
      "설계"
    ]
  },
  {
    "id": "JAVA-047",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "그렇다면 컴파일 과정에서, final 키워드는 다르게 취급되나요?",
    "answer": "예, 컴파일러가 final을 특별히 처리합니다.\n상수 폴딩 (Constant Folding)\nstatic final 기본형/String은 컴파일 타임 상수\n사용처에 값이 직접 삽입됨 (인라이닝)\n바이트코드 차이\n바이트코드 자체는 유사하지만, JIT 최적화에 영향\nfinal 메서드\ninvokevirtual 대신 더 효율적인 호출 가능\n인라이닝 가능성 증가\nfinal 클래스\n하위 타입 없음 보장 → 최적화 기회\n\n주의:\nstatic final 참조 타입은 상수 폴딩 안 됨\n\n실무 영향:\n큰 성능 차이는 드물지만, JIT 최적화에 힌트 제공\n코드 명확성이 더 중요한 이점",
    "references": [
      {
        "title": "JLS Constant Expressions",
        "url": "https://docs.oracle.com/javase/specs/jls/se17/html/jls-15.html#jls-15.29"
      }
    ],
    "keywords": [
      "constant",
      "folding",
      "string",
      "jit",
      "컴파일러가",
      "특별히",
      "처리합니다",
      "상수",
      "폴딩",
      "기본형",
      "컴파일",
      "타임",
      "사용처에",
      "값이",
      "직접"
    ]
  },
  {
    "id": "JAVA-048",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "인터페이스와 추상 클래스의 차이에 대해 설명해 주세요.",
    "answer": "구분   인터페이스   추상 클래스\n\n다중 상속   가능   불가 (단일 상속)\n생성자   없음   있음\n필드   public static final   모든 종류\n메서드   public abstract + default/static   모든 종류\n접근 제어자   public만   모두 가능\n목적   행위 계약 (can-do)   공통 구현 공유 (is-a)\n\n언제 사용?\n\n인터페이스:\n관련 없는 클래스에 공통 기능 부여\n다중 역할이 필요할 때\nAPI 계약 정의\n\n추상 클래스:\n밀접한 클래스 간 코드 공유\n공통 상태(필드) 필요\n템플릿 메서드 패턴\n\nJava 8+ 변화:\n인터페이스에 default 메서드로 구현 가능해져 차이 줄어듦\n하지만 상태(인스턴스 필드) 여부가 여전히 핵심 차이",
    "references": [
      {
        "title": "Interfaces",
        "url": "https://docs.oracle.com/javase/tutorial/java/IandI/createinterface.html"
      }
    ],
    "keywords": [
      "can-do",
      "is-a",
      "api",
      "java",
      "구분",
      "인터페이스",
      "추상",
      "클래스",
      "다중",
      "상속",
      "가능",
      "불가",
      "단일",
      "생성자",
      "없음"
    ]
  },
  {
    "id": "JAVA-049",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "왜 클래스는 단일 상속만 가능한데, 인터페이스는 2개 이상 구현이 가능할까요?",
    "answer": "다이아몬드 문제 (Diamond Problem) 회피\n\n클래스 다중 상속의 문제:\n상태(필드)와 구현이 충돌\n어느 부모의 구현을 사용할지 모호\n\n인터페이스가 안전한 이유:\n상태 없음\n인터페이스는 인스턴스 필드가 없음\n상태 충돌 불가능\n메서드 시그니처만 정의 (Java 7까지)\n구현이 없으니 충돌할 것이 없음\nJava 8+ default 메서드 충돌 해결:\n컴파일러가 강제로 오버라이딩 요구\n개발자가 명시적으로 해결\n\n결론:\n클래스 다중 상속은 복잡성과 모호성 유발\n인터페이스는 계약만 정의하므로 안전하게 다중 구현 가능",
    "references": [
      {
        "title": "Multiple Inheritance",
        "url": "https://docs.oracle.com/javase/tutorial/java/IandI/multipleinheritance.html"
      }
    ],
    "keywords": [
      "diamond",
      "problem",
      "java",
      "다이아몬드",
      "문제",
      "회피",
      "클래스",
      "다중",
      "상속의",
      "상태",
      "필드",
      "구현이",
      "충돌",
      "어느",
      "부모의"
    ]
  },
  {
    "id": "JAVA-050",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "리플렉션에 대해 설명해 주세요.",
    "answer": "개념:\n런타임에 클래스의 구조(메서드, 필드, 생성자 등)를 분석하고 조작하는 기능\n\n핵심 클래스:\nClass<?>: 클래스 메타정보\nMethod: 메서드 정보 및 호출\nField: 필드 접근 및 수정\nConstructor: 객체 생성\n\n사용 예:\n\n사용 사례:\n프레임워크 (Spring, Hibernate, JUnit)\n의존성 주입 (DI)\nORM 매핑\n직렬화/역직렬화\nIDE 기능 (자동완성, 리팩토링)",
    "references": [
      {
        "title": "Reflection API",
        "url": "https://docs.oracle.com/javase/tutorial/reflect/index.html"
      }
    ],
    "keywords": [
      "class",
      "method",
      "field",
      "constructor",
      "spring",
      "hibernate",
      "junit",
      "orm",
      "ide",
      "개념",
      "런타임에",
      "클래스의",
      "구조",
      "메서드",
      "필드"
    ]
  },
  {
    "id": "JAVA-051",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "의미만 들어보면 리플렉션은 보안적인 문제가 있을 가능성이 있어보이는데, 실제로 그렇게 생각하시나요? 만약 그렇다면, 어떻게 방지할 수 있을까요?",
    "answer": "예, 보안 위험이 있습니다.\n\n보안 문제:\n캡슐화 위반: private 필드/메서드 접근 가능\n불변 객체 변경: final 필드도 수정 가능\n접근 제어 무력화: setAccessible(true)로 모든 제한 우회\n악성 코드 실행: 임의 클래스 로드 및 메서드 호출\n\n방지 방법:\nSecurityManager (Java 17 deprecated)\n모듈 시스템 (Java 9+)\nsetAccessible 제한\n모듈 경계에서 기본적으로 차단\n--illegal-access=deny 옵션\n코드 설계\n신뢰할 수 없는 입력으로 Class.forName() 금지\n화이트리스트 기반 클래스 허용\n\n실무 관점:\n내부 프레임워크/라이브러리에서는 필요악\n외부 입력 기반 리플렉션은 위험\nJava 모듈 시스템이 현대적 해결책",
    "references": [
      {
        "title": "Security Manager",
        "url": "https://docs.oracle.com/en/java/javase/17/security/permissions-jdk.html"
      }
    ],
    "keywords": [
      "securitymanager",
      "java",
      "illegal-access",
      "class",
      "보안",
      "위험이",
      "문제",
      "캡슐화",
      "위반",
      "필드",
      "메서드",
      "접근",
      "가능",
      "불변",
      "객체"
    ]
  },
  {
    "id": "JAVA-052",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "리플렉션을 언제 활용할 수 있을까요?",
    "answer": "프레임워크 개발\nSpring DI: @Autowired로 의존성 자동 주입\nJPA/Hibernate: 엔티티 ↔ 테이블 매핑\nJUnit: @Test 메서드 자동 발견 및 실행\n동적 객체 생성\n직렬화/역직렬화\nJackson, Gson이 JSON ↔ 객체 변환 시 사용\n필드명으로 setter/getter 호출\n프록시 생성\nAOP (로깅, 트랜잭션)\nMock 객체 (Mockito)\n어노테이션 처리\nIDE/개발도구\n자동완성, 리팩토링\n디버거\n\n사용 시 주의:\n성능 오버헤드 (캐싱으로 완화)\n컴파일 타임 체크 불가\n꼭 필요한 경우에만 사용",
    "references": [
      {
        "title": "Uses of Reflection",
        "url": "https://docs.oracle.com/javase/tutorial/reflect/index.html"
      }
    ],
    "keywords": [
      "spring",
      "autowired",
      "jpa",
      "hibernate",
      "junit",
      "test",
      "jackson",
      "gson",
      "json",
      "aop",
      "mock",
      "mockito",
      "ide",
      "프레임워크",
      "개발"
    ]
  },
  {
    "id": "JAVA-053",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "static class와 static method를 비교해 주세요.",
    "answer": "Static Method:\n\n특징:\n클래스 레벨에 속함\n인스턴스 멤버 접근 불가 (this 없음)\n유틸리티 메서드에 적합\n\n---\n\nStatic Class (Static Nested Class):\n\n특징:\n외부 클래스 인스턴스 없이 생성 가능\n외부 클래스의 인스턴스 멤버 접근 불가\nstatic 멤버만 접근 가능\n\n---\n\n비교:\n\n구분   Static Method   Static Class\n\n대상   메서드   내부 클래스\n인스턴스 필요   호출 시 불필요   생성 시 외부 인스턴스 불필요\n외부 접근   static 멤버만   static 멤버만\n용도   유틸리티 함수   논리적 그룹화, 빌더 패턴\n\n참고: 최상위 클래스는 static 불가 (내부 클래스만 static 가능)",
    "references": [
      {
        "title": "Nested Classes",
        "url": "https://docs.oracle.com/javase/tutorial/java/javaOO/nested.html"
      }
    ],
    "keywords": [
      "static",
      "method",
      "class",
      "nested",
      "특징",
      "클래스",
      "레벨에",
      "속함",
      "인스턴스",
      "멤버",
      "접근",
      "불가",
      "없음",
      "유틸리티",
      "메서드에"
    ]
  },
  {
    "id": "JAVA-054",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "static 을 사용하면 어떤 이점을 얻을 수 있나요? 어떤 제약이 걸릴까요?",
    "answer": "이점:\n메모리 효율\n인스턴스 생성 없이 사용\n모든 인스턴스가 공유 (중복 제거)\n전역 접근\n클래스명으로 어디서든 접근\n유틸리티 메서드에 적합\n상수 정의\n팩토리 메서드\n   \n\n---\n\n제약:\n인스턴스 멤버 접근 불가\n오버라이딩 불가\n다형성 활용 제한\n하위 클래스에서 숨기기(hiding)만 가능\n테스트 어려움\nMock 어려움, 상태 공유로 테스트 격리 문제\n메모리 누수 위험\n클래스 로더 언로드 전까지 유지\n컬렉션에 객체 쌓이면 누수\n멀티스레드 동기화 필요\n공유 상태이므로 동시 접근 주의",
    "references": [
      {
        "title": "Understanding Class Members",
        "url": "https://docs.oracle.com/javase/tutorial/java/javaOO/classvars.html"
      }
    ],
    "keywords": [
      "mock",
      "이점",
      "메모리",
      "효율",
      "인스턴스",
      "생성",
      "없이",
      "사용",
      "모든",
      "인스턴스가",
      "공유",
      "중복",
      "제거",
      "전역",
      "접근"
    ]
  },
  {
    "id": "JAVA-055",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "컴파일 과정에서 static 이 어떻게 처리되는지 설명해 주세요.",
    "answer": "컴파일 시:\nstatic 멤버 바이트코드 생성\n메서드 호출: invokestatic 명령어\n필드 접근: getstatic, putstatic 명령어\n상수 폴딩 (static final)\n   \n\n---\n\n클래스 로딩 시:\nMethod Area에 저장\n클래스 메타정보와 함께 static 변수 저장\n모든 인스턴스가 공유\n초기화 순서\nclinit 메서드\n컴파일러가 static 초기화 코드를 모아 <clinit> 생성\n클래스 로딩 시 한 번만 실행\n스레드 안전하게 동기화됨\n\n바이트코드 예:\n\nvs 인스턴스:\n인스턴스: invokevirtual, getfield\nstatic: invokestatic, getstatic",
    "references": [
      {
        "title": "JVM Initialization",
        "url": "https://docs.oracle.com/javase/specs/jvms/se17/html/jvms-5.html#jvms-5.5"
      }
    ],
    "keywords": [
      "method",
      "area",
      "컴파일",
      "멤버",
      "바이트코드",
      "생성",
      "메서드",
      "호출",
      "명령어",
      "필드",
      "접근",
      "상수",
      "폴딩",
      "클래스",
      "로딩"
    ]
  },
  {
    "id": "JAVA-056",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java의 Exception에 대해 설명해 주세요.",
    "answer": "예외 계층 구조:\n\nException vs Error:\nException: 애플리케이션 레벨, 처리 가능\nError: JVM/시스템 레벨, 복구 불가\n\n예외 처리:\n\n예외 전파:\n\n목적:\n정상 흐름과 오류 처리 분리\n오류 정보 전달 (메시지, 스택 트레이스)\n적절한 수준에서 처리 가능",
    "references": [
      {
        "title": "Exceptions",
        "url": "https://docs.oracle.com/javase/tutorial/essential/exceptions/index.html"
      }
    ],
    "keywords": [
      "exception",
      "error",
      "jvm",
      "예외",
      "계층",
      "구조",
      "애플리케이션",
      "레벨",
      "처리",
      "가능",
      "시스템",
      "복구",
      "불가",
      "전파",
      "목적"
    ]
  },
  {
    "id": "JAVA-057",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "예외처리를 하는 세 방법에 대해 설명해 주세요.",
    "answer": "예외 복구 (Recovery)\n예외 상황을 복구하고 정상 흐름 진행\n재시도, 대체 값 반환 등\n예외 회피 (Avoidance/Propagation)\n상위 호출자에게 처리 책임 전가\n해당 레이어에서 처리할 수 없을 때\n예외 전환 (Translation)\n저수준 예외를 고수준으로 변환\n추상화 수준 유지, 의미 있는 예외로 변경\n원본 예외를 cause로 포함\n\n선택 기준:\n복구 가능? → 복구\n상위에서 처리해야? → 회피\n더 의미 있는 예외로? → 전환",
    "references": [
      {
        "title": "Catching and Handling Exceptions",
        "url": "https://docs.oracle.com/javase/tutorial/essential/exceptions/handling.html"
      }
    ],
    "keywords": [
      "recovery",
      "avoidance",
      "propagation",
      "translation",
      "예외",
      "복구",
      "상황을",
      "복구하고",
      "정상",
      "흐름",
      "진행",
      "재시도",
      "대체",
      "반환",
      "회피"
    ]
  },
  {
    "id": "JAVA-058",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "CheckedException, UncheckedException 의 차이에 대해 설명해 주세요.",
    "answer": "구분   Checked Exception   Unchecked Exception\n\n상속   Exception (RuntimeException 제외)   RuntimeException\n컴파일 검사   O (try-catch 또는 throws 필수)   X\n발생 시점   예측 가능한 외부 요인   프로그래밍 오류\n복구 가능성   복구 시도 기대   버그 수정 필요\n\nChecked Exception:\nIOException, SQLException, FileNotFoundException\n외부 시스템 오류, 복구 가능\n\nUnchecked Exception:\nNullPointerException, IllegalArgumentException\n프로그래밍 실수, 방어 코딩으로 예방\n\n현대적 관점:\nSpring, JPA는 Unchecked 선호\nChecked는 과도한 보일러플레이트 유발\n중요한 예외만 명시적 처리, 나머지는 전역 핸들러",
    "references": [
      {
        "title": "Checked vs Unchecked",
        "url": "https://docs.oracle.com/javase/tutorial/essential/exceptions/runtime.html"
      }
    ],
    "keywords": [
      "checked",
      "exception",
      "unchecked",
      "runtimeexception",
      "try-catch",
      "ioexception",
      "sqlexception",
      "filenotfoundexception",
      "nullpointerexception",
      "illegalargumentexception",
      "spring",
      "jpa",
      "구분",
      "상속",
      "제외"
    ]
  },
  {
    "id": "JAVA-059",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "예외처리가 성능에 큰 영향을 미치나요? 만약 그렇다면, 어떻게 하면 부하를 줄일 수 있을까요?",
    "answer": "성능 영향:\n예, 예외 발생 시 상당한 오버헤드가 있습니다.\n\n비용 발생 원인:\n스택 트레이스 생성: 호출 스택 전체 캡처 (가장 비용 큼)\n예외 객체 생성: 힙 메모리 할당\n스택 언와인딩: catch 블록 탐색\n\n측정:\n정상 흐름 대비 수십~수백 배 느림\nfillInStackTrace()가 대부분의 비용\n\n---\n\n부하 줄이는 방법:\n예외를 제어 흐름으로 사용 금지\n스택 트레이스 생략 (성능 중시 시)\n예외 재사용 (특수 상황)\n예외 발생 조건 사전 검사\n\n결론:\n정상 흐름에서 예외 사용 금지\n예외는 진정한 예외 상황에만",
    "references": [
      {
        "title": "Exception Performance",
        "url": "https://docs.oracle.com/javase/tutorial/essential/exceptions/index.html"
      }
    ],
    "keywords": [
      "성능",
      "영향",
      "예외",
      "발생",
      "상당한",
      "오버헤드가",
      "비용",
      "원인",
      "스택",
      "트레이스",
      "생성",
      "호출",
      "전체",
      "캡처",
      "가장"
    ]
  },
  {
    "id": "JAVA-060",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Synchronized 키워드에 대해 설명해 주세요.",
    "answer": "개념:\n임계 영역(Critical Section)에 하나의 스레드만 진입하도록 보장하는 키워드\n\n동작 원리:\n모니터 락(Monitor Lock) 기반\n락 획득 → 코드 실행 → 락 해제\n다른 스레드는 락 획득까지 대기 (blocking)\n\n사용 방법:\n\n보장하는 것:\n상호 배제: 한 번에 한 스레드만\n가시성: 락 해제 시 변경사항 다른 스레드에 보임\nHappens-Before: 락 해제 → 락 획득 순서 보장\n\n특징:\n재진입 가능 (같은 스레드가 락을 다시 획득 가능)\n자동 락 해제 (예외 발생해도)",
    "references": [
      {
        "title": "Synchronized Methods",
        "url": "https://docs.oracle.com/javase/tutorial/essential/concurrency/syncmeth.html"
      }
    ],
    "keywords": [
      "critical",
      "section",
      "monitor",
      "lock",
      "happens-before",
      "개념",
      "임계",
      "영역",
      "하나의",
      "스레드만",
      "진입하도록",
      "보장하는",
      "키워드",
      "동작",
      "원리"
    ]
  },
  {
    "id": "JAVA-061",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Synchronized 키워드가 어디에 붙는지에 따라 의미가 약간씩 변화하는데, 각각 어떤 의미를 갖게 되는지 설명해 주세요.",
    "answer": "인스턴스 메서드\n락 객체: this (현재 인스턴스)\n같은 인스턴스의 synchronized 메서드끼리 상호 배제\n다른 인스턴스는 동시 실행 가능\n정적 메서드\n락 객체: Class 객체 (MyClass.class)\n모든 인스턴스에서 상호 배제\n인스턴스 메서드와는 다른 락\nsynchronized 블록\n락 객체: 명시한 객체\n세밀한 제어 가능\n필요한 부분만 동기화\n\n주의:\n\n권장:\n메서드 전체보다 블록 동기화 선호 (범위 최소화)\nprivate final 락 객체 사용",
    "references": [
      {
        "title": "Intrinsic Locks",
        "url": "https://docs.oracle.com/javase/tutorial/essential/concurrency/locksync.html"
      }
    ],
    "keywords": [
      "class",
      "myclass",
      "인스턴스",
      "메서드",
      "객체",
      "현재",
      "같은",
      "인스턴스의",
      "메서드끼리",
      "상호",
      "배제",
      "다른",
      "인스턴스는",
      "동시",
      "실행"
    ]
  },
  {
    "id": "JAVA-062",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "효율적인 코드 작성 측면에서, Synchronized는 좋은 키워드일까요?",
    "answer": "장점:\n사용이 간단하고 직관적\n자동 락 해제 (예외 시에도)\n재진입 가능\nJVM 최적화 (바이어스 락, 경량 락)\n\n단점:\n유연성 부족\ntryLock (타임아웃) 불가\n공정성 설정 불가\n조건 분기 어려움\n성능 제한\n읽기-읽기도 블로킹\n블록 단위로만 해제\n데드락 위험\n락 순서 제어 어려움\n대기 중 인터럽트 불가\n\n언제 사용?\n단순한 동기화\n짧은 임계 영역\n복잡한 동기화 불필요 시\n\n대안 고려:\n\n결론:\n단순한 케이스에는 충분히 좋음\n복잡한 동기화는 java.util.concurrent 활용",
    "references": [
      {
        "title": "High Level Concurrency",
        "url": "https://docs.oracle.com/javase/tutorial/essential/concurrency/highlevel.html"
      }
    ],
    "keywords": [
      "jvm",
      "장점",
      "사용이",
      "간단하고",
      "직관적",
      "자동",
      "해제",
      "예외",
      "시에도",
      "재진입",
      "가능",
      "최적화",
      "바이어스",
      "경량",
      "단점"
    ]
  },
  {
    "id": "JAVA-063",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Synchronized 를 대체할 수 있는 자바의 다른 동기화 기법에 대해 설명해 주세요.",
    "answer": "ReentrantLock\n명시적 락/언락\ntryLock, 인터럽트 지원\n공정성 설정 가능\nReadWriteLock\n읽기 작업 많을 때 성능 향상\nAtomic 클래스\n락 프리(Lock-free)\n단일 변수 원자적 연산\nvolatile\n가시성 보장\n단순 읽기/쓰기만 원자적\nStampedLock (Java 8+)\n낙관적 읽기 지원\n높은 성능\n\n선택 기준:\n상황   권장\n\n단순 동기화   synchronized\n복잡한 제어   ReentrantLock\n읽기 위주   ReadWriteLock\n단일 변수   Atomic",
    "references": [
      {
        "title": "Lock Objects",
        "url": "https://docs.oracle.com/javase/tutorial/essential/concurrency/newlocks.html"
      }
    ],
    "keywords": [
      "reentrantlock",
      "readwritelock",
      "atomic",
      "lock-free",
      "stampedlock",
      "java",
      "명시적",
      "언락",
      "인터럽트",
      "지원",
      "공정성",
      "설정",
      "가능",
      "읽기",
      "작업"
    ]
  },
  {
    "id": "JAVA-064",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Thread Local에 대해 설명해 주세요.",
    "answer": "개념:\n각 스레드가 독립적인 변수 복사본을 가지게 하는 클래스\n\n사용법:\n\n동작 원리:\n각 Thread 내부에 ThreadLocalMap 존재\nThreadLocal 객체를 키로, 값을 저장\n스레드별 격리된 저장 공간\n\n사용 사례:\n사용자 세션/인증 정보 (SecurityContextHolder)\n트랜잭션 컨텍스트\n포맷터 (SimpleDateFormat - 스레드 안전하지 않음)\n요청별 로깅 컨텍스트\n\n주의사항:\n스레드 풀 환경에서 remove() 안 하면 메모리 누수\n이전 요청 데이터가 남아 보안 문제 가능\n\nInheritableThreadLocal:\n자식 스레드에 값 상속",
    "references": [
      {
        "title": "ThreadLocal",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/ThreadLocal.html"
      }
    ],
    "keywords": [
      "thread",
      "threadlocalmap",
      "threadlocal",
      "securitycontextholder",
      "simpledateformat",
      "inheritablethreadlocal",
      "개념",
      "스레드가",
      "독립적인",
      "변수",
      "복사본을",
      "가지게",
      "하는",
      "클래스",
      "사용법"
    ]
  },
  {
    "id": "JAVA-065",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java Stream에 대해 설명해 주세요.",
    "answer": "개념:\n데이터 컬렉션을 선언적으로 처리하는 API (Java 8+)\n\n특징:\n데이터 소스를 변경하지 않음 (불변)\n일회용 (한 번 사용 후 재사용 불가)\n지연 평가 (Lazy Evaluation)\n내부 반복 (명시적 루프 없음)\n\n구조:\n\n중간 연산:\nfilter, map, flatMap, sorted, distinct, limit, skip\n지연 평가됨 (최종 연산 전까지 실행 안 함)\n\n최종 연산:\ncollect, forEach, reduce, count, findFirst, anyMatch\n실행을 트리거하고 결과 반환\n\n장점:\n가독성 향상 (선언적)\n병렬 처리 쉬움 (parallelStream)\n파이프라인 최적화\n\n주의:\n부작용(side-effect) 피하기\n무한 스트림 주의 (limit 필수)",
    "references": [
      {
        "title": "Stream API",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/stream/Stream.html"
      }
    ],
    "keywords": [
      "api",
      "java",
      "lazy",
      "evaluation",
      "side-effect",
      "개념",
      "데이터",
      "컬렉션을",
      "선언적으로",
      "처리하는",
      "특징",
      "소스를",
      "변경하지",
      "않음",
      "불변"
    ]
  },
  {
    "id": "JAVA-066",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Stream과 for ~ loop의 성능 차이를 비교해 주세요,",
    "answer": "일반적 성능 비교:\n\n구분   for-loop   Stream\n\n단순 반복   빠름   약간 느림\n복잡한 파이프라인   유사   유사\n병렬 처리   직접 구현   parallelStream\nJIT 최적화   최적화됨   추가 오버헤드\n\nStream 오버헤드 원인:\n람다 호출 비용\n중간 객체 생성 (박싱/언박싱)\n파이프라인 구축 비용\n\n성능 차이 예:\n\n실무 관점:\n성능 차이는 대부분 미미 (1.5~2배)\n가독성과 유지보수성이 더 중요\n핫 코드에서만 최적화 고려\n\nStream이 유리한 경우:\n복잡한 데이터 변환\n병렬 처리 필요\n가독성 중시\n\nfor-loop이 유리한 경우:\n단순 반복\n극한의 성능 필요\n조기 종료가 복잡할 때\n\n결론: 대부분 Stream 사용, 성능 이슈 시 프로파일링 후 판단",
    "references": [
      {
        "title": "Stream Performance",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/stream/package-summary.html"
      }
    ],
    "keywords": [
      "for-loop",
      "stream",
      "jit",
      "일반적",
      "성능",
      "비교",
      "구분",
      "단순",
      "반복",
      "빠름",
      "약간",
      "느림",
      "복잡한",
      "파이프라인",
      "유사"
    ]
  },
  {
    "id": "JAVA-067",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Stream은 병렬처리 할 수 있나요?",
    "answer": "예, parallelStream으로 병렬 처리 가능합니다.\n\n동작 원리:\nForkJoinPool.commonPool() 사용\n데이터를 분할(split)하여 병렬 처리\n결과를 결합(combine)\n\n효과적인 경우:\n대용량 데이터\n요소당 처리 비용이 높은 연산\n독립적인 연산 (상태 없음)\n분할하기 좋은 소스 (배열, ArrayList)\n\n비효율적인 경우:\n작은 데이터셋 (오버헤드 > 이득)\n순서 의존적 연산\n공유 상태 접근\nLinkedList (분할 비용 높음)\nI/O 작업 (블로킹)\n\n주의사항:",
    "references": [
      {
        "title": "Parallelism",
        "url": "https://docs.oracle.com/javase/tutorial/collections/streams/parallelism.html"
      }
    ],
    "keywords": [
      "forkjoinpool",
      "arraylist",
      "linkedlist",
      "으로",
      "병렬",
      "처리",
      "가능합니다",
      "동작",
      "원리",
      "사용",
      "데이터를",
      "분할",
      "하여",
      "결과를",
      "결합"
    ]
  },
  {
    "id": "JAVA-068",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Stream에서 사용할 수 있는 함수형 인터페이스에 대해 설명해 주세요.",
    "answer": "주요 함수형 인터페이스:\n\n인터페이스   메서드   용도   Stream 메서드\n\nPredicate<T>   boolean test(T)   조건 검사   filter\nFunction<T,R>   R apply(T)   변환   map\nConsumer<T>   void accept(T)   소비   forEach\nSupplier<T>   T get()   생성   generate\nBiFunction<T,U,R>   R apply(T,U)   이항 변환   reduce\nBinaryOperator<T>   T apply(T,T)   같은 타입 결합   reduce\nUnaryOperator<T>   T apply(T)   같은 타입 변환   iterate\n\n사용 예:\n\n기본형 특화 (박싱 회피):\nIntPredicate, LongFunction, DoubleConsumer\nToIntFunction, ToDoubleFunction",
    "references": [
      {
        "title": "java.util.function",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/function/package-summary.html"
      }
    ],
    "keywords": [
      "stream",
      "predicate",
      "function",
      "consumer",
      "supplier",
      "bifunction",
      "binaryoperator",
      "unaryoperator",
      "intpredicate",
      "longfunction",
      "doubleconsumer",
      "tointfunction",
      "todoublefunction",
      "주요",
      "함수형"
    ]
  },
  {
    "id": "JAVA-069",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "가끔 외부 변수를 사용할 때, final 키워드를 붙여서 사용하는데 왜 그럴까요? 꼭 그래야 할까요?",
    "answer": "이유: Effectively Final 규칙\n\n람다나 익명 클래스에서 외부 지역 변수를 캡처할 때, 해당 변수는 final이거나 effectively final이어야 합니다.\n\neffectively final:\nfinal 키워드는 없지만 값이 변경되지 않는 변수\nJava 8부터 명시적 final 불필요\n\n왜 이런 제약이 있을까?\n값 캡처: 람다는 변수의 복사본을 캡처\n동시성 안전: 람다가 다른 스레드에서 실행될 수 있음\n혼란 방지: 외부 변수 변경 시 어느 값이 캡처되었는지 불명확\n\n우회 방법:\n\n결론:\n명시적 final은 선택 (가독성 위해 권장)\n변수 값을 변경하면 컴파일 에러",
    "references": [
      {
        "title": "Lambda Expressions",
        "url": "https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html"
      }
    ],
    "keywords": [
      "effectively",
      "final",
      "java",
      "이유",
      "규칙",
      "람다나",
      "익명",
      "클래스에서",
      "외부",
      "지역",
      "변수를",
      "캡처할",
      "해당",
      "변수는",
      "이거나"
    ]
  },
  {
    "id": "JAVA-070",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Java의 GC에 대해 설명해 주세요.",
    "answer": "개념:\nGarbage Collection - 사용하지 않는 객체의 메모리를 자동으로 해제하는 JVM 기능\n\n동작 원리 (Mark & Sweep):\nMark: GC Root에서 참조 가능한 객체를 마킹\nSweep: 마킹되지 않은 객체를 제거\nCompact: 메모리 단편화 방지를 위해 압축 (선택적)\n\nGC Root:\nStack의 지역 변수\nStatic 변수\nJNI 참조\n실행 중인 스레드\n\n세대별 GC (Generational GC):\nYoung Generation: 새 객체, Minor GC (빈번, 빠름)\nEden: 객체 최초 생성\nSurvivor (S0, S1): Eden에서 살아남은 객체\nOld Generation: 오래 살아남은 객체, Major GC (드묾, 느림)\n\nGC 종류:\nGC   특징\n\nSerial   단일 스레드, 소규모\nParallel   멀티 스레드, 처리량 최적화\nG1   Region 기반, Java 9+ 기본\nZGC   초저지연 (< 10ms)",
    "references": [
      {
        "title": "Garbage Collection",
        "url": "https://docs.oracle.com/en/java/javase/17/gctuning/introduction-garbage-collection-tuning.html"
      }
    ],
    "keywords": [
      "garbage",
      "collection",
      "jvm",
      "mark",
      "sweep",
      "root",
      "compact",
      "stack",
      "static",
      "jni",
      "generational",
      "young",
      "generation",
      "minor",
      "eden"
    ]
  },
  {
    "id": "JAVA-071",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "finalize() 를 수동으로 호출하는 것은 왜 문제가 될 수 있을까요?",
    "answer": "finalize()란:\nObject 클래스의 메서드\nGC가 객체 수거 전 호출 (Java 9부터 deprecated)\n\n문제점:\n실행 보장 없음\nGC가 언제 실행될지 모름\nfinalize()가 호출 안 될 수도 있음\n성능 저하\nfinalize()가 있는 객체는 별도 큐에서 관리\n최소 2번의 GC 사이클 필요\n객체 수명 연장\n예외 무시\nfinalize()에서 발생한 예외는 무시됨\n디버깅 어려움\n부활 가능 (Resurrection)\n순서 보장 없음\n어떤 순서로 호출될지 불명확\n스레드 안전성 문제\nFinalizer 스레드에서 실행\n\n대안:",
    "references": [
      {
        "title": "Effective Java - Avoid finalizers",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#finalize("
      }
    ],
    "keywords": [
      "object",
      "java",
      "resurrection",
      "finalizer",
      "클래스의",
      "메서드",
      "객체",
      "수거",
      "호출",
      "부터",
      "문제점",
      "실행",
      "보장",
      "없음",
      "언제"
    ]
  },
  {
    "id": "JAVA-072",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "어떤 변수의 값이 null이 되었다면, 이 값은 GC가 될 가능성이 있을까요?",
    "answer": "가능성은 있지만, 보장되지 않습니다.\n\nGC 대상이 되려면:\n객체가 어떤 GC Root에서도 도달 불가능(unreachable)해야 함\n\nnull 할당만으로는 불충분한 경우:\n다른 참조가 존재\n컬렉션에 포함\n클로저에 캡처\n\nGC 대상이 되는 경우:\n\n주의:\nGC 시점은 JVM이 결정\nSystem.gc()는 힌트일 뿐, 강제 아님\nnull 할당보다 스코프를 좁히는 것이 좋은 습관",
    "references": [
      {
        "title": "Memory Management",
        "url": "https://docs.oracle.com/javase/specs/jls/se17/html/jls-12.html#jls-12.6"
      }
    ],
    "keywords": [
      "root",
      "jvm",
      "system",
      "가능성은",
      "있지만",
      "보장되지",
      "않습니다",
      "대상이",
      "되려면",
      "객체가",
      "어떤",
      "에서도",
      "도달",
      "불가능",
      "해야"
    ]
  },
  {
    "id": "JAVA-073",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "equals()와 hashcode()에 대해 설명해 주세요.",
    "answer": "equals():\n두 객체의 논리적 동등성을 비교\n\nhashCode():\n객체를 해시 기반 컬렉션에서 사용하기 위한 정수값 반환\n\n계약 (Contract):\nequals()가 true면 hashCode()도 같아야 함 (필수!)\nhashCode()가 같아도 equals()는 다를 수 있음\nequals()가 false여도 hashCode()는 같을 수 있음 (충돌)\n\n위반 시 문제:\n\n해시 기반 컬렉션 동작:\nhashCode()로 버킷 찾기\n버킷 내에서 equals()로 비교",
    "references": [
      {
        "title": "Object.equals()",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#equals(java.lang.Object"
      }
    ],
    "keywords": [
      "contract",
      "객체의",
      "논리적",
      "동등성을",
      "비교",
      "객체를",
      "해시",
      "기반",
      "컬렉션에서",
      "사용하기",
      "위한",
      "정수값",
      "반환",
      "계약",
      "같아야"
    ]
  },
  {
    "id": "JAVA-074",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "본인이 hashcode() 를 정의해야 한다면, 어떤 점을 염두에 두고 구현할 것 같으세요?",
    "answer": "구현 원칙:\nequals()와 일관성\nequals()에 사용된 필드만 hashCode()에 사용\nequals()가 true면 hashCode()도 같아야 함\n좋은 분산\n해시 충돌 최소화\n다른 객체는 다른 해시값을 가지도록\n불변 필드 사용\n가변 필드 사용 시 컬렉션에서 문제\n\n구현 방법:\n\n권장: Objects.hash() 사용\n\n수동 구현 (성능 중시):\n\n왜 31인가?\n소수: 분산 좋음\n31  i == (i << 5) - i: JVM 최적화\n\n주의:\nnull 필드 처리 (0 또는 무시)\n배열: Arrays.hashCode() 사용\n캐싱 고려 (불변 객체에서)",
    "references": [
      {
        "title": "Objects.hash()",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Objects.html#hash(java.lang.Object..."
      }
    ],
    "keywords": [
      "objects",
      "jvm",
      "arrays",
      "구현",
      "원칙",
      "일관성",
      "사용된",
      "필드만",
      "사용",
      "같아야",
      "좋은",
      "분산",
      "해시",
      "충돌",
      "최소화"
    ]
  },
  {
    "id": "JAVA-075",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "그렇다면 equals() 를 재정의 해야 할 때, 어떤 점을 염두에 두어야 하는지 설명해 주세요.",
    "answer": "equals() 규약 (5가지):\n반사성 (Reflexive)\n대칭성 (Symmetric)\n추이성 (Transitive)\n일관성 (Consistent)\n객체 변경 없으면 항상 같은 결과\nnull 비교\n\n구현 패턴:\n\n주의사항:\ngetClass() vs instanceof: 상속 시 행동 다름\n부동소수점: Float.compare(), Double.compare() 사용\nhashCode()도 함께 재정의\n상속 시 대칭성 주의\n\nLombok/IDE 활용:",
    "references": [
      {
        "title": "Effective Java - equals",
        "url": "https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#equals(java.lang.Object"
      }
    ],
    "keywords": [
      "reflexive",
      "symmetric",
      "transitive",
      "consistent",
      "float",
      "double",
      "lombok",
      "ide",
      "규약",
      "가지",
      "반사성",
      "대칭성",
      "추이성",
      "일관성",
      "객체"
    ]
  },
  {
    "id": "JS-001",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "JavaScript의 데이터 타입에 대해 설명해주세요.",
    "answer": "원시 타입 (Primitive, 7가지):\n\n타입   설명   예시\n\nnumber   정수/실수 (64비트 부동소수점)   42, 3.14, NaN, Infinity\nstring   문자열   'hello', \"world\", \\template\\\nboolean   논리값   true, false\nnull   의도적 빈 값   null\nundefined   미정의 값   undefined\nsymbol   고유 식별자 (ES6)   Symbol('id')\nbigint   큰 정수 (ES2020)   9007199254740991n\n\n참조 타입 (Reference):\nObject, Array, Function, Date, RegExp, Map, Set 등\n\n타입 확인:\n\n원시 vs 참조:\n원시: 값 복사, 불변\n참조: 주소 복사, 가변",
    "references": [
      {
        "title": "Data Types",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures"
      }
    ],
    "keywords": [
      "primitive",
      "nan",
      "infinity",
      "es6",
      "symbol",
      "es2020",
      "reference",
      "object",
      "array",
      "function",
      "date",
      "regexp",
      "map",
      "set",
      "원시"
    ]
  },
  {
    "id": "JS-002",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "var, let, const의 차이점과 호이스팅에 대해 설명해주세요.",
    "answer": "구분   var   let   const\n\n스코프   함수 스코프   블록 스코프   블록 스코프\n재선언   가능   불가   불가\n재할당   가능   가능   불가\n호이스팅   O (undefined)   O (TDZ)   O (TDZ)\n\n호이스팅 (Hoisting):\n선언이 스코프 최상단으로 끌어올려지는 것처럼 동작\n\nTDZ (Temporal Dead Zone):\n스코프 시작 ~ 변수 선언까지의 구간\n이 구간에서 접근 시 ReferenceError\n\n권장사항:\nconst 기본 사용\n재할당 필요시 let\nvar 사용 지양",
    "references": [
      {
        "title": "let",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/let"
      }
    ],
    "keywords": [
      "tdz",
      "hoisting",
      "temporal",
      "dead",
      "zone",
      "referenceerror",
      "구분",
      "스코프",
      "함수",
      "블록",
      "재선언",
      "가능",
      "불가",
      "재할당",
      "호이스팅"
    ]
  },
  {
    "id": "JS-003",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "실행 컨텍스트와 스코프 체인에 대해 설명해주세요.",
    "answer": "실행 컨텍스트 (Execution Context):\n코드 실행에 필요한 환경 정보를 담은 객체\n\n구성 요소:\nVariable Environment: 변수/함수 선언, 호이스팅\nLexical Environment: 현재 환경 + 외부 환경 참조\nThis Binding: this 값\n\n종류:\nGlobal Execution Context (전역)\nFunction Execution Context (함수 호출마다)\nEval Execution Context\n\n콜 스택:\n\n---\n\n스코프 체인 (Scope Chain):\n변수를 찾기 위해 현재 스코프 → 상위 스코프 → 전역까지 탐색\n\n렉시컬 스코프:\n함수 정의 시점의 스코프가 기준\n호출 위치가 아닌 선언 위치 기준",
    "references": [
      {
        "title": "Closures",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Closures"
      }
    ],
    "keywords": [
      "execution",
      "context",
      "variable",
      "environment",
      "lexical",
      "this",
      "binding",
      "global",
      "function",
      "eval",
      "scope",
      "chain",
      "실행",
      "컨텍스트",
      "코드"
    ]
  },
  {
    "id": "JS-004",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "클로저(Closure)란 무엇이고 어떻게 활용할 수 있나요?",
    "answer": "클로저:\n함수가 자신이 선언된 렉시컬 환경을 기억하여, 외부 함수 실행이 끝나도 외부 변수에 접근 가능한 것\n\n활용 사례:\n데이터 은닉 (캡슐화)\n함수 팩토리\n이벤트 핸들러\n커링\n\n주의:\n메모리 누수 가능 (불필요한 참조 유지)\n루프에서 var 사용 시 문제 (let 또는 IIFE 사용)",
    "references": [
      {
        "title": "Closures",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Closures"
      }
    ],
    "keywords": [
      "iife",
      "클로저",
      "함수가",
      "자신이",
      "선언된",
      "렉시컬",
      "환경을",
      "기억하여",
      "외부",
      "함수",
      "실행이",
      "끝나도",
      "변수에",
      "접근",
      "가능한"
    ]
  },
  {
    "id": "JS-005",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "this 바인딩의 종류와 동작 원리를 설명해주세요.",
    "answer": "this는 함수 호출 방식에 따라 결정됩니다.\n기본 바인딩 (단독 호출)\n암시적 바인딩 (메서드 호출)\n명시적 바인딩 (call, apply, bind)\nnew 바인딩\n화살표 함수 (렉시컬 this)\n\n우선순위:\nnew > 명시적(bind) > 암시적 > 기본\n\n주의: this 소실",
    "references": [
      {
        "title": "this",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/this"
      }
    ],
    "keywords": [
      "함수",
      "호출",
      "방식에",
      "따라",
      "결정됩니다",
      "기본",
      "바인딩",
      "단독",
      "암시적",
      "메서드",
      "명시적",
      "화살표",
      "렉시컬",
      "우선순위",
      "주의"
    ]
  },
  {
    "id": "JS-006",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "화살표 함수와 일반 함수의 차이점은 무엇인가요?",
    "answer": "구분   일반 함수   화살표 함수\n\nthis   호출 방식에 따라 결정   렉시컬 (선언 시점)\narguments   있음   없음\nnew 가능   가능   불가\nprototype   있음   없음\n생성자   가능   불가\n\nthis 차이:\n\narguments 없음:\n\n생성자 불가:\n\n화살표 함수 적합한 경우:\n콜백 함수 (map, filter 등)\nthis를 바인딩하지 않아야 할 때\n\n일반 함수 적합한 경우:\n메서드 정의\n생성자 함수\narguments 필요 시",
    "references": [
      {
        "title": "Arrow Functions",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Arrow_functions"
      }
    ],
    "keywords": [
      "구분",
      "일반",
      "함수",
      "화살표",
      "호출",
      "방식에",
      "따라",
      "결정",
      "렉시컬",
      "선언",
      "시점",
      "있음",
      "없음",
      "가능",
      "불가"
    ]
  },
  {
    "id": "JS-007",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "프로토타입 체인과 상속에 대해 설명해주세요.",
    "answer": "프로토타입:\n모든 객체는 [[Prototype]] 내부 슬롯을 가지며, 다른 객체를 참조\n\n프로토타입 체인:\n객체의 프로퍼티 접근 시 해당 객체 → [[Prototype]] → ... → null 까지 탐색\n\n프로토타입 접근:\n\n프로토타입 상속:\n\nES6 Class로 동일 구현:",
    "references": [
      {
        "title": "Inheritance",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Inheritance_and_the_prototype_chain"
      }
    ],
    "keywords": [
      "prototype",
      "es6",
      "class",
      "프로토타입",
      "모든",
      "객체는",
      "내부",
      "슬롯을",
      "가지며",
      "다른",
      "객체를",
      "참조",
      "체인",
      "객체의",
      "프로퍼티"
    ]
  },
  {
    "id": "JS-008",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "ES6 Class 문법과 프로토타입 기반 상속의 차이점은 무엇인가요?",
    "answer": "핵심: Class는 프로토타입의 문법적 설탕(Syntactic Sugar)\n\n내부적으로 동일:\n\n차이점:\n\n구분   프로토타입   Class\n\n호이스팅   함수 호이스팅   TDZ 존재\nnew 없이 호출   가능 (this = window)   TypeError\nstrict mode   선택   항상 적용\n메서드 열거   enumerable: true   enumerable: false\n상속 문법   복잡   extends 간단\n\nClass 추가 기능:\n\n상속 비교:",
    "references": [
      {
        "title": "Classes",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes"
      }
    ],
    "keywords": [
      "class",
      "syntactic",
      "sugar",
      "tdz",
      "typeerror",
      "핵심",
      "프로토타입의",
      "문법적",
      "설탕",
      "내부적으로",
      "동일",
      "차이점",
      "구분",
      "프로토타입",
      "호이스팅"
    ]
  },
  {
    "id": "JS-009",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Promise의 동작 원리와 상태에 대해 설명해주세요.",
    "answer": "Promise:\n비동기 작업의 완료/실패를 나타내는 객체\n\n3가지 상태:\nPending: 초기 상태, 대기 중\nFulfilled: 성공 완료\nRejected: 실패\n\n한 번 결정되면 변경 불가 (settled)\n\n생성과 사용:\n\n체이닝:\n\n정적 메서드:",
    "references": [
      {
        "title": "Promise",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise"
      }
    ],
    "keywords": [
      "promise",
      "pending",
      "fulfilled",
      "rejected",
      "비동기",
      "작업의",
      "완료",
      "실패를",
      "나타내는",
      "객체",
      "가지",
      "상태",
      "초기",
      "대기",
      "성공"
    ]
  },
  {
    "id": "JS-010",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "async/await와 Promise의 차이점은 무엇인가요?",
    "answer": "async/await:\nPromise를 더 직관적으로 사용하기 위한 문법 (ES2017)\n\n비교:\n\n차이점:\n\n구분   Promise   async/await\n\n문법   체이닝 (.then)   동기식 스타일\n에러 처리   .catch()   try/catch\n디버깅   스택 추적 어려움   명확한 스택\n조건부 로직   복잡   직관적\n\nasync 함수 특징:\n항상 Promise 반환\nawait는 async 함수 내에서만 사용 (Top-level await 제외)\n\n병렬 실행:\n\n주의:\nforEach에서 await 사용 시 의도대로 동작 안 함\nfor...of 또는 map + Promise.all 사용",
    "references": [
      {
        "title": "async/await",
        "url": "https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Promises"
      }
    ],
    "keywords": [
      "promise",
      "es2017",
      "top-level",
      "직관적으로",
      "사용하기",
      "위한",
      "문법",
      "비교",
      "차이점",
      "구분",
      "체이닝",
      "동기식",
      "스타일",
      "에러",
      "처리"
    ]
  },
  {
    "id": "JS-011",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "이벤트 루프(Event Loop)의 동작 원리를 설명해주세요.",
    "answer": "이벤트 루프:\nJavaScript의 단일 스레드에서 비동기 처리를 가능하게 하는 메커니즘\n\n구성 요소:\n\n동작 순서:\nCall Stack의 모든 동기 코드 실행\nStack이 비면 Microtask Queue 전부 처리\nMacrotask Queue에서 하나 실행\n다시 Microtask Queue 확인\n반복\n\n예시:\n\nMicrotask가 우선:\nPromise.then/catch/finally\nqueueMicrotask()\nMutationObserver\n\nMacrotask:\nsetTimeout, setInterval\nI/O, UI 렌더링",
    "references": [
      {
        "title": "Event Loop",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/EventLoop"
      }
    ],
    "keywords": [
      "javascript",
      "call",
      "stack",
      "microtask",
      "queue",
      "macrotask",
      "promise",
      "mutationobserver",
      "이벤트",
      "루프",
      "단일",
      "스레드에서",
      "비동기",
      "처리를",
      "가능하게"
    ]
  },
  {
    "id": "JS-012",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "마이크로태스크와 매크로태스크의 차이점은 무엇인가요?",
    "answer": "구분   Microtask   Macrotask\n\n우선순위   높음   낮음\n실행 시점   Stack 비우고 즉시   Microtask 후\n처리 방식   큐 전체 비움   하나씩\n\nMicrotask 예:\nPromise.then/catch/finally\nqueueMicrotask()\nMutationObserver\nprocess.nextTick() (Node.js)\n\nMacrotask (Task) 예:\nsetTimeout / setInterval\nsetImmediate (Node.js)\nI/O 작업\nUI 렌더링\nrequestAnimationFrame\n\n실행 순서:\n\n핵심 차이:\nMicrotask: 현재 작업 직후, 모든 Microtask 처리\nMacrotask: Microtask 전부 처리 후 하나씩\n\n주의:\nMicrotask 무한 루프 시 UI 블로킹\n무거운 작업은 Macrotask로 분할",
    "references": [
      {
        "title": "Microtasks",
        "url": "https://developer.mozilla.org/en-US/docs/Web/API/HTML_DOM_API/Microtask_guide"
      }
    ],
    "keywords": [
      "microtask",
      "macrotask",
      "stack",
      "promise",
      "mutationobserver",
      "node",
      "task",
      "구분",
      "우선순위",
      "높음",
      "낮음",
      "실행",
      "시점",
      "비우고",
      "즉시"
    ]
  },
  {
    "id": "JS-013",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "디바운싱(Debouncing)과 스로틀링(Throttling)의 차이와 구현 방법은 무엇인가요?",
    "answer": "디바운싱 (Debouncing):\n연속된 이벤트 중 마지막 이벤트만 처리 (일정 시간 후)\n\n스로틀링 (Throttling):\n일정 시간 간격으로 최대 한 번만 실행\n\n비교:\n구분   Debounce   Throttle\n\n실행 시점   마지막 이벤트 후   일정 간격마다\n사용 예   검색 자동완성, resize 후   스크롤, 마우스 이동\n특징   지연 실행   주기적 실행\n\n사용 시나리오:\nDebounce: 입력 완료 후 처리 (검색, 폼 검증)\nThrottle: 지속적 이벤트 제한 (스크롤, 드래그)",
    "references": [
      {
        "title": "Debounce and Throttle",
        "url": "https://developer.mozilla.org/en-US/docs/Glossary/Debounce"
      }
    ],
    "keywords": [
      "debouncing",
      "throttling",
      "debounce",
      "throttle",
      "디바운싱",
      "연속된",
      "이벤트",
      "마지막",
      "이벤트만",
      "처리",
      "일정",
      "시간",
      "스로틀링",
      "간격으로",
      "최대"
    ]
  },
  {
    "id": "JS-014",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "얕은 복사와 깊은 복사의 차이점과 구현 방법은 무엇인가요?",
    "answer": "얕은 복사 (Shallow Copy):\n1단계 프로퍼티만 복사, 중첩 객체는 참조 공유\n\n깊은 복사 (Deep Copy):\n모든 레벨의 프로퍼티를 재귀적으로 복사\n\n비교:\n구분   얕은 복사   깊은 복사\n\n중첩 객체   참조 공유   새로 생성\n성능   빠름   느림\n사용   단순 객체   복잡한 객체",
    "references": [
      {
        "title": "structuredClone",
        "url": "https://developer.mozilla.org/en-US/docs/Web/API/structuredClone"
      }
    ],
    "keywords": [
      "shallow",
      "copy",
      "deep",
      "얕은",
      "복사",
      "단계",
      "프로퍼티만",
      "중첩",
      "객체는",
      "참조",
      "공유",
      "깊은",
      "모든",
      "레벨의",
      "프로퍼티를"
    ]
  },
  {
    "id": "JS-015",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "구조 분해 할당(Destructuring)에 대해 설명해주세요.",
    "answer": "구조 분해 할당:\n배열이나 객체의 값을 개별 변수로 추출\n\n객체 구조 분해:\n\n배열 구조 분해:\n\n함수 파라미터:\n\n활용:\nAPI 응답 처리\n설정 객체 추출\n다중 반환값 처리",
    "references": [
      {
        "title": "Destructuring",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment"
      }
    ],
    "keywords": [
      "api",
      "구조",
      "분해",
      "할당",
      "배열이나",
      "객체의",
      "값을",
      "개별",
      "변수로",
      "추출",
      "객체",
      "배열",
      "함수",
      "파라미터",
      "활용"
    ]
  },
  {
    "id": "JS-016",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "스프레드 연산자와 레스트 파라미터의 차이점은 무엇인가요?",
    "answer": "둘 다 ... 문법을 사용하지만 반대 방향으로 동작합니다.\n\n스프레드 (Spread): 펼치기\n\n레스트 (Rest): 모으기\n\n비교:\n구분   Spread   Rest\n\n방향   펼침 (확장)   모음 (수집)\n위치   배열/객체/호출 시   함수 선언/구조분해 시\n용도   복사, 병합, 전달   가변 인자 수집\n\n주의:\nRest는 항상 마지막에 위치해야 함\nfunction fn(...a, b) {} // SyntaxError",
    "references": [
      {
        "title": "Spread",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_syntax"
      }
    ],
    "keywords": [
      "spread",
      "rest",
      "syntaxerror",
      "문법을",
      "사용하지만",
      "반대",
      "방향으로",
      "동작합니다",
      "스프레드",
      "펼치기",
      "레스트",
      "모으기",
      "비교",
      "구분",
      "방향"
    ]
  },
  {
    "id": "JS-017",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Map과 Object의 차이점은 무엇인가요?",
    "answer": "구분   Object   Map\n\n키 타입   문자열/Symbol만   모든 타입\n순서 보장   ES2015부터 부분적   삽입 순서 보장\n크기 확인   Object.keys().length   map.size\n반복   for...in, Object.keys   for...of, forEach\n성능   삽입/삭제 느림   빈번한 추가/삭제에 최적화\n프로토타입   있음 (주의 필요)   없음\n\nMap 사용:\n\nObject vs Map 선택:\n\nObject 권장:\nJSON 직렬화 필요\n메서드/로직 포함\n간단한 레코드 구조\n\nMap 권장:\n키가 문자열이 아닌 경우\n빈번한 추가/삭제\n키-값 쌍 순회 필요\n크기를 자주 확인",
    "references": [
      {
        "title": "Map",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map"
      }
    ],
    "keywords": [
      "object",
      "map",
      "symbol",
      "es2015",
      "json",
      "구분",
      "타입",
      "문자열",
      "모든",
      "순서",
      "보장",
      "부터",
      "부분적",
      "삽입",
      "크기"
    ]
  },
  {
    "id": "JS-018",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Set과 WeakSet, Map과 WeakMap의 차이점을 설명해주세요.",
    "answer": "Weak- 버전의 핵심: 약한 참조 (Weak Reference)\nGC가 다른 참조 없으면 수거 가능\n메모리 누수 방지\n\n구분   Set/Map   WeakSet/WeakMap\n\n키/값 타입   모든 타입   객체만\n참조   강한 참조   약한 참조\n반복   가능   불가 (iterable X)\nsize   있음   없음\nGC   참조 유지   자동 제거 가능\n\nWeakMap 예:\n\nWeakSet 예:\n\n사용 사례:\n\nWeakMap:\n객체에 private 데이터 연결\nDOM 노드에 메타데이터 저장\n캐싱 (메모리 자동 정리)\n\nWeakSet:\n객체 방문 여부 추적\n순환 참조 감지",
    "references": [
      {
        "title": "WeakMap",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WeakMap"
      }
    ],
    "keywords": [
      "weak",
      "reference",
      "set",
      "map",
      "weakset",
      "weakmap",
      "dom",
      "버전의",
      "핵심",
      "약한",
      "참조",
      "다른",
      "없으면",
      "수거",
      "가능"
    ]
  },
  {
    "id": "JS-019",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Symbol의 용도와 사용 방법을 설명해주세요.",
    "answer": "Symbol:\n고유하고 변경 불가능한 원시 타입 (ES6)\n\n주요 용도:\n객체의 고유 프로퍼티 키\n이름 충돌 방지\nWell-Known Symbols (내장 심볼)\n\nSymbol.for() - 전역 심볼:\n\nWell-Known Symbols:\nSymbol.iterator, Symbol.asyncIterator\nSymbol.toStringTag, Symbol.toPrimitive\nSymbol.hasInstance, Symbol.species",
    "references": [
      {
        "title": "Symbol",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Symbol"
      }
    ],
    "keywords": [
      "symbol",
      "es6",
      "well-known",
      "symbols",
      "고유하고",
      "변경",
      "불가능한",
      "원시",
      "타입",
      "주요",
      "용도",
      "객체의",
      "고유",
      "프로퍼티",
      "이름"
    ]
  },
  {
    "id": "JS-020",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Proxy와 Reflect API에 대해 설명해주세요.",
    "answer": "Proxy:\n객체 기본 동작(읽기, 쓰기, 열거 등)을 가로채서 커스터마이징\n\n주요 트랩 (Handler 메서드):\nget, set, has (in 연산자)\ndeleteProperty, apply (함수 호출)\nconstruct (new), ownKeys\n\nReflect:\n객체 조작을 위한 메서드 모음 (Proxy 트랩과 1:1 대응)\n\n활용 사례:\n유효성 검사\n반응형 시스템 (Vue 3)",
    "references": [
      {
        "title": "Proxy",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy"
      }
    ],
    "keywords": [
      "proxy",
      "handler",
      "reflect",
      "vue",
      "객체",
      "기본",
      "동작",
      "읽기",
      "쓰기",
      "열거",
      "가로채서",
      "커스터마이징",
      "주요",
      "트랩",
      "메서드"
    ]
  },
  {
    "id": "JS-021",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Generator 함수와 Iterator의 동작 원리를 설명해주세요.",
    "answer": "Iterator:\n순차적 접근을 위한 프로토콜\n\nIterable 프로토콜:\n\n---\n\nGenerator:\n일시 중지/재개 가능한 함수 (Iterator 자동 생성)\n\nyield 양방향 통신:\n\n활용:\n지연 평가 (무한 시퀀스)\nasync/await 이전의 비동기 처리 (co 라이브러리)\n상태 머신",
    "references": [
      {
        "title": "Generator",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator"
      }
    ],
    "keywords": [
      "iterator",
      "iterable",
      "generator",
      "순차적",
      "접근을",
      "위한",
      "프로토콜",
      "일시",
      "중지",
      "재개",
      "가능한",
      "함수",
      "자동",
      "생성",
      "양방향"
    ]
  },
  {
    "id": "JS-022",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "모듈 시스템(CommonJS, ES6 Module)의 차이점은 무엇인가요?",
    "answer": "구분   CommonJS   ES Module\n\n문법   require/module.exports   import/export\n로딩   동기 (런타임)   비동기 (컴파일 타임)\n환경   Node.js 기본   브라우저, Node.js\n트리쉐이킹   어려움   가능\n바인딩   값 복사   라이브 바인딩\n\nCommonJS:\n\nES Module:\n\n라이브 바인딩 차이:\n\nNode.js에서 ESM:\npackage.json에 \"type\": \"module\"\n또는 .mjs 확장자",
    "references": [
      {
        "title": "Modules",
        "url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules"
      }
    ],
    "keywords": [
      "commonjs",
      "module",
      "node",
      "esm",
      "구분",
      "문법",
      "로딩",
      "동기",
      "런타임",
      "비동기",
      "컴파일",
      "타임",
      "환경",
      "기본",
      "브라우저"
    ]
  },
  {
    "id": "JS-023",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "TypeScript의 타입 시스템에 대해 설명해주세요.",
    "answer": "TypeScript:\nJavaScript에 정적 타입을 추가한 상위 집합 (Superset)\n\n기본 타입:\n\n특수 타입:\n\n타입 정의:\n\n구조적 타이핑 (Structural Typing):\n\n장점:\n컴파일 타임 오류 발견\nIDE 자동완성/리팩토링\n문서화 효과",
    "references": [
      {
        "title": "TypeScript Handbook",
        "url": "https://www.typescriptlang.org/docs/handbook/intro.html"
      }
    ],
    "keywords": [
      "typescript",
      "javascript",
      "superset",
      "structural",
      "typing",
      "ide",
      "정적",
      "타입을",
      "추가한",
      "상위",
      "집합",
      "기본",
      "타입",
      "특수",
      "정의"
    ]
  },
  {
    "id": "JS-024",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "TypeScript의 제네릭(Generic) 사용 방법과 제약사항은 무엇인가요?",
    "answer": "제네릭:\n타입을 파라미터화하여 재사용 가능한 컴포넌트 작성\n\n기본 사용:\n\n제약조건 (Constraints):\n\n다중 타입 파라미터:\n\n기본값:\n\n제약사항:\n런타임에 타입 정보 없음 (타입 소거)\nnew T() 직접 불가",
    "references": [
      {
        "title": "Generics",
        "url": "https://www.typescriptlang.org/docs/handbook/2/generics.html"
      }
    ],
    "keywords": [
      "constraints",
      "제네릭",
      "타입을",
      "파라미터화하여",
      "재사용",
      "가능한",
      "컴포넌트",
      "작성",
      "기본",
      "사용",
      "제약조건",
      "다중",
      "타입",
      "파라미터",
      "기본값"
    ]
  },
  {
    "id": "JS-025",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "TypeScript의 Union Type과 Intersection Type의 차이점은 무엇인가요?",
    "answer": "Union Type (|): 또는\n여러 타입 중 하나\n\nIntersection Type (&): 그리고\n여러 타입을 모두 만족\n\n비교:\n\n실무 활용:",
    "references": [
      {
        "title": "Union and Intersection Types",
        "url": "https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#union-types"
      }
    ],
    "keywords": [
      "union",
      "type",
      "intersection",
      "여러",
      "타입",
      "하나",
      "타입을",
      "모두",
      "만족",
      "비교",
      "실무",
      "활용"
    ]
  },
  {
    "id": "JS-026",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "TypeScript의 타입 가드(Type Guard) 종류와 사용 방법을 설명해주세요.",
    "answer": "타입 가드:\n런타임에 타입을 좁히는(narrowing) 표현식\ntypeof 가드\ninstanceof 가드\nin 연산자\n사용자 정의 타입 가드\nDiscriminated Union",
    "references": [
      {
        "title": "Narrowing",
        "url": "https://www.typescriptlang.org/docs/handbook/2/narrowing.html"
      }
    ],
    "keywords": [
      "discriminated",
      "union",
      "타입",
      "가드",
      "런타임에",
      "타입을",
      "좁히는",
      "표현식",
      "연산자",
      "사용자",
      "정의",
      "narrowing"
    ]
  },
  {
    "id": "JS-027",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "TypeScript의 유틸리티 타입(Partial, Pick, Omit 등)에 대해 설명해주세요.",
    "answer": "유틸리티 타입:\n기존 타입을 변환하여 새 타입 생성\n\nPartial<T>: 모든 속성 선택적\n\nRequired<T>: 모든 속성 필수\n\nPick<T, K>: 특정 속성만 선택\n\nOmit<T, K>: 특정 속성 제외\n\nRecord<K, T>: 키-값 타입 생성\n\nReadonly<T>: 모든 속성 읽기 전용\n\n기타:",
    "references": [
      {
        "title": "Utility Types",
        "url": "https://www.typescriptlang.org/docs/handbook/utility-types.html"
      }
    ],
    "keywords": [
      "partial",
      "required",
      "pick",
      "omit",
      "record",
      "readonly",
      "유틸리티",
      "타입",
      "기존",
      "타입을",
      "변환하여",
      "생성",
      "모든",
      "속성",
      "선택적"
    ]
  },
  {
    "id": "JS-028",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "TypeScript의 never 타입은 언제 사용하나요?",
    "answer": "never:\n절대 발생하지 않는 값의 타입\n\n사용 사례:\n절대 반환하지 않는 함수\n완전성 검사 (Exhaustiveness Check)\n타입 좁히기 결과\n불가능한 타입 표현\n\nnever vs void:\nvoid: 값이 없음 (undefined 반환 가능)\nnever: 값이 절대 없음 (반환 자체가 없음)",
    "references": [
      {
        "title": "never Type",
        "url": "https://www.typescriptlang.org/docs/handbook/2/narrowing.html#the-never-type"
      }
    ],
    "keywords": [
      "exhaustiveness",
      "check",
      "절대",
      "발생하지",
      "않는",
      "값의",
      "타입",
      "사용",
      "사례",
      "반환하지",
      "함수",
      "완전성",
      "검사",
      "좁히기",
      "결과"
    ]
  },
  {
    "id": "JS-029",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "TypeScript의 컴파일 과정과 설정 옵션을 설명해주세요.",
    "answer": "컴파일 과정:\n파싱: 소스를 AST(Abstract Syntax Tree)로\n타입 검사: AST 기반 타입 분석\n변환: JavaScript + 타입 선언 파일 생성\n\ntsconfig.json 주요 옵션:\n\n주요 strict 옵션:\nstrictNullChecks: null/undefined 엄격 체크\nnoImplicitAny: 암시적 any 금지\nstrictFunctionTypes: 함수 타입 엄격 체크\n\n빌드 도구:\ntsc (기본)\nts-node (런타임 실행)\nesbuild, swc (빠른 변환)",
    "references": [
      {
        "title": "tsconfig Reference",
        "url": "https://www.typescriptlang.org/tsconfig"
      }
    ],
    "keywords": [
      "ast",
      "abstract",
      "syntax",
      "tree",
      "javascript",
      "ts-node",
      "컴파일",
      "과정",
      "파싱",
      "소스를",
      "타입",
      "검사",
      "기반",
      "분석",
      "변환"
    ]
  },
  {
    "id": "JS-030",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "TypeScript의 데코레이터(Decorator)에 대해 설명해주세요.",
    "answer": "데코레이터:\n클래스, 메서드, 프로퍼티 등을 수정하는 선언적 문법\n\n설정 필요:\n\n데코레이터 종류:\n클래스 데코레이터\n메서드 데코레이터\n프로퍼티 데코레이터\n파라미터 데코레이터\n\n실행 순서:\n파라미터 → 메서드 → 프로퍼티 → 클래스\n\n활용:\nNestJS: @Controller, @Get, @Injectable\nAngular: @Component, @Input",
    "references": [
      {
        "title": "Decorators",
        "url": "https://www.typescriptlang.org/docs/handbook/decorators.html"
      }
    ],
    "keywords": [
      "nestjs",
      "controller",
      "get",
      "injectable",
      "angular",
      "component",
      "input",
      "데코레이터",
      "클래스",
      "메서드",
      "프로퍼티",
      "등을",
      "수정하는",
      "선언적",
      "문법"
    ]
  },
  {
    "id": "PY-001",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 메모리 관리 방식을 설명해주세요.",
    "answer": "Python 메모리 관리자:\nPrivate heap에서 모든 객체와 데이터 구조 관리\n참조 카운팅 (Reference Counting)\n가비지 컬렉션 (순환 참조 처리)\n메모리 풀 (PyMalloc)\n작은 객체 (< 512 bytes): 전용 풀에서 할당\n큰 객체: OS malloc 사용\n블록 → 풀 → 아레나 계층 구조\n객체 캐싱\n\n메모리 최적화:\nslots: dict 대신 고정 속성\n제너레이터: 지연 평가로 메모리 절약",
    "references": [
      {
        "title": "Memory Management",
        "url": "https://docs.python.org/3/c-api/memory.html"
      }
    ],
    "keywords": [
      "python",
      "private",
      "reference",
      "counting",
      "pymalloc",
      "메모리",
      "관리자",
      "에서",
      "모든",
      "객체와",
      "데이터",
      "구조",
      "관리",
      "참조",
      "카운팅"
    ]
  },
  {
    "id": "PY-002",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 GIL(Global Interpreter Lock)이란 무엇인가요?",
    "answer": "GIL:\n한 번에 하나의 스레드만 Python 바이트코드를 실행하도록 하는 뮤텍스\n\n존재 이유:\nCPython의 메모리 관리 (참조 카운팅)가 스레드 안전하지 않음\n단순성과 C 확장 통합 용이\n\n영향:\n\nCPU 바운드 작업:\n\nI/O 바운드 작업:\n\n우회 방법:\nmultiprocessing: 별도 프로세스 (GIL 우회)\nC 확장: GIL 해제하고 실행 (NumPy 등)\nasyncio: 비동기 I/O\n다른 인터프리터**: Jython, PyPy (STM)",
    "references": [
      {
        "title": "GIL",
        "url": "https://docs.python.org/3/glossary.html#term-global-interpreter-lock"
      }
    ],
    "keywords": [
      "gil",
      "python",
      "cpython",
      "cpu",
      "numpy",
      "jython",
      "pypy",
      "stm",
      "번에",
      "하나의",
      "스레드만",
      "바이트코드를",
      "실행하도록",
      "하는",
      "뮤텍스"
    ]
  },
  {
    "id": "PY-003",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 데이터 타입과 가변/불변 객체를 설명해주세요.",
    "answer": "불변 객체 (Immutable):\n타입   예시\n\nint   42\nfloat   3.14\nstr   'hello'\ntuple   (1, 2, 3)\nfrozenset   frozenset([1, 2])\nbool   True\n\n가변 객체 (Mutable):\n타입   예시\n\nlist   [1, 2, 3]\ndict   {'a': 1}\nset   {1, 2, 3}\n사용자 정의 클래스   기본적으로 가변\n\n영향:\n함수 인자\n딕셔너리 키\n기본 인자 주의",
    "references": [
      {
        "title": "Data Model",
        "url": "https://docs.python.org/3/reference/datamodel.html"
      }
    ],
    "keywords": [
      "immutable",
      "true",
      "mutable",
      "불변",
      "객체",
      "타입",
      "예시",
      "가변",
      "사용자",
      "정의",
      "클래스",
      "기본적으로",
      "영향",
      "함수",
      "인자"
    ]
  },
  {
    "id": "PY-004",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 얕은 복사와 깊은 복사의 차이점은 무엇인가요?",
    "answer": "얕은 복사 (Shallow Copy):\n1단계만 복사, 중첩 객체는 참조 공유\n\n깊은 복사 (Deep Copy):\n모든 레벨 재귀적 복사\n\n비교:\n구분   얕은 복사   깊은 복사\n\n1단계   새 객체   새 객체\n중첩 객체   참조 공유   재귀 복사\n성능   빠름   느림\n순환 참조   문제 없음   처리함\n\n주의사항:",
    "references": [
      {
        "title": "copy module",
        "url": "https://docs.python.org/3/library/copy.html"
      }
    ],
    "keywords": [
      "shallow",
      "copy",
      "deep",
      "얕은",
      "복사",
      "단계만",
      "중첩",
      "객체는",
      "참조",
      "공유",
      "깊은",
      "모든",
      "레벨",
      "재귀적",
      "비교"
    ]
  },
  {
    "id": "PY-005",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 \\*args와 \\*\\*kwargs에 대해 설명해주세요.",
    "answer": "args: 가변 위치 인자를 튜플로 수집\n\n*kwargs: 가변 키워드 인자를 딕셔너리로 수집\n\n함께 사용:\n\n언패킹:*\n\n파라미터 순서:*",
    "references": [
      {
        "title": "Defining Functions",
        "url": "https://docs.python.org/3/tutorial/controlflow.html#more-on-defining-functions"
      }
    ],
    "keywords": [
      "가변",
      "위치",
      "인자를",
      "튜플로",
      "수집",
      "키워드",
      "딕셔너리로",
      "함께",
      "사용",
      "언패킹",
      "파라미터",
      "순서"
    ]
  },
  {
    "id": "PY-006",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 데코레이터(Decorator)란 무엇이고 어떻게 동작하나요?",
    "answer": "데코레이터:\n함수를 인자로 받아 새 함수를 반환하는 함수 (함수 확장)\n\n기본 구조:\n\n인자 있는 데코레이터:*\n\nfunctools.wraps (메타데이터 보존):*\n\n클래스 데코레이터:*",
    "references": [
      {
        "title": "Decorators",
        "url": "https://docs.python.org/3/glossary.html#term-decorator"
      }
    ],
    "keywords": [
      "데코레이터",
      "함수를",
      "인자로",
      "받아",
      "반환하는",
      "함수",
      "확장",
      "기본",
      "구조",
      "인자",
      "있는",
      "메타데이터",
      "보존",
      "클래스"
    ]
  },
  {
    "id": "PY-007",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 제너레이터(Generator)와 이터레이터(Iterator)를 설명해주세요.",
    "answer": "Iterator:\niter(), next()를 구현한 객체\n\nGenerator:\nyield를 사용하여 Iterator를 간단히 생성\n\nGenerator Expression:\n\n장점:\n메모리 효율: 필요할 때만 값 생성\n지연 평가: 무한 시퀀스 가능\n간결한 코드\n\nsend, throw, close:",
    "references": [
      {
        "title": "Generators",
        "url": "https://docs.python.org/3/tutorial/classes.html#generators"
      }
    ],
    "keywords": [
      "iterator",
      "generator",
      "expression",
      "구현한",
      "객체",
      "사용하여",
      "간단히",
      "생성",
      "장점",
      "메모리",
      "효율",
      "필요할",
      "때만",
      "지연",
      "평가"
    ]
  },
  {
    "id": "PY-008",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 컨텍스트 매니저(Context Manager)란 무엇인가요?",
    "answer": "컨텍스트 매니저:\nwith 문에서 리소스 설정/정리를 자동화하는 객체\n\n기본 사용:\n\n클래스로 구현:\n\ncontextlib로 간단히:\n\n활용 사례:\n파일, 네트워크, DB 연결\n락 획득/해제\n트랜잭션\n임시 설정 변경",
    "references": [
      {
        "title": "Context Managers",
        "url": "https://docs.python.org/3/reference/datamodel.html#with-statement-context-managers"
      }
    ],
    "keywords": [
      "컨텍스트",
      "매니저",
      "문에서",
      "리소스",
      "설정",
      "정리를",
      "자동화하는",
      "객체",
      "기본",
      "사용",
      "클래스로",
      "구현",
      "간단히",
      "활용",
      "사례"
    ]
  },
  {
    "id": "PY-009",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 리스트 컴프리헨션과 제너레이터 표현식의 차이점은 무엇인가요?",
    "answer": "구분   리스트 컴프리헨션   제너레이터 표현식\n\n문법   [x for x in ...]   (x for x in ...)\n반환   list   generator\n메모리   전체 할당   지연 생성\n재사용   가능   1회성\n속도   빠름 (한번에)   느림 (순차)\n\n리스트 컴프리헨션:\n\n제너레이터 표현식:\n\n선택 기준:\n\n리스트 컴프리헨션:\n데이터 크기가 작을 때\n여러 번 순회 필요\n인덱싱/슬라이싱 필요\nlen() 필요\n\n제너레이터:\n대용량 데이터\n한 번만 순회\n메모리 제한 환경\n무한 시퀀스",
    "references": [
      {
        "title": "Generator Expressions",
        "url": "https://docs.python.org/3/reference/expressions.html#generator-expressions"
      }
    ],
    "keywords": [
      "구분",
      "리스트",
      "컴프리헨션",
      "제너레이터",
      "표현식",
      "문법",
      "반환",
      "메모리",
      "전체",
      "할당",
      "지연",
      "생성",
      "재사용",
      "가능",
      "회성"
    ]
  },
  {
    "id": "PY-010",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 람다 함수의 특징과 제한사항은 무엇인가요?",
    "answer": "람다 함수:\n단일 표현식을 가진 익명 함수\n\n활용:\n\n제한사항:\n단일 표현식만\n문(statements) 불가\n타입 힌트 불가\n문서화 어려움\n\n권장:**\n간단한 콜백에만 사용\n복잡하면 일반 함수로",
    "references": [
      {
        "title": "Lambda Expressions",
        "url": "https://docs.python.org/3/reference/expressions.html#lambda"
      }
    ],
    "keywords": [
      "람다",
      "함수",
      "단일",
      "표현식을",
      "가진",
      "익명",
      "활용",
      "제한사항",
      "표현식만",
      "불가",
      "타입",
      "힌트",
      "문서화",
      "어려움",
      "권장"
    ]
  },
  {
    "id": "PY-011",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 클로저(Closure)와 nonlocal 키워드에 대해 설명해주세요.",
    "answer": "클로저:\n내부 함수가 외부 함수의 변수를 기억하고 접근하는 함수\n\nnonlocal:\n중첩 함수에서 외부 함수의 변수를 수정할 때 사용\n\nnonlocal vs global:\n\n클로저 활용:\n데이터 은닉 (private 변수)\n상태 유지 함수\n팩토리 함수\n데코레이터",
    "references": [
      {
        "title": "nonlocal",
        "url": "https://docs.python.org/3/reference/simple_stmts.html#the-nonlocal-statement"
      }
    ],
    "keywords": [
      "클로저",
      "내부",
      "함수가",
      "외부",
      "함수의",
      "변수를",
      "기억하고",
      "접근하는",
      "함수",
      "중첩",
      "함수에서",
      "수정할",
      "사용",
      "활용",
      "데이터"
    ]
  },
  {
    "id": "PY-012",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 클래스 변수와 인스턴스 변수의 차이점은 무엇인가요?",
    "answer": "구분   클래스 변수   인스턴스 변수\n\n정의 위치   클래스 내부   init 내부 (self.xxx)\n공유   모든 인스턴스   인스턴스별 독립\n접근   클래스명.변수 / self.변수   self.변수\n\n주의: 가변 객체 클래스 변수\n\n클래스 변수 활용:",
    "references": [
      {
        "title": "Classes",
        "url": "https://docs.python.org/3/tutorial/classes.html#class-and-instance-variables"
      }
    ],
    "keywords": [
      "구분",
      "클래스",
      "변수",
      "인스턴스",
      "정의",
      "위치",
      "내부",
      "공유",
      "모든",
      "인스턴스별",
      "독립",
      "접근",
      "클래스명",
      "주의",
      "가변"
    ]
  },
  {
    "id": "PY-013",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 매직 메서드(init, str, repr 등)에 대해 설명해주세요.",
    "answer": "매직 메서드 (던더 메서드):\nxxx 형태, Python 내장 동작을 커스터마이징\n\n객체 생성/초기화:\n\n문자열 표현:\n\n연산자 오버로딩:\n\n컨테이너 동작:",
    "references": [
      {
        "title": "Data Model",
        "url": "https://docs.python.org/3/reference/datamodel.html#special-method-names"
      }
    ],
    "keywords": [
      "python",
      "매직",
      "메서드",
      "던더",
      "형태",
      "내장",
      "동작을",
      "커스터마이징",
      "객체",
      "생성",
      "초기화",
      "문자열",
      "표현",
      "연산자",
      "오버로딩"
    ]
  },
  {
    "id": "PY-014",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 프로퍼티(Property)와 디스크립터(Descriptor)를 설명해주세요.",
    "answer": "Property:\ngetter/setter를 통한 속성 접근 제어\n\nDescriptor:\nget, set, delete를 구현한 클래스\n\nProperty vs Descriptor:*\nProperty: 단일 클래스에서 사용\nDescriptor: 여러 클래스에서 재사용 가능",
    "references": [
      {
        "title": "Descriptor",
        "url": "https://docs.python.org/3/howto/descriptor.html"
      }
    ],
    "keywords": [
      "property",
      "descriptor",
      "통한",
      "속성",
      "접근",
      "제어",
      "구현한",
      "클래스",
      "단일",
      "클래스에서",
      "사용",
      "여러",
      "재사용",
      "가능"
    ]
  },
  {
    "id": "PY-015",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 다중 상속과 MRO(Method Resolution Order)에 대해 설명해주세요.",
    "answer": "다중 상속:\n\nMRO (Method Resolution Order):\nC3 선형화 알고리즘으로 결정\n\nC3 규칙:\n자식 클래스가 부모보다 먼저\n부모 클래스 순서 유지 (왼쪽 우선)\n공통 부모는 마지막에\n\nsuper() 사용:\n\n다이아몬드 문제 해결:\nC3 선형화로 명확한 순서 보장\nsuper()로 협력적 상속",
    "references": [
      {
        "title": "MRO",
        "url": "https://docs.python.org/3/tutorial/classes.html#multiple-inheritance"
      }
    ],
    "keywords": [
      "mro",
      "method",
      "resolution",
      "order",
      "다중",
      "상속",
      "선형화",
      "알고리즘으로",
      "결정",
      "규칙",
      "자식",
      "클래스가",
      "부모보다",
      "먼저",
      "부모"
    ]
  },
  {
    "id": "PY-016",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 추상 클래스(ABC)와 인터페이스 구현 방법은 무엇인가요?",
    "answer": "ABC (Abstract Base Class):\n\n추상 프로퍼티:\n\n인터페이스 패턴 (Protocol - Python 3.8+):\n\nABC vs Protocol:\nABC: 명시적 상속 필요, 런타임 검사\nProtocol: 구조적 타이핑, 정적 타입 체크",
    "references": [
      {
        "title": "abc module",
        "url": "https://docs.python.org/3/library/abc.html"
      }
    ],
    "keywords": [
      "abc",
      "abstract",
      "base",
      "class",
      "protocol",
      "python",
      "추상",
      "프로퍼티",
      "인터페이스",
      "패턴",
      "명시적",
      "상속",
      "필요",
      "런타임",
      "검사"
    ]
  },
  {
    "id": "PY-017",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 Duck Typing이란 무엇인가요?",
    "answer": "Duck Typing:\n\"오리처럼 걷고 오리처럼 꽥꽥거리면, 그것은 오리다\"\n\n객체의 타입보다 행동(메서드/속성)을 기준으로 판단\n\n장점:\n유연한 다형성\n명시적 상속 불필요\n테스트/목 객체 쉬움\n\nEAFP vs LBYL:\n\n타입 힌트와 함께:",
    "references": [
      {
        "title": "Duck Typing",
        "url": "https://docs.python.org/3/glossary.html#term-duck-typing"
      }
    ],
    "keywords": [
      "duck",
      "typing",
      "eafp",
      "lbyl",
      "오리처럼",
      "걷고",
      "꽥꽥거리면",
      "그것은",
      "오리다",
      "객체의",
      "타입보다",
      "행동",
      "메서드",
      "속성",
      "기준으로"
    ]
  },
  {
    "id": "PY-018",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 타입 힌팅(Type Hinting)과 정적 타입 체커(mypy)에 대해 설명해주세요?",
    "answer": "타입 힌팅 (Python 3.5+):\n\n주요 타입:\n\nmypy 사용:\n\n주의:\n런타임에 타입 검사 안 함 (힌트일 뿐)\n정적 분석 도구로 검사",
    "references": [
      {
        "title": "typing module",
        "url": "https://docs.python.org/3/library/typing.html"
      }
    ],
    "keywords": [
      "python",
      "타입",
      "힌팅",
      "주요",
      "사용",
      "주의",
      "런타임에",
      "검사",
      "힌트일",
      "정적",
      "분석",
      "도구로"
    ]
  },
  {
    "id": "PY-019",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 동시성 처리 방법(Threading, Multiprocessing, Asyncio)을 비교해주세요.",
    "answer": "구분   Threading   Multiprocessing   Asyncio\n\n단위   스레드   프로세스   코루틴\nGIL 영향   O   X (별도 프로세스)   O\n메모리   공유   격리   공유\n적합   I/O 바운드   CPU 바운드   I/O 바운드\n컨텍스트 스위칭   OS   OS   사용자 레벨\n\nThreading:\n\nMultiprocessing:\n\nAsyncio:\n\n선택 기준:\nI/O + 간단함 → Threading\nI/O + 대량 동시성 → Asyncio\nCPU 집약적 → Multiprocessing",
    "references": [
      {
        "title": "concurrent.futures",
        "url": "https://docs.python.org/3/library/concurrent.futures.html"
      }
    ],
    "keywords": [
      "threading",
      "multiprocessing",
      "asyncio",
      "gil",
      "cpu",
      "구분",
      "단위",
      "스레드",
      "프로세스",
      "코루틴",
      "영향",
      "별도",
      "메모리",
      "공유",
      "격리"
    ]
  },
  {
    "id": "PY-020",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 asyncio와 비동기 프로그래밍에 대해 설명해주세요.",
    "answer": "asyncio:\n단일 스레드에서 동시성을 제공하는 비동기 I/O 프레임워크\n\n핵심 개념:\n\n주요 함수:\n\n이벤트 루프:\n\nasync 컨텍스트 매니저:\n\n주의:\n블로킹 코드 사용 금지 (time.sleep X)\nI/O 라이브러리도 async 버전 필요",
    "references": [
      {
        "title": "asyncio",
        "url": "https://docs.python.org/3/library/asyncio.html"
      }
    ],
    "keywords": [
      "단일",
      "스레드에서",
      "동시성을",
      "제공하는",
      "비동기",
      "프레임워크",
      "핵심",
      "개념",
      "주요",
      "함수",
      "이벤트",
      "루프",
      "컨텍스트",
      "매니저",
      "주의"
    ]
  },
  {
    "id": "PY-021",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python 2와 Python 3의 주요 차이점은 무엇인가요?",
    "answer": "구분   Python 2   Python 3\n\nprint   print \"hello\"   print(\"hello\")\n나눗셈   5/2 = 2 (정수)   5/2 = 2.5 (실수)\n문자열   str (바이트), unicode   str (유니코드), bytes\nrange   range() → list   range() → iterator\ninput   raw_input()   input()\n예외   except E, e:   except E as e:\n\n주요 차이:\nprint 함수\n정수 나눗셈\n유니코드\n반복자\n\nPython 2 EOL:\n2020년 1월 1일 지원 종료\n신규 프로젝트는 Python 3 필수",
    "references": [
      {
        "title": "What's New",
        "url": "https://docs.python.org/3/whatsnew/3.0.html"
      }
    ],
    "keywords": [
      "python",
      "raw_input",
      "eol",
      "구분",
      "나눗셈",
      "정수",
      "실수",
      "문자열",
      "바이트",
      "유니코드",
      "예외",
      "주요",
      "차이",
      "함수",
      "반복자"
    ]
  },
  {
    "id": "PY-022",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 패키지 관리 도구(pip, pipenv, poetry)를 비교해주세요.",
    "answer": "구분   pip   pipenv   poetry\n\n표준   O   X   X\n가상환경   별도 (venv)   통합   통합\nlock 파일   X   Pipfile.lock   poetry.lock\n의존성 해결   기본   향상   향상\n빌드/배포   X   X   O\n\npip:\n기본 도구, 단순\nlock 파일 없어 재현성 이슈\n\npipenv:\nPipfile, Pipfile.lock 사용\n가상환경 자동 관리\n\npoetry:\npyproject.toml (PEP 518 표준)\n프로젝트 생성부터 배포까지\n현대적 도구로 인기 상승\n\n선택 기준:\n단순 스크립트 → pip + venv\n애플리케이션 → pipenv 또는 poetry\n라이브러리 배포 → poetry",
    "references": [
      {
        "title": "pip",
        "url": "https://pip.pypa.io/en/stable/"
      }
    ],
    "keywords": [
      "pipfile",
      "pep",
      "구분",
      "표준",
      "가상환경",
      "별도",
      "통합",
      "파일",
      "의존성",
      "해결",
      "기본",
      "향상",
      "빌드",
      "배포",
      "도구"
    ]
  },
  {
    "id": "PY-023",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 가상 환경(venv, virtualenv)이 필요한 이유는 무엇인가요?",
    "answer": "필요한 이유:\n의존성 격리\n프로젝트마다 다른 버전의 패키지 사용 가능\n프로젝트 A: Django 3.x, 프로젝트 B: Django 4.x\n시스템 Python 보호\nOS 시스템 Python과 분리\n시스템 패키지 충돌 방지\n재현 가능한 환경\n개발/프로덕션 환경 일치\nrequirements.txt로 환경 공유\n\n사용법:\n\nvenv vs virtualenv:\n구분   venv   virtualenv\n\n설치   내장   pip 설치\nPython 버전   현재만   여러 버전\n속도   빠름   빠름\n\n가상환경 위치:",
    "references": [
      {
        "title": "venv",
        "url": "https://docs.python.org/3/library/venv.html"
      }
    ],
    "keywords": [
      "django",
      "python",
      "필요한",
      "이유",
      "의존성",
      "격리",
      "프로젝트마다",
      "다른",
      "버전의",
      "패키지",
      "사용",
      "가능",
      "프로젝트",
      "시스템",
      "보호"
    ]
  },
  {
    "id": "PY-024",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 모듈 import 방식과 init.py의 역할을 설명해주세요.",
    "answer": "import 방식:\n\n모듈 검색 순서:\n현재 디렉토리\nPYTHONPATH 환경변수\n설치된 패키지 (site-packages)\n표준 라이브러리\n\n패키지 구조:\n\ninit.py 역할:\n패키지 표시 (Python 3.3+ namespace packages로 선택적)\n패키지 초기화 코드\n공개 API 정의\n하위 모듈 자동 import",
    "references": [
      {
        "title": "Modules",
        "url": "https://docs.python.org/3/tutorial/modules.html"
      }
    ],
    "keywords": [
      "pythonpath",
      "site-packages",
      "python",
      "api",
      "방식",
      "모듈",
      "검색",
      "순서",
      "현재",
      "디렉토리",
      "환경변수",
      "설치된",
      "패키지",
      "표준",
      "라이브러리"
    ]
  },
  {
    "id": "PY-025",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Python의 성능 최적화 방법에는 어떤 것들이 있나요?",
    "answer": "프로파일링 먼저\n내장 함수/라이브러리 활용\n적절한 자료구조\n제너레이터 사용\nC 확장 라이브러리\n멀티프로세싱 (CPU 바운드)\nasyncio (I/O 바운드)\n기타*\nslots: 메모리 최적화\nfunctools.lrucache: 메모이제이션\nPyPy: 대안 인터프리터",
    "references": [
      {
        "title": "Performance Tips",
        "url": "https://docs.python.org/3/howto/perf-tips.html"
      }
    ],
    "keywords": [
      "cpu",
      "pypy",
      "프로파일링",
      "먼저",
      "내장",
      "함수",
      "라이브러리",
      "활용",
      "적절한",
      "자료구조",
      "제너레이터",
      "사용",
      "확장",
      "멀티프로세싱",
      "바운드"
    ]
  },
  {
    "id": "GO-001",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go 언어의 특징과 장단점을 설명해주세요.",
    "answer": "특징:\n정적 타입, 컴파일 언어\n간결한 문법 (키워드 25개)\n내장 동시성 (goroutine, channel)\n빠른 컴파일\n단일 바이너리 배포\n가비지 컬렉션\n\n장점:\n동시성: goroutine이 가볍고 효율적\n성능: C에 근접한 실행 속도\n단순함: 학습 곡선 낮음, 코드 일관성\n빠른 빌드: 대규모 프로젝트도 빠름\n도구 통합: go fmt, go test, go mod 내장\n크로스 컴파일: 쉬운 멀티 플랫폼 빌드\n\n단점:\n제네릭: Go 1.18에서 추가되었으나 제한적\n에러 처리: if err != nil 반복\n의존성 주입: 프레임워크 지원 부족\n함수형: map, filter 등 내장 없음\nGUI: 네이티브 지원 없음\n\n사용 사례:\n마이크로서비스 (Docker, Kubernetes)\nCLI 도구 (Terraform, Hugo)\n네트워크 서버\nDevOps 도구",
    "references": [
      {
        "title": "Go Documentation",
        "url": "https://go.dev/doc/"
      }
    ],
    "keywords": [
      "gui",
      "docker",
      "kubernetes",
      "cli",
      "terraform",
      "hugo",
      "devops",
      "특징",
      "정적",
      "타입",
      "컴파일",
      "언어",
      "간결한",
      "문법",
      "키워드"
    ]
  },
  {
    "id": "GO-002",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 고루틴(Goroutine)과 스레드의 차이점은 무엇인가요?",
    "answer": "구분   Goroutine   OS Thread\n\n메모리   ~2KB 스택   ~1MB 스택\n생성 비용   매우 낮음   높음\n스케줄링   Go 런타임   OS 커널\n컨텍스트 스위칭   빠름   느림\n개수   수십만 가능   수천 제한적\n\nGoroutine 사용:\n\nM:N 스케줄링:\nM개의 goroutine을 N개의 OS 스레드에 매핑\nGOMAXPROCS로 사용할 OS 스레드 수 설정\n\nGo 스케줄러 (GMP):\nG: Goroutine\nM: Machine (OS Thread)\nP: Processor (논리적 프로세서)\n\n장점:\n가벼움: 수십만 동시 실행 가능\n간단: go 키워드만으로 생성\n효율적: 블로킹 I/O 시 자동으로 다른 goroutine 실행\n\n주의:\nmain 종료 시 모든 goroutine 종료\nsync.WaitGroup으로 대기",
    "references": [
      {
        "title": "Goroutines",
        "url": "https://go.dev/doc/effective_go#goroutines"
      }
    ],
    "keywords": [
      "goroutine",
      "thread",
      "gomaxprocs",
      "gmp",
      "machine",
      "processor",
      "waitgroup",
      "구분",
      "메모리",
      "스택",
      "생성",
      "비용",
      "매우",
      "낮음",
      "높음"
    ]
  },
  {
    "id": "GO-003",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 채널(Channel)의 동작 원리와 사용 방법을 설명해주세요.",
    "answer": "Channel:\ngoroutine 간 통신을 위한 타입 안전한 파이프\n\n생성과 사용:\n\nUnbuffered vs Buffered:\n구분   Unbuffered   Buffered\n\n생성   make(chan T)   make(chan T, n)\n송신   수신자 대기까지 블로킹   버퍼 찰 때까지 비블로킹\n동기화   동기식   비동기식\n\n패턴:\n\nWorker Pool:",
    "references": [
      {
        "title": "Channels",
        "url": "https://go.dev/doc/effective_go#channels"
      }
    ],
    "keywords": [
      "channel",
      "unbuffered",
      "buffered",
      "worker",
      "pool",
      "통신을",
      "위한",
      "타입",
      "안전한",
      "파이프",
      "생성과",
      "사용",
      "구분",
      "생성",
      "송신"
    ]
  },
  {
    "id": "GO-004",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 select 문의 동작 원리를 설명해주세요.",
    "answer": "select:\n여러 채널 연산을 동시에 대기하는 제어 구조\n\n동작 원리:\n모든 case의 채널 연산 확인\n준비된 case가 있으면 하나 무작위 선택 실행\n준비된 case 없으면 default 실행 (있을 경우)\ndefault 없으면 하나가 준비될 때까지 블로킹\n\n활용 패턴:\n타임아웃:\n취소 (Context):\n논블로킹 연산:\n무한 루프:",
    "references": [
      {
        "title": "Select",
        "url": "https://go.dev/tour/concurrency/5"
      }
    ],
    "keywords": [
      "context",
      "여러",
      "채널",
      "연산을",
      "동시에",
      "대기하는",
      "제어",
      "구조",
      "동작",
      "원리",
      "모든",
      "연산",
      "확인",
      "준비된",
      "있으면"
    ]
  },
  {
    "id": "GO-005",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 인터페이스(Interface)와 타입 시스템에 대해 설명해주세요.",
    "answer": "인터페이스:\n메서드 시그니처의 집합. 암시적 구현 (implements 키워드 없음)\n\n빈 인터페이스:\n\n타입 단언:\n\n타입 스위치:\n\n인터페이스 합성:\n\n특징:\n덕 타이핑의 정적 버전\n작은 인터페이스 선호 (io.Reader, io.Writer)\nnil 인터페이스 주의",
    "references": [
      {
        "title": "Interfaces",
        "url": "https://go.dev/doc/effective_go#interfaces"
      }
    ],
    "keywords": [
      "reader",
      "writer",
      "인터페이스",
      "메서드",
      "시그니처의",
      "집합",
      "암시적",
      "구현",
      "키워드",
      "없음",
      "타입",
      "단언",
      "스위치",
      "합성",
      "특징"
    ]
  },
  {
    "id": "GO-006",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 포인터와 값 타입의 차이점은 무엇인가요?",
    "answer": "값 타입:\n변수가 실제 값을 직접 저장. 할당/전달 시 복사\n\n포인터 타입:\n메모리 주소를 저장. 간접 참조\n\n함수 인자:\n\n메서드 수신자:\n\n포인터 사용 시점:\n구조체 크기가 클 때 (복사 비용)\n원본 수정이 필요할 때\nnil 상태가 의미 있을 때\n\n주의:\nGo는 포인터 연산 없음 (안전)\nnil 포인터 역참조 시 panic",
    "references": [
      {
        "title": "Pointers",
        "url": "https://go.dev/tour/moretypes/1"
      }
    ],
    "keywords": [
      "타입",
      "변수가",
      "실제",
      "값을",
      "직접",
      "저장",
      "할당",
      "전달",
      "복사",
      "포인터",
      "메모리",
      "주소를",
      "간접",
      "참조",
      "함수"
    ]
  },
  {
    "id": "GO-007",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 슬라이스(Slice)와 배열(Array)의 차이점을 설명해주세요.",
    "answer": "구분   Array   Slice\n\n크기   고정 (타입 일부)   가변\n타입   [5]int != [10]int   []int\n값/참조   값 타입 (복사)   참조 타입\n전달   전체 복사   헤더만 복사\n\n배열:\n\n슬라이스:\n\n슬라이스 내부 구조:\n\n주요 연산:\n\n주의:",
    "references": [
      {
        "title": "Slices",
        "url": "https://go.dev/blog/slices-intro"
      }
    ],
    "keywords": [
      "array",
      "slice",
      "구분",
      "크기",
      "고정",
      "타입",
      "일부",
      "가변",
      "참조",
      "복사",
      "전달",
      "전체",
      "헤더만",
      "배열",
      "슬라이스"
    ]
  },
  {
    "id": "GO-008",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 맵(Map)의 내부 구조와 동작 원리는 무엇인가요?",
    "answer": "Map:\n해시 테이블 기반 키-값 저장소\n\n사용법:\n\n내부 구조 (hmap):\n버킷 배열 (각 버킷 8개 키-값)\n오버플로우 버킷 (체이닝)\n로드 팩터 초과 시 확장\n\n특징:\n참조 타입 (포인터처럼 동작)\nnil map에 쓰기 시 panic\n동시 읽기 안전, 동시 쓰기 불안전\n순회 순서 비결정적\n\n동시성:",
    "references": [
      {
        "title": "Maps",
        "url": "https://go.dev/blog/maps"
      }
    ],
    "keywords": [
      "map",
      "해시",
      "테이블",
      "기반",
      "저장소",
      "사용법",
      "내부",
      "구조",
      "버킷",
      "배열",
      "오버플로우",
      "체이닝",
      "로드",
      "팩터",
      "초과"
    ]
  },
  {
    "id": "GO-009",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 defer, panic, recover에 대해 설명해주세요.",
    "answer": "defer:\n함수 종료 시 실행되는 지연 호출 (LIFO 순서)\n\npanic:\n런타임 오류, 프로그램 비정상 종료\n\nrecover:\npanic을 잡아서 복구 (defer 내에서만 유효)\n\n패턴:\n\n주의:\ndefer 인자는 즉시 평가\n루프 내 defer 주의 (축적됨)\npanic은 예외적 상황에만 사용",
    "references": [
      {
        "title": "Defer, Panic, Recover",
        "url": "https://go.dev/blog/defer-panic-and-recover"
      }
    ],
    "keywords": [
      "lifo",
      "함수",
      "종료",
      "실행되는",
      "지연",
      "호출",
      "순서",
      "런타임",
      "오류",
      "프로그램",
      "비정상",
      "잡아서",
      "복구",
      "내에서만",
      "유효"
    ]
  },
  {
    "id": "GO-010",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 에러 처리 방식과 모범 사례는 무엇인가요?",
    "answer": "Go 에러 처리:\nerror 인터페이스 반환, 명시적 처리\n\n에러 생성:\n\n에러 래핑/언래핑 (Go 1.13+):\n\n모범 사례:\n에러 즉시 처리 또는 반환\n컨텍스트 추가하여 래핑\n센티널 에러: var ErrNotFound = errors.New(\"not found\")\npanic 대신 error 반환",
    "references": [
      {
        "title": "Error Handling",
        "url": "https://go.dev/blog/error-handling-and-go"
      }
    ],
    "keywords": [
      "errnotfound",
      "new",
      "에러",
      "처리",
      "인터페이스",
      "반환",
      "명시적",
      "생성",
      "래핑",
      "언래핑",
      "모범",
      "사례",
      "즉시",
      "컨텍스트",
      "추가하여"
    ]
  },
  {
    "id": "GO-011",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 컨텍스트(Context) 패키지의 용도와 사용 방법은 무엇인가요?",
    "answer": "Context:\n요청 범위 데이터, 취소 신호, 타임아웃을 전달하는 표준 방법\n\n주요 용도:\n요청 취소 전파\n타임아웃/데드라인 설정\n요청 범위 값 전달\n\n생성:\n\n사용:\n\n모범 사례:\n함수 첫 번째 인자로 전달\nnil context 전달 금지\ncontext에 비즈니스 로직 데이터 넣지 않기\n항상 cancel 호출 (리소스 누수 방지)",
    "references": [
      {
        "title": "context",
        "url": "https://go.dev/blog/context"
      }
    ],
    "keywords": [
      "context",
      "요청",
      "범위",
      "데이터",
      "취소",
      "신호",
      "타임아웃을",
      "전달하는",
      "표준",
      "방법",
      "주요",
      "용도",
      "전파",
      "타임아웃",
      "데드라인"
    ]
  },
  {
    "id": "GO-012",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 sync 패키지의 주요 기능들을 설명해주세요.",
    "answer": "Mutex (상호 배제)\nRWMutex (읽기-쓰기 락)\nWaitGroup (고루틴 대기)\nOnce (한 번만 실행)\nCond (조건 변수)\nPool (객체 풀)",
    "references": [
      {
        "title": "sync package",
        "url": "https://pkg.go.dev/sync"
      }
    ],
    "keywords": [
      "mutex",
      "rwmutex",
      "waitgroup",
      "once",
      "cond",
      "pool",
      "상호",
      "배제",
      "읽기",
      "쓰기",
      "고루틴",
      "대기",
      "번만",
      "실행",
      "조건"
    ]
  },
  {
    "id": "GO-013",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 가비지 컬렉션 방식을 설명해주세요.",
    "answer": "Go GC:\nConcurrent, Tri-color Mark-and-Sweep\n\n삼색 마킹 알고리즘:\n흰색: 아직 방문 안 함 (수거 대상 후보)\n회색: 방문했지만 참조 확인 중\n검은색: 방문 완료, 유지\n\n동작 과정:\nSTW(Stop-The-World): 짧은 일시 정지, 루트셋 스캔\nMark (concurrent): 회색 객체 처리, 검은색으로 변경\nSTW: 마킹 종료 확인\nSweep (concurrent): 흰색 객체 수거\n\n특징:\n낮은 지연: 대부분 동시 실행, STW 최소화\n쓰기 배리어: 동시 마킹 중 참조 변경 추적\n페이싱: 힙 크기 기반 GC 주기 조절\n\n튜닝:\n\n최적화 팁:\n불필요한 할당 줄이기\nsync.Pool 활용\n포인터 사용 최소화",
    "references": [
      {
        "title": "GC Guide",
        "url": "https://go.dev/doc/gc-guide"
      }
    ],
    "keywords": [
      "concurrent",
      "tri-color",
      "mark-and-sweep",
      "stw",
      "stop-the-world",
      "mark",
      "sweep",
      "pool",
      "삼색",
      "마킹",
      "알고리즘",
      "흰색",
      "아직",
      "방문",
      "수거"
    ]
  },
  {
    "id": "GO-014",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go의 빌드와 컴파일 과정을 설명해주세요.",
    "answer": "빌드 과정:\n\n기본 명령:\n\n크로스 컴파일:\n\n빌드 옵션:\n\n빌드 모드:\n\n특징:\n빠른 컴파일 (의존성 분석 효율적)\n정적 링크 기본 (단일 바이너리)\nCGO: C 코드 연동 가능",
    "references": [
      {
        "title": "go build",
        "url": "https://pkg.go.dev/cmd/go#hdr-Compile_packages_and_dependencies"
      }
    ],
    "keywords": [
      "cgo",
      "빌드",
      "과정",
      "기본",
      "명령",
      "크로스",
      "컴파일",
      "옵션",
      "모드",
      "특징",
      "빠른",
      "의존성",
      "분석",
      "효율적",
      "정적"
    ]
  },
  {
    "id": "GO-015",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Go 모듈(Go Modules)과 의존성 관리에 대해 설명해주세요.",
    "answer": "Go Modules (Go 1.11+):\n공식 의존성 관리 시스템\n\n초기화:\n\ngo.mod:\n\n주요 명령:\n\ngo.sum:\n체크섬 파일 (보안, 재현성)\n버전 커밋에 포함해야 함\n\n버전 관리:\n\nSemantic Versioning:\nv1.2.3 (major.minor.patch)\nv2+ 는 모듈 경로에 버전 포함: module github.com/user/pkg/v2\n\nreplace/exclude:",
    "references": [
      {
        "title": "Go Modules",
        "url": "https://go.dev/doc/modules/"
      }
    ],
    "keywords": [
      "modules",
      "semantic",
      "versioning",
      "공식",
      "의존성",
      "관리",
      "시스템",
      "초기화",
      "주요",
      "명령",
      "체크섬",
      "파일",
      "보안",
      "재현성",
      "버전"
    ]
  },
  {
    "id": "LANG-001",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "객체지향 프로그래밍(OOP)의 4가지 특징을 설명해주세요.",
    "answer": "캡슐화 (Encapsulation)\n데이터와 메서드를 하나로 묶음\n내부 구현 숨김 (정보 은닉)\n접근 제어자로 보호\n상속 (Inheritance)\n기존 클래스를 확장하여 새 클래스 생성\n코드 재사용, 계층 구조\n다형성 (Polymorphism)\n같은 인터페이스, 다른 동작\n오버라이딩, 오버로딩\n추상화 (Abstraction)\n복잡한 시스템에서 핵심만 추출\n인터페이스/추상 클래스로 구현\n\n관계:\n캡슐화 → 구현 숨김\n상속 → 코드 재사용\n다형성 → 유연한 설계\n추상화 → 복잡도 관리",
    "references": [],
    "keywords": [
      "encapsulation",
      "inheritance",
      "polymorphism",
      "abstraction",
      "캡슐화",
      "데이터와",
      "메서드를",
      "하나로",
      "묶음",
      "내부",
      "구현",
      "숨김",
      "정보",
      "은닉",
      "접근"
    ]
  },
  {
    "id": "LANG-002",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "SOLID 원칙에 대해 설명해주세요.",
    "answer": "S - 단일 책임 원칙 (Single Responsibility)\n클래스는 하나의 책임만 가져야 함\n변경 이유가 하나여야 함\n\nO - 개방-폐쇄 원칙 (Open-Closed)\n확장에는 열려있고, 수정에는 닫혀있어야 함\n기존 코드 수정 없이 기능 추가\n\nL - 리스코프 치환 원칙 (Liskov Substitution)\n하위 타입은 상위 타입을 대체할 수 있어야 함\n상속 시 계약 위반 금지\n\nI - 인터페이스 분리 원칙 (Interface Segregation)\n클라이언트가 사용하지 않는 메서드에 의존하지 않아야 함\n작은 인터페이스로 분리\n\nD - 의존성 역전 원칙 (Dependency Inversion)\n고수준 모듈이 저수준 모듈에 의존하지 않음\n추상화에 의존",
    "references": [],
    "keywords": [
      "single",
      "responsibility",
      "open-closed",
      "liskov",
      "substitution",
      "interface",
      "segregation",
      "dependency",
      "inversion",
      "단일",
      "책임",
      "원칙",
      "클래스는",
      "하나의",
      "책임만"
    ]
  },
  {
    "id": "LANG-003",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "함수형 프로그래밍의 특징과 장점은 무엇인가요?",
    "answer": "핵심 개념:\n순수 함수 (Pure Function)\n같은 입력 → 같은 출력\n부작용 없음\n불변성 (Immutability)\n데이터 변경 대신 새 데이터 생성\n일급 함수 (First-class Function)\n함수를 값으로 취급 (변수 할당, 인자 전달, 반환)\n고차 함수 (Higher-order Function)\n함수를 인자로 받거나 반환하는 함수 (map, filter, reduce)\n선언적 프로그래밍\n\"무엇을\" 할지 기술 (vs 명령형: \"어떻게\")\n\n장점:\n테스트 용이: 순수 함수는 격리 테스트 쉬움\n동시성 안전: 불변 데이터, 공유 상태 없음\n예측 가능성: 부작용 없어 디버깅 쉬움\n재사용성: 작은 함수 조합\n지연 평가: 필요할 때만 계산\n\n예시:",
    "references": [],
    "keywords": [
      "pure",
      "function",
      "immutability",
      "first-class",
      "higher-order",
      "핵심",
      "개념",
      "순수",
      "함수",
      "같은",
      "입력",
      "출력",
      "부작용",
      "없음",
      "불변성"
    ]
  },
  {
    "id": "LANG-004",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "순수 함수(Pure Function)란 무엇인가요?",
    "answer": "순수 함수의 조건:\n결정론적 (Deterministic)\n같은 입력 → 항상 같은 출력\n부작용 없음 (No Side Effects)\n외부 상태 변경 없음\nI/O 없음 (콘솔, 파일, 네트워크)\n\n장점:\n테스트 용이 (Mock 불필요)\n캐싱/메모이제이션 가능\n병렬 실행 안전\n리팩토링 안전\n\n순수 함수 예:",
    "references": [],
    "keywords": [
      "deterministic",
      "side",
      "effects",
      "mock",
      "순수",
      "함수의",
      "조건",
      "결정론적",
      "같은",
      "입력",
      "항상",
      "출력",
      "부작용",
      "없음",
      "외부"
    ]
  },
  {
    "id": "LANG-005",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "불변성(Immutability)의 중요성과 구현 방법은 무엇인가요?",
    "answer": "불변성:\n생성 후 상태를 변경할 수 없는 특성\n\n중요성:\n동시성 안전: 공유 상태 변경 없음\n예측 가능: 값이 변하지 않아 추적 쉬움\n변경 감지: 참조 비교로 빠른 변경 확인 (React)\n히스토리/되돌리기: 이전 상태 보존\n\n구현 방법:\n\nJavaScript:\n\nJava:\n\nPython:",
    "references": [],
    "keywords": [
      "react",
      "javascript",
      "java",
      "python",
      "불변성",
      "생성",
      "상태를",
      "변경할",
      "없는",
      "특성",
      "중요성",
      "동시성",
      "안전",
      "공유",
      "상태"
    ]
  },
  {
    "id": "LANG-006",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "동시성(Concurrency)과 병렬성(Parallelism)의 차이점은 무엇인가요?",
    "answer": "구분   동시성   병렬성\n\n정의   여러 작업 동시에 다룸   여러 작업 동시에 실행\n목적   응답성, 구조화   처리량, 속도\n하드웨어   싱글 코어 가능   멀티 코어 필요\n관점   설계/구조   실행 방식\n\n동시성 (Concurrency):\n\"여러 일을 한꺼번에 다루는 것\"\n작업 간 전환 (인터리빙)\n싱글 코어에서도 가능\n구조적 개념\n\n병렬성 (Parallelism):\n\"여러 일을 한꺼번에 실행하는 것\"\n물리적 동시 실행\n멀티 코어 필수\n실행 개념\n\n관계:\n동시성 없이 병렬성 가능 (독립 작업)\n병렬성 없이 동시성 가능 (싱글 코어 멀티태스킹)\n둘 다 가능 (멀티코어 + 멀티태스킹)\n\n예시:\n동시성: Node.js 이벤트 루프 (싱글 스레드)\n병렬성: 멀티 프로세스 데이터 처리",
    "references": [],
    "keywords": [
      "concurrency",
      "parallelism",
      "node",
      "구분",
      "동시성",
      "병렬성",
      "정의",
      "여러",
      "작업",
      "동시에",
      "다룸",
      "실행",
      "목적",
      "응답성",
      "구조화"
    ]
  },
  {
    "id": "LANG-007",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Race Condition과 Deadlock에 대해 설명해주세요.",
    "answer": "Race Condition (경쟁 상태):\n여러 스레드가 공유 자원에 동시 접근하여 결과가 실행 순서에 따라 달라지는 현상\n\nDeadlock (교착 상태):\n두 개 이상의 스레드가 서로의 자원을 기다리며 영원히 블로킹\n\nDeadlock 조건 (모두 충족 시):\n상호 배제: 자원은 한 번에 하나만 사용\n점유 대기: 자원 보유하며 다른 자원 대기\n비선점: 강제로 자원 회수 불가\n순환 대기: 순환 형태의 대기\n\nDeadlock 방지:\n락 순서 일관되게 유지\n타임아웃 사용\ntryLock() 사용\n락 계층 구조",
    "references": [],
    "keywords": [
      "race",
      "condition",
      "deadlock",
      "경쟁",
      "상태",
      "여러",
      "스레드가",
      "공유",
      "자원에",
      "동시",
      "접근하여",
      "결과가",
      "실행",
      "순서에",
      "따라"
    ]
  },
  {
    "id": "LANG-008",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "동기(Synchronous)와 비동기(Asynchronous)의 차이점은 무엇인가요?",
    "answer": "구분   동기   비동기\n\n실행   순차적, 완료 대기   요청 후 다른 작업\n호출자   블로킹   논블로킹\n결과   즉시 반환   콜백/Promise/Future\n복잡도   단순   복잡\n\n동기 (Synchronous):\n\n비동기 (Asynchronous):\n\n비동기 처리 방법:\n콜백: 함수 전달\nPromise: then/catch\nasync/await: 동기식 문법\n이벤트: 이벤트 리스너\n\n사용 시나리오:\n동기: 단순 작업, 순서 중요\n비동기: I/O, 네트워크, UI 응답성",
    "references": [],
    "keywords": [
      "promise",
      "future",
      "synchronous",
      "asynchronous",
      "구분",
      "동기",
      "비동기",
      "실행",
      "순차적",
      "완료",
      "대기",
      "요청",
      "다른",
      "작업",
      "호출자"
    ]
  },
  {
    "id": "LANG-009",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "블로킹(Blocking)과 논블로킹(Non-blocking)의 차이점은 무엇인가요?",
    "answer": "블로킹:\n호출된 함수가 완료될 때까지 호출자가 대기\n\n논블로킹:\n호출된 함수가 즉시 반환, 호출자는 다른 작업 가능\n\n동기/비동기 vs 블로킹/논블로킹:\n\n조합   설명\n\n동기 + 블로킹   완료까지 대기 (일반적)\n동기 + 논블로킹   즉시 반환, 폴링으로 확인\n비동기 + 논블로킹   즉시 반환, 콜백/이벤트로 알림\n비동기 + 블로킹   비효율적 (드묾)\n\n예시:\n\nI/O 모델:\n블로킹 I/O: read() 호출 시 데이터 올 때까지 대기\n논블로킹 I/O: 데이터 없으면 에러 반환\nI/O 멀티플렉싱: select/poll/epoll\n비동기 I/O: 커널이 완료 알림",
    "references": [],
    "keywords": [
      "블로킹",
      "호출된",
      "함수가",
      "완료될",
      "때까지",
      "호출자가",
      "대기",
      "논블로킹",
      "즉시",
      "반환",
      "호출자는",
      "다른",
      "작업",
      "가능",
      "동기"
    ]
  },
  {
    "id": "LANG-010",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "컴파일 언어와 인터프리터 언어의 차이점은 무엇인가요?",
    "answer": "구분   컴파일 언어   인터프리터 언어\n\n변환 시점   실행 전 전체   실행 중 한 줄씩\n출력   기계어/바이트코드   없음 (직접 실행)\n실행 속도   빠름   느림\n개발 속도   느림 (빌드)   빠름\n에러 검출   컴파일 타임   런타임\n\n컴파일 언어:\n예: C, C++, Go, Rust\n장점: 빠른 실행, 최적화\n단점: 플랫폼 의존, 빌드 시간\n\n인터프리터 언어:\n예: Python, JavaScript, Ruby\n장점: 빠른 개발, 플랫폼 독립\n단점: 느린 실행\n\n혼합 방식:\nJava: 컴파일(바이트코드) + 인터프리터/JIT\nPython: 바이트코드 컴파일 + VM 실행\nJavaScript: JIT 컴파일 (V8)\n\nJIT (Just-In-Time):\n런타임에 기계어로 컴파일\n핫스팟 최적화\n인터프리터 + 컴파일 장점 결합",
    "references": [],
    "keywords": [
      "rust",
      "python",
      "javascript",
      "ruby",
      "java",
      "jit",
      "just-in-time",
      "구분",
      "컴파일",
      "언어",
      "인터프리터",
      "변환",
      "시점",
      "실행",
      "전체"
    ]
  },
  {
    "id": "LANG-011",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "JIT(Just-In-Time) 컴파일러의 동작 원리를 설명해주세요.",
    "answer": "JIT 컴파일:\n런타임에 바이트코드를 기계어로 변환하여 성능 향상\n\n동작 과정:\n\n주요 기법:\n핫스팟 감지\n자주 실행되는 코드 영역 파악\n카운터로 호출 횟수 추적\n프로파일링 기반 최적화\n런타임 정보로 최적화 결정\n타입 예측, 분기 예측\n최적화 기법\n인라이닝: 함수 호출 제거\n루프 언롤링: 반복문 펼치기\n데드 코드 제거\n탈출 분석: 스택 할당 최적화\n탈최적화 (Deoptimization)\n가정 깨지면 다시 인터프리터 모드\n\nJIT 사용 환경:\nJava: HotSpot C1/C2 컴파일러\nJavaScript: V8 (TurboFan), SpiderMonkey\n.NET: RyuJIT\nPython: PyPy\n\nTrade-off:\n워밍업 시간 필요\n메모리 사용 증가\n장기 실행에 유리",
    "references": [],
    "keywords": [
      "jit",
      "deoptimization",
      "java",
      "hotspot",
      "javascript",
      "turbofan",
      "spidermonkey",
      "net",
      "ryujit",
      "python",
      "pypy",
      "trade-off",
      "컴파일",
      "런타임에",
      "바이트코드를"
    ]
  },
  {
    "id": "LANG-012",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "정적 타이핑과 동적 타이핑의 장단점은 무엇인가요?",
    "answer": "구분   정적 타이핑   동적 타이핑\n\n타입 검사   컴파일 타임   런타임\n선언   명시적 타입   타입 생략\n에러 발견   빠름   늦음\n유연성   낮음   높음\n\n정적 타이핑:\n예: Java, C++, Go, TypeScript\n장점:\n컴파일 타임 에러 발견\nIDE 자동완성, 리팩토링\n성능 최적화\n문서화 효과\n단점:\n장황한 코드\n유연성 부족\n학습 곡선\n\n동적 타이핑:\n예: Python, JavaScript, Ruby\n장점:\n간결한 코드\n빠른 프로토타이핑\n유연한 API\n덕 타이핑\n단점:\n런타임 에러\n리팩토링 어려움\n대규모 프로젝트 유지보수\n\n점진적 타이핑:\nTypeScript, Python (타입 힌트)\n선택적 타입 추가",
    "references": [],
    "keywords": [
      "java",
      "typescript",
      "ide",
      "python",
      "javascript",
      "ruby",
      "api",
      "구분",
      "정적",
      "타이핑",
      "동적",
      "타입",
      "검사",
      "컴파일",
      "타임"
    ]
  },
  {
    "id": "LANG-013",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "강타입과 약타입 언어의 차이점은 무엇인가요?",
    "answer": "강타입 (Strongly Typed):\n타입 간 암시적 변환 제한적\n\n약타입 (Weakly Typed):\n타입 간 암시적 변환 허용\n\n구분   강타입   약타입\n\n변환   명시적   암시적\n안전성   높음   낮음\n편의성   불편   편리 (위험)\n예측성   높음   낮음\n\n언어 분류:\n타입   정적   동적\n\n강   Java, C#, Go   Python, Ruby\n약   C   JavaScript, PHP\n\n주의:\n정적/동적과 독립적 개념\n스펙트럼 (완전 강/약 없음)\n\n강타입 장점:\n타입 관련 버그 방지\n의도 명확\n\n약타입 장점:\n유연한 코드 (위험 동반)",
    "references": [],
    "keywords": [
      "strongly",
      "typed",
      "weakly",
      "java",
      "python",
      "ruby",
      "javascript",
      "php",
      "강타입",
      "타입",
      "암시적",
      "변환",
      "제한적",
      "약타입",
      "허용"
    ]
  },
  {
    "id": "LANG-014",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "Call by Value와 Call by Reference의 차이점을 설명해주세요.",
    "answer": "Call by Value:\n값의 복사본 전달\n\nCall by Reference:\n변수의 참조(주소) 전달\n\n언어별 특성:\n\nJava: Call by Value (항상)\n\nPython: Call by Object Reference\n\nJavaScript: Call by Sharing\n기본형: 값 복사\n객체: 참조 복사\n\n정리:\n언어   방식\n\nC   Value, 포인터로 참조 흉내\nC++   Value, Reference (&)\nJava   Value (참조값 복사)\nPython   Object Reference\nGo   Value, 포인터 사용",
    "references": [],
    "keywords": [
      "call",
      "value",
      "reference",
      "java",
      "python",
      "object",
      "javascript",
      "sharing",
      "값의",
      "복사본",
      "전달",
      "변수의",
      "참조",
      "주소",
      "언어별"
    ]
  },
  {
    "id": "LANG-015",
    "category": "pl",
    "categoryName": "프로그래밍 언어",
    "priority": "P3",
    "question": "메모리 누수(Memory Leak)가 발생하는 원인과 방지 방법은 무엇인가요?",
    "answer": "메모리 누수:\n사용하지 않는 메모리를 해제하지 않아 점점 메모리 증가\n\n원인:\n참조 유지\n이벤트 리스너 해제 안 함\n클로저가 참조 유지\nThreadLocal 정리 안 함\n리소스 해제 안 함\n파일, DB 연결, 소켓\n\n---\n\n방지 방법:\n약한 참조 사용: WeakMap, WeakReference\n리스너 해제: removeEventListener\n리소스 정리: try-with-resources, using\n캐시 정책: LRU, TTL\n순환 참조 주의\n프로파일링: heap dump, memory profiler",
    "references": [],
    "keywords": [
      "threadlocal",
      "weakmap",
      "weakreference",
      "try-with",
      "lru",
      "ttl",
      "메모리",
      "누수",
      "사용하지",
      "않는",
      "메모리를",
      "해제하지",
      "않아",
      "점점",
      "증가"
    ]
  },
  {
    "id": "SD-001",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "메시지(Message)와 이벤트(Event)의 근본적인 차이점은 무엇인가요?",
    "answer": "메시지는 특정 수신자에게 전달되는 데이터로, 발신자가 수신자를 알고 직접 통신합니다. 이벤트는 시스템에서 발생한 사실이며, 발신자는 누가 구독하는지 모릅니다.\n메시지: Point-to-Point, 수신자 지정, 명령(Command) 성격\n이벤트: Publish-Subscribe, 수신자 미지정, 사실(Fact) 성격",
    "references": [
      {
        "title": "Enterprise Integration Patterns",
        "url": "https://www.enterpriseintegrationpatterns.com/patterns/messaging/"
      }
    ],
    "keywords": [
      "point-to-point",
      "command",
      "publish-subscribe",
      "fact",
      "메시지는",
      "특정",
      "수신자에게",
      "전달되는",
      "데이터로",
      "발신자가",
      "수신자를",
      "알고",
      "직접",
      "통신합니다",
      "이벤트는"
    ]
  },
  {
    "id": "SD-002",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "\"메시지는 '지시(Command)'이고 이벤트는 '사실(Fact)'이다\"라는 말에 대해 설명해 보세요.",
    "answer": "Command: \"이것을 해라\"라는 지시. 실패/거부 가능. 예: CreateOrder\n\nEvent: \"이것이 일어났다\"라는 과거 사실. 불변. 예: OrderCreated\n\n이 구분은 시스템의 결합도와 책임 분리에 영향을 줍니다.",
    "references": [
      {
        "title": "Microsoft EDA",
        "url": "https://learn.microsoft.com/en-us/azure/architecture/guide/architecture-styles/event-driven"
      }
    ],
    "keywords": [
      "command",
      "createorder",
      "event",
      "ordercreated",
      "이것을",
      "해라",
      "라는",
      "지시",
      "실패",
      "거부",
      "가능",
      "이것이",
      "일어났다",
      "과거",
      "사실"
    ]
  },
  {
    "id": "SD-003",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "어떤 상황에서 메시지 큐(Message Queue)를 사용하고, 어떤 상황에서 이벤트 브로커/스트림(Event Broker/Stream)을 사용해야 할까요?",
    "answer": "메시지 큐 (RabbitMQ, SQS): 작업 분배, Point-to-Point, 한 번만 처리\n\n이벤트 브로커 (Kafka): 다중 구독자, 이벤트 재처리(replay), 순서 보장, 로그 보존",
    "references": [
      {
        "title": "Kafka Documentation",
        "url": "https://kafka.apache.org/documentation/"
      }
    ],
    "keywords": [
      "rabbitmq",
      "sqs",
      "point-to-point",
      "kafka",
      "메시지",
      "작업",
      "분배",
      "번만",
      "처리",
      "이벤트",
      "브로커",
      "다중",
      "구독자",
      "재처리",
      "순서"
    ]
  },
  {
    "id": "SD-004",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이벤트는 '발신자(Publisher)'가 '수신자(Subscriber)'를 몰라야 한다는 특징이 있습니다. 이것이 시스템 설계에 어떤 이점과 단점을 주나요?",
    "answer": "이점: 느슨한 결합, 독립적 배포, 확장성 향상, 새 구독자 추가 용이\n\n단점: 디버깅 어려움, 이벤트 흐름 추적 복잡, 최종 일관성 관리 필요",
    "references": [
      {
        "title": "Microsoft EDA Guide",
        "url": "https://learn.microsoft.com/en-us/azure/architecture/guide/architecture-styles/event-driven"
      }
    ],
    "keywords": [
      "이점",
      "느슨한",
      "결합",
      "독립적",
      "배포",
      "확장성",
      "향상",
      "구독자",
      "추가",
      "용이",
      "단점",
      "디버깅",
      "어려움",
      "이벤트",
      "흐름"
    ]
  },
  {
    "id": "SD-005",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이벤트 드리븐 아키텍처(EDA)란 무엇이며, 기존의 요청-응답(Request-Response) 모델과 무엇이 다른가요?",
    "answer": "EDA: 이벤트 발생 시 반응하는 비동기 아키텍처. 서비스들이 이벤트를 발행/구독.\n\nRequest-Response: 동기식. 호출자가 응답을 기다림. 강한 결합.\n\n차이점: EDA는 비동기, 느슨한 결합, 확장성 우수. Request-Response는 즉각적 응답, 단순한 흐름.",
    "references": [
      {
        "title": "AWS Event-Driven Architecture",
        "url": "https://aws.amazon.com/event-driven-architecture/"
      }
    ],
    "keywords": [
      "eda",
      "request-response",
      "이벤트",
      "발생",
      "반응하는",
      "비동기",
      "아키텍처",
      "서비스들이",
      "이벤트를",
      "발행",
      "구독",
      "동기식",
      "호출자가",
      "응답을",
      "기다림"
    ]
  },
  {
    "id": "SD-006",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "EDA를 도입했을 때 얻을 수 있는 가장 큰 장점 3가지와 가장 큰 단점 3가지는 무엇인가요?",
    "answer": "장점:\n느슨한 결합 - 서비스 독립성\n확장성 - 이벤트 기반 스케일링\n실시간 반응 - 즉각적인 이벤트 처리\n\n단점:\n복잡성 - 이벤트 흐름 추적 어려움\n최종 일관성 - 강한 일관성 보장 어려움\n디버깅 - 분산 트레이싱 필요",
    "references": [
      {
        "title": "Martin Fowler - Event-Driven",
        "url": "https://martinfowler.com/articles/201701-event-driven.html"
      }
    ],
    "keywords": [
      "장점",
      "느슨한",
      "결합",
      "서비스",
      "독립성",
      "확장성",
      "이벤트",
      "기반",
      "스케일링",
      "실시간",
      "반응",
      "즉각적인",
      "처리",
      "단점",
      "복잡성"
    ]
  },
  {
    "id": "SD-007",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "EDA에서 서비스 간의 데이터 흐름을 관리하는 두 가지 방식, Choreography와 Orchestration을 비교 설명해 주세요.",
    "answer": "Choreography: 각 서비스가 이벤트에 반응하여 독립적으로 동작. 중앙 제어 없음. 분산적.\n\nOrchestration: 중앙 오케스트레이터가 전체 흐름을 제어. 명시적인 워크플로우.\n\n비교   Choreography   Orchestration\n\n결합도   낮음   높음\n가시성   낮음   높음\n복잡도   서비스 증가시 복잡   오케스트레이터에 집중",
    "references": [
      {
        "title": "Microservices.io - Saga",
        "url": "https://microservices.io/patterns/data/saga.html"
      }
    ],
    "keywords": [
      "choreography",
      "orchestration",
      "서비스가",
      "이벤트에",
      "반응하여",
      "독립적으로",
      "동작",
      "중앙",
      "제어",
      "없음",
      "분산적",
      "오케스트레이터가",
      "전체",
      "흐름을",
      "명시적인"
    ]
  },
  {
    "id": "SD-008",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이벤트 브로커(예: Kafka, RabbitMQ)가 다운되면 전체 시스템이 마비될 수 있습니다. 이 SPOF(Single Point of Failure) 문제를 어떻게 해결할 수 있을까요?",
    "answer": "클러스터링: 다중 브로커 노드 구성 (Kafka 클러스터)\n레플리케이션: 파티션 복제 (replication factor)\n다중 데이터센터: 지역 간 복제\nCircuit Breaker: 장애 시 폴백 처리",
    "references": [
      {
        "title": "Kafka Replication",
        "url": "https://kafka.apache.org/documentation/#replication"
      }
    ],
    "keywords": [
      "kafka",
      "circuit",
      "breaker",
      "클러스터링",
      "다중",
      "브로커",
      "노드",
      "구성",
      "클러스터",
      "레플리케이션",
      "파티션",
      "복제",
      "데이터센터",
      "지역",
      "장애"
    ]
  },
  {
    "id": "SD-009",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "메시지/이벤트 전송 보장 레벨인 'At-least-once', 'At-most-once', 'Exactly-once'의 차이점은 무엇인가요?",
    "answer": "At-most-once: 최대 한 번 전송. 유실 가능. 중복 없음.\n\nAt-least-once: 최소 한 번 전송. 유실 없음. 중복 가능.\n\nExactly-once: 정확히 한 번. 유실/중복 없음. 구현 어려움.",
    "references": [
      {
        "title": "Kafka Semantics",
        "url": "https://kafka.apache.org/documentation/#semantics"
      }
    ],
    "keywords": [
      "at-most-once",
      "at-least-once",
      "exactly-once",
      "최대",
      "전송",
      "유실",
      "가능",
      "중복",
      "없음",
      "최소",
      "정확히",
      "구현",
      "어려움"
    ]
  },
  {
    "id": "SD-010",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "EDA에서 'Exactly-once'를 구현하기 어려운 이유는 무엇이며, 이를 위해 어떤 기술(예: Idempotency)이 필요한가요?",
    "answer": "어려운 이유: 네트워크 장애, 프로세스 크래시 시 ACK 유실로 재전송 발생\n\n해결 기술:\nIdempotency: 동일 요청 여러 번 처리해도 같은 결과\nIdempotent Key: 메시지 ID로 중복 체크\nTransactional Outbox: DB 트랜잭션과 이벤트 발행 원자화",
    "references": [
      {
        "title": "Kafka Exactly-Once",
        "url": "https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/"
      }
    ],
    "keywords": [
      "ack",
      "idempotency",
      "idempotent",
      "key",
      "transactional",
      "outbox",
      "어려운",
      "이유",
      "네트워크",
      "장애",
      "프로세스",
      "크래시",
      "유실로",
      "재전송",
      "발생"
    ]
  },
  {
    "id": "SD-011",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이벤트 스키마(Event Schema) 관리는 왜 중요한가요? 스키마가 변경될 때 하위 호환성을 어떻게 보장할 수 있을까요?",
    "answer": "중요성: 프로듀서/컨슈머 간 계약. 스키마 불일치 시 파싱 오류.\n\n하위 호환성 보장:\n새 필드는 optional/default 값 지정\n기존 필드 삭제 금지\nSchema Registry 사용 (Avro, Protobuf)\n버전 관리",
    "references": [
      {
        "title": "Confluent Schema Registry",
        "url": "https://docs.confluent.io/platform/current/schema-registry/"
      }
    ],
    "keywords": [
      "schema",
      "registry",
      "avro",
      "protobuf",
      "중요성",
      "프로듀서",
      "컨슈머",
      "계약",
      "스키마",
      "불일치",
      "파싱",
      "오류",
      "하위",
      "호환성",
      "보장"
    ]
  },
  {
    "id": "SD-012",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이벤트가 불변성(Immutability)을 가져야 하는 이유는 무엇인가요?",
    "answer": "신뢰성: 이미 발생한 사실은 변경 불가\n재처리: 이벤트 replay 시 일관된 결과\n감사 로그: 완전한 히스토리 보존\n동시성: 불변 데이터는 락 불필요",
    "references": [
      {
        "title": "Event Sourcing - Martin Fowler",
        "url": "https://martinfowler.com/eaaDev/EventSourcing.html"
      }
    ],
    "keywords": [
      "신뢰성",
      "이미",
      "발생한",
      "사실은",
      "변경",
      "불가",
      "재처리",
      "이벤트",
      "일관된",
      "결과",
      "감사",
      "로그",
      "완전한",
      "히스토리",
      "보존"
    ]
  },
  {
    "id": "SD-013",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "만약 과거에 발생한 이벤트 데이터에 오류가 있었다면, 불변성 원칙을 지키면서 이 오류를 어떻게 수정(또는 보정)해야 할까요?",
    "answer": "보정 이벤트(Compensating Event) 발행:\n기존 이벤트는 그대로 유지\n새로운 \"수정\" 이벤트 발행 (예: OrderAmountCorrected)\n현재 상태는 모든 이벤트 적용 결과로 계산",
    "references": [
      {
        "title": "Event Sourcing Pattern",
        "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/event-sourcing"
      }
    ],
    "keywords": [
      "compensating",
      "event",
      "orderamountcorrected",
      "보정",
      "이벤트",
      "발행",
      "기존",
      "이벤트는",
      "그대로",
      "유지",
      "새로운",
      "수정",
      "현재",
      "상태는",
      "모든"
    ]
  },
  {
    "id": "SD-014",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "분산 트랜잭션(Distributed Transaction)이 무엇인지, 그리고 왜 필요한지 설명해 주세요.",
    "answer": "정의: 여러 서비스/DB에 걸친 트랜잭션을 원자적으로 처리하는 것\n\n필요성: MSA에서 하나의 비즈니스 로직이 여러 서비스에 분산되어 있을 때, 전체의 일관성을 보장하기 위해 필요",
    "references": [
      {
        "title": "Microservices.io - Distributed Transactions",
        "url": "https://microservices.io/patterns/data/saga.html"
      }
    ],
    "keywords": [
      "msa",
      "정의",
      "여러",
      "서비스",
      "걸친",
      "트랜잭션을",
      "원자적으로",
      "처리하는",
      "필요성",
      "에서",
      "하나의",
      "비즈니스",
      "로직이",
      "서비스에",
      "분산되어"
    ]
  },
  {
    "id": "SD-015",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "전통적인 분산 트랜잭션 기법인 2PC(Two-Phase Commit) 프로토콜에 대해 설명해 주세요.",
    "answer": "Phase 1 (Prepare): 코디네이터가 모든 참여자에게 커밋 준비 요청. 참여자는 준비 완료/실패 응답.\n\nPhase 2 (Commit/Rollback): 모두 준비 완료 시 커밋, 하나라도 실패 시 전체 롤백",
    "references": [
      {
        "title": "2PC Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Two-phase_commit_protocol"
      }
    ],
    "keywords": [
      "phase",
      "prepare",
      "commit",
      "rollback",
      "코디네이터가",
      "모든",
      "참여자에게",
      "커밋",
      "준비",
      "요청",
      "참여자는",
      "완료",
      "실패",
      "응답",
      "모두"
    ]
  },
  {
    "id": "SD-016",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "2PC의 가장 큰 단점(예: 코디네이터 장애, 블로킹)은 무엇이며, 이 때문에 실제 환경에서 잘 사용되지 않는 이유는 무엇인가요?",
    "answer": "단점:\n블로킹: 참여자가 코디네이터 응답 대기 중 락 유지\nSPOF: 코디네이터 장애 시 전체 트랜잭션 중단\n성능: 동기식 통신으로 지연 발생\n확장성 제한: 참여자 증가 시 성능 저하",
    "references": [
      {
        "title": "Designing Data-Intensive Applications",
        "url": "https://dataintensive.net/"
      }
    ],
    "keywords": [
      "spof",
      "단점",
      "블로킹",
      "참여자가",
      "코디네이터",
      "응답",
      "대기",
      "유지",
      "장애",
      "전체",
      "트랜잭션",
      "중단",
      "성능",
      "동기식",
      "통신으로"
    ]
  },
  {
    "id": "SD-017",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "2PC의 대안으로 등장한 SAGA 패턴이 무엇인지, 그리고 2PC와 어떻게 다른지 설명해 주세요.",
    "answer": "SAGA: 로컬 트랜잭션의 시퀀스. 각 단계 실패 시 보상 트랜잭션으로 롤백.\n\n2PC와의 차이:\n비교   2PC   SAGA\n\n일관성   강한 일관성   최종 일관성\n락   글로벌 락   로컬 락\n가용성   낮음   높음",
    "references": [
      {
        "title": "Microservices.io - Saga",
        "url": "https://microservices.io/patterns/data/saga.html"
      }
    ],
    "keywords": [
      "saga",
      "로컬",
      "트랜잭션의",
      "시퀀스",
      "단계",
      "실패",
      "보상",
      "트랜잭션으로",
      "롤백",
      "와의",
      "차이",
      "비교",
      "일관성",
      "강한",
      "최종"
    ]
  },
  {
    "id": "SD-018",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "SAGA의 핵심 구성요소인 '보상 트랜잭션(Compensating Transaction)'이란 무엇이며, 이를 설계할 때 가장 중요하게 고려해야 할 점은 무엇인가요?",
    "answer": "정의: 이전 트랜잭션의 효과를 취소하는 트랜잭션\n\n설계 고려사항:\n멱등성: 여러 번 실행해도 같은 결과\n가역성: 모든 작업이 취소 가능해야 함\n순서: 역순으로 실행",
    "references": [
      {
        "title": "AWS SAGA Pattern",
        "url": "https://docs.aws.amazon.com/prescriptive-guidance/latest/modernization-data-persistence/saga-pattern.html"
      }
    ],
    "keywords": [
      "정의",
      "이전",
      "트랜잭션의",
      "효과를",
      "취소하는",
      "트랜잭션",
      "설계",
      "고려사항",
      "멱등성",
      "여러",
      "실행해도",
      "같은",
      "결과",
      "가역성",
      "모든"
    ]
  },
  {
    "id": "SD-019",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "보상 트랜잭션 자체가 실패하면 어떻게 해야 하나요?",
    "answer": "재시도: 지수 백오프로 재시도\nDead Letter Queue: 실패한 보상 작업 저장\n수동 개입: 운영자 알림 및 수동 처리\nForward Recovery: 이전 상태로 되돌리는 대신 앞으로 진행",
    "references": [
      {
        "title": "Microservices Patterns - Chris Richardson",
        "url": "https://microservices.io/book"
      }
    ],
    "keywords": [
      "dead",
      "letter",
      "queue",
      "forward",
      "recovery",
      "재시도",
      "지수",
      "백오프로",
      "실패한",
      "보상",
      "작업",
      "저장",
      "수동",
      "개입",
      "운영자"
    ]
  },
  {
    "id": "SD-020",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "SAGA 패턴에서 발생하는 '중간 상태(intermediate state)'란 무엇을 의미하나요?",
    "answer": "정의: SAGA 진행 중 일부 서비스는 커밋되고 일부는 아직 처리 중인 상태\n\n예시: 주문 서비스는 주문 생성 완료, 결제 서비스는 아직 처리 중\n\n특징: 외부에서 볼 때 일관성이 깨진 것처럼 보임",
    "references": [
      {
        "title": "SAGA Pattern",
        "url": "https://microservices.io/patterns/data/saga.html"
      }
    ],
    "keywords": [
      "saga",
      "정의",
      "진행",
      "일부",
      "서비스는",
      "커밋되고",
      "일부는",
      "아직",
      "처리",
      "중인",
      "상태",
      "예시",
      "주문",
      "생성",
      "완료"
    ]
  },
  {
    "id": "SD-021",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이 '중간 상태'가 비즈니스 로직이나 사용자 경험(UX)에 어떤 문제를 일으킬 수 있으며, 이를 어떻게 처리해야 할까요?",
    "answer": "문제:\n사용자 혼란 (주문은 됐는데 결제 상태 불명)\n잘못된 데이터 조회\n\n해결책:\n상태 표시: \"처리 중\" 상태 명시\nSemantic Lock: 리소스를 \"예약\" 상태로 표시\n읽기 격리: 완료된 SAGA만 조회 가능",
    "references": [
      {
        "title": "Chris Richardson - Managing Data Consistency",
        "url": "https://chrisrichardson.net/post/microservices/2019/07/09/developing-sagas-part-1.html"
      }
    ],
    "keywords": [
      "semantic",
      "lock",
      "saga",
      "문제",
      "사용자",
      "혼란",
      "주문은",
      "됐는데",
      "결제",
      "상태",
      "불명",
      "잘못된",
      "데이터",
      "조회",
      "해결책"
    ]
  },
  {
    "id": "SD-022",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "SAGA를 구현하는 두 가지 방식, 'Choreography'와 'Orchestration'을 비교 설명하고, 각각의 장단점을 논해주세요.",
    "answer": "Choreography: 각 서비스가 이벤트 발행/구독으로 자율 협력\n\nOrchestration: 중앙 오케스트레이터가 순서 제어\n\n비교   Choreography   Orchestration\n\n장점   느슨한 결합   명확한 흐름\n단점   흐름 파악 어려움   오케스트레이터 SPOF\n적합   단순 흐름   복잡한 워크플로우",
    "references": [
      {
        "title": "Microservices.io - SAGA",
        "url": "https://microservices.io/patterns/data/saga.html"
      }
    ],
    "keywords": [
      "choreography",
      "orchestration",
      "spof",
      "서비스가",
      "이벤트",
      "발행",
      "구독으로",
      "자율",
      "협력",
      "중앙",
      "오케스트레이터가",
      "순서",
      "제어",
      "비교",
      "장점"
    ]
  },
  {
    "id": "SD-023",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이벤트 소싱(Event Sourcing) 패턴이 무엇인지 설명해 주세요.",
    "answer": "정의: 상태를 직접 저장하지 않고, 상태 변경 이벤트를 순서대로 저장하는 패턴\n\n특징:\n모든 변경 히스토리 보존\n현재 상태 = 이벤트 순차 적용 결과\n감사 로그 자동 생성",
    "references": [
      {
        "title": "Martin Fowler - Event Sourcing",
        "url": "https://martinfowler.com/eaaDev/EventSourcing.html"
      }
    ],
    "keywords": [
      "정의",
      "상태를",
      "직접",
      "저장하지",
      "않고",
      "상태",
      "변경",
      "이벤트를",
      "순서대로",
      "저장하는",
      "패턴",
      "특징",
      "모든",
      "히스토리",
      "보존"
    ]
  },
  {
    "id": "SD-024",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이벤트 소싱에서 '현재 상태(Current State)'는 어떻게 계산하나요?",
    "answer": "방법: 해당 엔티티의 모든 이벤트를 처음부터 순서대로 재생(replay)하여 현재 상태 계산\n\n최적화: 스냅샷을 주기적으로 저장하여 전체 재생 방지",
    "references": [
      {
        "title": "Event Store Documentation",
        "url": "https://www.eventstore.com/event-sourcing"
      }
    ],
    "keywords": [
      "방법",
      "해당",
      "엔티티의",
      "모든",
      "이벤트를",
      "처음부터",
      "순서대로",
      "재생",
      "하여",
      "현재",
      "상태",
      "계산",
      "최적화",
      "스냅샷을",
      "주기적으로"
    ]
  },
  {
    "id": "SD-025",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이벤트 소싱을 사용하면 얻을 수 있는 장점(예: 감사 로그, 시간 여행)은 무엇인가요?",
    "answer": "완전한 감사 로그: 모든 변경 이력 보존\n시간 여행: 특정 시점의 상태 재구성\n디버깅: 문제 발생 시점 추적 용이\n이벤트 재처리: 새로운 뷰 생성 가능\n버그 수정: 과거 이벤트 재처리로 데이터 복구",
    "references": [
      {
        "title": "Microsoft Event Sourcing",
        "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/event-sourcing"
      }
    ],
    "keywords": [
      "완전한",
      "감사",
      "로그",
      "모든",
      "변경",
      "이력",
      "보존",
      "시간",
      "여행",
      "특정",
      "시점의",
      "상태",
      "재구성",
      "디버깅",
      "문제"
    ]
  },
  {
    "id": "SD-026",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이벤트 소싱의 단점, 특히 이벤트가 누적될수록 '현재 상태'를 재구성하는 성능 문제를 어떻게 해결할 수 있나요?",
    "answer": "스냅샷(Snapshot): 특정 시점의 상태를 저장\n\n동작: 스냅샷 이후 이벤트만 재생하여 현재 상태 계산",
    "references": [
      {
        "title": "Event Sourcing Snapshots",
        "url": "https://www.eventstore.com/blog/snapshots-in-event-sourcing"
      }
    ],
    "keywords": [
      "snapshot",
      "스냅샷",
      "특정",
      "시점의",
      "상태를",
      "저장",
      "동작",
      "이후",
      "이벤트만",
      "재생하여",
      "현재",
      "상태",
      "계산"
    ]
  },
  {
    "id": "SD-027",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "스냅샷(Snapshot)의 생성 주기(frequency)는 어떻게 결정하는 것이 좋을까요?",
    "answer": "기준:\n이벤트 수 기반: N개 이벤트마다 (예: 100개)\n시간 기반: 주기적 (예: 매일)\n성능 기반: 재생 시간이 임계치 초과 시\n\n트레이드오프: 저장 공간 vs 읽기 성능",
    "references": [
      {
        "title": "Axon Framework - Snapshotting",
        "url": "https://docs.axoniq.io/reference-guide/axon-framework/tuning/event-snapshots"
      }
    ],
    "keywords": [
      "기준",
      "이벤트",
      "기반",
      "이벤트마다",
      "시간",
      "주기적",
      "매일",
      "성능",
      "재생",
      "시간이",
      "임계치",
      "초과",
      "트레이드오프",
      "저장",
      "공간"
    ]
  },
  {
    "id": "SD-028",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "서비스 로직에서 'DB 트랜잭션'과 '이벤트 발행'을 원자적으로 묶고 싶을 때(Dual-write 문제) 어떻게 해야 할까요?",
    "answer": "Dual-write 문제: DB 저장 성공 후 이벤트 발행 실패 시 불일치\n\n해결책:\nTransactional Outbox: 같은 트랜잭션에서 Outbox 테이블에 이벤트 저장\nEvent Sourcing: 이벤트 자체가 원본 데이터\nCDC (Change Data Capture): DB 변경을 캡처하여 이벤트 발행",
    "references": [
      {
        "title": "Microservices.io - Transactional Outbox",
        "url": "https://microservices.io/patterns/data/transactional-outbox.html"
      }
    ],
    "keywords": [
      "dual-write",
      "transactional",
      "outbox",
      "event",
      "sourcing",
      "cdc",
      "change",
      "data",
      "capture",
      "문제",
      "저장",
      "성공",
      "이벤트",
      "발행",
      "실패"
    ]
  },
  {
    "id": "SD-029",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이 문제를 해결하기 위한 'Transactional Outbox' 패턴에 대해 설명해 주세요.",
    "answer": "동작:\n비즈니스 데이터와 이벤트를 같은 DB 트랜잭션에서 저장\n이벤트는 Outbox 테이블에 저장\n별도 프로세스가 Outbox에서 이벤트를 읽어 브로커에 발행\n발행 완료 후 Outbox 레코드 삭제/마킹",
    "references": [
      {
        "title": "Debezium Outbox",
        "url": "https://debezium.io/documentation/reference/transformations/outbox-event-router.html"
      }
    ],
    "keywords": [
      "outbox",
      "동작",
      "비즈니스",
      "데이터와",
      "이벤트를",
      "같은",
      "트랜잭션에서",
      "저장",
      "이벤트는",
      "테이블에",
      "별도",
      "프로세스가",
      "에서",
      "읽어",
      "브로커에"
    ]
  },
  {
    "id": "SD-030",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "Outbox 패턴을 사용할 때, DB Outbox 테이블에 저장된 이벤트를 어떻게 안정적으로 이벤트 브로커에게 전달할 수 있을까요?",
    "answer": "방법 1: Polling Publisher\n주기적으로 Outbox 테이블 조회\n미발행 이벤트 전송 후 상태 업데이트\n\n방법 2: CDC (Change Data Capture)\nDB 트랜잭션 로그를 캡처 (Debezium)\n실시간으로 이벤트 브로커에 전달",
    "references": [
      {
        "title": "Debezium Documentation",
        "url": "https://debezium.io/documentation/"
      }
    ],
    "keywords": [
      "polling",
      "publisher",
      "outbox",
      "cdc",
      "change",
      "data",
      "capture",
      "debezium",
      "방법",
      "주기적으로",
      "테이블",
      "조회",
      "미발행",
      "이벤트",
      "전송"
    ]
  },
  {
    "id": "SD-031",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "CQRS 패턴이 무엇인지 CQS(Command Query Separation) 원칙과 비교하여 설명해 주세요.",
    "answer": "CQS (원칙): 메서드는 Command(상태 변경) 또는 Query(데이터 반환) 중 하나만 수행\n\nCQRS (패턴): 읽기와 쓰기 모델을 완전히 분리하여 다른 저장소/모델 사용\n\n차이: CQS는 메서드 레벨, CQRS는 시스템 아키텍처 레벨",
    "references": [
      {
        "title": "Martin Fowler - CQRS",
        "url": "https://martinfowler.com/bliki/CQRS.html"
      }
    ],
    "keywords": [
      "cqs",
      "command",
      "query",
      "cqrs",
      "원칙",
      "메서드는",
      "상태",
      "변경",
      "데이터",
      "반환",
      "하나만",
      "수행",
      "패턴",
      "읽기와",
      "쓰기"
    ]
  },
  {
    "id": "SD-032",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "CQRS를 사용하는 가장 주된 이유는 무엇인가요?",
    "answer": "읽기/쓰기 최적화: 각각에 맞는 데이터 모델 사용\n확장성: 읽기/쓰기 독립적 스케일링\n복잡한 도메인: 쓰기는 도메인 모델, 읽기는 단순 DTO\n성능: 읽기에 비정규화된 뷰 사용",
    "references": [
      {
        "title": "Microsoft CQRS",
        "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cqrs"
      }
    ],
    "keywords": [
      "dto",
      "읽기",
      "쓰기",
      "최적화",
      "각각에",
      "맞는",
      "데이터",
      "모델",
      "사용",
      "확장성",
      "독립적",
      "스케일링",
      "복잡한",
      "도메인",
      "쓰기는"
    ]
  },
  {
    "id": "SD-033",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "CQRS 패턴을 도입하면 시스템이 어떻게 복잡해지나요?",
    "answer": "코드 중복: 읽기/쓰기 모델 각각 구현\n동기화: Command → Query 모델 동기화 로직 필요\n최종 일관성: 즉각적 일관성 보장 어려움\n인프라: 별도 저장소 운영 비용",
    "references": [
      {
        "title": "CQRS Journey",
        "url": "https://learn.microsoft.com/en-us/previous-versions/msp-n-p/jj554200(v=pandp.10"
      }
    ],
    "keywords": [
      "command",
      "query",
      "코드",
      "중복",
      "읽기",
      "쓰기",
      "모델",
      "각각",
      "구현",
      "동기화",
      "로직",
      "필요",
      "최종",
      "일관성",
      "즉각적"
    ]
  },
  {
    "id": "SD-034",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "CQRS에서 'Command 모델'과 'Query 모델'의 데이터 동기화는 어떻게 이루어지나요?",
    "answer": "이벤트 기반 동기화:\nCommand 모델에서 상태 변경 후 이벤트 발행\nQuery 모델이 이벤트 구독하여 뷰 업데이트\n\n동기화 방식:\n비동기: 이벤트 브로커 통해 전달\n동기: 같은 트랜잭션에서 양쪽 업데이트 (권장 X)",
    "references": [
      {
        "title": "CQRS Pattern",
        "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cqrs"
      }
    ],
    "keywords": [
      "command",
      "query",
      "이벤트",
      "기반",
      "동기화",
      "모델에서",
      "상태",
      "변경",
      "발행",
      "모델이",
      "구독하여",
      "업데이트",
      "방식",
      "비동기",
      "브로커"
    ]
  },
  {
    "id": "SD-035",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이 동기화 과정에서 발생하는 '지연(lag)'으로 인해 '최종 일관성(Eventual Consistency)'이 나타납니다. 이 문제를 어떻게 처리해야 할까요?",
    "answer": "UI 낙관적 업데이트: 쓰기 후 UI에서 바로 반영\nRead-your-writes: 쓴 사용자는 자신의 변경 즉시 조회\nPolling/WebSocket: 동기화 완료 시 알림\n버전 체크: 데이터 버전으로 최신 여부 확인",
    "references": [
      {
        "title": "Eventual Consistency",
        "url": "https://www.allthingsdistributed.com/2008/12/eventually_consistent.html"
      }
    ],
    "keywords": [
      "read-your-writes",
      "polling",
      "websocket",
      "낙관적",
      "업데이트",
      "쓰기",
      "에서",
      "바로",
      "반영",
      "사용자는",
      "자신의",
      "변경",
      "즉시",
      "조회",
      "동기화"
    ]
  },
  {
    "id": "SD-036",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "CQRS에서 'Query 모델(Read Model)'은 어떤 기술을 사용해 구현하는 것이 좋을까요?",
    "answer": "용도별 선택:\n단순 조회: RDB (PostgreSQL)\n전문 검색: Elasticsearch\n캐싱: Redis\n복잡한 쿼리: MongoDB\n분석: ClickHouse, BigQuery\n\n핵심: 읽기 패턴에 최적화된 기술 선택",
    "references": [
      {
        "title": "Polyglot Persistence",
        "url": "https://martinfowler.com/bliki/PolyglotPersistence.html"
      }
    ],
    "keywords": [
      "rdb",
      "postgresql",
      "elasticsearch",
      "redis",
      "mongodb",
      "clickhouse",
      "bigquery",
      "용도별",
      "선택",
      "단순",
      "조회",
      "전문",
      "검색",
      "캐싱",
      "복잡한"
    ]
  },
  {
    "id": "SD-037",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "모든 시스템에 CQRS를 적용하는 것이 좋을까요? 어떤 경우에 CQRS가 적합하고, 어떤 경우에 부적합할까요?",
    "answer": "적합한 경우:\n읽기/쓰기 비율 차이가 큰 경우\n복잡한 도메인 모델\n높은 확장성 요구\n\n부적합한 경우:\n단순 CRUD 애플리케이션\n강한 일관성이 필수인 경우\n소규모 팀/프로젝트",
    "references": [
      {
        "title": "When to use CQRS",
        "url": "https://martinfowler.com/bliki/CQRS.html"
      }
    ],
    "keywords": [
      "crud",
      "적합한",
      "읽기",
      "쓰기",
      "비율",
      "차이가",
      "복잡한",
      "도메인",
      "모델",
      "높은",
      "확장성",
      "요구",
      "부적합한",
      "단순",
      "애플리케이션"
    ]
  },
  {
    "id": "SD-038",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "\"CQRS는 이벤트 소싱이 아니다\"라는 말에 대해 어떻게 생각하시나요? 둘의 관계를 설명해 주세요.",
    "answer": "독립적 패턴: CQRS와 Event Sourcing은 별개의 패턴\nCQRS만: 읽기/쓰기 분리, 일반 DB 사용 가능\nEvent Sourcing만: 이벤트 저장, 단일 모델 가능\n함께 사용: 시너지 효과",
    "references": [
      {
        "title": "Greg Young - CQRS and Event Sourcing",
        "url": "https://cqrs.files.wordpress.com/2010/11/cqrs_documents.pdf"
      }
    ],
    "keywords": [
      "cqrs",
      "event",
      "sourcing",
      "독립적",
      "패턴",
      "별개의",
      "읽기",
      "쓰기",
      "분리",
      "일반",
      "사용",
      "가능",
      "이벤트",
      "저장",
      "단일"
    ]
  },
  {
    "id": "SD-039",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "CQRS와 이벤트 소싱을 함께 사용할 때 얻을 수 있는 시너지는 무엇인가요?",
    "answer": "자연스러운 동기화: 이벤트가 Query 모델 업데이트 트리거\n다양한 뷰: 같은 이벤트로 여러 Query 모델 구축\n시간 여행 쿼리: 과거 시점의 Read Model 재구성\n이벤트 재처리: 새로운 Read Model 추가 용이",
    "references": [
      {
        "title": "Event Sourcing + CQRS",
        "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/event-sourcing"
      }
    ],
    "keywords": [
      "query",
      "read",
      "model",
      "자연스러운",
      "동기화",
      "이벤트가",
      "모델",
      "업데이트",
      "트리거",
      "다양한",
      "같은",
      "이벤트로",
      "여러",
      "구축",
      "시간"
    ]
  },
  {
    "id": "SD-040",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "데이터베이스 샤딩(Sharding)이 무엇이며, 왜 필요한가요?",
    "answer": "정의: 데이터를 여러 DB 인스턴스에 수평 분할하여 저장\n\n필요성:\n단일 DB의 용량/성능 한계 극복\n읽기/쓰기 부하 분산\n수평적 확장(Scale-out)",
    "references": [
      {
        "title": "MongoDB Sharding",
        "url": "https://www.mongodb.com/docs/manual/sharding/"
      }
    ],
    "keywords": [
      "scale-out",
      "정의",
      "데이터를",
      "여러",
      "인스턴스에",
      "수평",
      "분할하여",
      "저장",
      "필요성",
      "단일",
      "용량",
      "성능",
      "한계",
      "극복",
      "읽기"
    ]
  },
  {
    "id": "SD-041",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "샤딩(Sharding)과 파티셔닝(Partitioning)의 차이점은 무엇인가요?",
    "answer": "파티셔닝: 단일 DB 인스턴스 내에서 테이블을 논리적으로 분할\n\n샤딩: 여러 물리적 DB 인스턴스에 데이터 분산\n\n비교   파티셔닝   샤딩\n\n범위   단일 DB   다중 DB\n확장   수직   수평\n복잡도   낮음   높음",
    "references": [
      {
        "title": "PostgreSQL Partitioning",
        "url": "https://www.postgresql.org/docs/current/ddl-partitioning.html"
      }
    ],
    "keywords": [
      "파티셔닝",
      "단일",
      "인스턴스",
      "내에서",
      "테이블을",
      "논리적으로",
      "분할",
      "샤딩",
      "여러",
      "물리적",
      "인스턴스에",
      "데이터",
      "분산",
      "비교",
      "범위"
    ]
  },
  {
    "id": "SD-042",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "수직 샤딩(Vertical Sharding)과 수평 샤딩(Horizontal Sharding)을 비교 설명해 주세요.",
    "answer": "수직 샤딩: 테이블/컬럼 단위로 분리 (예: 사용자 테이블은 DB1, 주문 테이블은 DB2)\n\n수평 샤딩: 행(row) 단위로 분리 (예: user_id 1-1000은 DB1, 1001-2000은 DB2)\n\n비교   수직   수평\n\n분리 단위   테이블/컬럼   행\n확장성   제한적   무한\n복잡도   낮음   높음",
    "references": [
      {
        "title": "Vitess Sharding",
        "url": "https://vitess.io/docs/concepts/shard/"
      }
    ],
    "keywords": [
      "db1",
      "db2",
      "user_id",
      "수직",
      "샤딩",
      "테이블",
      "컬럼",
      "단위로",
      "분리",
      "사용자",
      "테이블은",
      "주문",
      "수평",
      "비교",
      "단위"
    ]
  },
  {
    "id": "SD-043",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "언제 수평 샤딩을 선택하고, 언제 수직 샤딩을 선택해야 할까요?",
    "answer": "수직 샤딩 선택:\n특정 테이블만 부하가 높을 때\n도메인별 분리가 명확할 때\n초기 단계 확장\n\n수평 샤딩 선택:\n단일 테이블의 데이터가 매우 클 때\n무한 확장이 필요할 때\n균등한 부하 분산 필요",
    "references": [
      {
        "title": "System Design Primer - Sharding",
        "url": "https://github.com/donnemartin/system-design-primer#sharding"
      }
    ],
    "keywords": [
      "수직",
      "샤딩",
      "선택",
      "특정",
      "테이블만",
      "부하가",
      "높을",
      "도메인별",
      "분리가",
      "명확할",
      "초기",
      "단계",
      "확장",
      "수평",
      "단일"
    ]
  },
  {
    "id": "SD-044",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "샤딩 키(Shard Key)를 선정할 때 가장 중요하게 고려해야 할 기준은 무엇인가요?",
    "answer": "카디널리티: 충분히 다양한 값 (균등 분포)\n쿼리 패턴: 자주 사용되는 조회 조건\n데이터 분포: 균등한 데이터 분산\n불변성: 변경되지 않는 값",
    "references": [
      {
        "title": "MongoDB Shard Key",
        "url": "https://www.mongodb.com/docs/manual/core/sharding-shard-key/"
      }
    ],
    "keywords": [
      "카디널리티",
      "충분히",
      "다양한",
      "균등",
      "분포",
      "쿼리",
      "패턴",
      "자주",
      "사용되는",
      "조회",
      "조건",
      "데이터",
      "균등한",
      "분산",
      "불변성"
    ]
  },
  {
    "id": "SD-045",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "샤딩 키를 잘못 선정하면 어떤 문제가 발생할 수 있나요?",
    "answer": "Hotspot: 특정 샤드에 트래픽 집중\n불균형 데이터: 샤드 간 데이터 크기 불균형\nCross-shard 쿼리 증가: 샤드 키 없는 쿼리 성능 저하\n리샤딩 비용: 키 변경 시 전체 데이터 마이그레이션",
    "references": [
      {
        "title": "Cassandra Data Modeling",
        "url": "https://cassandra.apache.org/doc/latest/cassandra/data_modeling/"
      }
    ],
    "keywords": [
      "hotspot",
      "cross-shard",
      "특정",
      "샤드에",
      "트래픽",
      "집중",
      "불균형",
      "데이터",
      "샤드",
      "크기",
      "쿼리",
      "증가",
      "없는",
      "성능",
      "저하"
    ]
  },
  {
    "id": "SD-046",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "특정 샤드에만 데이터가 몰리는 '핫스팟' 문제를 완화하기 위한 전략에는 무엇이 있을까요?",
    "answer": "복합 샤드 키: 여러 필드 조합\n해시 샤딩: 키를 해시하여 분산\nSalt 추가: 키에 랜덤 값 추가\n시간 기반 분산: 타임스탬프에 랜덤 요소 추가",
    "references": [
      {
        "title": "DynamoDB Best Practices",
        "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-partition-key-design.html"
      }
    ],
    "keywords": [
      "salt",
      "복합",
      "샤드",
      "여러",
      "필드",
      "조합",
      "해시",
      "샤딩",
      "키를",
      "해시하여",
      "분산",
      "추가",
      "키에",
      "랜덤",
      "시간"
    ]
  },
  {
    "id": "SD-047",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "대표적인 샤딩 전략 3가지(Range, Hash, Directory-based)를 설명하고 장단점을 비교해 주세요.",
    "answer": "Range Sharding: 키 범위로 분할\n장점: 범위 쿼리 효율적\n단점: Hotspot 발생 가능\n\nHash Sharding: 해시 값으로 분할\n장점: 균등 분산\n단점: 범위 쿼리 비효율\n\nDirectory-based: 룩업 테이블로 매핑\n장점: 유연한 분배\n단점: 룩업 테이블이 SPOF",
    "references": [
      {
        "title": "Sharding Strategies",
        "url": "https://www.mongodb.com/docs/manual/sharding/"
      }
    ],
    "keywords": [
      "range",
      "sharding",
      "hotspot",
      "hash",
      "directory-based",
      "spof",
      "범위로",
      "분할",
      "장점",
      "범위",
      "쿼리",
      "효율적",
      "단점",
      "발생",
      "가능"
    ]
  },
  {
    "id": "SD-048",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "MongoDB는 샤딩을 어떻게 구현하나요? 'mongos', 'config server', 'shard'의 역할을 설명해 주세요.",
    "answer": "mongos: 쿼리 라우터. 클라이언트 요청을 적절한 샤드로 전달\n\nConfig Server: 메타데이터 저장. 샤드 키 범위, 청크 위치 정보\n\nShard: 실제 데이터 저장. 각 샤드는 레플리카 셋",
    "references": [
      {
        "title": "MongoDB Sharded Cluster",
        "url": "https://www.mongodb.com/docs/manual/sharding/"
      }
    ],
    "keywords": [
      "config",
      "server",
      "shard",
      "쿼리",
      "라우터",
      "클라이언트",
      "요청을",
      "적절한",
      "샤드로",
      "전달",
      "메타데이터",
      "저장",
      "샤드",
      "범위",
      "청크"
    ]
  },
  {
    "id": "SD-049",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "(MongoDB) '청크(Chunk)'란 무엇이며, '밸런서(Balancer)'는 어떤 역할을 하나요?",
    "answer": "청크: 연속된 샤드 키 범위의 데이터 집합. 기본 128MB\n\n밸런서: 백그라운드 프로세스\n샤드 간 청크 균등 분배\n청크 분할 (split) 및 마이그레이션",
    "references": [
      {
        "title": "MongoDB Balancer",
        "url": "https://www.mongodb.com/docs/manual/core/sharding-balancer-administration/"
      }
    ],
    "keywords": [
      "청크",
      "연속된",
      "샤드",
      "범위의",
      "데이터",
      "집합",
      "기본",
      "밸런서",
      "백그라운드",
      "프로세스",
      "균등",
      "분배",
      "분할",
      "마이그레이션",
      "split"
    ]
  },
  {
    "id": "SD-050",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "Elasticsearch는 샤딩을 어떻게 구현하나요? '인덱스', '샤드', '레플리카'의 관계를 설명해 주세요.",
    "answer": "인덱스: 문서의 논리적 컨테이너\n\n샤드: 인덱스를 물리적으로 분할한 단위 (Primary Shard)\n\n레플리카: 샤드의 복제본. 가용성과 읽기 성능 향상",
    "references": [
      {
        "title": "Elasticsearch Shards",
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/scalability.html"
      }
    ],
    "keywords": [
      "primary",
      "shard",
      "인덱스",
      "문서의",
      "논리적",
      "컨테이너",
      "샤드",
      "인덱스를",
      "물리적으로",
      "분할한",
      "단위",
      "레플리카",
      "샤드의",
      "복제본",
      "가용성과"
    ]
  },
  {
    "id": "SD-051",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "Cassandra와 같은 Dynamo-style DB는 '샤딩'이라는 용어 대신 '파티셔닝'을 사용합니다. Cassandra의 데이터 분산 방식(Consistent Hashing)에 대해 설명해 주세요.",
    "answer": "Consistent Hashing:\n해시 링(Ring)에 노드 배치\n파티션 키 해시 → 링에서 시계방향으로 다음 노드에 저장\n노드 추가/제거 시 영향 범위 최소화\n\n장점: 노드 변경 시 일부 데이터만 재분배",
    "references": [
      {
        "title": "Cassandra Architecture",
        "url": "https://cassandra.apache.org/doc/latest/cassandra/architecture/"
      }
    ],
    "keywords": [
      "consistent",
      "hashing",
      "ring",
      "해시",
      "노드",
      "배치",
      "파티션",
      "링에서",
      "시계방향으로",
      "다음",
      "노드에",
      "저장",
      "추가",
      "제거",
      "영향"
    ]
  },
  {
    "id": "SD-052",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "(Cassandra) '가상 노드(Virtual Nodes)'가 왜 필요한가요?",
    "answer": "문제: 물리 노드만 사용 시 불균등한 데이터 분포\n\nVnode 해결책:\n각 물리 노드가 여러 가상 노드 담당\n기본 256개 vnode per 물리 노드\n균등한 데이터 분포 보장\n노드 추가/제거 시 부하 분산",
    "references": [
      {
        "title": "Cassandra Virtual Nodes",
        "url": "https://cassandra.apache.org/doc/latest/cassandra/architecture/dynamo.html#virtual-nodes"
      }
    ],
    "keywords": [
      "vnode",
      "문제",
      "물리",
      "노드만",
      "사용",
      "불균등한",
      "데이터",
      "분포",
      "해결책",
      "노드가",
      "여러",
      "가상",
      "노드",
      "담당",
      "기본"
    ]
  },
  {
    "id": "SD-053",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "Vitess나 Citus와 같이 RDBMS를 샤딩해주는 미들웨어는 어떤 원리로 동작하나요?",
    "answer": "동작 원리:\n쿼리 라우팅: SQL 파싱 후 적절한 샤드로 전달\n결과 병합: 여러 샤드 결과 조합\n스키마 관리: 샤드 간 일관된 스키마 유지\n연결 풀링: 백엔드 DB 연결 관리",
    "references": [
      {
        "title": "Vitess Architecture",
        "url": "https://vitess.io/docs/concepts/vtgate/"
      }
    ],
    "keywords": [
      "sql",
      "동작",
      "원리",
      "쿼리",
      "라우팅",
      "파싱",
      "적절한",
      "샤드로",
      "전달",
      "결과",
      "병합",
      "여러",
      "샤드",
      "조합",
      "스키마"
    ]
  },
  {
    "id": "SD-054",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "샤딩된 환경에서 여러 샤드에 걸친 쿼리(Cross-shard query)는 어떻게 처리해야 하며, 어떤 성능 문제가 있을까요?",
    "answer": "처리 방법:\nScatter-Gather: 모든 샤드에 쿼리 후 결과 병합\n\n성능 문제:\n네트워크 지연 증가\n가장 느린 샤드에 종속\n메모리 사용량 증가 (결과 병합)\n\n최적화: 샤드 키 포함 쿼리 유도",
    "references": [
      {
        "title": "Vitess Query Serving",
        "url": "https://vitess.io/docs/concepts/query-serving/"
      }
    ],
    "keywords": [
      "scatter-gather",
      "처리",
      "방법",
      "모든",
      "샤드에",
      "쿼리",
      "결과",
      "병합",
      "성능",
      "문제",
      "네트워크",
      "지연",
      "증가",
      "가장",
      "느린"
    ]
  },
  {
    "id": "SD-055",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "샤딩된 환경에서 'JOIN' 연산은 어떻게 수행해야 할까요?",
    "answer": "방법:\nCo-location: 관련 데이터를 같은 샤드에 배치\n애플리케이션 레벨 JOIN: 별도 쿼리 후 앱에서 조합\n브로드캐스트 조인: 작은 테이블 전체 복제\n비정규화: JOIN 불필요하게 데이터 구조 변경",
    "references": [
      {
        "title": "CockroachDB Joins",
        "url": "https://www.cockroachlabs.com/docs/stable/joins.html"
      }
    ],
    "keywords": [
      "co-location",
      "join",
      "방법",
      "관련",
      "데이터를",
      "같은",
      "샤드에",
      "배치",
      "애플리케이션",
      "레벨",
      "별도",
      "쿼리",
      "앱에서",
      "조합",
      "브로드캐스트"
    ]
  },
  {
    "id": "SD-056",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "샤딩된 환경에서 '트랜잭션'은 어떻게 처리해야 할까요? (SAGA와의 연관성)",
    "answer": "단일 샤드: 로컬 트랜잭션 사용\n\nCross-shard:\n2PC: 분산 트랜잭션 (성능 저하)\nSAGA: 보상 트랜잭션으로 최종 일관성\n설계로 회피: 관련 데이터 같은 샤드 배치",
    "references": [
      {
        "title": "Spanner Transactions",
        "url": "https://cloud.google.com/spanner/docs/transactions"
      }
    ],
    "keywords": [
      "cross-shard",
      "saga",
      "단일",
      "샤드",
      "로컬",
      "트랜잭션",
      "사용",
      "분산",
      "성능",
      "저하",
      "보상",
      "트랜잭션으로",
      "최종",
      "일관성",
      "설계로"
    ]
  },
  {
    "id": "SD-057",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "리샤딩(Resharding)은 무엇이며, 언제 필요한가요?",
    "answer": "정의: 샤드 수 변경 또는 샤딩 전략 변경으로 데이터 재분배\n\n필요 시점:\n샤드 용량 한계 도달\nHotspot 해결\n샤드 키 변경\n노드 추가/제거",
    "references": [
      {
        "title": "MongoDB Resharding",
        "url": "https://www.mongodb.com/docs/manual/core/sharding-reshard-a-collection/"
      }
    ],
    "keywords": [
      "hotspot",
      "정의",
      "샤드",
      "변경",
      "샤딩",
      "전략",
      "변경으로",
      "데이터",
      "재분배",
      "필요",
      "시점",
      "용량",
      "한계",
      "도달",
      "해결"
    ]
  },
  {
    "id": "SD-058",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "시스템 다운타임 없이 리샤딩을 수행하는 방법에 대해 설명해 주세요.",
    "answer": "온라인 리샤딩 단계:\n이중 쓰기: 기존/신규 샤드에 동시 쓰기\n백필: 기존 데이터를 신규 샤드로 복사\n검증: 데이터 일관성 확인\n트래픽 전환: 읽기를 신규 샤드로 전환\n정리: 기존 샤드 데이터 삭제",
    "references": [
      {
        "title": "Stripe Online Migrations",
        "url": "https://stripe.com/blog/online-migrations"
      }
    ],
    "keywords": [
      "온라인",
      "리샤딩",
      "단계",
      "이중",
      "쓰기",
      "기존",
      "신규",
      "샤드에",
      "동시",
      "백필",
      "데이터를",
      "샤드로",
      "복사",
      "검증",
      "데이터"
    ]
  },
  {
    "id": "SD-059",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "CAP 이론(Theorem)에 대해 설명해 주세요. (Consistency, Availability, Partition Tolerance)",
    "answer": "C (Consistency): 모든 노드가 동일한 데이터를 반환\n\nA (Availability): 모든 요청이 응답을 받음\n\nP (Partition Tolerance): 네트워크 분할에도 시스템 동작\n\n정리: 분산 시스템은 세 가지 중 두 가지만 보장 가능",
    "references": [
      {
        "title": "CAP Theorem - Brewer",
        "url": "https://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed/"
      }
    ],
    "keywords": [
      "consistency",
      "availability",
      "partition",
      "tolerance",
      "모든",
      "노드가",
      "동일한",
      "데이터를",
      "반환",
      "요청이",
      "응답을",
      "받음",
      "네트워크",
      "분할에도",
      "시스템"
    ]
  },
  {
    "id": "SD-060",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "CAP 이론에서 왜 현대 분산 시스템은 'P(Partition Tolerance)'를 포기할 수 없는지 설명해 주세요.",
    "answer": "이유: 네트워크 파티션은 피할 수 없는 현실\n분산 시스템에서 네트워크 장애는 반드시 발생\nP를 포기 = 단일 노드 시스템 = 분산 시스템이 아님\n\n결론: 실제 선택은 CP vs AP",
    "references": [
      {
        "title": "You Can't Sacrifice Partition Tolerance",
        "url": "https://codahale.com/you-cant-sacrifice-partition-tolerance/"
      }
    ],
    "keywords": [
      "이유",
      "네트워크",
      "파티션은",
      "피할",
      "없는",
      "현실",
      "분산",
      "시스템에서",
      "장애는",
      "반드시",
      "발생",
      "포기",
      "단일",
      "노드",
      "시스템"
    ]
  },
  {
    "id": "SD-061",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "CAP 이론에 따라 시스템은 CP 또는 AP를 선택해야 합니다. 각각의 특징과 대표적인 시스템 예시를 들어주세요.",
    "answer": "CP (Consistency + Partition Tolerance):\n파티션 시 가용성 포기\n예: ZooKeeper, etcd, HBase, MongoDB (기본)\n\nAP (Availability + Partition Tolerance):\n파티션 시 일관성 포기 (최종 일관성)\n예: Cassandra, DynamoDB, CouchDB",
    "references": [
      {
        "title": "CAP FAQ",
        "url": "https://www.the-paper-trail.org/page/cap-faq/"
      }
    ],
    "keywords": [
      "consistency",
      "partition",
      "tolerance",
      "zookeeper",
      "hbase",
      "mongodb",
      "availability",
      "cassandra",
      "dynamodb",
      "couchdb",
      "파티션",
      "가용성",
      "포기",
      "기본",
      "일관성"
    ]
  },
  {
    "id": "SD-062",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "CP 시스템은 네트워크 파티션 발생 시 어떻게 동작하나요?",
    "answer": "동작:\n과반수(Quorum) 미달 파티션은 요청 거부\n일관성 유지를 위해 가용성 희생\n클라이언트는 에러 또는 타임아웃 수신\n\n예시: ZooKeeper에서 리더와 연결 끊긴 팔로워는 읽기/쓰기 불가",
    "references": [
      {
        "title": "ZooKeeper Internals",
        "url": "https://zookeeper.apache.org/doc/current/zookeeperInternals.html"
      }
    ],
    "keywords": [
      "quorum",
      "zookeeper",
      "동작",
      "과반수",
      "미달",
      "파티션은",
      "요청",
      "거부",
      "일관성",
      "유지를",
      "가용성",
      "희생",
      "클라이언트는",
      "에러",
      "타임아웃"
    ]
  },
  {
    "id": "SD-063",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "AP 시스템은 네트워크 파티션 발생 시 어떻게 동작하나요?",
    "answer": "동작:\n모든 파티션이 계속 요청 처리\n일관성 포기, 충돌 가능\n파티션 복구 후 충돌 해결 (reconciliation)\n\n예시: Cassandra는 파티션 상태에서도 각 노드가 독립적으로 쓰기 허용",
    "references": [
      {
        "title": "Cassandra Consistency",
        "url": "https://cassandra.apache.org/doc/latest/cassandra/architecture/dynamo.html#tunable-consistency"
      }
    ],
    "keywords": [
      "cassandra",
      "동작",
      "모든",
      "파티션이",
      "계속",
      "요청",
      "처리",
      "일관성",
      "포기",
      "충돌",
      "가능",
      "파티션",
      "복구",
      "해결",
      "예시"
    ]
  },
  {
    "id": "SD-064",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "\"CAP 이론은 셋 중 둘만 선택할 수 있다는 것이 아니다\"라는 비판이 있습니다. 이 비판의 근거는 무엇인가요?",
    "answer": "비판 근거:\n파티션은 드묾: 정상 상황에서는 CA 모두 가능\n연속적 스펙트럼: 이분법이 아닌 조율 가능\nLatency 미고려: 실제로는 응답 시간도 중요\n\n대안: PACELC (Partition 시 AC, Else Latency-Consistency 트레이드오프)",
    "references": [
      {
        "title": "PACELC",
        "url": "https://en.wikipedia.org/wiki/PACELC_theorem"
      }
    ],
    "keywords": [
      "latency",
      "pacelc",
      "partition",
      "else",
      "latency-consistency",
      "비판",
      "근거",
      "파티션은",
      "드묾",
      "정상",
      "상황에서는",
      "모두",
      "가능",
      "연속적",
      "스펙트럼"
    ]
  },
  {
    "id": "SD-065",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "CAP의 'C'는 '강한 일관성(Strong Consistency)'을 의미합니다. '최종 일관성(Eventual Consistency)' 모델이 무엇인지, AP 시스템과 어떤 관계가 있는지 설명해 주세요.",
    "answer": "최종 일관성: 업데이트 중단 시 결국 모든 노드가 같은 값 수렴\n\nAP 시스템과의 관계:\nAP 시스템은 가용성을 위해 강한 일관성 포기\n대신 최종 일관성 제공\n예: Cassandra, DynamoDB",
    "references": [
      {
        "title": "Eventually Consistent - Werner Vogels",
        "url": "https://www.allthingsdistributed.com/2008/12/eventually_consistent.html"
      }
    ],
    "keywords": [
      "cassandra",
      "dynamodb",
      "최종",
      "일관성",
      "업데이트",
      "중단",
      "결국",
      "모든",
      "노드가",
      "같은",
      "수렴",
      "시스템과의",
      "관계",
      "시스템은",
      "가용성을"
    ]
  },
  {
    "id": "SD-066",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "'강한 일관성'과 '최종 일관성' 사이에는 어떤 다른 일관성 모델들이 존재하나요?",
    "answer": "Read-your-writes: 자신이 쓴 것은 즉시 읽기 가능\nMonotonic Reads: 한번 본 값보다 과거 값 읽기 불가\nMonotonic Writes: 쓰기 순서 보장\nCausal Consistency: 인과 관계 있는 연산 순서 보장\nSession Consistency: 세션 내 일관성 보장",
    "references": [
      {
        "title": "Consistency Models",
        "url": "https://jepsen.io/consistency"
      }
    ],
    "keywords": [
      "read-your-writes",
      "monotonic",
      "reads",
      "writes",
      "causal",
      "consistency",
      "session",
      "자신이",
      "것은",
      "즉시",
      "읽기",
      "가능",
      "한번",
      "값보다",
      "과거"
    ]
  },
  {
    "id": "SD-067",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "분산 시스템에서 '합의(Consensus)' 문제는 무엇을 해결하기 위한 것인가요?",
    "answer": "문제: 분산 노드들이 하나의 값/결정에 동의하는 것\n\n필요 상황:\n리더 선출\n분산 트랜잭션 커밋 여부\n로그 복제 순서\n설정 변경",
    "references": [
      {
        "title": "Raft Paper",
        "url": "https://raft.github.io/raft.pdf"
      }
    ],
    "keywords": [
      "문제",
      "분산",
      "노드들이",
      "하나의",
      "결정에",
      "동의하는",
      "필요",
      "상황",
      "리더",
      "선출",
      "트랜잭션",
      "커밋",
      "여부",
      "로그",
      "복제"
    ]
  },
  {
    "id": "SD-068",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "비잔티움 장군 문제(Byzantine Generals Problem)에 대해 설명해 주세요.",
    "answer": "문제 설정:\n여러 장군이 공격/후퇴 합의 필요\n일부 장군이 배신자(거짓 정보 전달)\n배신자가 있어도 올바른 합의 도달 필요\n\n조건: n개 노드 중 f개 악의적 노드가 있을 때, n >= 3f + 1 이어야 합의 가능",
    "references": [
      {
        "title": "Byzantine Generals Problem - Lamport",
        "url": "https://lamport.azurewebsites.net/pubs/byz.pdf"
      }
    ],
    "keywords": [
      "문제",
      "설정",
      "여러",
      "장군이",
      "공격",
      "후퇴",
      "합의",
      "필요",
      "일부",
      "배신자",
      "거짓",
      "정보",
      "전달",
      "배신자가",
      "있어도"
    ]
  },
  {
    "id": "SD-069",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이 문제가 분산 시스템에서 왜 중요한가요? (어떤 종류의 장애를 가정하는 것인가요?)",
    "answer": "가정하는 장애: 악의적(Byzantine) 장애\n노드가 의도적으로 잘못된 정보 전송\n해킹, 버그, 하드웨어 오류로 비정상 동작\n\n중요성:\n신뢰할 수 없는 노드 환경 (퍼블릭 블록체인)\n고신뢰성 시스템 (항공, 금융)",
    "references": [
      {
        "title": "Byzantine Fault Tolerance",
        "url": "https://pmg.csail.mit.edu/papers/osdi99.pdf"
      }
    ],
    "keywords": [
      "byzantine",
      "가정하는",
      "장애",
      "악의적",
      "노드가",
      "의도적으로",
      "잘못된",
      "정보",
      "전송",
      "해킹",
      "버그",
      "하드웨어",
      "오류로",
      "비정상",
      "동작"
    ]
  },
  {
    "id": "SD-070",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "비잔티움 장애 허용(BFT, Byzantine Fault Tolerance)이 무엇인지, 그리고 이것이 블록체인과 어떤 관련이 있는지 설명해 주세요.",
    "answer": "BFT: 악의적 노드가 있어도 시스템이 올바르게 동작\n\n블록체인 관계:\n퍼블릭 블록체인은 신뢰 없는 참여자 환경\nPoW, PoS 등은 BFT의 변형\nPBFT는 프라이빗 블록체인에서 사용 (Hyperledger)",
    "references": [
      {
        "title": "Hyperledger PBFT",
        "url": "https://hyperledger-fabric.readthedocs.io/"
      }
    ],
    "keywords": [
      "bft",
      "pow",
      "pos",
      "pbft",
      "hyperledger",
      "악의적",
      "노드가",
      "있어도",
      "시스템이",
      "올바르게",
      "동작",
      "블록체인",
      "관계",
      "퍼블릭",
      "블록체인은"
    ]
  },
  {
    "id": "SD-071",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "BFT를 구현하기 위한 알고리즘(예: PBFT)과, 그렇지 않은 합의 알고리즘(예: Raft, Paxos)의 근본적인 차이는 무엇인가요?",
    "answer": "CFT (Crash Fault Tolerance) - Raft, Paxos:\n노드가 크래시만 가정 (정직한 실패)\nf개 장애 허용에 2f+1 노드 필요\n성능 우수\n\nBFT - PBFT:\n악의적 노드 가정\nf개 장애 허용에 3f+1 노드 필요\n메시지 복잡도 O(n^2)",
    "references": [
      {
        "title": "Raft vs PBFT",
        "url": "https://decentralizedthoughts.github.io/2019-06-07-modeling-consensus/"
      }
    ],
    "keywords": [
      "cft",
      "crash",
      "fault",
      "tolerance",
      "raft",
      "paxos",
      "bft",
      "pbft",
      "노드가",
      "크래시만",
      "가정",
      "정직한",
      "실패",
      "장애",
      "허용에"
    ]
  },
  {
    "id": "SD-072",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "Raft 합의 알고리즘의 '리더 선출(Leader Election)' 과정에 대해 설명해 주세요.",
    "answer": "과정:\n리더 heartbeat 타임아웃 발생\nFollower가 Candidate로 전환\nTerm 증가, 자신에게 투표, 다른 노드에 RequestVote 전송\n과반수 투표 획득 시 리더 선출\n리더는 heartbeat 전송 시작",
    "references": [
      {
        "title": "Raft Visualization",
        "url": "https://raft.github.io/"
      }
    ],
    "keywords": [
      "follower",
      "candidate",
      "term",
      "requestvote",
      "과정",
      "리더",
      "타임아웃",
      "발생",
      "전환",
      "증가",
      "자신에게",
      "투표",
      "다른",
      "노드에",
      "전송"
    ]
  },
  {
    "id": "SD-073",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "Raft에서 '로그 복제(Log Replication)'는 어떻게 이루어지나요?",
    "answer": "과정:\n클라이언트 요청 → 리더가 로그에 추가\n리더가 AppendEntries RPC로 팔로워에 전파\n과반수 복제 완료 시 커밋\n다음 heartbeat에서 커밋 알림\n팔로워도 커밋 적용",
    "references": [
      {
        "title": "Raft Paper - Log Replication",
        "url": "https://raft.github.io/raft.pdf"
      }
    ],
    "keywords": [
      "appendentries",
      "rpc",
      "과정",
      "클라이언트",
      "요청",
      "리더가",
      "로그에",
      "추가",
      "팔로워에",
      "전파",
      "과반수",
      "복제",
      "완료",
      "커밋",
      "다음"
    ]
  },
  {
    "id": "SD-074",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "데이터베이스 레플리케이션(Replication, 복제)은 왜 필요한가요? (가용성 vs 확장성)",
    "answer": "가용성: 노드 장애 시 다른 복제본이 서비스 지속\n\n확장성: 읽기 부하를 여러 복제본에 분산\n\n추가 이점:\n지리적 분산 (지연 감소)\n데이터 내구성",
    "references": [
      {
        "title": "MySQL Replication",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/replication.html"
      }
    ],
    "keywords": [
      "가용성",
      "노드",
      "장애",
      "다른",
      "복제본이",
      "서비스",
      "지속",
      "확장성",
      "읽기",
      "부하를",
      "여러",
      "복제본에",
      "분산",
      "추가",
      "이점"
    ]
  },
  {
    "id": "SD-075",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "'동기식(Synchronous)' 복제와 '비동기식(Asynchronous)' 복제의 장단점을 비교 설명해 주세요.",
    "answer": "동기식:\n장점: 데이터 유실 없음, 강한 일관성\n단점: 높은 지연, 복제본 장애 시 전체 중단\n\n비동기식:\n장점: 낮은 지연, 높은 가용성\n단점: 데이터 유실 가능, 복제 지연",
    "references": [
      {
        "title": "PostgreSQL Replication",
        "url": "https://www.postgresql.org/docs/current/warm-standby.html"
      }
    ],
    "keywords": [
      "동기식",
      "장점",
      "데이터",
      "유실",
      "없음",
      "강한",
      "일관성",
      "단점",
      "높은",
      "지연",
      "복제본",
      "장애",
      "전체",
      "중단",
      "비동기식"
    ]
  },
  {
    "id": "SD-076",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "'반-동기식(Semi-Synchronous)' 복제는 무엇이며, 어떤 문제를 해결하기 위해 등장했나요?",
    "answer": "정의: 최소 하나의 복제본 확인 후 커밋 응답\n\n해결 문제:\n동기식의 성능 저하\n비동기식의 데이터 유실 위험\n\n동작: 리더 + 최소 1개 복제본 확인 → 커밋",
    "references": [
      {
        "title": "MySQL Semi-Sync",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/replication-semisync.html"
      }
    ],
    "keywords": [
      "정의",
      "최소",
      "하나의",
      "복제본",
      "확인",
      "커밋",
      "응답",
      "해결",
      "문제",
      "동기식의",
      "성능",
      "저하",
      "비동기식의",
      "데이터",
      "유실"
    ]
  },
  {
    "id": "SD-077",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "단일 리더(Single-Leader) 복제 아키텍처 (Master-Slave)에 대해 설명해 주세요.",
    "answer": "구조:\n하나의 리더(Master): 모든 쓰기 처리\n여러 팔로워(Slave): 리더 복제, 읽기 처리\n\n복제 흐름:\n클라이언트 → 리더 쓰기\n리더 → 팔로워 복제\n클라이언트 ← 팔로워 읽기",
    "references": [
      {
        "title": "Redis Replication",
        "url": "https://redis.io/docs/management/replication/"
      }
    ],
    "keywords": [
      "master",
      "slave",
      "구조",
      "하나의",
      "리더",
      "모든",
      "쓰기",
      "처리",
      "여러",
      "팔로워",
      "복제",
      "읽기",
      "흐름",
      "클라이언트"
    ]
  },
  {
    "id": "SD-078",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "단일 리더 아키텍처의 가장 큰 장점과 단점은 무엇인가요?",
    "answer": "장점:\n단순한 구현\n쓰기 충돌 없음\n일관성 유지 용이\n\n단점:\n리더가 SPOF\n쓰기 확장 불가 (수직 확장만)\n리더-팔로워 지연",
    "references": [
      {
        "title": "DDIA - Replication",
        "url": "https://dataintensive.net/"
      }
    ],
    "keywords": [
      "spof",
      "장점",
      "단순한",
      "구현",
      "쓰기",
      "충돌",
      "없음",
      "일관성",
      "유지",
      "용이",
      "단점",
      "리더가",
      "확장",
      "불가",
      "수직"
    ]
  },
  {
    "id": "SD-079",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "(단일 리더 문제) 만약 리더(Master) 노드가 다운되면 어떤 문제가 발생하나요?",
    "answer": "쓰기 불가: 새 쓰기 요청 처리 불가\n데이터 유실 가능: 비동기 복제 시 미복제 데이터 손실\n서비스 중단: Failover까지 다운타임\n읽기 일관성 문제: 복제본 간 데이터 차이",
    "references": [
      {
        "title": "MySQL Failover",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/replication-solutions-switch.html"
      }
    ],
    "keywords": [
      "failover",
      "쓰기",
      "불가",
      "요청",
      "처리",
      "데이터",
      "유실",
      "가능",
      "비동기",
      "복제",
      "미복제",
      "손실",
      "서비스",
      "중단",
      "까지"
    ]
  },
  {
    "id": "SD-080",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "리더가 다운되었을 때 새로운 리더를 선출하는 과정(Failover)에 대해 설명해 주세요.",
    "answer": "Failover 단계:\n장애 감지: 타임아웃으로 리더 다운 인식\n새 리더 선출: 가장 최신 데이터 가진 팔로워 선택\n구성 변경: 클라이언트/팔로워에게 새 리더 알림\n복구: 이전 리더 복귀 시 팔로워로 전환",
    "references": [
      {
        "title": "Redis Sentinel",
        "url": "https://redis.io/docs/management/sentinel/"
      }
    ],
    "keywords": [
      "failover",
      "단계",
      "장애",
      "감지",
      "타임아웃으로",
      "리더",
      "다운",
      "인식",
      "선출",
      "가장",
      "최신",
      "데이터",
      "가진",
      "팔로워",
      "선택"
    ]
  },
  {
    "id": "SD-081",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "이 Failover 과정에서 'Split-Brain' 문제가 발생할 수 있습니다. 이것이 무엇이며, 어떻게 방지할 수 있나요?",
    "answer": "Split-Brain: 네트워크 파티션으로 두 개의 리더가 동시에 존재\n\n문제: 데이터 불일치, 충돌\n\n방지 방법:\nQuorum: 과반수 연결 확인 필수\nFencing: 이전 리더 강제 중단 (STONITH)\nLease: 리더 임기 만료 시 재선출",
    "references": [
      {
        "title": "Fencing in Distributed Systems",
        "url": "https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html"
      }
    ],
    "keywords": [
      "split-brain",
      "quorum",
      "fencing",
      "stonith",
      "lease",
      "네트워크",
      "파티션으로",
      "개의",
      "리더가",
      "동시에",
      "존재",
      "문제",
      "데이터",
      "불일치",
      "충돌"
    ]
  },
  {
    "id": "SD-082",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "비동기식 복제를 사용할 때, 리더 장애 조치(Failover) 과정에서 데이터 유실이 발생할 수 있습니다. 왜 그런지 설명해 주세요.",
    "answer": "원인:\n리더에 쓰기 완료\n팔로워에 복제 전 리더 다운\n팔로워가 새 리더로 승격\n복제되지 않은 쓰기 데이터 유실\n\n대책: Semi-sync 복제, 수동 승인",
    "references": [
      {
        "title": "MySQL Data Loss",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/replication-solutions-unexpected-replica-halt.html"
      }
    ],
    "keywords": [
      "semi-sync",
      "원인",
      "리더에",
      "쓰기",
      "완료",
      "팔로워에",
      "복제",
      "리더",
      "다운",
      "팔로워가",
      "리더로",
      "승격",
      "복제되지",
      "않은",
      "데이터"
    ]
  },
  {
    "id": "SD-083",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "(단일 리더 문제) 리더로 모든 쓰기 요청이 몰릴 때 발생하는 쓰기 병목 현상을 어떻게 해결할 수 있을까요?",
    "answer": "수직 확장: 리더 서버 스펙 향상\n샤딩: 여러 샤드로 분산, 각 샤드마다 리더\n다중 리더: 여러 리더 허용 (충돌 해결 필요)\n쓰기 최적화: 배치 처리, 비동기 쓰기",
    "references": [
      {
        "title": "Scaling Writes",
        "url": "https://www.citusdata.com/blog/2016/10/03/scaling-distributed-database-writes/"
      }
    ],
    "keywords": [
      "수직",
      "확장",
      "리더",
      "서버",
      "스펙",
      "향상",
      "샤딩",
      "여러",
      "샤드로",
      "분산",
      "샤드마다",
      "다중",
      "허용",
      "충돌",
      "해결"
    ]
  },
  {
    "id": "SD-084",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "다중 리더(Multi-Leader) 복제 아키텍처 (Master-Master)에 대해 설명해 주세요.",
    "answer": "구조: 여러 노드가 모두 리더 역할, 쓰기 허용\n\n복제: 각 리더가 다른 리더에게 변경 전파\n\n사용 사례:\n다중 데이터센터\n오프라인 클라이언트 (노트 앱)",
    "references": [
      {
        "title": "CouchDB Replication",
        "url": "https://docs.couchdb.org/en/stable/replication/"
      }
    ],
    "keywords": [
      "구조",
      "여러",
      "노드가",
      "모두",
      "리더",
      "역할",
      "쓰기",
      "허용",
      "복제",
      "리더가",
      "다른",
      "리더에게",
      "변경",
      "전파",
      "사용"
    ]
  },
  {
    "id": "SD-085",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "다중 리더 아키텍처는 어떤 경우에 유용한가요?",
    "answer": "Multi-Datacenter: 각 DC에 로컬 리더 → 지연 감소\n오프라인 작업: 오프라인에서 쓰기 후 동기화\n협업 도구: 동시 편집 (Google Docs)\n고가용성: 리더 장애에도 다른 리더로 계속 서비스",
    "references": [
      {
        "title": "Multi-Leader Replication",
        "url": "https://dataintensive.net/"
      }
    ],
    "keywords": [
      "multi-datacenter",
      "google",
      "docs",
      "로컬",
      "리더",
      "지연",
      "감소",
      "오프라인",
      "작업",
      "오프라인에서",
      "쓰기",
      "동기화",
      "협업",
      "도구",
      "동시"
    ]
  },
  {
    "id": "SD-086",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "(다중 리더 문제) 다중 리더 아키텍처의 가장 큰 단점, 즉 '쓰기 충돌(Write Conflict)' 문제에 대해 설명해 주세요.",
    "answer": "발생 상황: 두 리더가 동시에 같은 데이터 수정\n\n예시:\n리더A: 이름을 \"Alice\"로 변경\n리더B: 이름을 \"Bob\"으로 변경\n둘 다 성공 후 복제 시 충돌\n\n문제: 어떤 값이 최종 값인가?",
    "references": [
      {
        "title": "Conflict Resolution",
        "url": "https://www.cockroachlabs.com/blog/consistency-model/"
      }
    ],
    "keywords": [
      "alice",
      "bob",
      "발생",
      "상황",
      "리더가",
      "동시에",
      "같은",
      "데이터",
      "수정",
      "예시",
      "리더",
      "이름을",
      "변경",
      "으로",
      "성공"
    ]
  },
  {
    "id": "SD-087",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "두 개의 리더에서 동일한 데이터를 동시에 수정할 경우 발생하는 이 충돌을 어떻게 감지하고 해결해야 할까요?",
    "answer": "감지:\n버전 벡터 / 타임스탬프 비교\n복제 시 충돌 발견\n\n해결 전략:\nLWW (Last Write Wins): 타임스탬프 최신 승\n병합: 두 값 합치기\n사용자 해결: 충돌 표시, 사용자가 선택\nCRDT: 자동 병합 가능한 데이터 구조",
    "references": [
      {
        "title": "CRDTs",
        "url": "https://crdt.tech/"
      }
    ],
    "keywords": [
      "lww",
      "last",
      "write",
      "wins",
      "crdt",
      "감지",
      "버전",
      "벡터",
      "타임스탬프",
      "비교",
      "복제",
      "충돌",
      "발견",
      "해결",
      "전략"
    ]
  },
  {
    "id": "SD-088",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "'Last Write Wins (LWW)'와 같은 자동 충돌 해결 전략의 문제점은 무엇인가요?",
    "answer": "문제점:\n데이터 유실: 먼저 쓴 값은 사라짐\n시계 동기화: 노드 간 시계 불일치 시 잘못된 판단\n동시 쓰기: 실제 동시 발생 시 임의 선택\n비즈니스 규칙 무시: 도메인 로직과 무관하게 결정",
    "references": [
      {
        "title": "LWW Problems",
        "url": "https://jepsen.io/consistency/models/lww"
      }
    ],
    "keywords": [
      "문제점",
      "데이터",
      "유실",
      "먼저",
      "값은",
      "사라짐",
      "시계",
      "동기화",
      "노드",
      "불일치",
      "잘못된",
      "판단",
      "동시",
      "쓰기",
      "실제"
    ]
  },
  {
    "id": "SD-089",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "리더가 없는(Leaderless) 아키텍처 (예: Cassandra, DynamoDB)는 다중 리더와 어떻게 다른가요?",
    "answer": "다중 리더: 지정된 리더들이 쓰기 처리\n\n리더리스: 모든 노드가 동등, 클라이언트가 여러 노드에 직접 쓰기\n\n차이:\n비교   Multi-Leader   Leaderless\n\n리더   지정됨   없음\n쓰기   리더만   모든 노드\n조정   리더 간 복제   Quorum",
    "references": [
      {
        "title": "Cassandra Architecture",
        "url": "https://cassandra.apache.org/doc/latest/cassandra/architecture/"
      }
    ],
    "keywords": [
      "multi-leader",
      "leaderless",
      "quorum",
      "다중",
      "리더",
      "지정된",
      "리더들이",
      "쓰기",
      "처리",
      "리더리스",
      "모든",
      "노드가",
      "동등",
      "클라이언트가",
      "여러"
    ]
  },
  {
    "id": "SD-090",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "리더리스 아키텍처에서는 'Quorum'을 사용하여 일관성을 조절합니다. R, W, N 값의 관계(R+W > N)에 대해 설명해 주세요.",
    "answer": "N: 총 복제본 수\nW: 쓰기 확인 필요 노드 수\nR: 읽기 확인 필요 노드 수\n\nR + W > N: 읽기와 쓰기 노드 집합이 반드시 겹침 → 최신 데이터 보장\n\n예시: N=3, W=2, R=2 → 2+2 > 3 ✓",
    "references": [
      {
        "title": "DynamoDB Consistency",
        "url": "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html"
      }
    ],
    "keywords": [
      "복제본",
      "쓰기",
      "확인",
      "필요",
      "노드",
      "읽기",
      "읽기와",
      "집합이",
      "반드시",
      "겹침",
      "최신",
      "데이터",
      "보장",
      "예시"
    ]
  },
  {
    "id": "SD-091",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "리더리스 아키텍처는 '쓰기 충돌'을 어떻게 처리하나요?",
    "answer": "Read Repair: 읽기 시 불일치 발견하면 최신 값으로 복구\n\nAnti-entropy: 백그라운드에서 노드 간 데이터 비교/복구\n\nVector Clock: 버전 추적으로 충돌 감지\n\n해결: LWW, Merge, 애플리케이션 해결",
    "references": [
      {
        "title": "Cassandra Read Repair",
        "url": "https://cassandra.apache.org/doc/latest/cassandra/operating/read_repair.html"
      }
    ],
    "keywords": [
      "read",
      "repair",
      "anti-entropy",
      "vector",
      "clock",
      "lww",
      "merge",
      "읽기",
      "불일치",
      "발견하면",
      "최신",
      "값으로",
      "복구",
      "백그라운드에서",
      "노드"
    ]
  },
  {
    "id": "SD-092",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "RDBMS와 NoSQL(Key-Value, Document, Graph) 각각의 특징을 설명하고, 언제 어떤 것을 선택해야 할지 기준을 설명해 주세요.",
    "answer": "RDBMS: 정형 데이터, ACID, 복잡한 쿼리/조인, 강한 일관성\n→ 트랜잭션 중요, 관계형 데이터\n\nKey-Value (Redis): 단순 조회, 높은 성능\n→ 캐싱, 세션\n\nDocument (MongoDB): 유연한 스키마, 중첩 구조\n→ 콘텐츠 관리, 카탈로그\n\nGraph (Neo4j): 관계 탐색 최적화\n→ 소셜 네트워크, 추천",
    "references": [
      {
        "title": "DB-Engines Ranking",
        "url": "https://db-engines.com/en/ranking"
      }
    ],
    "keywords": [
      "rdbms",
      "acid",
      "key-value",
      "redis",
      "document",
      "mongodb",
      "graph",
      "neo4j",
      "정형",
      "데이터",
      "복잡한",
      "쿼리",
      "조인",
      "강한",
      "일관성"
    ]
  },
  {
    "id": "SD-093",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "마이크로서비스 아키텍처(MSA)를 설계할 때, 서비스 간 통신 방법(동기식 API vs 비동기식 이벤트)을 어떻게 결정해야 할까요?",
    "answer": "동기식 (REST, gRPC):\n즉각적 응답 필요\n단순한 요청-응답\n강한 일관성 필요\n\n비동기식 (이벤트):\n응답 대기 불필요\n느슨한 결합 원함\n확장성/탄력성 중요",
    "references": [
      {
        "title": "Microservices Communication",
        "url": "https://microservices.io/patterns/communication-style/"
      }
    ],
    "keywords": [
      "rest",
      "동기식",
      "즉각적",
      "응답",
      "필요",
      "단순한",
      "요청",
      "강한",
      "일관성",
      "비동기식",
      "이벤트",
      "대기",
      "불필요",
      "느슨한",
      "결합"
    ]
  },
  {
    "id": "SD-094",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "API 게이트웨이는 MSA에서 어떤 역할을 하며, 왜 필요한가요?",
    "answer": "역할:\n단일 진입점: 클라이언트에게 하나의 엔드포인트 제공\n라우팅: 요청을 적절한 서비스로 전달\n인증/인가: 중앙화된 보안\nRate Limiting: 트래픽 제어\n응답 집계: 여러 서비스 응답 병합",
    "references": [
      {
        "title": "Kong Gateway",
        "url": "https://docs.konghq.com/"
      }
    ],
    "keywords": [
      "rate",
      "limiting",
      "역할",
      "단일",
      "진입점",
      "클라이언트에게",
      "하나의",
      "엔드포인트",
      "제공",
      "라우팅",
      "요청을",
      "적절한",
      "서비스로",
      "전달",
      "인증"
    ]
  },
  {
    "id": "SD-095",
    "category": "system_design",
    "categoryName": "시스템 설계",
    "priority": "P3",
    "question": "서비스 메시(Service Mesh)는 무엇이며, API 게이트웨이나 기존 라이브러리 방식(예: Spring Cloud)과 어떻게 다른가요?",
    "answer": "Service Mesh: 서비스 간 통신을 담당하는 인프라 계층 (Sidecar Proxy)\n\n차이점:\n비교   API Gateway   Library   Service Mesh\n\n위치   Edge   애플리케이션 내   Sidecar\n범위   North-South   애플리케이션   East-West\n언어   무관   언어별   무관\n\n예시: Istio, Linkerd",
    "references": [
      {
        "title": "Istio Documentation",
        "url": "https://istio.io/latest/docs/"
      }
    ],
    "keywords": [
      "service",
      "mesh",
      "sidecar",
      "proxy",
      "api",
      "gateway",
      "library",
      "edge",
      "north-south",
      "east-west",
      "istio",
      "linkerd",
      "서비스",
      "통신을",
      "담당하는"
    ]
  },
  {
    "id": "WS-001",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket의 기본 개념과 HTTP와의 차이점은 무엇인가요?",
    "answer": "WebSocket이란?\n클라이언트와 서버 간 양방향 전이중(Full-Duplex) 통신을 제공하는 프로토콜\n단일 TCP 연결을 통해 지속적인 통신 가능\nws:// (비암호화) 또는 wss:// (TLS 암호화) 스킴 사용\n\nHTTP와의 주요 차이점\n\n구분   HTTP   WebSocket\n\n통신 방식   요청-응답 (반이중)   양방향 (전이중)\n연결   매 요청마다 연결/해제   한 번 연결 후 지속 유지\n오버헤드   매 요청마다 헤더 전송   초기 핸드셰이크 후 최소\n서버 푸시   불가 (폴링 필요)   가능\n상태   Stateless   Stateful",
    "references": [
      {
        "title": "RFC 6455 - The WebSocket Protocol",
        "url": "https://datatracker.ietf.org/doc/html/rfc6455"
      },
      {
        "title": "MDN WebSocket API",
        "url": "https://developer.mozilla.org/en-US/docs/Web/API/WebSocket"
      }
    ],
    "keywords": [
      "websocket",
      "full-duplex",
      "tcp",
      "tls",
      "http",
      "stateless",
      "stateful",
      "이란",
      "클라이언트와",
      "서버",
      "양방향",
      "전이중",
      "통신을",
      "제공하는",
      "프로토콜"
    ]
  },
  {
    "id": "WS-002",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 연결의 Handshake 과정은 어떻게 진행되나요?",
    "answer": "WebSocket Handshake 과정\n\nWebSocket 연결은 HTTP Upgrade 요청으로 시작됩니다.\n클라이언트 요청\n서버 응답\n\n주요 헤더 설명\nUpgrade: websocket: 프로토콜 업그레이드 요청\nSec-WebSocket-Key: 클라이언트가 생성한 Base64 인코딩 키\nSec-WebSocket-Accept: 서버가 Key + GUID를 SHA-1 해시 후 Base64 인코딩한 값\nSec-WebSocket-Version: 프로토콜 버전 (현재 13)",
    "references": [
      {
        "title": "RFC 6455 Section 4 - Opening Handshake",
        "url": "https://datatracker.ietf.org/doc/html/rfc6455#section-4"
      }
    ],
    "keywords": [
      "websocket",
      "handshake",
      "http",
      "upgrade",
      "sec-websocket-key",
      "base64",
      "sec-websocket-accept",
      "key",
      "guid",
      "sha-1",
      "sec-websocket-version",
      "과정",
      "연결은",
      "요청으로",
      "시작됩니다"
    ]
  },
  {
    "id": "WS-003",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket의 메시지 프레이밍(message framing) 메커니즘에 대해 설명해주세요.",
    "answer": "WebSocket 프레임 구조\n\n주요 필드\nFIN: 메시지의 마지막 프레임인지 표시 (1비트)\nOpcode: 프레임 타입 (4비트)\n0x0: Continuation, 0x1: Text, 0x2: Binary\n0x8: Close, 0x9: Ping, 0xA: Pong\nMASK: 클라이언트→서버 메시지는 반드시 마스킹\nPayload length: 페이로드 크기 (7/16/64비트)",
    "references": [
      {
        "title": "RFC 6455 Section 5 - Data Framing",
        "url": "https://datatracker.ietf.org/doc/html/rfc6455#section-5"
      }
    ],
    "keywords": [
      "websocket",
      "fin",
      "opcode",
      "continuation",
      "text",
      "binary",
      "close",
      "ping",
      "pong",
      "mask",
      "payload",
      "프레임",
      "구조",
      "주요",
      "필드"
    ]
  },
  {
    "id": "WS-004",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "Long Polling과 WebSocket의 차이점은 무엇인가요?",
    "answer": "구분   Long Polling   WebSocket\n\n연결 방식   HTTP 요청을 길게 유지   단일 TCP 연결 유지\n통신 방향   단방향 (요청-응답)   양방향\n오버헤드   매 요청마다 HTTP 헤더   핸드셰이크 후 최소 오버헤드\n지연시간   응답 후 재연결 필요   실시간\n서버 부하   연결 재설정 비용 높음   연결 유지 비용만\n호환성   모든 브라우저/프록시 지원   일부 프록시 문제 가능\n\nLong Polling 동작\n클라이언트가 요청 전송\n서버는 이벤트가 발생할 때까지 응답 대기\n이벤트 발생 시 응답 반환\n클라이언트가 즉시 새 요청 전송 (반복)\n\nWebSocket 선택 기준\n실시간성이 중요하고 양방향 통신이 필요한 경우 → WebSocket\n프록시 호환성이 중요하거나 간단한 서버 푸시만 필요한 경우 → Long Polling",
    "references": [],
    "keywords": [
      "long",
      "polling",
      "websocket",
      "http",
      "tcp",
      "구분",
      "연결",
      "방식",
      "요청을",
      "길게",
      "유지",
      "단일",
      "통신",
      "방향",
      "단방향"
    ]
  },
  {
    "id": "WS-005",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 통신에서 보안을 강화하기 위한 주요 고려 사항은 무엇인가요?",
    "answer": "WSS (WebSocket Secure) 사용\nwss:// 프로토콜로 TLS/SSL 암호화 적용\n중간자 공격(MITM) 방지\nOrigin 검증\n인증 및 토큰 관리\n핸드셰이크 시 JWT 토큰 검증\n쿼리 파라미터나 첫 메시지로 토큰 전달\n토큰 만료 시 연결 종료 처리\n입력 검증\n모든 수신 메시지의 형식 및 크기 검증\nXSS, 인젝션 공격 방지\nRate Limiting\n메시지 빈도 제한으로 DoS 공격 방지\n연결 수 제한\n메시지 크기 제한\n최대 프레임/메시지 크기 설정\n메모리 고갈 공격 방지",
    "references": [
      {
        "title": "OWASP WebSocket Security",
        "url": "https://owasp.org/www-project-web-security-testing-guide/"
      }
    ],
    "keywords": [
      "wss",
      "websocket",
      "secure",
      "tls",
      "ssl",
      "mitm",
      "origin",
      "jwt",
      "xss",
      "rate",
      "limiting",
      "dos",
      "사용",
      "프로토콜로",
      "암호화"
    ]
  },
  {
    "id": "WS-006",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 연결이 끊어졌을 때 재연결(reconnect) 로직은 어떻게 구현하나요?",
    "answer": "재연결 구현 핵심 요소\nExponential Backoff (지수 백오프)\n고려사항\nJitter 추가: 다수 클라이언트 동시 재연결 방지\n최대 재시도 횟수: 무한 재시도 방지\n상태 복구: 재연결 후 구독 정보 재전송\n오프라인 감지: navigator.onLine 활용\n라이브러리 활용\nSocket.IO: 자동 재연결 내장\nReconnectingWebSocket: 경량 재연결 래퍼",
    "references": [],
    "keywords": [
      "exponential",
      "backoff",
      "jitter",
      "socket",
      "reconnectingwebsocket",
      "재연결",
      "구현",
      "핵심",
      "요소",
      "지수",
      "백오프",
      "고려사항",
      "추가",
      "다수",
      "클라이언트"
    ]
  },
  {
    "id": "WS-007",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 프로토콜에서 사용되는 상태 코드와 그 의미에 대해 설명해주세요.",
    "answer": "주요 Close 상태 코드 (RFC 6455)\n\n코드   이름   설명\n\n1000   Normal Closure   정상 종료\n1001   Going Away   서버 셧다운, 브라우저 이탈\n1002   Protocol Error   프로토콜 오류\n1003   Unsupported Data   지원하지 않는 데이터 타입\n1005   No Status Received   상태 코드 없이 종료 (예약)\n1006   Abnormal Closure   비정상 종료 (연결 끊김)\n1007   Invalid Payload   잘못된 데이터 (예: UTF-8 오류)\n1008   Policy Violation   정책 위반\n1009   Message Too Big   메시지 크기 초과\n1010   Mandatory Extension   필수 확장 미지원\n1011   Internal Error   서버 내부 오류\n1015   TLS Handshake   TLS 핸드셰이크 실패 (예약)\n\n사용 예시",
    "references": [
      {
        "title": "RFC 6455 Section 7.4 - Status Codes",
        "url": "https://datatracker.ietf.org/doc/html/rfc6455#section-7.4"
      }
    ],
    "keywords": [
      "close",
      "rfc",
      "normal",
      "closure",
      "going",
      "away",
      "protocol",
      "error",
      "unsupported",
      "data",
      "status",
      "received",
      "abnormal",
      "invalid",
      "payload"
    ]
  },
  {
    "id": "WS-008",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "Ping/Pong 메커니즘이 WebSocket 연결 유지에 어떻게 활용되는지 설명해주세요.",
    "answer": "Ping/Pong 개념\nWebSocket 제어 프레임 (Opcode: Ping=0x9, Pong=0xA)\n연결 상태 확인 및 유지(Keep-Alive) 목적\n\n동작 방식\n한 쪽이 Ping 프레임 전송\n수신 측은 반드시 Pong으로 응답 (자동 처리)\n응답 없으면 연결 끊김으로 판단\n\n활용 목적\n연결 상태 확인: Dead connection 감지\nNAT/방화벽 타임아웃 방지: 주기적 트래픽으로 연결 유지\n지연시간 측정: RTT(Round Trip Time) 계산\n\n구현 예시",
    "references": [
      {
        "title": "RFC 6455 Section 5.5.2 - Ping",
        "url": "https://datatracker.ietf.org/doc/html/rfc6455#section-5.5.2"
      }
    ],
    "keywords": [
      "ping",
      "pong",
      "websocket",
      "opcode",
      "keep-alive",
      "dead",
      "nat",
      "rtt",
      "round",
      "trip",
      "time",
      "개념",
      "제어",
      "프레임",
      "연결"
    ]
  },
  {
    "id": "WS-009",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 확장(extensions) 기능은 무엇이며, 어떤 용도로 사용되나요?",
    "answer": "WebSocket 확장이란?\n기본 WebSocket 프로토콜에 추가 기능을 제공하는 메커니즘\n핸드셰이크 시 Sec-WebSocket-Extensions 헤더로 협상\n\n대표적인 확장\npermessage-deflate (RFC 7692)\n메시지 압축 확장\nzlib/DEFLATE 알고리즘 사용\n대역폭 절약 (텍스트 데이터 70-90% 압축)\n사용 예시\n\n주의사항\n압축/해제에 CPU 오버헤드 발생\n작은 메시지는 압축 효율 낮음\n이미 압축된 데이터(이미지 등)는 비효율적",
    "references": [
      {
        "title": "RFC 7692 - Compression Extensions",
        "url": "https://datatracker.ietf.org/doc/html/rfc7692"
      }
    ],
    "keywords": [
      "websocket",
      "sec-websocket-extensions",
      "permessage-deflate",
      "rfc",
      "deflate",
      "cpu",
      "확장이란",
      "기본",
      "프로토콜에",
      "추가",
      "기능을",
      "제공하는",
      "메커니즘",
      "핸드셰이크",
      "헤더로"
    ]
  },
  {
    "id": "WS-010",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 구현 시 발생할 수 있는 Cross-Origin 문제와 그 해결 방법은 무엇인가요?",
    "answer": "WebSocket과 CORS의 관계\n\nWebSocket은 HTTP CORS 정책의 적용을 받지 않습니다. 그러나 보안상 Origin 검증이 필요합니다.\n\n브라우저 동작\n브라우저는 핸드셰이크 시 Origin 헤더를 자동 전송\n서버가 연결을 수락하면 통신 가능\n\n보안 문제: CSWSH (Cross-Site WebSocket Hijacking)\n악성 사이트에서 사용자 세션으로 WebSocket 연결 시도 가능\n서버가 Origin을 검증하지 않으면 취약\n\n해결 방법\n서버 측 Origin 검증\n토큰 기반 인증\n핸드셰이크 URL에 일회용 토큰 포함\n첫 메시지에서 JWT 검증\nCSRF 토큰 활용\n기존 웹 애플리케이션의 CSRF 토큰 재사용",
    "references": [],
    "keywords": [
      "websocket",
      "cors",
      "http",
      "origin",
      "cswsh",
      "cross-site",
      "hijacking",
      "url",
      "jwt",
      "csrf",
      "관계",
      "정책의",
      "적용을",
      "받지",
      "않습니다"
    ]
  },
  {
    "id": "WS-011",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "단일 서버와 클러스터 환경에서의 WebSocket 구현 차이점은 무엇인가요?",
    "answer": "단일 서버 환경\n모든 연결이 하나의 서버 메모리에 존재\n브로드캐스트가 간단 (로컬 연결만 순회)\n수직 확장의 한계\n\n클러스터 환경의 문제점\n클라이언트 A와 B가 서로 다른 서버에 연결\nA가 B에게 메시지를 보내려면 서버 간 통신 필요\nSticky Session만으로는 불충분\n\n해결 방법\nPub/Sub 백엔드 (권장)\n외부 메시지 브로커\nRedis, Kafka, RabbitMQ 등 활용\n서버 간 메시지 동기화\nSocket.IO Redis Adapter",
    "references": [
      {
        "title": "Socket.IO Redis Adapter",
        "url": "https://socket.io/docs/v4/redis-adapter/"
      }
    ],
    "keywords": [
      "sticky",
      "session",
      "pub",
      "sub",
      "redis",
      "kafka",
      "rabbitmq",
      "socket",
      "adapter",
      "단일",
      "서버",
      "환경",
      "모든",
      "연결이",
      "하나의"
    ]
  },
  {
    "id": "WS-012",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket에서 텍스트와 이진 데이터 전송 방식의 장단점은 무엇인가요?",
    "answer": "데이터 프레임 타입\nText Frame (Opcode 0x1): UTF-8 인코딩 문자열\nBinary Frame (Opcode 0x2): 바이트 배열\n\n텍스트 데이터 (JSON 등)\n\n장점   단점\n\n사람이 읽기 쉬움   크기가 큼 (Base64 인코딩 시 33% 증가)\n디버깅 용이   파싱 오버헤드\n호환성 높음   바이너리 데이터 표현 비효율적\n\n이진 데이터 (Protobuf, MessagePack 등)\n\n장점   단점\n\n작은 페이로드 크기   디버깅 어려움\n파싱 속도 빠름   스키마 관리 필요\n바이너리 데이터 직접 전송   추가 라이브러리 필요\n\n선택 기준\n실시간 게임/미디어 스트리밍 → Binary\n일반 채팅/알림 → Text (JSON)\n대용량 트래픽 + 성능 중요 → Binary (Protobuf)",
    "references": [
      {
        "title": "RFC 6455 Section 5.6 - Data Frames",
        "url": "https://datatracker.ietf.org/doc/html/rfc6455#section-5.6"
      }
    ],
    "keywords": [
      "text",
      "frame",
      "opcode",
      "utf-8",
      "binary",
      "json",
      "base64",
      "protobuf",
      "messagepack",
      "데이터",
      "프레임",
      "타입",
      "인코딩",
      "문자열",
      "바이트"
    ]
  },
  {
    "id": "WS-013",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "실시간 채팅이나 게임 애플리케이션에서 WebSocket이 선호되는 이유는 무엇인가요?",
    "answer": "실시간 애플리케이션 요구사항\n낮은 지연시간: 메시지가 즉시 전달되어야 함\n양방향 통신: 서버도 클라이언트에 능동적으로 푸시\n빈번한 메시지: 초당 수십~수백 건의 이벤트\n\nWebSocket이 적합한 이유\n\n요구사항   HTTP Polling   WebSocket\n\n지연시간   폴링 간격만큼 지연   실시간 (~ms)\n오버헤드   매번 HTTP 헤더   2-14바이트 프레임 헤더\n서버 푸시   불가능   가능\n연결 수   요청마다 새 연결   단일 연결 유지\n\n채팅 애플리케이션 예시\n\n게임 애플리케이션 예시\n캐릭터 위치 동기화 (초당 30-60회 업데이트)\n실시간 액션 입력 전달\n게임 상태 브로드캐스트\n\n대안과 비교\nSSE: 단방향만 가능, 클라이언트→서버는 별도 HTTP 필요\nHTTP/2 Push: 리소스 프리로드용, 양방향 불가\nWebRTC: P2P 가능하나 복잡도 높음",
    "references": [],
    "keywords": [
      "websocket",
      "http",
      "polling",
      "sse",
      "push",
      "webrtc",
      "p2p",
      "실시간",
      "애플리케이션",
      "요구사항",
      "낮은",
      "지연시간",
      "메시지가",
      "즉시",
      "전달되어야"
    ]
  },
  {
    "id": "WS-014",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 서버의 부하 분산(load balancing) 전략에는 어떤 것들이 있나요?",
    "answer": "WebSocket 로드밸런싱의 특수성\nHTTP와 달리 장시간 연결 유지 (Stateful)\n한 번 연결되면 같은 서버와 통신해야 함\nSticky Session (Session Affinity)\n같은 클라이언트는 항상 같은 서버로 라우팅\nIP 해시, 쿠키 기반 등 방식 존재\nL4 로드밸런싱\nTCP 레벨에서 연결 분산\nWebSocket Upgrade 후에도 연결 유지\nAWS NLB, HAProxy 등\nL7 로드밸런싱\nHTTP Upgrade 요청 분석 가능\n경로/헤더 기반 라우팅\nNginx, Envoy, AWS ALB\n\nNginx WebSocket 프록시 설정\n서버 간 동기화 (필수)\nRedis Pub/Sub, Kafka 등으로 메시지 동기화\n어떤 서버로 연결되든 메시지 수신 보장",
    "references": [
      {
        "title": "Nginx WebSocket Proxying",
        "url": "https://nginx.org/en/docs/http/websocket.html"
      }
    ],
    "keywords": [
      "websocket",
      "http",
      "stateful",
      "sticky",
      "session",
      "affinity",
      "tcp",
      "upgrade",
      "aws",
      "nlb",
      "haproxy",
      "nginx",
      "envoy",
      "alb",
      "redis"
    ]
  },
  {
    "id": "WS-015",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 연결 유지 시 메모리 및 리소스 관리 방법은 무엇인가요?",
    "answer": "리소스 관리의 중요성\n수만 개의 동시 연결 시 메모리 사용량 급증\n유휴 연결도 리소스 점유\n연결 수 제한\n유휴 연결 정리\n메시지 버퍼 제한\n메모리 모니터링\n연결당 메모리 사용량 추적\n임계치 도달 시 알림/조치\n연결 풀링 및 그룹화\nOS 레벨 튜닝",
    "references": [],
    "keywords": [
      "리소스",
      "관리의",
      "중요성",
      "수만",
      "개의",
      "동시",
      "연결",
      "메모리",
      "사용량",
      "급증",
      "유휴",
      "연결도",
      "점유",
      "제한",
      "정리"
    ]
  },
  {
    "id": "WS-016",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket과 HTTP/2의 주요 차이점은 무엇인가요?",
    "answer": "기본 비교\n\n구분   WebSocket   HTTP/2\n\n목적   양방향 실시간 통신   HTTP 성능 개선\n연결   단일 TCP 연결 유지   단일 TCP, 멀티플렉싱\n통신 방향   전이중 (Full-Duplex)   요청-응답 기반\n서버 푸시   자유로운 서버→클라이언트   리소스 프리로드 한정\n프레이밍   WebSocket 프레임   HTTP/2 프레임\n\nHTTP/2 특징\n멀티플렉싱: 하나의 연결에서 여러 요청/응답 병렬 처리\n헤더 압축: HPACK으로 반복 헤더 압축\nServer Push: 클라이언트 요청 전에 리소스 전송 (캐시 용도)\n스트림 우선순위: 중요한 리소스 먼저 전송\n\nWebSocket 특징\n진정한 양방향: 서버가 언제든 메시지 전송 가능\n낮은 오버헤드: 핸드셰이크 후 최소 프레임 헤더\n애플리케이션 프로토콜 자유도: 메시지 형식 자유 정의\n\n선택 기준\nWebSocket: 실시간 채팅, 게임, 협업 도구 등 양방향 필수\nHTTP/2: 웹사이트 로딩 최적화, API 호출 (REST)\n\nWebSocket over HTTP/2 (RFC 8441)\nHTTP/2 연결 위에서 WebSocket 사용 가능\n연결 효율성 + 양방향 통신 장점 결합",
    "references": [
      {
        "title": "RFC 7540 - HTTP/2",
        "url": "https://datatracker.ietf.org/doc/html/rfc7540"
      },
      {
        "title": "RFC 8441 - WebSocket over HTTP/2",
        "url": "https://datatracker.ietf.org/doc/html/rfc8441"
      }
    ],
    "keywords": [
      "websocket",
      "http",
      "tcp",
      "full-duplex",
      "hpack",
      "server",
      "push",
      "api",
      "rest",
      "rfc",
      "기본",
      "비교",
      "구분",
      "목적",
      "양방향"
    ]
  },
  {
    "id": "WS-017",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 연결의 성능 최적화를 위한 고려사항은 무엇인가요?",
    "answer": "메시지 최적화\n\n직렬화 포맷 선택\n\n포맷   크기   속도   사용 사례\n\nJSON   큼   보통   일반 웹앱\nMessagePack   작음   빠름   모바일 앱\nProtobuf   매우 작음   매우 빠름   고성능 시스템\n메시지 배치 처리\n압축 활용\n연결 풀링\n단일 연결로 여러 채널 멀티플렉싱\n연결 수 최소화\nBackpressure 처리\n효율적인 브로드캐스트",
    "references": [],
    "keywords": [
      "json",
      "messagepack",
      "protobuf",
      "backpressure",
      "메시지",
      "최적화",
      "직렬화",
      "포맷",
      "선택",
      "크기",
      "속도",
      "사용",
      "사례",
      "보통",
      "일반"
    ]
  },
  {
    "id": "WS-018",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 서버 구축 시 장애 조치(failover) 방안을 어떻게 마련할 수 있나요?",
    "answer": "헬스 체크 및 자동 복구\n클라이언트 측 재연결\n상태 동기화 전략\nStateless 설계: 세션 상태를 Redis 등 외부 저장소에 저장\n이벤트 소싱: 재연결 시 마지막 이벤트부터 재전송\n서킷 브레이커\n다중 데이터센터\nDNS 기반 장애 조치\nGeoDNS로 가장 가까운 서버 연결\n데이터센터 간 메시지 동기화",
    "references": [],
    "keywords": [
      "stateless",
      "redis",
      "dns",
      "geodns",
      "헬스",
      "체크",
      "자동",
      "복구",
      "클라이언트",
      "재연결",
      "상태",
      "동기화",
      "전략",
      "설계",
      "세션"
    ]
  },
  {
    "id": "WS-019",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "클라이언트에서 WebSocket 연결 오류를 디버깅하는 방법에는 어떤 것들이 있나요?",
    "answer": "브라우저 개발자 도구\n\nNetwork 탭\nWS 필터로 WebSocket 연결만 필터링\n핸드셰이크 요청/응답 헤더 확인\nMessages 탭에서 송수신 메시지 확인\n\nConsole 로깅\n이벤트 핸들러 상세 로깅\n상태 코드 분석\n코드   의미   해결 방법\n\n1006   비정상 종료   네트워크/서버 문제 확인\n1002   프로토콜 오류   프레임 형식 확인\n1003   지원 안되는 데이터   데이터 타입 확인\n1015   TLS 실패   인증서 확인\n외부 도구\nWireshark: 패킷 레벨 분석\nwscat: CLI WebSocket 클라이언트\nPostman: WebSocket 요청 테스트\n서버 측 로깅 확인\n핸드셰이크 실패 원인\nOrigin 검증 실패 여부\n인증/인가 오류\n일반적인 문제와 해결\nCORS 오류: 서버 Origin 화이트리스트 확인\nSSL 오류: wss:// 사용 시 유효한 인증서 필요\n프록시 문제: Upgrade 헤더 전달 확인",
    "references": [],
    "keywords": [
      "network",
      "websocket",
      "messages",
      "console",
      "tls",
      "wireshark",
      "cli",
      "postman",
      "origin",
      "cors",
      "ssl",
      "upgrade",
      "브라우저",
      "개발자",
      "도구"
    ]
  },
  {
    "id": "WS-020",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket과 서버 푸시(Server-Sent Events)의 차이점은 무엇인가요?",
    "answer": "기본 비교\n\n구분   WebSocket   SSE (Server-Sent Events)\n\n통신 방향   양방향 (Full-Duplex)   단방향 (서버→클라이언트)\n프로토콜   ws:// / wss://   HTTP/HTTPS\n데이터 형식   텍스트/바이너리   텍스트만 (UTF-8)\n재연결   직접 구현   자동 재연결 내장\n브라우저 지원   대부분 지원   IE 미지원\n프록시 호환   문제 가능   HTTP라 호환성 좋음\n\nSSE 특징\n\nSSE 장점\nHTTP 기반으로 구현 간단\n자동 재연결 (retry: 필드)\n이벤트 ID로 누락 메시지 복구\n\nWebSocket 장점\n클라이언트→서버 실시간 전송\n바이너리 데이터 지원\n낮은 오버헤드\n\n선택 기준\nSSE: 주식 시세, 알림, 뉴스 피드 등 단방향\nWebSocket: 채팅, 게임, 협업 도구 등 양방향",
    "references": [
      {
        "title": "MDN Server-Sent Events",
        "url": "https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events"
      }
    ],
    "keywords": [
      "websocket",
      "sse",
      "server-sent",
      "events",
      "full-duplex",
      "http",
      "https",
      "utf-8",
      "기본",
      "비교",
      "구분",
      "통신",
      "방향",
      "양방향",
      "단방향"
    ]
  },
  {
    "id": "WS-021",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "TLS/SSL을 활용하여 WebSocket 연결을 보호하는 방법에 대해 설명해주세요.",
    "answer": "WSS (WebSocket Secure)\nwss:// 프로토콜 사용\nTLS/SSL 위에서 WebSocket 통신 암호화\nHTTPS와 동일한 보안 수준\n\nNode.js WSS 서버 설정\n\n인증서 관리\nLet's Encrypt: 무료 SSL 인증서 (90일 갱신)\n상용 CA: 유효 기간 긴 인증서\n자체 서명: 개발 환경용\n\nTLS 버전 설정\n\nNginx TLS 터미네이션\n\n보안 고려사항\n취약한 암호화 스위트 비활성화\nHSTS 헤더 설정\n인증서 자동 갱신 설정",
    "references": [
      {
        "title": "RFC 6455 Section 11.1.2 - Secure WebSocket",
        "url": "https://datatracker.ietf.org/doc/html/rfc6455#section-11.1.2"
      }
    ],
    "keywords": [
      "wss",
      "websocket",
      "secure",
      "tls",
      "ssl",
      "https",
      "node",
      "let",
      "encrypt",
      "nginx",
      "hsts",
      "프로토콜",
      "사용",
      "위에서",
      "통신"
    ]
  },
  {
    "id": "WS-022",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 통신에서 프록시 서버 사용 시 발생할 수 있는 문제는 무엇인가요?",
    "answer": "주요 문제점\nHTTP Upgrade 미지원\n일부 프록시가 Upgrade 헤더를 인식하지 못함\n101 Switching Protocols 응답 차단\n연결 타임아웃\n프록시가 유휴 연결을 강제 종료\n기본값이 짧은 경우 (30초~2분) 빈번한 끊김\n버퍼링 문제\n프록시가 응답을 버퍼링하여 실시간성 저하\n청크 전송 시 문제 발생 가능\nSSL 종료\n중간에서 SSL 종료 시 ws:// vs wss:// 혼동\n\n해결 방법\n\nNginx 프록시 설정\n\nHAProxy 설정\n\n클라이언트 측 대응\nWSS 사용 (HTTPS 포트 443 통과 용이)\nPolling 폴백 (Socket.IO 방식)\n짧은 Ping 간격으로 연결 유지",
    "references": [],
    "keywords": [
      "http",
      "upgrade",
      "switching",
      "protocols",
      "ssl",
      "nginx",
      "haproxy",
      "wss",
      "https",
      "polling",
      "socket",
      "ping",
      "주요",
      "문제점",
      "미지원"
    ]
  },
  {
    "id": "WS-023",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 라이브러리(예: Socket.IO, ws 등)의 차이점과 선택 기준에 대해 설명해주세요.",
    "answer": "주요 라이브러리 비교\n\n라이브러리   특징   장점   단점\n\nws   순수 WebSocket   경량, 빠름, 표준 준수   기능 최소\nSocket.IO   기능 풍부한 추상화   자동 재연결, 룸, 폴백   무거움, 비표준\nSockJS   폴백 지원   브라우저 호환성   Socket.IO보다 가벼움\nµWebSockets   고성능   매우 빠름   C++ 바인딩\n\nws (Node.js 표준)\n순수 WebSocket RFC 6455 구현\n추가 기능 없음 (직접 구현 필요)\n\nSocket.IO\n자동 재연결: 지수 백오프 내장\n룸/네임스페이스: 그룹 통신\n폴백: Long Polling 자동 전환\n이벤트 기반 API: emit/on 패턴\n\n선택 기준\n\n상황   추천\n\n고성능, 최소 오버헤드   ws, µWebSockets\n빠른 개발, 풍부한 기능   Socket.IO\n레거시 브라우저 지원   SockJS, Socket.IO\n클러스터 환경   Socket.IO (Redis Adapter)\n표준 WebSocket 클라이언트 연동   ws (Socket.IO는 호환 불가)\n\n주의: Socket.IO 클라이언트는 순수 WebSocket 서버와 호환되지 않음",
    "references": [
      {
        "title": "ws npm package",
        "url": "https://www.npmjs.com/package/ws"
      },
      {
        "title": "Socket.IO Documentation",
        "url": "https://socket.io/docs/v4/"
      }
    ],
    "keywords": [
      "websocket",
      "socket",
      "sockjs",
      "websockets",
      "node",
      "rfc",
      "long",
      "polling",
      "api",
      "redis",
      "adapter",
      "주요",
      "라이브러리",
      "비교",
      "특징"
    ]
  },
  {
    "id": "WS-024",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket을 활용한 Pub/Sub 시스템 구현 방법에 대해 설명해주세요.",
    "answer": "Pub/Sub 패턴\nPublisher: 메시지 발행자\nSubscriber: 메시지 구독자\nChannel/Topic: 메시지 분류\n\n기본 구현\n\nRedis Pub/Sub 연동 (클러스터 환경)\n\n고급 기능\n와일드카드 구독: news.* 패턴 매칭\n메시지 필터링: 구독 시 조건 지정\n메시지 히스토리: 최근 N개 메시지 캐싱",
    "references": [],
    "keywords": [
      "pub",
      "sub",
      "publisher",
      "subscriber",
      "channel",
      "topic",
      "redis",
      "패턴",
      "메시지",
      "발행자",
      "구독자",
      "분류",
      "기본",
      "구현",
      "연동"
    ]
  },
  {
    "id": "WS-025",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 연결 종료 시 graceful shutdown을 구현하는 방법은 무엇인가요?",
    "answer": "Graceful Shutdown 필요성\n클라이언트에게 종료 사유 전달\n진행 중인 메시지 처리 완료\n리소스 정리 시간 확보\n\n클라이언트 측 구현\n\n서버 측 구현\n\nClose Frame 교환\n종료 측이 Close 프레임 전송\n상대방이 Close 프레임으로 응답\nTCP 연결 종료",
    "references": [],
    "keywords": [
      "graceful",
      "shutdown",
      "close",
      "frame",
      "tcp",
      "필요성",
      "클라이언트에게",
      "종료",
      "사유",
      "전달",
      "진행",
      "중인",
      "메시지",
      "처리",
      "완료"
    ]
  },
  {
    "id": "WS-026",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket의 버전 관리 및 프로토콜 업데이트가 필요한 이유는 무엇인가요?",
    "answer": "버전 관리의 필요성\nAPI 변경 시 하위 호환성 유지\n점진적 마이그레이션 지원\n클라이언트-서버 불일치 방지\n\n프로토콜 버전 관리 방법\n핸드셰이크 시 버전 협상\nSec-WebSocket-Protocol 활용\n메시지 레벨 버전\n\n업데이트 전략\nBackward Compatible: 새 필드는 optional\nDeprecation Period: 구버전 일정 기간 지원\nFeature Flags: 기능별 활성화/비활성화",
    "references": [
      {
        "title": "RFC 6455 Section 4.2 - Protocol Negotiation",
        "url": "https://datatracker.ietf.org/doc/html/rfc6455#section-4.2"
      }
    ],
    "keywords": [
      "api",
      "sec-websocket-protocol",
      "backward",
      "compatible",
      "deprecation",
      "period",
      "feature",
      "flags",
      "버전",
      "관리의",
      "필요성",
      "변경",
      "하위",
      "호환성",
      "유지"
    ]
  },
  {
    "id": "WS-027",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 통신에서 데이터 압축 기능을 사용할 때 고려해야 할 점은 무엇인가요?",
    "answer": "permessage-deflate 확장 (RFC 7692)\nzlib DEFLATE 알고리즘 사용\n메시지 단위로 압축/해제\n\n설정 예시\n\n고려사항\n\n항목   고려점\n\nCPU 오버헤드   압축/해제에 CPU 사용, 고빈도 메시지 시 부하\n메시지 크기   작은 메시지는 압축 효율 낮음 (오히려 증가 가능)\n이미 압축된 데이터   이미지, 동영상 등은 압축 효과 없음\n메모리 사용   Sliding window 유지에 메모리 필요\n지연시간   압축 시간만큼 추가 지연\n\n권장 사항\nthreshold 설정: 일정 크기 이상만 압축\n압축 레벨: 1-3 (빠른 속도) vs 9 (최대 압축)\nContextTakeover: false로 설정 시 메모리 절약 but 압축률 감소\n선택적 압축: 텍스트 데이터만 압축, 바이너리는 제외\n\n비활성화가 나은 경우\n짧은 메시지 위주\nCPU 리소스 제한적\n이미 압축된 데이터 (Protobuf 등)",
    "references": [
      {
        "title": "RFC 7692 - Compression Extensions",
        "url": "https://datatracker.ietf.org/doc/html/rfc7692"
      }
    ],
    "keywords": [
      "permessage-deflate",
      "rfc",
      "deflate",
      "cpu",
      "sliding",
      "contexttakeover",
      "protobuf",
      "확장",
      "알고리즘",
      "사용",
      "메시지",
      "단위로",
      "압축",
      "해제",
      "설정"
    ]
  },
  {
    "id": "WS-028",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 연결 시 세션 관리를 구현하는 방법에는 어떤 것들이 있나요?",
    "answer": "세션 관리의 필요성\n사용자 식별\n상태 유지 (인증, 권한)\n재연결 시 컨텍스트 복구\n연결별 세션 저장\n외부 저장소 연동 (Redis)\n쿠키 기반 세션\n재연결 시 세션 복구\n\n세션 만료 처리",
    "references": [],
    "keywords": [
      "redis",
      "세션",
      "관리의",
      "필요성",
      "사용자",
      "식별",
      "상태",
      "유지",
      "인증",
      "권한",
      "재연결",
      "컨텍스트",
      "복구",
      "연결별",
      "저장"
    ]
  },
  {
    "id": "WS-029",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 서버와 클라이언트 간의 인증 및 인가 방식은 어떻게 구현하나요?",
    "answer": "인증 타이밍\n핸드셰이크 시 (권장): 연결 전 검증\n연결 후 첫 메시지: 인증 전까지 제한된 동작만 허용\n쿼리 파라미터 토큰\n핸드셰이크 헤더 (제한적)\n쿠키 기반 인증\n첫 메시지 인증\n\n인가 (Authorization)",
    "references": [],
    "keywords": [
      "authorization",
      "인증",
      "타이밍",
      "핸드셰이크",
      "권장",
      "연결",
      "검증",
      "메시지",
      "전까지",
      "제한된",
      "동작만",
      "허용",
      "쿼리",
      "파라미터",
      "토큰"
    ]
  },
  {
    "id": "WS-030",
    "category": "websocket",
    "categoryName": "WebSocket",
    "priority": "P3",
    "question": "WebSocket 기반 애플리케이션에서 발생할 수 있는 일반적인 문제와 해결 방안은 무엇인가요?",
    "answer": "연결 끊김 (Connection Drop)\n원인   해결\n\n네트워크 불안정   자동 재연결 + Exponential Backoff\n프록시/방화벽 타임아웃   Ping/Pong Heartbeat\n서버 재시작   Graceful shutdown + 클라이언트 재연결\n메시지 유실\n메모리 누수\n이벤트 리스너 해제 누락\n연결 종료 시 정리\n순서 보장 문제\n대량 연결 처리\nOS 파일 디스크립터 제한 증가\nConnection 풀링\n로드밸런서 도입\n브라우저 호환성\n폴백 메커니즘 (Long Polling)\nSocket.IO 등 라이브러리 활용\n디버깅 어려움\n구조화된 로깅\n연결 ID 추적\n메시지 샘플링 기록\n\n모니터링 지표\n동시 연결 수\n메시지 처리량 (msg/sec)\n평균 지연시간\n에러율",
    "references": [],
    "keywords": [
      "connection",
      "drop",
      "exponential",
      "backoff",
      "ping",
      "pong",
      "heartbeat",
      "graceful",
      "long",
      "polling",
      "socket",
      "연결",
      "끊김",
      "원인",
      "해결"
    ]
  },
  {
    "id": "KTOR-001",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor가 무엇인지, 다른 웹 프레임워크(Spring, NestJS 등)와 비교했을 때 어떤 특징이 있는지 설명해 주세요.",
    "answer": "Ktor는 JetBrains에서 개발한 Kotlin 기반의 비동기 웹 프레임워크입니다.\n\n주요 특징:\n경량성: 필요한 기능만 플러그인으로 추가하는 모듈식 구조\nKotlin 네이티브: Kotlin DSL을 활용한 직관적인 API 설계\nCoroutine 기반: 비동기 처리를 코루틴으로 자연스럽게 구현\n멀티플랫폼: JVM, Android, JavaScript, Native 지원\n서버/클라이언트 통합: 동일한 프레임워크로 서버와 HTTP 클라이언트 구현 가능\n\nSpring과 비교:\n항목   Ktor   Spring\n\n학습 곡선   낮음   높음\n시작 시간   빠름   상대적으로 느림\n생태계   성장 중   매우 풍부\nDI   선택적 (Koin, Kodein)   내장 (IoC Container)",
    "references": [
      {
        "title": "Ktor 공식 홈페이지",
        "url": "https://ktor.io/"
      }
    ],
    "keywords": [
      "ktor",
      "jetbrains",
      "kotlin",
      "dsl",
      "api",
      "coroutine",
      "jvm",
      "android",
      "javascript",
      "native",
      "http",
      "spring",
      "koin",
      "kodein",
      "ioc"
    ]
  },
  {
    "id": "KTOR-002",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor의 비동기 처리 방식에 대해 설명해 주세요. Kotlin Coroutine과 어떻게 연동되나요?",
    "answer": "Ktor는 처음부터 Kotlin Coroutine을 기반으로 설계되어 비동기 처리가 자연스럽게 통합되어 있습니다.\n\n비동기 처리 방식:\n\nCoroutine 연동 특징:\n모든 핸들러가 suspend 함수: 블로킹 없이 I/O 작업 처리\nCIO 엔진: Coroutine-based I/O 엔진으로 순수 Kotlin 구현\nStructured Concurrency: 클라이언트 연결 해제 시 관련 코루틴 자동 취소\n병렬 요청 처리: launch나 async를 사용해 동시 요청 가능",
    "references": [
      {
        "title": "Ktor Async Documentation",
        "url": "https://ktor.io/docs/async.html"
      }
    ],
    "keywords": [
      "ktor",
      "kotlin",
      "coroutine",
      "cio",
      "coroutine-based",
      "structured",
      "concurrency",
      "처음부터",
      "기반으로",
      "설계되어",
      "비동기",
      "처리가",
      "자연스럽게",
      "통합되어",
      "처리"
    ]
  },
  {
    "id": "KTOR-003",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 Application과 Application Module의 개념에 대해 설명해 주세요.",
    "answer": "Application:\nKtor 서버의 핵심 인스턴스로, 모든 설정과 플러그인이 등록되는 컨테이너입니다.\n\nApplication Module:\nApplication의 설정을 구성하는 확장 함수입니다. 플러그인 설치, 라우팅 설정 등을 담당합니다.\n\n특징:\n모듈 분리: 기능별로 모듈을 나눠 관리 가능\n플러그인 공유: 한 모듈에 설치된 플러그인은 다른 모듈에서도 적용\n설정 파일 연동: application.conf에서 모듈 지정 가능",
    "references": [
      {
        "title": "Ktor Modules",
        "url": "https://ktor.io/docs/server-modules.html"
      }
    ],
    "keywords": [
      "application",
      "ktor",
      "module",
      "서버의",
      "핵심",
      "인스턴스로",
      "모든",
      "설정과",
      "플러그인이",
      "등록되는",
      "컨테이너입니다",
      "설정을",
      "구성하는",
      "확장",
      "함수입니다"
    ]
  },
  {
    "id": "KTOR-004",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor의 경량성(Lightweight)이란 무엇을 의미하나요? 어떤 장단점이 있나요?",
    "answer": "Ktor의 경량성은 필요한 기능만 선택적으로 추가하는 플러그인 기반 아키텍처를 의미합니다.\n\n경량성의 의미:\n코어에는 최소한의 기능만 포함\n인증, 직렬화, 세션 등은 별도 플러그인으로 제공\n사용하지 않는 기능은 애플리케이션에 포함되지 않음\n\n장점:\n빠른 시작 시간: 불필요한 기능 로딩 없음\n낮은 메모리 사용량: 필요한 것만 로드\n유연한 구성: 프로젝트 요구사항에 맞춤 설정\n작은 배포 크기: Fat JAR 크기 최소화\n\n단점:\n수동 설정 필요: 기능별로 직접 플러그인 추가\n작은 생태계: Spring 대비 서드파티 라이브러리 부족\n학습 필요: 필요한 플러그인 파악 필요",
    "references": [
      {
        "title": "Ktor Server Plugins",
        "url": "https://ktor.io/docs/server-plugins.html"
      }
    ],
    "keywords": [
      "ktor",
      "fat",
      "jar",
      "spring",
      "경량성은",
      "필요한",
      "기능만",
      "선택적으로",
      "추가하는",
      "플러그인",
      "기반",
      "아키텍처를",
      "의미합니다",
      "경량성의",
      "의미"
    ]
  },
  {
    "id": "KTOR-005",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 라우팅(Routing)을 설정하는 방법에 대해 설명해 주세요.",
    "answer": "Ktor에서 라우팅은 routing DSL을 사용하여 설정합니다.\n\nHTTP 메서드 함수:\nget(), post(), put(), delete(), patch(), head(), options()\n\n라우팅 특징:\n계층적 구조: route()로 경로 중첩 가능\nDSL 기반: Kotlin DSL로 가독성 높은 코드\n플러그인 적용: 특정 라우트에만 플러그인 적용 가능",
    "references": [
      {
        "title": "Ktor Routing",
        "url": "https://ktor.io/docs/server-routing.html"
      }
    ],
    "keywords": [
      "ktor",
      "dsl",
      "http",
      "kotlin",
      "에서",
      "라우팅은",
      "사용하여",
      "설정합니다",
      "메서드",
      "함수",
      "라우팅",
      "특징",
      "계층적",
      "구조",
      "경로"
    ]
  },
  {
    "id": "KTOR-006",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor의 Route DSL에 대해 설명해 주세요.",
    "answer": "Route DSL은 Kotlin의 타입 안전 빌더 패턴을 활용한 라우팅 정의 방식입니다.\n\nDSL 구성 요소:\nroute(): 경로 그룹화\nHTTP 동사 함수: get, post, put, delete 등\n경로 패턴: 정적 경로, 파라미터({id}), 와일드카드(`), 테일카드({...}`)\n\nType-Safe Routing (Resources 플러그인):",
    "references": [
      {
        "title": "Ktor Type-safe Routing",
        "url": "https://ktor.io/docs/server-resources.html"
      }
    ],
    "keywords": [
      "route",
      "dsl",
      "kotlin",
      "http",
      "type-safe",
      "routing",
      "resources",
      "타입",
      "안전",
      "빌더",
      "패턴을",
      "활용한",
      "라우팅",
      "정의",
      "방식입니다"
    ]
  },
  {
    "id": "KTOR-007",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Path Parameter, Query Parameter를 처리하는 방법에 대해 설명해 주세요.",
    "answer": "Path Parameter 처리:\n\nQuery Parameter 처리:\n\nType-Safe 방식 (Resources 플러그인):",
    "references": [
      {
        "title": "Ktor Handling Requests",
        "url": "https://ktor.io/docs/server-requests.html"
      }
    ],
    "keywords": [
      "path",
      "parameter",
      "query",
      "type-safe",
      "resources",
      "처리",
      "방식",
      "플러그인"
    ]
  },
  {
    "id": "KTOR-008",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 요청 본문(Request Body)을 파싱하는 방법은 무엇인가요?",
    "answer": "ContentNegotiation 플러그인 사용 (권장):\n\n수동 파싱:",
    "references": [
      {
        "title": "Ktor Content Negotiation",
        "url": "https://ktor.io/docs/server-serialization.html"
      }
    ],
    "keywords": [
      "contentnegotiation",
      "플러그인",
      "사용",
      "권장",
      "수동",
      "파싱"
    ]
  },
  {
    "id": "KTOR-009",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor의 ApplicationCall이란 무엇이고, 어떤 역할을 하나요?",
    "answer": "ApplicationCall은 HTTP 요청/응답 사이클을 나타내는 핵심 객체입니다.\n\n주요 구성 요소:\n\nApplicationCall의 역할:\n요청 정보 접근: HTTP 메서드, 헤더, 경로, 파라미터\n요청 본문 수신: receive(), receiveText(), receiveMultipart()\n응답 전송: respond(), respondText(), respondFile()\n속성 저장: call.attributes로 요청 간 데이터 공유\n인증 정보: call.principal<T>()로 인증된 사용자 접근",
    "references": [
      {
        "title": "ApplicationCall API",
        "url": "https://api.ktor.io/ktor-server/ktor-server-core/io.ktor.server.application/-application-call/index.html"
      }
    ],
    "keywords": [
      "applicationcall",
      "http",
      "요청",
      "응답",
      "사이클을",
      "나타내는",
      "핵심",
      "객체입니다",
      "주요",
      "구성",
      "요소",
      "역할",
      "정보",
      "접근",
      "메서드"
    ]
  },
  {
    "id": "KTOR-010",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor의 플러그인(Plugin) 시스템에 대해 설명해 주세요.",
    "answer": "플러그인은 Ktor 애플리케이션에 기능을 추가하는 모듈식 구성 요소입니다.\n\n플러그인 설치:\n\n주요 내장 플러그인:\n플러그인   기능\n\nContentNegotiation   JSON/XML 직렬화\nAuthentication   인증 처리\nSessions   세션 관리\nStatusPages   예외/상태 처리\nCORS   교차 출처 요청 허용\nCallLogging   요청 로깅\n\n플러그인 동작 원리:\n요청/응답 파이프라인에 인터셉터 등록\n설정 블록에서 동작 커스터마이징\n라우트별 또는 전역으로 적용 가능",
    "references": [
      {
        "title": "Ktor Server Plugins",
        "url": "https://ktor.io/docs/server-plugins.html"
      }
    ],
    "keywords": [
      "ktor",
      "contentnegotiation",
      "json",
      "xml",
      "authentication",
      "sessions",
      "statuspages",
      "cors",
      "calllogging",
      "플러그인은",
      "애플리케이션에",
      "기능을",
      "추가하는",
      "모듈식",
      "구성"
    ]
  },
  {
    "id": "KTOR-011",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "ContentNegotiation 플러그인의 역할과 사용 방법에 대해 설명해 주세요.",
    "answer": "ContentNegotiation은 요청/응답의 콘텐츠 타입을 자동으로 처리하는 플러그인입니다.\n\n주요 역할:\nContent-Type 협상: Accept 헤더 기반으로 응답 형식 결정\n직렬화: 객체를 JSON/XML 등으로 변환\n역직렬화: 요청 본문을 객체로 변환\n\n지원 형식:\njson() - kotlinx.serialization\njackson() - Jackson\ngson() - Gson\nxml() - XML\n\n의존성:",
    "references": [
      {
        "title": "Ktor Content Negotiation",
        "url": "https://ktor.io/docs/server-serialization.html"
      }
    ],
    "keywords": [
      "contentnegotiation",
      "content-type",
      "accept",
      "json",
      "xml",
      "jackson",
      "gson",
      "요청",
      "응답의",
      "콘텐츠",
      "타입을",
      "자동으로",
      "처리하는",
      "플러그인입니다",
      "주요"
    ]
  },
  {
    "id": "KTOR-012",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 JSON 직렬화/역직렬화를 설정하는 방법은 무엇인가요? (kotlinx.serialization, Jackson, Gson)",
    "answer": "kotlinx.serialization (권장):\n\nJackson:\n\nGson:\n\n선택 기준:\nkotlinx.serialization: 멀티플랫폼, 컴파일 타임 안전성\nJackson: 풍부한 기능, Java 생태계 호환\nGson: 간단한 사용, 가벼움",
    "references": [
      {
        "title": "Ktor Serialization",
        "url": "https://ktor.io/docs/server-serialization.html"
      }
    ],
    "keywords": [
      "jackson",
      "gson",
      "java",
      "권장",
      "선택",
      "기준",
      "멀티플랫폼",
      "컴파일",
      "타임",
      "안전성",
      "풍부한",
      "기능",
      "생태계",
      "호환",
      "간단한"
    ]
  },
  {
    "id": "KTOR-013",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "StatusPages 플러그인을 사용한 예외 처리 방법에 대해 설명해 주세요.",
    "answer": "StatusPages는 예외와 HTTP 상태 코드를 일관되게 처리하는 플러그인입니다.\n\n사용 예시:",
    "references": [
      {
        "title": "Ktor Status Pages",
        "url": "https://ktor.io/docs/server-status-pages.html"
      }
    ],
    "keywords": [
      "statuspages",
      "http",
      "예외와",
      "상태",
      "코드를",
      "일관되게",
      "처리하는",
      "플러그인입니다",
      "사용",
      "예시"
    ]
  },
  {
    "id": "KTOR-014",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "CORS 플러그인 설정 방법과 주요 옵션에 대해 설명해 주세요.",
    "answer": "CORS는 Cross-Origin Resource Sharing을 활성화하는 플러그인입니다.\n\n주요 옵션:\n옵션   설명\n\nanyHost()   모든 도메인 허용\nallowHost()   특정 도메인 허용\nallowMethod()   HTTP 메서드 허용\nallowHeader()   요청 헤더 허용\nexposeHeader()   응답 헤더 노출\nallowCredentials   쿠키/인증 허용",
    "references": [
      {
        "title": "Ktor CORS",
        "url": "https://ktor.io/docs/cors.html"
      }
    ],
    "keywords": [
      "cors",
      "cross-origin",
      "resource",
      "sharing",
      "http",
      "활성화하는",
      "플러그인입니다",
      "주요",
      "옵션",
      "설명",
      "모든",
      "도메인",
      "허용",
      "특정",
      "메서드"
    ]
  },
  {
    "id": "KTOR-015",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "커스텀 플러그인을 만드는 방법에 대해 설명해 주세요.",
    "answer": "Ktor 2.0+에서는 createApplicationPlugin 함수로 커스텀 플러그인을 생성합니다.\n\n기본 플러그인:\n\n설정 가능한 플러그인:\n\n사용 가능한 핸들러:\nonCall: 요청 수신 시\nonCallReceive: 요청 본문 수신 시\nonCallRespond: 응답 전송 시",
    "references": [
      {
        "title": "Ktor Custom Plugins",
        "url": "https://ktor.io/docs/server-custom-plugins.html"
      }
    ],
    "keywords": [
      "ktor",
      "에서는",
      "함수로",
      "커스텀",
      "플러그인을",
      "생성합니다",
      "기본",
      "플러그인",
      "설정",
      "가능한",
      "사용",
      "핸들러",
      "요청",
      "수신",
      "본문"
    ]
  },
  {
    "id": "KTOR-016",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 Authentication 플러그인을 사용한 인증 구현 방법에 대해 설명해 주세요.",
    "answer": "Authentication 플러그인은 다양한 인증 방식을 제공합니다.\n\n지원 인증 방식:\nbasic: HTTP Basic Authentication\ndigest: HTTP Digest Authentication\nform: 폼 기반 인증\nbearer: Bearer 토큰 (JWT/OAuth)\nsession: 세션 기반 인증\noauth: OAuth 2.0",
    "references": [
      {
        "title": "Ktor Authentication",
        "url": "https://ktor.io/docs/server-auth.html"
      }
    ],
    "keywords": [
      "authentication",
      "http",
      "basic",
      "digest",
      "bearer",
      "jwt",
      "oauth",
      "플러그인은",
      "다양한",
      "인증",
      "방식을",
      "제공합니다",
      "지원",
      "방식",
      "기반"
    ]
  },
  {
    "id": "KTOR-017",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "JWT 인증을 Ktor에서 구현하는 방법에 대해 설명해 주세요.",
    "answer": "JWT (JSON Web Token) 인증 구현 방법입니다.",
    "references": [
      {
        "title": "Ktor JWT",
        "url": "https://ktor.io/docs/server-jwt.html"
      }
    ],
    "keywords": [
      "jwt",
      "json",
      "web",
      "token",
      "인증",
      "구현",
      "방법입니다",
      "json web token"
    ]
  },
  {
    "id": "KTOR-018",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Session 기반 인증을 Ktor에서 구현하는 방법은 무엇인가요?",
    "answer": "Sessions 플러그인으로 세션 기반 인증을 구현합니다.",
    "references": [
      {
        "title": "Ktor Session Authentication",
        "url": "https://ktor.io/docs/session-auth.html"
      }
    ],
    "keywords": [
      "sessions",
      "플러그인으로",
      "세션",
      "기반",
      "인증을",
      "구현합니다"
    ]
  },
  {
    "id": "KTOR-019",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "OAuth 인증을 Ktor에서 구현하는 방법에 대해 설명해 주세요.",
    "answer": "OAuth 2.0 인증 구현 방법입니다.",
    "references": [
      {
        "title": "Ktor OAuth",
        "url": "https://ktor.io/docs/server-oauth.html"
      }
    ],
    "keywords": [
      "oauth",
      "인증",
      "구현",
      "방법입니다"
    ]
  },
  {
    "id": "KTOR-020",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 HTTPS/SSL을 설정하는 방법은 무엇인가요?",
    "answer": "HTTPS/SSL 설정 방법:\napplication.conf 사용:\nembeddedServer 코드에서 설정:\nHTTPS 리다이렉트:\n\n인증서 생성 (keytool):",
    "references": [
      {
        "title": "Ktor SSL",
        "url": "https://ktor.io/docs/server-ssl.html"
      }
    ],
    "keywords": [
      "https",
      "ssl",
      "설정",
      "방법",
      "사용",
      "코드에서",
      "리다이렉트",
      "인증서",
      "생성",
      "keytool"
    ]
  },
  {
    "id": "KTOR-021",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor Client란 무엇이고, 어떤 상황에서 사용하나요?",
    "answer": "Ktor Client는 Kotlin으로 작성된 멀티플랫폼 비동기 HTTP 클라이언트입니다.\n\n사용 상황:\n외부 API 호출 (REST, GraphQL)\n마이크로서비스 간 통신\n웹 스크래핑\n파일 다운로드/업로드\nWebSocket 클라이언트\n\n멀티플랫폼 지원:\nJVM, Android, iOS, JavaScript, Native",
    "references": [
      {
        "title": "Ktor Client",
        "url": "https://ktor.io/docs/client-create-and-configure.html"
      }
    ],
    "keywords": [
      "ktor",
      "client",
      "kotlin",
      "http",
      "api",
      "rest",
      "graphql",
      "websocket",
      "jvm",
      "android",
      "javascript",
      "native",
      "으로",
      "작성된",
      "멀티플랫폼"
    ]
  },
  {
    "id": "KTOR-022",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor Client에서 HTTP 요청을 보내는 방법에 대해 설명해 주세요.",
    "answer": "다양한 HTTP 요청 방법:",
    "references": [
      {
        "title": "Ktor Client Requests",
        "url": "https://ktor.io/docs/client-requests.html"
      }
    ],
    "keywords": [
      "http",
      "다양한",
      "요청",
      "방법"
    ]
  },
  {
    "id": "KTOR-023",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor Client의 Engine 개념과 종류(CIO, OkHttp, Apache 등)에 대해 설명해 주세요.",
    "answer": "Engine은 실제 HTTP 통신을 처리하는 플랫폼별 구현체입니다.\n\n주요 엔진:\n\n엔진   플랫폼   특징\n\nCIO   JVM, Native   순수 Kotlin/Coroutine 기반, 가벼움\nOkHttp   JVM, Android   Android 권장, HTTP/2, 연결 풀링\nApache   JVM   풍부한 설정, 기업용\nJava   JVM 11+   java.net.http 사용\nJetty   JVM   HTTP/2 지원\nDarwin   iOS, macOS   Apple 네이티브 URLSession\nWinHttp   Windows Native   Windows 네이티브\nCurl   Linux Native   libcurl 사용\nJs   JavaScript   fetch API",
    "references": [
      {
        "title": "Ktor Client Engines",
        "url": "https://ktor.io/docs/client-engines.html"
      }
    ],
    "keywords": [
      "engine",
      "http",
      "cio",
      "jvm",
      "native",
      "kotlin",
      "coroutine",
      "okhttp",
      "android",
      "apache",
      "java",
      "jetty",
      "darwin",
      "apple",
      "urlsession"
    ]
  },
  {
    "id": "KTOR-024",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor Client에서 요청/응답 인터셉터를 설정하는 방법은 무엇인가요?",
    "answer": "인터셉터 설정 방법:\nHttpSend 플러그인 사용:\n커스텀 플러그인:\n기본 헤더 설정:",
    "references": [
      {
        "title": "Ktor HttpSend",
        "url": "https://ktor.io/docs/client-http-send.html"
      }
    ],
    "keywords": [
      "httpsend",
      "인터셉터",
      "설정",
      "방법",
      "플러그인",
      "사용",
      "커스텀",
      "기본",
      "헤더"
    ]
  },
  {
    "id": "KTOR-025",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor 애플리케이션을 테스트하는 방법에 대해 설명해 주세요.",
    "answer": "Ktor는 ktor-server-test-host 모듈로 테스트 기능을 제공합니다.\n\n테스트 특징:\n실제 서버 없이 인메모리 테스트\n빠른 실행 속도\nHTTP 클라이언트로 요청/응답 검증",
    "references": [
      {
        "title": "Ktor Testing",
        "url": "https://ktor.io/docs/server-testing.html"
      }
    ],
    "keywords": [
      "ktor",
      "ktor-server",
      "test-host",
      "http",
      "모듈로",
      "테스트",
      "기능을",
      "제공합니다",
      "특징",
      "실제",
      "서버",
      "없이",
      "인메모리",
      "빠른",
      "실행"
    ]
  },
  {
    "id": "KTOR-026",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "testApplication을 사용한 통합 테스트 작성 방법은 무엇인가요?",
    "answer": "testApplication은 Ktor 2.0+에서 제공하는 통합 테스트 DSL입니다.",
    "references": [
      {
        "title": "Ktor Testing",
        "url": "https://ktor.io/docs/server-testing.html"
      }
    ],
    "keywords": [
      "ktor",
      "dsl",
      "에서",
      "제공하는",
      "통합",
      "테스트"
    ]
  },
  {
    "id": "KTOR-027",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 Mock을 활용한 단위 테스트 작성 방법에 대해 설명해 주세요.",
    "answer": "클라이언트 MockEngine 사용:\n\n서비스 계층 Mock (Mockk 사용):\n\n의존성:",
    "references": [
      {
        "title": "Ktor Client Testing",
        "url": "https://ktor.io/docs/client-testing.html"
      }
    ],
    "keywords": [
      "mockengine",
      "mock",
      "mockk",
      "클라이언트",
      "사용",
      "서비스",
      "계층",
      "의존성"
    ]
  },
  {
    "id": "KTOR-028",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor 애플리케이션을 배포하는 방법에 대해 설명해 주세요. (Fat JAR, Docker 등)",
    "answer": "Fat JAR 배포:\nDocker 배포:\nDocker Compose:",
    "references": [
      {
        "title": "Ktor Deployment",
        "url": "https://ktor.io/docs/server-deployment.html"
      },
      {
        "title": "Ktor Docker",
        "url": "https://ktor.io/docs/docker.html"
      }
    ],
    "keywords": [
      "fat",
      "jar",
      "docker",
      "compose",
      "배포"
    ]
  },
  {
    "id": "KTOR-029",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 환경 설정(application.conf, application.yaml)을 관리하는 방법은 무엇인가요?",
    "answer": "HOCON 형식 (application.conf):\n\nYAML 형식 (application.yaml):\n\n코드에서 설정 읽기:\n\n커맨드라인 오버라이드:",
    "references": [
      {
        "title": "Ktor Configuration",
        "url": "https://ktor.io/docs/server-configuration-file.html"
      }
    ],
    "keywords": [
      "hocon",
      "yaml",
      "형식",
      "코드에서",
      "설정",
      "읽기",
      "커맨드라인",
      "오버라이드"
    ]
  },
  {
    "id": "KTOR-030",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor 애플리케이션의 로깅을 설정하는 방법에 대해 설명해 주세요.",
    "answer": "CallLogging 플러그인:\n\nlogback.xml 설정:\n\n코드에서 로깅:",
    "references": [
      {
        "title": "Ktor Call Logging",
        "url": "https://ktor.io/docs/call-logging.html"
      }
    ],
    "keywords": [
      "calllogging",
      "플러그인",
      "설정",
      "코드에서",
      "로깅"
    ]
  },
  {
    "id": "KTOR-031",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 Metrics와 모니터링을 설정하는 방법은 무엇인가요?",
    "answer": "MicrometerMetrics 플러그인:\n\n제공되는 메트릭:\nktor.http.server.requests: 요청 타이머\nktor.http.server.requests.active: 활성 요청 수\nJVM 메모리, GC, CPU 메트릭\n\nDropwizardMetrics (대안):",
    "references": [
      {
        "title": "Ktor Micrometer Metrics",
        "url": "https://ktor.io/docs/server-metrics-micrometer.html"
      }
    ],
    "keywords": [
      "micrometermetrics",
      "jvm",
      "cpu",
      "dropwizardmetrics",
      "플러그인",
      "제공되는",
      "메트릭",
      "요청",
      "타이머",
      "활성",
      "메모리",
      "대안"
    ]
  },
  {
    "id": "KTOR-032",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 WebSocket을 구현하는 방법에 대해 설명해 주세요.",
    "answer": "WebSocket 서버 구현:\n\n브로드캐스트 채팅 예시:",
    "references": [
      {
        "title": "Ktor WebSockets",
        "url": "https://ktor.io/docs/server-websockets.html"
      }
    ],
    "keywords": [
      "websocket",
      "서버",
      "구현",
      "브로드캐스트",
      "채팅",
      "예시"
    ]
  },
  {
    "id": "KTOR-033",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 Server-Sent Events(SSE)를 구현하는 방법은 무엇인가요?",
    "answer": "SSE 서버 구현:\n\n클라이언트 (JavaScript):\n\nSSE vs WebSocket:\nSSE: 서버 -> 클라이언트 단방향, HTTP 기반\nWebSocket: 양방향, 별도 프로토콜",
    "references": [
      {
        "title": "Ktor SSE",
        "url": "https://ktor.io/docs/server-server-sent-events.html"
      }
    ],
    "keywords": [
      "sse",
      "javascript",
      "websocket",
      "http",
      "서버",
      "구현",
      "클라이언트",
      "단방향",
      "기반",
      "양방향",
      "별도",
      "프로토콜"
    ]
  },
  {
    "id": "KTOR-034",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 파일 업로드/다운로드를 처리하는 방법에 대해 설명해 주세요.",
    "answer": "파일 업로드:\n\n파일 다운로드:",
    "references": [
      {
        "title": "Ktor Requests",
        "url": "https://ktor.io/docs/server-requests.html"
      }
    ],
    "keywords": [
      "파일",
      "업로드",
      "다운로드"
    ]
  },
  {
    "id": "KTOR-035",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor에서 Dependency Injection을 구현하는 방법에 대해 설명해 주세요. (Koin, Kodein 등)",
    "answer": "Koin 사용:\nKtor 내장 DI (3.x+):\n수동 DI (권장 - 간단한 경우):",
    "references": [
      {
        "title": "Ktor Dependency Injection",
        "url": "https://ktor.io/docs/server-dependency-injection.html"
      },
      {
        "title": "Koin for Ktor",
        "url": "https://start.ktor.io/p/koin"
      }
    ],
    "keywords": [
      "koin",
      "ktor",
      "사용",
      "내장",
      "수동",
      "권장",
      "간단한"
    ]
  },
  {
    "id": "KTOR-036",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor와 Spring Boot를 비교했을 때 각각의 장단점은 무엇인가요?",
    "answer": "항목   Ktor   Spring Boot\n\n언어   Kotlin 네이티브   Java/Kotlin\n아키텍처   경량, 모듈식   풀스택, 컨벤션 기반\n비동기   Coroutine 기본   WebFlux 별도\n시작 시간   매우 빠름   상대적으로 느림\n메모리   낮음   높음\n학습 곡선   낮음   높음\n생태계   성장 중   매우 풍부\nDI   외부 라이브러리   내장 IoC\n문서/커뮤니티   적음   풍부함\n\nKtor 장점:\nKotlin DSL로 간결한 코드\n빠른 시작 시간과 낮은 메모리\n필요한 기능만 선택적 추가\nCoroutine 자연스러운 통합\n\nSpring Boot 장점:\n풍부한 생태계와 서드파티\n엔터프라이즈 검증된 안정성\n방대한 문서와 커뮤니티\n다양한 통합 기능 내장\n\nKtor 단점:\n작은 생태계\n기업 채용 시장에서 덜 인기\n직접 설정해야 할 것이 많음\n\nSpring Boot 단점:\n무거운 초기 설정\n복잡한 학습 곡선\n오버헤드가 큼",
    "references": [
      {
        "title": "Ktor 공식 홈페이지",
        "url": "https://ktor.io/"
      }
    ],
    "keywords": [
      "ktor",
      "spring",
      "boot",
      "kotlin",
      "java",
      "coroutine",
      "webflux",
      "ioc",
      "dsl",
      "항목",
      "언어",
      "네이티브",
      "아키텍처",
      "경량",
      "모듈식"
    ]
  },
  {
    "id": "KTOR-037",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor를 선택해야 하는 상황과 그렇지 않은 상황에 대해 설명해 주세요.",
    "answer": "Ktor를 선택해야 하는 상황:\n마이크로서비스: 경량 프레임워크로 빠른 시작과 낮은 메모리\nKotlin 전용 프로젝트: Kotlin DSL의 이점 최대화\n비동기 처리 중심: Coroutine 기반 자연스러운 비동기\n빠른 프로토타이핑: 간단한 설정으로 빠른 개발\n서버리스/컨테이너: 작은 배포 크기, 빠른 콜드 스타트\n멀티플랫폼: 서버/클라이언트 코드 공유\n\nKtor를 피해야 하는 상황:\n엔터프라이즈 레거시 통합: Spring 생태계 필요\n대규모 팀: Spring의 컨벤션이 유리\n풍부한 ORM 필요: JPA/Hibernate 통합 선호 시\n복잡한 보안 요구: Spring Security 수준 필요\nJava 개발자 위주 팀: Kotlin 학습 비용\n검증된 솔루션 필요: 기업 레퍼런스 중요\n\n권장 사용 사례:\nREST API 서버\n실시간 통신 (WebSocket, SSE)\nBFF (Backend for Frontend)\n내부 마이크로서비스",
    "references": [
      {
        "title": "Ktor FAQ",
        "url": "https://ktor.io/docs/faq.html"
      }
    ],
    "keywords": [
      "ktor",
      "kotlin",
      "dsl",
      "coroutine",
      "spring",
      "orm",
      "jpa",
      "hibernate",
      "security",
      "java",
      "rest",
      "api",
      "websocket",
      "sse",
      "bff"
    ]
  },
  {
    "id": "KTOR-038",
    "category": "ktor",
    "categoryName": "Ktor",
    "priority": "P4",
    "question": "Ktor의 성능 특성과 최적화 방법에 대해 설명해 주세요.",
    "answer": "Ktor 성능 특성:\nCoroutine 기반: 스레드 블로킹 없는 비동기 처리\n경량 런타임: 최소한의 오버헤드\nCIO 엔진: 순수 Kotlin으로 구현된 경량 엔진\n\n최적화 방법:\n엔진 선택:\n연결 풀 설정:\n직렬화 최적화:\n응답 압축:\n캐싱:\n데이터베이스 연결 풀:",
    "references": [
      {
        "title": "Ktor Server Engines",
        "url": "https://ktor.io/docs/server-engines.html"
      }
    ],
    "keywords": [
      "ktor",
      "coroutine",
      "cio",
      "kotlin",
      "성능",
      "특성",
      "기반",
      "스레드",
      "블로킹",
      "없는",
      "비동기",
      "처리",
      "경량",
      "런타임",
      "최소한의"
    ]
  },
  {
    "id": "SPRING-001",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "IoC와 DI에 대해 설명해 주세요.",
    "answer": "IoC (Inversion of Control, 제어의 역전)\n객체의 생성과 생명주기 관리를 개발자가 아닌 프레임워크(컨테이너)가 담당하는 것\n기존에는 개발자가 직접 new 키워드로 객체를 생성하고 의존성을 관리했지만, IoC에서는 컨테이너가 이를 대신 수행\n\"Don't call us, we'll call you\" (할리우드 원칙)\n\nDI (Dependency Injection, 의존성 주입)\nIoC를 구현하는 디자인 패턴 중 하나\n객체가 필요로 하는 의존성을 외부에서 주입받는 방식\n주입 방식 3가지:\n생성자 주입 (권장): 불변성 보장, 테스트 용이\nSetter 주입: 선택적 의존성에 사용\n필드 주입: 간단하지만 테스트 어려움\n\n장점\n결합도 감소, 유연성 증가\n단위 테스트 용이 (Mock 객체 주입 가능)\n코드 재사용성 향상",
    "references": [],
    "keywords": [
      "ioc",
      "inversion",
      "control",
      "don",
      "dependency",
      "injection",
      "setter",
      "mock",
      "제어의",
      "역전",
      "객체의",
      "생성과",
      "생명주기",
      "관리를",
      "개발자가"
    ]
  },
  {
    "id": "SPRING-002",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "후보 없이 특정 기능을 하는 클래스가 딱 한 개하면, 구체 클래스를 그냥 사용해도 되지 않나요? 그럼에도 불구하고 왜 Spring에선 Bean을 사용 할까요?",
    "answer": "구체 클래스 직접 사용의 문제점\n클래스 간 강한 결합(tight coupling) 발생\n테스트 시 Mock 객체로 대체하기 어려움\n향후 요구사항 변경 시 코드 수정 범위가 커짐\n\nSpring Bean을 사용하는 이유\n생명주기 관리: Bean의 생성, 초기화, 소멸을 컨테이너가 관리\n싱글톤 보장: 기본적으로 하나의 인스턴스만 생성하여 메모리 효율성 확보\nAOP 적용 가능: 프록시 기반으로 트랜잭션, 로깅 등 횡단 관심사 적용\n테스트 용이성: 테스트 환경에서 쉽게 다른 구현체로 교체 가능\n확장성: 나중에 구현체가 추가되더라도 설정만 변경하면 됨\n설정 외부화: 환경별로 다른 Bean 설정 적용 가능 (Profile)\n\n결론: 현재는 구현체가 하나여도, 미래의 확장성과 테스트 용이성, AOP 적용을 위해 Bean으로 관리하는 것이 좋습니다.",
    "references": [],
    "keywords": [
      "mock",
      "spring",
      "bean",
      "aop",
      "profile",
      "구체",
      "클래스",
      "직접",
      "사용의",
      "문제점",
      "강한",
      "결합",
      "발생",
      "테스트",
      "객체로"
    ]
  },
  {
    "id": "SPRING-003",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring의 Bean 생성 주기에 대해 설명해 주세요.",
    "answer": "Spring Bean 생명주기 단계\n스프링 컨테이너 생성\nBean 인스턴스화: 생성자 호출하여 객체 생성\n의존성 주입 (DI): @Autowired 등으로 의존성 주입\n초기화 콜백:\n@PostConstruct 메서드 실행\nInitializingBean.afterPropertiesSet() 실행\n@Bean(initMethod=\"...\") 지정 메서드 실행\nBean 사용: 애플리케이션에서 Bean 사용\n소멸 콜백 (컨테이너 종료 시):\n@PreDestroy 메서드 실행\nDisposableBean.destroy() 실행\n@Bean(destroyMethod=\"...\") 지정 메서드 실행\n\n콜백 우선순위\n@PostConstruct > InitializingBean > initMethod\n@PreDestroy > DisposableBean > destroyMethod\n\n권장 방식: @PostConstruct와 @PreDestroy 사용 (간결하고 스프링 독립적)",
    "references": [],
    "keywords": [
      "spring",
      "bean",
      "autowired",
      "postconstruct",
      "initializingbean",
      "predestroy",
      "disposablebean",
      "생명주기",
      "단계",
      "스프링",
      "컨테이너",
      "생성",
      "인스턴스화",
      "생성자",
      "호출하여"
    ]
  },
  {
    "id": "SPRING-004",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "프로토타입 빈은 무엇인가요?",
    "answer": "프로토타입 빈 (Prototype Bean)\n요청할 때마다 새로운 인스턴스를 생성하는 스코프\n@Scope(\"prototype\") 또는 @Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)로 설정\n\n싱글톤 vs 프로토타입\n구분   싱글톤   프로토타입\n\n인스턴스 수   1개   요청마다 새로 생성\n생명주기 관리   컨테이너가 전체 관리   생성과 DI까지만 관리\n@PreDestroy   호출됨   호출 안됨\n\n사용 사례\n상태를 가지는(stateful) 객체\n매번 새로운 인스턴스가 필요한 경우\n\n주의사항\n싱글톤 Bean에서 프로토타입 Bean을 주입받으면, 프로토타입도 한 번만 주입되어 싱글톤처럼 동작함\n→ 해결: ObjectProvider, Provider<T>, 또는 @Lookup 사용",
    "references": [],
    "keywords": [
      "prototype",
      "bean",
      "scope",
      "configurablebeanfactory",
      "scope_prototype",
      "predestroy",
      "objectprovider",
      "provider",
      "lookup",
      "프로토타입",
      "요청할",
      "때마다",
      "새로운",
      "인스턴스를",
      "생성하는"
    ]
  },
  {
    "id": "SPRING-005",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "AOP에 대해 설명해 주세요.",
    "answer": "AOP (Aspect Oriented Programming, 관점 지향 프로그래밍)\n횡단 관심사(Cross-Cutting Concerns)를 모듈화하는 프로그래밍 패러다임\n핵심 비즈니스 로직과 부가 기능(로깅, 트랜잭션, 보안 등)을 분리\n\n핵심 용어\n용어   설명\n\nAspect   횡단 관심사를 모듈화한 것 (예: 로깅 Aspect)\nJoin Point   Advice가 적용될 수 있는 지점 (메서드 실행 시점)\nPointcut   Join Point를 선별하는 표현식\nAdvice   실제 수행할 부가 기능 로직\nTarget   Advice가 적용되는 대상 객체\nWeaving   Aspect를 Target에 적용하는 과정\n\nAdvice 종류\n@Before: 메서드 실행 전\n@After: 메서드 실행 후 (성공/실패 무관)\n@AfterReturning: 메서드 정상 종료 후\n@AfterThrowing: 예외 발생 시\n@Around: 메서드 실행 전후 (가장 강력)\n\n적용 사례: 트랜잭션 관리, 로깅, 성능 측정, 보안 검사, 캐싱",
    "references": [],
    "keywords": [
      "aop",
      "aspect",
      "oriented",
      "programming",
      "cross-cutting",
      "concerns",
      "join",
      "point",
      "advice",
      "pointcut",
      "target",
      "weaving",
      "afterreturning",
      "afterthrowing",
      "around"
    ]
  },
  {
    "id": "SPRING-006",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "@Aspect는 어떻게 동작하나요?",
    "answer": "@Aspect 동작 원리: 프록시 기반 AOP\nBean 등록 시점에 스프링이 @Aspect 클래스를 스캔\nPointcut에 해당하는 Target Bean을 프록시 객체로 감싸서 컨테이너에 등록\n클라이언트가 Target 메서드 호출 시 프록시가 먼저 호출됨\n프록시가 Advice 로직을 실행하고, 필요시 실제 Target 메서드 호출\n\n프록시 생성 방식\nJDK 동적 프록시: 인터페이스 기반 (인터페이스가 있을 때)\nCGLIB 프록시: 클래스 기반, 상속을 이용 (인터페이스가 없을 때)\nSpring Boot 2.0+에서는 기본적으로 CGLIB 사용\n\n동작 흐름 예시 (@Around)\n\n주의사항\nSelf-invocation 문제: 같은 클래스 내에서 this.method() 호출 시 프록시를 거치지 않아 AOP 미적용\n해결: 자기 자신을 주입받거나 AopContext.currentProxy() 사용",
    "references": [],
    "keywords": [
      "aspect",
      "aop",
      "bean",
      "pointcut",
      "target",
      "advice",
      "jdk",
      "cglib",
      "spring",
      "boot",
      "around",
      "self-invocation",
      "aopcontext",
      "동작",
      "원리"
    ]
  },
  {
    "id": "SPRING-007",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring 에서 Interceptor와 Servlet Filter에 대해 설명해 주세요.",
    "answer": "실행 순서\n\nServlet Filter\n서블릿 스펙에 정의된 기술 (스프링 독립적)\nDispatcherServlet 이전에 실행\n모든 요청에 대해 동작 (정적 리소스 포함)\njavax.servlet.Filter 인터페이스 구현\n\nSpring Interceptor\n스프링 MVC가 제공하는 기술\nDispatcherServlet과 Controller 사이에서 실행\n스프링 컨텍스트에 접근 가능 (Bean 사용 가능)\nHandlerInterceptor 인터페이스 구현\n\n구분   Filter   Interceptor\n\n관리 주체   서블릿 컨테이너   스프링 컨테이너\nRequest/Response 조작   가능   불가능\n스프링 Bean 접근   제한적   자유로움\n예외 처리   서블릿 예외 처리   @ControllerAdvice 사용 가능\n\nInterceptor 메서드\npreHandle(): 컨트롤러 실행 전\npostHandle(): 컨트롤러 실행 후, 뷰 렌더링 전\nafterCompletion(): 뷰 렌더링 후, 완료 시점",
    "references": [],
    "keywords": [
      "servlet",
      "filter",
      "dispatcherservlet",
      "spring",
      "interceptor",
      "mvc",
      "controller",
      "bean",
      "handlerinterceptor",
      "request",
      "response",
      "controlleradvice",
      "실행",
      "순서",
      "서블릿"
    ]
  },
  {
    "id": "SPRING-008",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "설명만 들어보면 인터셉터만 쓰는게 나아보이는데, 아닌가요? 필터는 어떤 상황에 사용 해야 하나요?",
    "answer": "Filter를 사용해야 하는 경우\nRequest/Response 자체를 조작해야 할 때\n요청 본문(body)을 읽거나 수정\n응답 본문을 압축하거나 변환\nServletRequest를 래핑하여 커스텀 기능 추가\n모든 요청에 공통 처리가 필요할 때\n인코딩 설정 (CharacterEncodingFilter)\nCORS 처리\n정적 리소스 요청 포함 처리\n스프링과 무관한 처리\n스프링 컨텍스트 로딩 전에 처리해야 하는 작업\n서블릿 스펙 기반의 표준화된 처리\n보안 관련 최전방 처리\nXSS, CSRF 방어\nSpring Security의 필터 체인\n\n실무 예시\nFilter 사용   Interceptor 사용\n\n인코딩 처리   로그인 체크\nCORS 설정   권한 검사\n요청 로깅 (body 포함)   API 호출 로깅\n보안 필터링   공통 데이터 세팅\n\n결론: 둘 다 적절한 용도가 있으며, Spring Security처럼 Filter 체인이 필수인 경우도 있습니다.",
    "references": [],
    "keywords": [
      "filter",
      "request",
      "response",
      "servletrequest",
      "characterencodingfilter",
      "cors",
      "xss",
      "csrf",
      "spring",
      "security",
      "interceptor",
      "api",
      "사용해야",
      "하는",
      "자체를"
    ]
  },
  {
    "id": "SPRING-009",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "DispatcherServlet 의 역할에 대해 설명해 주세요.",
    "answer": "DispatcherServlet이란?\nSpring MVC의 프론트 컨트롤러(Front Controller)\n모든 HTTP 요청을 받아 적절한 컨트롤러에 분배하는 중앙 서블릿\nHttpServlet을 상속받은 서블릿\n\n요청 처리 흐름\n요청 수신: 클라이언트 요청을 받음\n핸들러 조회: HandlerMapping을 통해 요청을 처리할 핸들러(컨트롤러) 검색\n핸들러 어댑터 조회: HandlerAdapter를 통해 핸들러 실행 방법 결정\n핸들러 실행: 어댑터가 실제 컨트롤러 메서드 호출\nModelAndView 반환: 컨트롤러가 처리 결과 반환\n뷰 리졸버 호출: ViewResolver가 뷰 이름을 실제 View로 변환\n뷰 렌더링: View가 Model 데이터로 응답 생성\n응답 반환: 클라이언트에게 응답\n\n주요 구성 요소\nHandlerMapping: URL과 핸들러 매핑\nHandlerAdapter: 다양한 핸들러 실행 방식 지원\nViewResolver: 뷰 이름 → 실제 View 객체 변환\nHandlerExceptionResolver: 예외 처리",
    "references": [],
    "keywords": [
      "dispatcherservlet",
      "spring",
      "mvc",
      "front",
      "controller",
      "http",
      "httpservlet",
      "handlermapping",
      "handleradapter",
      "modelandview",
      "viewresolver",
      "view",
      "model",
      "url",
      "handlerexceptionresolver"
    ]
  },
  {
    "id": "SPRING-010",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "요청이 들어온다고 가정할 때, DispatcherServlet은 한번에 여러 요청을 모두 받을 수 있나요?",
    "answer": "네, 가능합니다.\n\n멀티스레드 처리 구조\nDispatcherServlet은 싱글톤으로 하나만 존재\n하지만 서블릿 컨테이너(Tomcat)가 스레드 풀을 관리\n각 요청마다 별도의 스레드가 할당되어 동시에 여러 요청 처리 가능\n\n동작 방식\n\nThread-Safe 이유\nDispatcherServlet 자체는 상태를 가지지 않음 (stateless)\n요청별 데이터는 각 스레드의 지역 변수나 ThreadLocal에 저장\n스프링의 싱글톤 Bean들도 상태를 가지지 않도록 설계해야 함\n\nTomcat 스레드 풀 설정\n\n주의: Controller나 Service에서 인스턴스 변수에 상태를 저장하면 동시성 문제 발생",
    "references": [],
    "keywords": [
      "dispatcherservlet",
      "tomcat",
      "thread-safe",
      "threadlocal",
      "bean",
      "controller",
      "service",
      "가능합니다",
      "멀티스레드",
      "처리",
      "구조",
      "싱글톤으로",
      "하나만",
      "존재",
      "서블릿"
    ]
  },
  {
    "id": "SPRING-011",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "@Controller 를 DispatcherServlet은 어떻게 구분 할까요?",
    "answer": "HandlerMapping을 통한 구분\n\nDispatcherServlet은 직접 @Controller를 찾지 않고 HandlerMapping에게 위임합니다.\n\n동작 과정\n스프링 컨텍스트 로딩 시 @Controller, @RequestMapping 붙은 클래스 스캔\nRequestMappingHandlerMapping이 URL 패턴과 핸들러 메서드를 매핑 정보로 저장\n요청 시 DispatcherServlet이 HandlerMapping에게 해당 URL의 핸들러 조회\n매핑된 컨트롤러 메서드 정보 반환\n\n주요 HandlerMapping 구현체\n구현체   설명\n\nRequestMappingHandlerMapping   @RequestMapping 기반 (가장 많이 사용)\nBeanNameUrlHandlerMapping   Bean 이름이 URL인 경우\nSimpleUrlHandlerMapping   직접 URL-핸들러 매핑 설정\n\n@Controller vs @RestController\n@Controller: View 이름 반환 → ViewResolver가 처리\n@RestController: @Controller + @ResponseBody, 객체를 JSON으로 직접 반환\n\n내부 저장 구조",
    "references": [],
    "keywords": [
      "handlermapping",
      "dispatcherservlet",
      "controller",
      "requestmapping",
      "requestmappinghandlermapping",
      "url",
      "beannameurlhandlermapping",
      "bean",
      "simpleurlhandlermapping",
      "restcontroller",
      "view",
      "viewresolver",
      "responsebody",
      "json",
      "통한"
    ]
  },
  {
    "id": "SPRING-012",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "JPA와 같은 ORM을 사용하는 이유가 무엇인가요?",
    "answer": "ORM (Object-Relational Mapping)이란?\n객체와 관계형 데이터베이스 테이블을 매핑해주는 기술\nSQL을 직접 작성하지 않고 객체 지향적으로 데이터 조작 가능\n\nORM 사용 이유\n패러다임 불일치 해결\n객체: 상속, 참조, 연관관계\nRDB: 테이블, 외래키, 조인\nORM이 이 차이를 자동으로 해결\n생산성 향상\n반복적인 CRUD SQL 작성 불필요\n객체 중심 개발 가능\n유지보수성\n필드 추가 시 SQL 수정 불필요\n데이터베이스 변경에 유연\nDB 독립성\nDialect 설정으로 DB 벤더 변경 용이\nMySQL → PostgreSQL 마이그레이션 쉬움\n성능 최적화 기능\n1차 캐시, 쓰기 지연\n변경 감지(Dirty Checking)\n지연 로딩(Lazy Loading)\n\n단점\n학습 곡선이 있음\n복잡한 쿼리는 직접 작성 필요 (JPQL, QueryDSL, Native Query)\nN+1 문제 등 성능 이슈 주의 필요",
    "references": [],
    "keywords": [
      "orm",
      "object-relational",
      "mapping",
      "sql",
      "rdb",
      "crud",
      "dialect",
      "mysql",
      "postgresql",
      "dirty",
      "checking",
      "lazy",
      "loading",
      "jpql",
      "querydsl"
    ]
  },
  {
    "id": "SPRING-013",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "영속성은 어떤 기능을 하나요? 이게 진짜 성능 향상에 큰 도움이 되나요?",
    "answer": "영속성 컨텍스트 (Persistence Context)\n엔티티를 영구 저장하는 환경, 1차 캐시 역할\nEntityManager를 통해 접근\n\n주요 기능과 성능 이점\n1차 캐시\n같은 트랜잭션 내에서 동일 엔티티 조회 시 DB 접근 없이 캐시에서 반환\n동일성(identity) 보장: em.find(Member.class, 1L) == em.find(Member.class, 1L)\n⚠️ 트랜잭션 범위 한정이라 효과는 제한적\n쓰기 지연 (Write-behind)\nINSERT/UPDATE를 즉시 실행하지 않고 모았다가 커밋 시점에 일괄 실행\n배치 처리로 DB 왕복 횟수 감소\n변경 감지 (Dirty Checking)\n엔티티 변경 시 자동으로 UPDATE SQL 생성\n별도 update() 메서드 호출 불필요\n지연 로딩 (Lazy Loading)\n연관 엔티티를 실제 사용할 때까지 로딩 지연\n불필요한 조인 방지\n\n성능 향상에 대한 현실적 평가\n1차 캐시: 같은 트랜잭션 내에서만 유효 → 효과 제한적\n쓰기 지연: 대량 INSERT 시 확실한 성능 향상\n전체적으로 개발 편의성 측면에서 더 큰 가치",
    "references": [],
    "keywords": [
      "persistence",
      "context",
      "entitymanager",
      "member",
      "write-behind",
      "insert",
      "update",
      "dirty",
      "checking",
      "sql",
      "lazy",
      "loading",
      "영속성",
      "컨텍스트",
      "엔티티를"
    ]
  },
  {
    "id": "SPRING-014",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "N + 1 문제에 대해 설명해 주세요.",
    "answer": "N+1 문제란?\n연관 관계가 있는 엔티티 조회 시, 1번의 쿼리로 N개의 데이터를 가져온 후\n각 데이터의 연관 엔티티를 조회하기 위해 추가로 N번의 쿼리가 실행되는 문제\n\n예시\n\n발생 원인\n지연 로딩(LAZY) 시: 연관 엔티티 접근 시점에 쿼리 발생\n즉시 로딩(EAGER) 시: 각 엔티티마다 별도 쿼리 발생\n\n해결 방법\nFetch Join (JPQL)\n@EntityGraph\nBatch Size 설정\nIN 절로 한 번에 여러 개 조회\n@BatchSize 어노테이션\n엔티티나 컬렉션에 개별 적용\n\n권장: 기본은 LAZY + 필요 시 Fetch Join 또는 Batch Size",
    "references": [],
    "keywords": [
      "lazy",
      "eager",
      "fetch",
      "join",
      "jpql",
      "entitygraph",
      "batch",
      "size",
      "batchsize",
      "문제란",
      "연관",
      "관계가",
      "있는",
      "엔티티",
      "조회"
    ]
  },
  {
    "id": "SPRING-015",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "@Transactional 은 어떤 기능을 하나요?",
    "answer": "@Transactional이란?\n선언적 트랜잭션 관리를 위한 어노테이션\n메서드 실행을 하나의 트랜잭션으로 묶어줌\nAOP 기반으로 동작 (프록시 패턴)\n\n동작 원리\n\n주요 속성\n\n속성   설명\n\npropagation   트랜잭션 전파 방식 (REQUIRED, REQUIRESNEW 등)\nisolation   격리 수준 (READCOMMITTED 등)\ntimeout   타임아웃 설정 (초)\nreadOnly   읽기 전용 여부\nrollbackFor   롤백할 예외 지정\nnoRollbackFor   롤백하지 않을 예외 지정\n\n전파 속성 (Propagation)\nREQUIRED (기본): 기존 트랜잭션 있으면 참여, 없으면 새로 시작\nREQUIRES_NEW: 항상 새 트랜잭션 시작\nNESTED: 중첩 트랜잭션 (Savepoint 사용)\nSUPPORTS: 트랜잭션 있으면 참여, 없으면 없이 실행\n\n주의사항\nChecked Exception은 기본적으로 롤백 안 됨 (rollbackFor 필요)\nSelf-invocation: 같은 클래스 내 호출 시 프록시 우회로 트랜잭션 미적용\npublic 메서드에만 적용 가능",
    "references": [],
    "keywords": [
      "transactional",
      "aop",
      "required",
      "requiresnew",
      "readcommitted",
      "propagation",
      "requires_new",
      "nested",
      "savepoint",
      "supports",
      "checked",
      "exception",
      "self-invocation",
      "이란",
      "선언적"
    ]
  },
  {
    "id": "SPRING-016",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "@Transactional(readonly=true) 는 어떤 기능인가요? 이게 도움이 되나요?",
    "answer": "@Transactional(readOnly=true)란?\n해당 트랜잭션이 읽기 전용임을 선언\nJPA와 DB 레벨에서 최적화 힌트로 사용\n\n성능 최적화 효과\n영속성 컨텍스트 최적화\n변경 감지(Dirty Checking) 비활성화\n스냅샷 저장 안 함 → 메모리 절약\nFlush 모드 변경\nFlushMode가 MANUAL로 설정\n불필요한 flush 연산 방지\nDB 레벨 최적화 (DB 벤더에 따라 다름)\nMySQL: 읽기 전용 트랜잭션으로 처리\nPostgreSQL: 읽기 전용 모드 활성화\nReplication 환경: Slave(읽기 전용 DB)로 라우팅 가능\n\n실질적 도움이 되나요?\n대량 조회: 스냅샷 미저장으로 메모리 절약 효과 있음\nReplication 환경: Master-Slave 분기에 매우 유용\n단순 조회: 효과는 미미하지만, 명시적 의도 표현으로 코드 가독성 향상\n\n권장",
    "references": [],
    "keywords": [
      "transactional",
      "jpa",
      "dirty",
      "checking",
      "flush",
      "flushmode",
      "manual",
      "mysql",
      "postgresql",
      "replication",
      "slave",
      "master-slave",
      "해당",
      "트랜잭션이",
      "읽기"
    ]
  },
  {
    "id": "SPRING-017",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "그런데, 읽기에 트랜잭션을 걸 필요가 있나요? @Transactional을 안 붙이면 되는거 아닐까요?",
    "answer": "@Transactional이 없을 때 발생하는 문제들\nOSIV(Open Session In View) 비활성화 시 LazyLoading 오류\nOSIV가 꺼져있으면 트랜잭션 범위 = 영속성 컨텍스트 범위\n@Transactional 없으면 지연 로딩 시 LazyInitializationException 발생\n데이터 일관성 문제\n여러 쿼리 수행 중 데이터가 변경될 수 있음\n트랜잭션 격리 수준에 따른 일관된 읽기 보장 안 됨\nDirty Read / Non-Repeatable Read\n트랜잭션 없이 조회하면 커밋되지 않은 데이터 읽을 가능성\n같은 데이터를 두 번 읽었을 때 다른 값이 나올 수 있음\n\n@Transactional이 필요한 경우\n\n@Transactional 없어도 되는 경우\n단순 단건 조회\nOSIV가 활성화된 환경 (Spring Boot 기본값: true)\n일관성이 크게 중요하지 않은 조회\n\n결론: 읽기에도 @Transactional(readOnly=true)를 붙이는 것을 권장\n명시적 의도 표현\nReplication 라우팅 가능\n영속성 컨텍스트 범위 명확화",
    "references": [],
    "keywords": [
      "transactional",
      "osiv",
      "open",
      "session",
      "view",
      "lazyloading",
      "lazyinitializationexception",
      "dirty",
      "read",
      "non-repeatable",
      "spring",
      "boot",
      "replication",
      "없을",
      "발생하는"
    ]
  },
  {
    "id": "SPRING-018",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Java 에서 Annotation 은 어떤 기능을 하나요?",
    "answer": "Annotation이란?\n소스 코드에 메타데이터를 추가하는 방법\n@ 기호로 시작\n그 자체로는 동작하는 코드가 아님 (메타데이터일 뿐)\n\nAnnotation의 용도\n컴파일러 지시\n@Override: 메서드 오버라이딩 검증\n@Deprecated: 사용 중지 권고 경고\n@SuppressWarnings: 경고 억제\n컴파일 타임 코드 생성\nLombok: @Getter, @Setter → 컴파일 시 코드 생성 (APT)\n런타임 처리\nReflection을 통해 어노테이션 정보 읽고 처리\n프레임워크가 활용\n\n메타 어노테이션\n\nRetention 정책\n정책   설명\n\nSOURCE   소스 코드까지만 유지 (컴파일 후 삭제)\nCLASS   클래스 파일까지 유지 (런타임 접근 불가)\nRUNTIME   런타임에도 유지 (Reflection 가능)",
    "references": [],
    "keywords": [
      "annotation",
      "override",
      "deprecated",
      "suppresswarnings",
      "lombok",
      "getter",
      "setter",
      "apt",
      "reflection",
      "retention",
      "source",
      "class",
      "runtime",
      "이란",
      "소스"
    ]
  },
  {
    "id": "SPRING-019",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "별 기능이 없는 것 같은데, 어떻게 Spring 에서는 Annotation 이 그렇게 많은 기능을 하는 걸까요?",
    "answer": "핵심: Annotation 자체는 아무것도 안 함\nAnnotation은 단순한 마커(표시)일 뿐\nSpring 프레임워크가 Reflection으로 읽고 처리하기 때문에 기능이 동작하는 것\n\nSpring의 Annotation 처리 방식\n컴포넌트 스캔 시점\n@ComponentScan이 지정된 패키지 스캔\n클래스에 @Component, @Service 등이 있는지 Reflection으로 확인\n있으면 Bean으로 등록\nBeanPostProcessor\nBean 생성 전후에 Annotation 확인하고 처리\n@Autowired → AutowiredAnnotationBeanPostProcessor가 의존성 주입\n@PostConstruct → CommonAnnotationBeanPostProcessor가 초기화 메서드 호출\nAOP / 프록시 생성\n@Transactional → 프록시로 감싸서 트랜잭션 로직 추가\n@Async → 프록시로 감싸서 비동기 실행\n\n동작 흐름 예시 (@Autowired)\n\n결론: Annotation은 메타데이터, 실제 동작은 Spring의 BeanPostProcessor, AOP 프록시, Reflection 덕분",
    "references": [],
    "keywords": [
      "annotation",
      "spring",
      "reflection",
      "componentscan",
      "component",
      "service",
      "bean",
      "beanpostprocessor",
      "autowired",
      "autowiredannotationbeanpostprocessor",
      "postconstruct",
      "commonannotationbeanpostprocessor",
      "aop",
      "transactional",
      "async"
    ]
  },
  {
    "id": "SPRING-020",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Lombok의 @Data를 잘 사용하지 않는 이유는 무엇일까요?",
    "answer": "@Data가 포함하는 것\n\n사용을 지양하는 이유\n@Setter의 무분별한 노출\n모든 필드에 Setter가 생성됨\n객체의 불변성이 깨지고, 어디서든 값 변경 가능\n의도치 않은 상태 변경 발생 위험\n@ToString의 순환 참조 문제\n양방향 연관관계 시 무한 루프 → StackOverflowError\n@EqualsAndHashCode 문제\n모든 필드 포함 → 연관 엔티티 비교 시 문제\nJPA Entity에서 @EqualsAndHashCode(of = \"id\") 권장\n불필요한 생성자\n@RequiredArgsConstructor가 항상 필요한 것은 아님\n\n권장 사용 방식\n\n@Data 사용해도 되는 경우\nDTO (단순 데이터 전달 객체)\n연관관계 없는 단순 클래스",
    "references": [],
    "keywords": [
      "data",
      "setter",
      "tostring",
      "stackoverflowerror",
      "equalsandhashcode",
      "jpa",
      "entity",
      "requiredargsconstructor",
      "dto",
      "포함하는",
      "사용을",
      "지양하는",
      "이유",
      "무분별한",
      "노출"
    ]
  },
  {
    "id": "SPRING-021",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Tomcat이 정확히 어떤 역할을 하는 도구인가요?",
    "answer": "Tomcat이란?\nApache 재단의 오픈소스 서블릿 컨테이너 (= 웹 컨테이너)\nJava Servlet, JSP 스펙을 구현한 WAS(Web Application Server)\n\n주요 역할\nHTTP 요청/응답 처리\nHTTP 프로토콜을 파싱하여 서블릿에 전달\n서블릿의 응답을 HTTP 형식으로 클라이언트에 전송\n서블릿 생명주기 관리\n서블릿 인스턴스 생성, 초기화, 소멸 관리\ninit() → service() → destroy()\n스레드 풀 관리\n요청마다 스레드를 할당하여 동시 처리\n커넥션 풀, 스레드 풀 관리\n정적 리소스 제공\nHTML, CSS, JS, 이미지 파일 서빙\n\nTomcat 구조\n\nSpring Boot와의 관계\nSpring Boot는 Embedded Tomcat을 내장\n별도 Tomcat 설치 없이 JAR 파일로 실행 가능\n다른 서버로 교체 가능: Jetty, Undertow, Netty\n\nWAS vs Web Server\n구분   Web Server   WAS (Tomcat)\n\n처리 대상   정적 콘텐츠   동적 콘텐츠\n예시   Nginx, Apache HTTP   Tomcat, Jetty",
    "references": [],
    "keywords": [
      "tomcat",
      "apache",
      "java",
      "servlet",
      "jsp",
      "web",
      "application",
      "server",
      "http",
      "html",
      "css",
      "spring",
      "boot",
      "embedded",
      "jar"
    ]
  },
  {
    "id": "SPRING-022",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "혹시 Netty에 대해 들어보셨나요? 왜 이런 것을 사용할까요?",
    "answer": "Netty란?\n비동기 이벤트 기반 네트워크 프레임워크\nNIO(Non-blocking I/O) 기반의 고성능 서버 개발용\n서블릿 스펙에 의존하지 않음\n\nTomcat vs Netty\n\n구분   Tomcat   Netty\n\nI/O 모델   Blocking (1요청 1스레드)   Non-blocking (이벤트 루프)\n스레드 수   요청 수에 비례   적은 스레드로 많은 요청 처리\n메모리   스레드당 스택 메모리 필요   효율적\n프로토콜   HTTP 중심   TCP/UDP/WebSocket 등 다양\n\nNetty 사용 이유\n대규모 동시 접속 처리\n적은 스레드로 수만 개 커넥션 처리 가능\nWebSocket, 채팅 서버, 게임 서버에 적합\n낮은 지연 시간 (Low Latency)\n이벤트 루프 기반으로 컨텍스트 스위칭 최소화\n다양한 프로토콜 지원\nHTTP/2, WebSocket, TCP, UDP 등\n\nSpring에서의 활용\nSpring WebFlux: Netty를 기본 서버로 사용\nSpring Cloud Gateway: Netty 기반 API 게이트웨이\n\n언제 Netty를 선택?\n대규모 동시 접속이 필요한 경우\n리액티브/비동기 프로그래밍 모델 사용 시\nWebSocket 기반 실시간 서비스",
    "references": [],
    "keywords": [
      "netty",
      "nio",
      "non-blocking",
      "tomcat",
      "blocking",
      "http",
      "tcp",
      "udp",
      "websocket",
      "low",
      "latency",
      "spring",
      "webflux",
      "cloud",
      "gateway"
    ]
  },
  {
    "id": "SPRING-023",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring Framework의 기본 개념과 주요 특징에 대해 설명해주세요.",
    "answer": "Spring Framework란?\nJava 기반 엔터프라이즈 애플리케이션 개발을 위한 경량 프레임워크\nEJB의 복잡성을 해결하고자 Rod Johnson이 2003년에 개발\n\n핵심 철학: POJO 기반 개발\nPlain Old Java Object를 사용한 비침투적 설계\n특정 기술에 종속되지 않는 깔끔한 코드\n\n주요 특징\nIoC/DI (제어의 역전/의존성 주입)\n객체 생성과 의존관계를 컨테이너가 관리\n결합도 감소, 테스트 용이성 향상\nAOP (관점 지향 프로그래밍)\n횡단 관심사 분리 (로깅, 트랜잭션, 보안)\n비즈니스 로직에 집중 가능\n선언적 트랜잭션 관리\n@Transactional로 간편한 트랜잭션 처리\n다양한 기술 통합\nJPA, MyBatis, Redis, Kafka 등과 쉬운 연동\n모듈화\n필요한 모듈만 선택 사용 가능\nCore, MVC, Data, Security 등\n\nSpring의 장점\n낮은 결합도, 높은 응집도\n테스트 용이성\n풍부한 생태계와 커뮤니티",
    "references": [],
    "keywords": [
      "spring",
      "framework",
      "java",
      "ejb",
      "rod",
      "johnson",
      "pojo",
      "plain",
      "old",
      "object",
      "ioc",
      "aop",
      "transactional",
      "jpa",
      "mybatis"
    ]
  },
  {
    "id": "SPRING-024",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring Boot와 전통적 Spring Framework의 차이점은 무엇인가요?",
    "answer": "Spring Boot의 탄생 배경\n기존 Spring의 복잡한 설정(XML, 의존성 관리)을 해결\n\"Convention over Configuration\" 철학\n\n주요 차이점\n\n구분   Spring Framework   Spring Boot\n\n설정 방식   XML/Java Config 직접 작성   자동 설정 (Auto-Configuration)\n의존성   개별 버전 관리   Starter로 통합 관리\n서버   외부 WAS 필요   내장 서버 (Tomcat, Jetty)\n배포   WAR 배포   JAR 실행\n설정 파일   여러 XML 파일   application.yml/properties\n\nSpring Boot 핵심 기능\nAuto-Configuration\n클래스패스 기반 자동 Bean 설정\n@EnableAutoConfiguration\nStarter Dependencies\n관련 의존성 버전 자동 관리\nEmbedded Server\nTomcat, Jetty, Undertow 내장\njava -jar app.jar로 바로 실행\nSpring Boot Actuator\n애플리케이션 모니터링 엔드포인트 제공\nProduction-Ready\nHealth check, Metrics 기본 제공",
    "references": [],
    "keywords": [
      "spring",
      "boot",
      "xml",
      "convention",
      "configuration",
      "framework",
      "java",
      "config",
      "auto-configuration",
      "starter",
      "tomcat",
      "jetty",
      "war",
      "jar",
      "bean"
    ]
  },
  {
    "id": "SPRING-025",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "IoC(Inversion of Control)와 DI(Dependency Injection)의 개념 및 이점에 대해 설명해주세요.",
    "answer": "IoC (제어의 역전)\n객체의 생성, 생명주기 관리 권한을 프레임워크에 위임\n개발자가 new로 직접 객체를 생성하지 않음\n\"Don't call us, we'll call you\" 원칙\n\nDI (의존성 주입)\nIoC를 구현하는 구체적인 방법\n객체가 필요한 의존성을 외부에서 주입받음\n\nDI 방식 3가지\n\n생성자 주입이 권장되는 이유\n불변성: final 키워드 사용 가능\n테스트 용이: Mock 객체 쉽게 주입\n순환 참조 방지: 컴파일 타임에 발견 가능\n필수 의존성 명확화: 생성 시점에 주입 필수\n\nIoC/DI의 이점\n느슨한 결합 (Loose Coupling)\n테스트 용이성 (Mock 주입)\n코드 재사용성 향상\n유지보수성 향상\n구현체 교체 용이",
    "references": [],
    "keywords": [
      "ioc",
      "don",
      "mock",
      "loose",
      "coupling",
      "제어의",
      "역전",
      "객체의",
      "생성",
      "생명주기",
      "관리",
      "권한을",
      "프레임워크에",
      "위임",
      "개발자가"
    ]
  },
  {
    "id": "SPRING-026",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring Bean의 라이프사이클과 관련 콜백 메서드에 대해 설명해주세요.",
    "answer": "Bean 라이프사이클 단계\n\n초기화 콜백 (Bean 생성 후)\n@PostConstruct (권장)\nInitializingBean 인터페이스\n@Bean(initMethod = \"init\")\n   \n\n소멸 콜백 (컨테이너 종료 시)\n@PreDestroy (권장)\nDisposableBean 인터페이스\n@Bean(destroyMethod = \"close\")\n\n실행 순서\n초기화: @PostConstruct → InitializingBean → initMethod\n소멸: @PreDestroy → DisposableBean → destroyMethod\n\n권장 방식\n@PostConstruct, @PreDestroy 사용\n자바 표준(JSR-250)으로 스프링에 의존하지 않음\n코드 수정 불가 시 @Bean의 initMethod/destroyMethod 사용",
    "references": [],
    "keywords": [
      "bean",
      "postconstruct",
      "initializingbean",
      "predestroy",
      "disposablebean",
      "jsr-250",
      "라이프사이클",
      "단계",
      "초기화",
      "콜백",
      "생성",
      "권장",
      "인터페이스",
      "소멸",
      "컨테이너"
    ]
  },
  {
    "id": "SPRING-027",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "@Component, @Service, @Repository의 차이점 및 사용 사례는 무엇인가요?",
    "answer": "기본 관계\n\n세 어노테이션 모두 @Component를 메타 어노테이션으로 가지며, 컴포넌트 스캔 대상이 됩니다.\n\n각 어노테이션의 역할\n\n어노테이션   계층   역할\n\n@Component   범용   일반적인 스프링 빈 등록\n@Service   서비스 계층   비즈니스 로직 처리\n@Repository   영속성 계층   데이터 접근 로직 (DAO)\n@Controller   표현 계층   HTTP 요청/응답 처리\n\n@Repository의 특별한 기능\n예외 변환: DB 관련 예외를 DataAccessException으로 자동 변환\nJPA, JDBC 등 기술에 종속적인 예외를 스프링 예외로 추상화\n\n@Service의 역할\n현재 특별한 추가 기능은 없음\n비즈니스 계층임을 의미적으로 표현\n향후 AOP 등에서 특별 처리 가능성\n\n사용 예시\n\n@Component 직접 사용 시\n특정 계층에 속하지 않는 유틸리티 클래스\n예: 이메일 발송기, 암호화 유틸 등",
    "references": [],
    "keywords": [
      "component",
      "service",
      "repository",
      "dao",
      "controller",
      "http",
      "dataaccessexception",
      "jpa",
      "jdbc",
      "aop",
      "기본",
      "관계",
      "어노테이션",
      "모두",
      "메타"
    ]
  },
  {
    "id": "SPRING-028",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "AOP(Aspect Oriented Programming)를 활용한 공통 관심사 분리 방법에 대해 설명해주세요.",
    "answer": "공통 관심사 (Cross-Cutting Concerns)\n여러 모듈에 걸쳐 반복되는 부가 기능\n예: 로깅, 트랜잭션, 보안, 성능 측정\n\nAOP로 분리하는 방법\nAspect 정의\n\nPointcut 표현식 예시\n\n표현식   설명\n\nexecution( com.example...(..))   모든 메서드\n@annotation(LogExecutionTime)   특정 어노테이션 붙은 메서드\nwithin(com.example.service.)   특정 패키지 내 모든 메서드\nbean(Service)   이름이 Service로 끝나는 Bean\n\n활용 예시\n\n관심사   구현 방식\n\n로깅   @Around로 메서드 실행 전후 로깅\n성능 측정   @Around로 실행 시간 측정\n권한 체크   @Before로 진입 전 권한 검증\n예외 처리   @AfterThrowing으로 예외 로깅\n트랜잭션   @Transactional (내부적으로 AOP)",
    "references": [],
    "keywords": [
      "cross-cutting",
      "concerns",
      "aop",
      "aspect",
      "pointcut",
      "logexecutiontime",
      "service",
      "bean",
      "around",
      "afterthrowing",
      "transactional",
      "공통",
      "관심사",
      "여러",
      "모듈에"
    ]
  },
  {
    "id": "SPRING-029",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring에서 트랜잭션 관리와 @Transactional 어노테이션의 역할에 대해 설명해주세요.",
    "answer": "트랜잭션 관리 방식\n프로그래밍 방식 (명시적)\n선언적 방식 (권장)\n   \n\n@Transactional 동작 원리\nAOP 프록시 기반으로 동작\n메서드 호출 전: 트랜잭션 시작\n정상 완료: 커밋\n예외 발생: 롤백\n\n주요 속성\n\n속성   설명   기본값\n\npropagation   전파 방식   REQUIRED\nisolation   격리 수준   DEFAULT\ntimeout   타임아웃(초)   -1 (무제한)\nreadOnly   읽기 전용   false\nrollbackFor   롤백할 예외   RuntimeException\n\n전파 속성 (Propagation)\n\n주의사항\npublic 메서드에만 적용\nself-invocation 시 프록시 우회\nChecked Exception은 기본 롤백 안 함",
    "references": [],
    "keywords": [
      "transactional",
      "aop",
      "required",
      "default",
      "runtimeexception",
      "propagation",
      "self-invocation",
      "checked",
      "exception",
      "트랜잭션",
      "관리",
      "방식",
      "프로그래밍",
      "명시적",
      "선언적"
    ]
  },
  {
    "id": "SPRING-030",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring MVC 아키텍처의 구성 요소와 요청 처리 과정을 설명해주세요.",
    "answer": "Spring MVC 핵심 구성 요소\n\n구성 요소   역할\n\nDispatcherServlet   프론트 컨트롤러, 모든 요청의 진입점\nHandlerMapping   URL → 핸들러(Controller) 매핑\nHandlerAdapter   다양한 핸들러 실행 방식 지원\nController   비즈니스 로직 처리\nViewResolver   뷰 이름 → 실제 View 변환\nView   응답 렌더링\n\n요청 처리 흐름\n\nREST API의 경우 (@RestController)\nViewResolver 단계 생략\n@ResponseBody로 객체를 JSON으로 직렬화\n\n주요 HandlerMapping\nRequestMappingHandlerMapping: @RequestMapping 기반 (가장 일반적)\nBeanNameUrlHandlerMapping: Bean 이름 기반\n\n주요 HandlerAdapter\nRequestMappingHandlerAdapter: @RequestMapping 처리",
    "references": [],
    "keywords": [
      "spring",
      "mvc",
      "dispatcherservlet",
      "handlermapping",
      "url",
      "controller",
      "handleradapter",
      "viewresolver",
      "view",
      "rest",
      "api",
      "restcontroller",
      "responsebody",
      "json",
      "requestmappinghandlermapping"
    ]
  },
  {
    "id": "SPRING-031",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring Boot의 자동 구성(Auto-Configuration) 원리에 대해 설명해주세요.",
    "answer": "Auto-Configuration이란?\n클래스패스, 설정값, Bean 존재 여부 등을 기반으로 자동으로 Bean을 등록하는 기능\n개발자가 직접 설정하지 않아도 필요한 설정이 자동 적용\n\n동작 원리\n@SpringBootApplication\nspring.factories / AutoConfiguration.imports 파일\nMETA-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports\n자동 구성 클래스 목록이 정의됨\n조건부 설정 (@Conditional)\n   \n\n주요 @Conditional 어노테이션\n\n어노테이션   조건\n\n@ConditionalOnClass   특정 클래스가 클래스패스에 있을 때\n@ConditionalOnMissingBean   해당 Bean이 없을 때\n@ConditionalOnProperty   특정 프로퍼티 값일 때\n@ConditionalOnWebApplication   웹 애플리케이션일 때\n\n예시: DataSource 자동 구성\nspring-boot-starter-jdbc 의존성 추가\n클래스패스에 DataSource.class 존재\nDataSourceAutoConfiguration 활성화\napplication.yml의 설정으로 DataSource Bean 생성\n\n자동 구성 비활성화",
    "references": [],
    "keywords": [
      "auto-configuration",
      "bean",
      "springbootapplication",
      "autoconfiguration",
      "meta-inf",
      "conditional",
      "conditionalonclass",
      "conditionalonmissingbean",
      "conditionalonproperty",
      "conditionalonwebapplication",
      "datasource",
      "spring-boot",
      "starter-jdbc",
      "datasourceautoconfiguration",
      "이란"
    ]
  },
  {
    "id": "SPRING-032",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "예외 처리를 위한 @ControllerAdvice의 역할과 활용 방법은 무엇인가요?",
    "answer": "@ControllerAdvice란?\n전역 예외 처리를 담당하는 클래스\n모든 컨트롤러에서 발생하는 예외를 한 곳에서 처리\nAOP 기반으로 동작\n\n기본 사용법\n\n주요 기능\n@ExceptionHandler: 특정 예외 처리\n@ModelAttribute: 모든 컨트롤러에 공통 모델 데이터 추가\n@InitBinder: 요청 파라미터 바인딩 커스터마이징\n\n적용 범위 제한\n\n예외 처리 우선순위\n컨트롤러 내 @ExceptionHandler\n@ControllerAdvice 내 @ExceptionHandler\n더 구체적인 예외가 우선",
    "references": [],
    "keywords": [
      "controlleradvice",
      "aop",
      "exceptionhandler",
      "modelattribute",
      "initbinder",
      "전역",
      "예외",
      "처리를",
      "담당하는",
      "클래스",
      "모든",
      "컨트롤러에서",
      "발생하는",
      "예외를",
      "곳에서"
    ]
  },
  {
    "id": "SPRING-033",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring Security의 기본 개념과 인증/인가 처리 흐름에 대해 설명해주세요.",
    "answer": "Spring Security란?\n인증(Authentication)과 인가(Authorization)를 담당하는 보안 프레임워크\nFilter 기반으로 동작\n\n인증 vs 인가\n구분   인증 (Authentication)   인가 (Authorization)\n\n의미   누구인지 확인   권한이 있는지 확인\n예시   로그인   관리자 페이지 접근 권한\n\n핵심 구성 요소\n\n구성 요소   역할\n\nSecurityFilterChain   보안 필터 체인\nAuthenticationManager   인증 처리 관리\nUserDetailsService   사용자 정보 로드\nPasswordEncoder   비밀번호 암호화\n\n인증 처리 흐름\n\n기본 설정 예시",
    "references": [],
    "keywords": [
      "spring",
      "security",
      "authentication",
      "authorization",
      "filter",
      "securityfilterchain",
      "authenticationmanager",
      "userdetailsservice",
      "passwordencoder",
      "인증",
      "인가",
      "담당하는",
      "보안",
      "프레임워크",
      "기반으로"
    ]
  },
  {
    "id": "SPRING-034",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "RESTful API를 Spring에서 구현하는 방법과 모범 사례는 무엇인가요?",
    "answer": "RESTful API 구현 기본\n\nREST 설계 모범 사례\n명사형 URI 사용\nGood: /api/users, /api/orders\nBad: /api/getUsers, /api/createOrder\nHTTP 메서드 의미 준수\n   메서드   용도   멱등성\n   \n   GET   조회   O\n   POST   생성   X\n   PUT   전체 수정   O\n   PATCH   부분 수정   O\n   DELETE   삭제   O\n적절한 상태 코드 반환\n200: 성공, 201: 생성됨, 204: 내용 없음\n400: 잘못된 요청, 401: 인증 필요, 403: 권한 없음, 404: 없음\n일관된 응답 형식\n페이징 처리\n버전 관리\nURI: /api/v1/users\nHeader: Accept: application/vnd.api.v1+json",
    "references": [],
    "keywords": [
      "restful",
      "api",
      "rest",
      "uri",
      "good",
      "bad",
      "http",
      "get",
      "post",
      "put",
      "patch",
      "delete",
      "header",
      "accept",
      "구현"
    ]
  },
  {
    "id": "SPRING-035",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring Boot Actuator를 통한 애플리케이션 모니터링 방법은 무엇인가요?",
    "answer": "Spring Boot Actuator란?\n애플리케이션의 상태, 메트릭, 헬스체크 등을 모니터링하는 기능 제공\n운영 환경에서 애플리케이션 관리를 위한 HTTP 엔드포인트 제공\n\n의존성 추가\n\n주요 엔드포인트\n\n엔드포인트   설명\n\n/actuator/health   애플리케이션 상태\n/actuator/info   애플리케이션 정보\n/actuator/metrics   메트릭 정보\n/actuator/env   환경 변수\n/actuator/loggers   로거 설정\n/actuator/beans   등록된 Bean 목록\n/actuator/threaddump   스레드 덤프\n/actuator/heapdump   힙 덤프\n\n설정 예시\n\nPrometheus + Grafana 연동\n/actuator/prometheus 엔드포인트 활성화\nPrometheus가 메트릭 수집 → Grafana로 시각화\n\n보안 설정\n운영 환경에서는 민감 엔드포인트 접근 제한 필요\nSpring Security와 연동하여 인증 적용",
    "references": [],
    "keywords": [
      "spring",
      "boot",
      "actuator",
      "http",
      "bean",
      "prometheus",
      "grafana",
      "security",
      "애플리케이션의",
      "상태",
      "메트릭",
      "헬스체크",
      "등을",
      "모니터링하는",
      "기능"
    ]
  },
  {
    "id": "SPRING-036",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring Cloud를 활용한 마이크로서비스 아키텍처 구현 전략에 대해 설명해주세요.",
    "answer": "Spring Cloud란?\n마이크로서비스 아키텍처(MSA) 구축을 위한 도구 모음\n분산 시스템의 공통 패턴들을 쉽게 구현\n\n핵심 구성 요소\n\n컴포넌트   역할   구현체\n\nService Discovery   서비스 등록/발견   Eureka, Consul\nAPI Gateway   라우팅, 인증, 로드밸런싱   Spring Cloud Gateway\nConfig Server   중앙 집중식 설정 관리   Spring Cloud Config\nCircuit Breaker   장애 전파 방지   Resilience4j\nDistributed Tracing   분산 추적   Zipkin, Jaeger\nService Discovery (Eureka)\nAPI Gateway\nCircuit Breaker (Resilience4j)\nConfig Server\nGit 저장소에 설정 파일 관리\n애플리케이션 재시작 없이 설정 변경 가능\n\nMSA 구현 시 고려사항**\n서비스 간 통신: REST, gRPC, 메시지 큐\n데이터 일관성: Saga 패턴, 이벤트 소싱\n장애 대응: 타임아웃, 재시도, 폴백",
    "references": [],
    "keywords": [
      "spring",
      "cloud",
      "msa",
      "service",
      "discovery",
      "eureka",
      "consul",
      "api",
      "gateway",
      "config",
      "server",
      "circuit",
      "breaker",
      "resilience4j",
      "distributed"
    ]
  },
  {
    "id": "SPRING-037",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring에서 메시징 시스템(Kafka, RabbitMQ 등)과의 연동 방법은 무엇인가요?",
    "answer": "메시징 시스템 사용 이유\n서비스 간 비동기 통신\n시스템 간 결합도 감소\n부하 분산 및 버퍼링\nSpring Kafka 연동\nSpring AMQP (RabbitMQ) 연동\n\nKafka vs RabbitMQ\n\n구분   Kafka   RabbitMQ\n\n처리량   높음 (대용량)   중간\n메시지 저장   디스크에 영구 저장   메모리 우선\n순서 보장   파티션 내 보장   큐 내 보장\n적합 용도   이벤트 스트리밍, 로그   작업 큐, RPC",
    "references": [],
    "keywords": [
      "spring",
      "kafka",
      "amqp",
      "rabbitmq",
      "rpc",
      "메시징",
      "시스템",
      "사용",
      "이유",
      "서비스",
      "비동기",
      "통신",
      "결합도",
      "감소",
      "부하"
    ]
  },
  {
    "id": "SPRING-038",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring의 캐싱 추상화(Cache Abstraction)와 캐시 적용 방법에 대해 설명해주세요.",
    "answer": "Spring Cache Abstraction이란?\n캐시 구현체에 독립적인 추상화 계층 제공\n어노테이션 기반으로 간편하게 캐시 적용\n구현체: ConcurrentHashMap, Ehcache, Redis, Caffeine 등\n\n활성화\n\n주요 어노테이션\n\n어노테이션   역할\n\n@Cacheable   캐시 조회, 없으면 메서드 실행 후 저장\n@CachePut   항상 메서드 실행 후 캐시 저장\n@CacheEvict   캐시 삭제\n@Caching   여러 캐시 작업 조합\n\n사용 예시\n\nRedis 캐시 설정\n\n주의사항\nSelf-invocation: 같은 클래스 내 호출 시 캐시 미적용 (프록시 우회)\n캐시 키 설계: 충돌 방지를 위해 명확한 키 전략 필요\nTTL 설정: 데이터 정합성을 위해 만료 시간 설정 권장",
    "references": [],
    "keywords": [
      "spring",
      "cache",
      "abstraction",
      "concurrenthashmap",
      "ehcache",
      "redis",
      "caffeine",
      "cacheable",
      "cacheput",
      "cacheevict",
      "caching",
      "self-invocation",
      "ttl",
      "이란",
      "캐시"
    ]
  },
  {
    "id": "SPRING-039",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring Boot에서 프로파일 관리와 환경별 설정 적용 방법은 무엇인가요?",
    "answer": "Spring Profile이란?\n환경별(개발, 테스트, 운영)로 다른 설정을 적용하는 기능\nBean, 설정 파일을 환경별로 분리 가능\n\n프로파일 설정 방법\n설정 파일 분리\n프로파일 활성화\n환경별 Bean 등록\n프로파일 그룹\n\n환경별 설정 예시\n\n@Profile 사용",
    "references": [],
    "keywords": [
      "spring",
      "profile",
      "bean",
      "이란",
      "환경별",
      "개발",
      "테스트",
      "운영",
      "다른",
      "설정을",
      "적용하는",
      "기능",
      "설정",
      "파일을",
      "환경별로"
    ]
  },
  {
    "id": "SPRING-040",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring Bean의 Scope(싱글톤, 프로토타입 등) 차이점과 활용 사례는 무엇인가요?",
    "answer": "Bean Scope 종류\n\nScope   설명   생명주기 관리\n\nsingleton   컨테이너당 하나 (기본값)   컨테이너 전체\nprototype   요청마다 새로 생성   생성까지만\nrequest   HTTP 요청당 하나   요청 범위\nsession   HTTP 세션당 하나   세션 범위\napplication   ServletContext당 하나   앱 전체\nwebsocket   WebSocket 세션당 하나   WebSocket 범위\nSingleton (기본값)\n활용: 상태 없는(stateless) 서비스, 레포지토리\n주의: 인스턴스 변수에 상태 저장 금지\nPrototype\n활용: 상태를 가지는 객체, 매번 새 인스턴스 필요 시\n주의: @PreDestroy 호출 안 됨\nRequest/Session (웹 스코프)\n활용: 사용자별 데이터, 요청 로깅\n\n싱글톤에서 프로토타입 주입 문제",
    "references": [],
    "keywords": [
      "bean",
      "scope",
      "http",
      "servletcontext",
      "websocket",
      "singleton",
      "prototype",
      "predestroy",
      "request",
      "session",
      "종류",
      "설명",
      "생명주기",
      "관리",
      "컨테이너당"
    ]
  },
  {
    "id": "SPRING-041",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring의 이벤트 발행 및 리스너(Event Listener) 메커니즘에 대해 설명해주세요.",
    "answer": "Spring Event란?\n애플리케이션 내 느슨한 결합으로 컴포넌트 간 통신\nObserver 패턴 기반\n발행자(Publisher)와 구독자(Listener) 분리\n\n이벤트 정의\n\n이벤트 발행\n\n이벤트 리스너\n\n트랜잭션 연동\n\n활용 사례\n주문 완료 → 이메일/알림 발송\n회원 가입 → 포인트 지급\n결제 완료 → 재고 차감",
    "references": [],
    "keywords": [
      "spring",
      "event",
      "observer",
      "publisher",
      "listener",
      "애플리케이션",
      "느슨한",
      "결합으로",
      "컴포넌트",
      "통신",
      "패턴",
      "기반",
      "발행자",
      "구독자",
      "분리"
    ]
  },
  {
    "id": "SPRING-042",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "커스텀 어노테이션을 생성하고 이를 Spring에서 활용하는 방법은 무엇인가요?",
    "answer": "커스텀 어노테이션 생성\n\n메타 어노테이션 설명\n어노테이션   역할\n\n@Target   적용 대상 (METHOD, TYPE, FIELD 등)\n@Retention   유지 범위 (SOURCE, CLASS, RUNTIME)\n@Documented   JavaDoc에 포함\n@Inherited   상속 시 전달\n\n활용 방법 1: AOP와 결합\n\n활용 방법 2: HandlerMethodArgumentResolver\n\n활용 방법 3: 조합 어노테이션",
    "references": [],
    "keywords": [
      "target",
      "method",
      "type",
      "field",
      "retention",
      "source",
      "class",
      "runtime",
      "documented",
      "javadoc",
      "inherited",
      "aop",
      "handlermethodargumentresolver",
      "커스텀",
      "어노테이션"
    ]
  },
  {
    "id": "SPRING-043",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring WebFlux와 Spring MVC의 차이점 및 사용 시나리오는 무엇인가요?",
    "answer": "핵심 차이점\n\n구분   Spring MVC   Spring WebFlux\n\n프로그래밍 모델   동기/블로킹   비동기/논블로킹\n서버   Tomcat (서블릿)   Netty (기본)\n스레드 모델   요청당 스레드   이벤트 루프\n반환 타입   Object, ResponseEntity   Mono, Flux\n동시 처리   스레드 수에 비례   적은 스레드로 많은 요청\n\nSpring WebFlux 코드 예시\n\nMono vs Flux\nMono: 0~1개의 데이터 (단건)\nFlux: 0~N개의 데이터 (스트림)\n\nWebFlux 사용이 적합한 경우\n대규모 동시 접속: 수만 개의 커넥션 처리\n스트리밍 데이터: 실시간 피드, SSE\n마이크로서비스 게이트웨이: 여러 서비스 호출 조합\nI/O 집약적 작업: 외부 API 호출이 많은 경우\n\nSpring MVC가 더 나은 경우\nCPU 집약적 작업: 복잡한 연산\nJDBC/JPA 사용: 블로킹 드라이버\n기존 동기 라이브러리 의존\n팀의 학습 곡선 고려\n\n주의사항\n전체 스택이 논블로킹이어야 효과 있음\n하나라도 블로킹 호출이 있으면 이벤트 루프 블록\nR2DBC (리액티브 DB 드라이버) 필요",
    "references": [],
    "keywords": [
      "spring",
      "mvc",
      "webflux",
      "tomcat",
      "netty",
      "object",
      "responseentity",
      "mono",
      "flux",
      "sse",
      "api",
      "cpu",
      "jdbc",
      "jpa",
      "r2dbc"
    ]
  },
  {
    "id": "SPRING-044",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring에서 비동기 처리(Asynchronous Processing)를 구현하는 방법에 대해 설명해주세요.",
    "answer": "비동기 처리 활성화\n@Async 사용\n커스텀 Executor 설정\nCompletableFuture 조합\n예외 처리\n\n주의사항\nSelf-invocation 불가: 같은 클래스 내 호출 시 @Async 미적용\nvoid 또는 Future 반환: 다른 타입 반환 시 결과를 받을 수 없음\n트랜잭션 분리: @Async 메서드는 별도 트랜잭션\n\n반환 타입\n타입   설명\n\nvoid   결과 불필요\nFuture<T>   결과 대기 가능\nCompletableFuture<T>   조합, 체이닝 가능",
    "references": [],
    "keywords": [
      "async",
      "executor",
      "completablefuture",
      "self-invocation",
      "future",
      "비동기",
      "처리",
      "활성화",
      "사용",
      "커스텀",
      "설정",
      "조합",
      "예외",
      "주의사항",
      "불가"
    ]
  },
  {
    "id": "SPRING-045",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Logback을 이용한 Spring Boot의 로깅 설정과 관리 방법은 무엇인가요?",
    "answer": "Spring Boot 기본 로깅\n기본 로깅 프레임워크: Logback\n로깅 파사드: SLF4J\n별도 설정 없이 바로 사용 가능\n\napplication.yml 설정\n\nlogback-spring.xml (상세 설정)\n\n로그 레벨\n레벨   용도\n\nTRACE   가장 상세한 정보\nDEBUG   디버깅용\nINFO   일반 정보\nWARN   경고\nERROR   오류\n\n코드에서 사용",
    "references": [],
    "keywords": [
      "spring",
      "boot",
      "logback",
      "slf4j",
      "logback-spring",
      "trace",
      "debug",
      "info",
      "warn",
      "error",
      "기본",
      "로깅",
      "프레임워크",
      "파사드",
      "별도"
    ]
  },
  {
    "id": "SPRING-046",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "HttpMessageConverter의 역할과 Spring에서의 메시지 변환 과정을 설명해주세요.",
    "answer": "HttpMessageConverter란?\nHTTP 요청/응답 본문(body)을 Java 객체로 변환하는 인터페이스\n@RequestBody, @ResponseBody 처리의 핵심\n\n동작 흐름\n\n요청 시 (역직렬화)\n\n응답 시 (직렬화)\n\n주요 HttpMessageConverter\n\nConverter   역할\n\nMappingJackson2HttpMessageConverter   JSON ↔ 객체 (Jackson)\nStringHttpMessageConverter   String 처리\nByteArrayHttpMessageConverter   byte[] 처리\nFormHttpMessageConverter   Form 데이터 처리\n\nContent-Type 기반 선택\napplication/json → MappingJackson2HttpMessageConverter\ntext/plain → StringHttpMessageConverter\napplication/x-www-form-urlencoded → FormHttpMessageConverter\n\n커스텀 설정\n\nJackson 설정 (application.yml)",
    "references": [],
    "keywords": [
      "httpmessageconverter",
      "http",
      "java",
      "requestbody",
      "responsebody",
      "converter",
      "mappingjackson2httpmessageconverter",
      "json",
      "jackson",
      "stringhttpmessageconverter",
      "string",
      "bytearrayhttpmessageconverter",
      "formhttpmessageconverter",
      "form",
      "content-type"
    ]
  },
  {
    "id": "SPRING-047",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "RestTemplate과 WebClient의 차이점 및 사용 사례에 대해 설명해주세요.",
    "answer": "RestTemplate vs WebClient\n\n구분   RestTemplate   WebClient\n\n방식   동기/블로킹   비동기/논블로킹\n스레드   응답까지 스레드 점유   논블로킹으로 스레드 효율적\n지원   유지보수 모드 (Deprecated 예정)   권장\n의존성   spring-web   spring-webflux\n\nRestTemplate 사용\n\nWebClient 사용\n\nWebClient 권장 이유\n성능: 논블로킹으로 리소스 효율적\n유연성: 동기/비동기 모두 지원\n함수형 API: 체이닝으로 가독성 좋음\n미래 지향적: Spring 공식 권장\n\n사용 시나리오\nRestTemplate: 간단한 동기 호출, 레거시 코드\nWebClient: 새 프로젝트, 높은 동시성, 리액티브 스택",
    "references": [],
    "keywords": [
      "resttemplate",
      "webclient",
      "deprecated",
      "spring-web",
      "spring-webflux",
      "api",
      "spring",
      "구분",
      "방식",
      "동기",
      "블로킹",
      "비동기",
      "논블로킹",
      "스레드",
      "응답까지"
    ]
  },
  {
    "id": "SPRING-048",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "@Scheduled 애노테이션을 사용한 스케줄링 작업 구현 방법은 무엇인가요?",
    "answer": "스케줄링 활성화\n\n@Scheduled 사용법\n고정 간격 (fixedRate)\n고정 지연 (fixedDelay)\nCron 표현식\n\nCron 표현식 형식\n\n필드   값 범위\n\n초   0-59\n분   0-59\n시   0-23\n일   1-31\n월   1-12 또는 JAN-DEC\n요일   0-7 또는 SUN-SAT\n\nCron 예시\n표현식   의미\n\n0 0       매시 정각\n0 0 0      매일 자정\n0 0 12   MON   매주 월요일 12시\n0 /10       10분마다\n\n스레드 풀 설정\n\n동적 스케줄링 (DB에서 주기 조회)",
    "references": [],
    "keywords": [
      "scheduled",
      "cron",
      "jan-dec",
      "sun-sat",
      "mon",
      "스케줄링",
      "활성화",
      "사용법",
      "고정",
      "간격",
      "지연",
      "표현식",
      "형식",
      "필드",
      "범위"
    ]
  },
  {
    "id": "SPRING-049",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Spring Boot Starter의 개념과 주요 Starter들의 역할에 대해 설명해주세요.",
    "answer": "Spring Boot Starter란?\n특정 기능에 필요한 의존성들을 묶어둔 패키지\n의존성 버전 관리 자동화\nAuto-Configuration과 함께 동작\n\nStarter의 장점\n관련 의존성 한 번에 추가\n호환되는 버전 자동 관리\n보일러플레이트 설정 최소화\n\n주요 Starter 목록\n\nStarter   역할\n\nspring-boot-starter   기본 (core, logging, autoconfigure)\nspring-boot-starter-web   웹 애플리케이션 (Tomcat, Spring MVC)\nspring-boot-starter-webflux   리액티브 웹 (Netty, WebFlux)\nspring-boot-starter-data-jpa   JPA + Hibernate\nspring-boot-starter-data-redis   Redis 연동\nspring-boot-starter-security   Spring Security\nspring-boot-starter-test   테스트 (JUnit, Mockito, AssertJ)\nspring-boot-starter-actuator   모니터링 엔드포인트\nspring-boot-starter-validation   Bean Validation\nspring-boot-starter-cache   캐시 추상화\nspring-boot-starter-mail   이메일 발송\nspring-boot-starter-batch   배치 처리\n\n사용 예시\n\nspring-boot-starter-web 포함 내용\nSpring MVC\nTomcat (내장 서버)\nJackson (JSON 처리)\nValidation\nLogging (Logback)\n\n커스텀 Starter 만들기\n자체 Auto-Configuration 제공 가능\n사내 공통 라이브러리 배포에 유용",
    "references": [],
    "keywords": [
      "spring",
      "boot",
      "starter",
      "auto-configuration",
      "spring-boot",
      "starter-web",
      "tomcat",
      "mvc",
      "starter-webflux",
      "netty",
      "webflux",
      "starter-data",
      "jpa",
      "hibernate",
      "redis"
    ]
  },
  {
    "id": "SPRING-050",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "Java Config와 XML Config를 통한 Bean 등록 및 설정 방식의 차이점은 무엇인가요?",
    "answer": "설정 방식 비교\n\n구분   XML Config   Java Config\n\n방식   XML 파일   Java 클래스 + 어노테이션\n컴파일 검증   런타임 오류   컴파일 타임 오류\nIDE 지원   제한적   자동완성, 리팩토링 가능\n트렌드   레거시   현재 표준\n\nXML Config 예시\n\nJava Config 예시\n\nComponent Scan 방식\n\nJava Config 장점\n타입 안전성: 컴파일 시 오류 검출\n리팩토링 용이: 클래스명 변경 시 자동 반영\n조건부 Bean: @Conditional 등 프로그래밍적 제어\n프로파일 적용: @Profile과 쉬운 통합\n가독성: 코드로 흐름 파악 가능\n\nXML Config 장점\n코드 수정 없이 설정 변경 가능\n외부화된 설정 관리\n레거시 시스템과 호환\n\n현재 권장 방식\nJava Config + @Component 스캔 조합\nXML은 외부 라이브러리 설정이나 레거시 통합 시에만 사용",
    "references": [],
    "keywords": [
      "xml",
      "config",
      "java",
      "ide",
      "component",
      "scan",
      "bean",
      "conditional",
      "profile",
      "설정",
      "방식",
      "비교",
      "구분",
      "파일",
      "클래스"
    ]
  },
  {
    "id": "SPRING-051",
    "category": "spring",
    "categoryName": "Spring",
    "priority": "P1",
    "question": "최신 Spring 버전에서 추가된 기능 및 개선 사항에 대해 설명해주세요.",
    "answer": "Spring Framework 6 / Spring Boot 3 주요 변경사항\nJava 17 기준선\n최소 요구 버전이 Java 17로 상향\nRecord, Sealed Class, Pattern Matching 등 활용 가능\nJakarta EE 9+ 마이그레이션\njavax. → jakarta. 패키지 변경\nNative Image 지원 (GraalVM)\nAOT(Ahead-of-Time) 컴파일 공식 지원\n빠른 시작 시간과 낮은 메모리 사용량\nHTTP Interface Client\n선언적 HTTP 클라이언트 (Feign과 유사)\n문제 세부 정보 (Problem Details)\nRFC 7807 기반 표준 에러 응답 형식 지원\nObservability 개선\nMicrometer 통합 강화\n분산 추적 (Tracing) 통합\nMicrometer Observation API 도입\nVirtual Threads 지원 (Java 21)\nProject Loom의 가상 스레드 지원\n\nSpring Boot 3.2+ 추가 기능\nRestClient 도입 (WebClient의 동기 버전)\nJdbcClient 도입 (JDBC 간소화)\nSSL Bundle 자동 구성\nDocker Compose 지원 개선",
    "references": [
      {
        "title": "Spring Framework 6.0 Release Notes",
        "url": "https://github.com/spring-projects/spring-framework/wiki/What%27s-New-in-Spring-Framework-6.x"
      },
      {
        "title": "Spring Boot 3.0 Release Notes",
        "url": "https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-3.0-Release-Notes"
      }
    ],
    "keywords": [
      "spring",
      "framework",
      "boot",
      "java",
      "record",
      "sealed",
      "class",
      "pattern",
      "matching",
      "jakarta",
      "native",
      "image",
      "graalvm",
      "aot",
      "ahead-of-time"
    ]
  },
  {
    "id": "DOCKER-001",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker란 무엇이며, 컨테이너 기술이 등장하게 된 배경을 설명해 주세요.",
    "answer": "Docker는 애플리케이션을 컨테이너라는 격리된 환경에서 실행할 수 있게 해주는 오픈소스 플랫폼입니다.\n\n컨테이너 기술 등장 배경:\n환경 불일치 문제: \"내 컴퓨터에서는 되는데\" 문제 해결 필요\n리소스 효율성: VM의 무거운 오버헤드 대비 경량화된 가상화 필요\n배포 속도: 빠른 애플리케이션 배포 및 스케일링 요구 증가\n마이크로서비스: 서비스 단위 독립적 배포 및 관리 필요성",
    "references": [
      {
        "title": "Docker Overview",
        "url": "https://docs.docker.com/get-started/overview/"
      }
    ],
    "keywords": [
      "docker",
      "애플리케이션을",
      "컨테이너라는",
      "격리된",
      "환경에서",
      "실행할",
      "있게",
      "해주는",
      "오픈소스",
      "플랫폼입니다",
      "컨테이너",
      "기술",
      "등장",
      "배경",
      "환경"
    ]
  },
  {
    "id": "DOCKER-002",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "컨테이너와 가상 머신(VM)의 차이점을 아키텍처 관점에서 설명해 주세요.",
    "answer": "구분   컨테이너   가상 머신\n\n가상화 레벨   OS 레벨 (커널 공유)   하드웨어 레벨\nGuest OS   불필요   각 VM마다 필요\n크기   MB 단위   GB 단위\n시작 시간   초 단위   분 단위\n격리 수준   프로세스 격리   완전한 격리\n성능   네이티브에 가까움   하이퍼바이저 오버헤드\n\n컨테이너는 호스트 OS 커널을 공유하므로 가볍고 빠르지만, VM은 하이퍼바이저 위에 완전한 OS를 실행하여 더 강한 격리를 제공합니다.",
    "references": [
      {
        "title": "What is a Container?",
        "url": "https://docs.docker.com/get-started/overview/#docker-objects"
      }
    ],
    "keywords": [
      "guest",
      "구분",
      "컨테이너",
      "가상",
      "머신",
      "가상화",
      "레벨",
      "커널",
      "공유",
      "하드웨어",
      "불필요",
      "마다",
      "필요",
      "크기",
      "단위"
    ]
  },
  {
    "id": "DOCKER-003",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 이미지와 컨테이너의 차이점을 설명해 주세요.",
    "answer": "Docker 이미지:\n읽기 전용 템플릿\n애플리케이션 실행에 필요한 모든 것(코드, 런타임, 라이브러리, 설정) 포함\n여러 레이어로 구성\n불변(Immutable)\n\nDocker 컨테이너:\n이미지의 실행 가능한 인스턴스\n이미지 위에 쓰기 가능한 레이어 추가\n생성, 시작, 중지, 삭제 가능\n격리된 프로세스로 실행\n\n비유하면, 이미지는 \"클래스\"이고 컨테이너는 \"인스턴스\"입니다.",
    "references": [
      {
        "title": "Images and Containers",
        "url": "https://docs.docker.com/get-started/overview/#images"
      }
    ],
    "keywords": [
      "docker",
      "immutable",
      "이미지",
      "읽기",
      "전용",
      "템플릿",
      "애플리케이션",
      "실행에",
      "필요한",
      "모든",
      "코드",
      "런타임",
      "라이브러리",
      "설정",
      "포함"
    ]
  },
  {
    "id": "DOCKER-004",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker의 레이어(Layer) 시스템이란 무엇이며, 어떤 장점이 있나요?",
    "answer": "Docker 이미지는 여러 개의 읽기 전용 레이어로 구성됩니다. Dockerfile의 각 명령어(FROM, RUN, COPY 등)가 새로운 레이어를 생성합니다.\n\n장점:\n공간 효율성: 동일한 베이스 이미지를 사용하는 이미지들이 레이어를 공유\n빌드 속도 향상: 변경되지 않은 레이어는 캐시에서 재사용\n배포 효율성: 변경된 레이어만 전송하면 됨\n버전 관리: 각 레이어가 변경 이력을 나타냄\n\n컨테이너 실행 시 최상위에 쓰기 가능한 레이어가 추가됩니다(Copy-on-Write).",
    "references": [
      {
        "title": "About storage drivers",
        "url": "https://docs.docker.com/storage/storagedriver/"
      }
    ],
    "keywords": [
      "docker",
      "dockerfile",
      "run",
      "copy",
      "copy-on-write",
      "이미지는",
      "여러",
      "개의",
      "읽기",
      "전용",
      "레이어로",
      "구성됩니다",
      "명령어",
      "새로운",
      "레이어를"
    ]
  },
  {
    "id": "DOCKER-005",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker가 사용하는 Linux 커널 기술인 namespace와 cgroups에 대해 설명해 주세요.",
    "answer": "Namespace (격리):\nPID namespace: 프로세스 ID 격리\nNET namespace: 네트워크 인터페이스 격리\nMNT namespace: 파일 시스템 마운트 포인트 격리\nUTS namespace: 호스트명, 도메인명 격리\nIPC namespace: 프로세스 간 통신 격리\nUSER namespace: 사용자/그룹 ID 격리\n\ncgroups (리소스 제한):\nCPU, 메모리, 디스크 I/O, 네트워크 대역폭 등 리소스 사용량 제한\n리소스 사용량 모니터링\n프로세스 그룹 단위로 관리\n\nNamespace는 \"무엇을 볼 수 있는지\", cgroups는 \"얼마나 사용할 수 있는지\"를 제어합니다.",
    "references": [
      {
        "title": "Docker and Linux Kernel",
        "url": "https://docs.docker.com/get-started/overview/#the-underlying-technology"
      }
    ],
    "keywords": [
      "namespace",
      "pid",
      "net",
      "mnt",
      "uts",
      "ipc",
      "user",
      "cpu",
      "격리",
      "프로세스",
      "네트워크",
      "인터페이스",
      "파일",
      "시스템",
      "마운트"
    ]
  },
  {
    "id": "DOCKER-006",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 데몬(Docker Daemon)의 역할과 Docker 클라이언트와의 통신 방식을 설명해 주세요.",
    "answer": "Docker Daemon (dockerd):\nDocker API 요청을 수신하고 처리\n이미지, 컨테이너, 네트워크, 볼륨 등 Docker 객체 관리\n다른 데몬과 통신하여 Docker 서비스 관리\n\n통신 방식:\nUnix 소켓: /var/run/docker.sock (기본값, 로컬 통신)\nTCP 소켓: 원격 API 접근 시 사용 (TLS 권장)\nfd: systemd 소켓 활성화\n\n아키텍처:",
    "references": [
      {
        "title": "Docker Architecture",
        "url": "https://docs.docker.com/get-started/overview/#docker-architecture"
      }
    ],
    "keywords": [
      "docker",
      "daemon",
      "api",
      "unix",
      "tcp",
      "tls",
      "요청을",
      "수신하고",
      "처리",
      "이미지",
      "컨테이너",
      "네트워크",
      "볼륨",
      "객체",
      "관리"
    ]
  },
  {
    "id": "DOCKER-007",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Union File System(UnionFS)이란 무엇이며, Docker에서 어떻게 활용되나요?",
    "answer": "UnionFS란:\n여러 개의 파일 시스템(레이어)을 하나의 통합된 뷰로 마운트하는 파일 시스템입니다.\n\nDocker에서의 활용:\n여러 읽기 전용 이미지 레이어를 하나의 파일 시스템으로 표현\n최상위에 쓰기 가능한 컨테이너 레이어 추가\nCopy-on-Write(CoW) 전략으로 효율적인 스토리지 사용\n\n주요 구현체:\noverlay2: 현재 Docker 기본 스토리지 드라이버 (권장)\naufs: 레거시, 일부 오래된 커널에서 사용\nbtrfs, zfs: 특수 파일 시스템 환경",
    "references": [
      {
        "title": "Use the OverlayFS storage driver",
        "url": "https://docs.docker.com/storage/storagedriver/overlayfs-driver/"
      }
    ],
    "keywords": [
      "unionfs",
      "docker",
      "copy-on-write",
      "cow",
      "여러",
      "개의",
      "파일",
      "시스템",
      "레이어",
      "하나의",
      "통합된",
      "뷰로",
      "마운트하는",
      "시스템입니다",
      "에서의"
    ]
  },
  {
    "id": "DOCKER-008",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker Hub와 프라이빗 레지스트리의 차이점과 각각의 사용 시나리오를 설명해 주세요.",
    "answer": "Docker Hub:\nDocker 공식 퍼블릭 레지스트리\n공식 이미지, 커뮤니티 이미지 제공\n무료 플랜: 퍼블릭 무제한, 프라이빗 제한\n자동 빌드, 취약점 스캔 기능\n\n프라이빗 레지스트리:\n자체 호스팅 또는 클라우드 제공 (ECR, GCR, ACR 등)\n완전한 접근 제어\n내부 네트워크에서 빠른 이미지 전송\n규정 준수 및 보안 요구사항 충족\n\n사용 시나리오:\nDocker Hub: 오픈소스 프로젝트, 공개 이미지 배포, 개인 학습\n프라이빗: 기업 내부 애플리케이션, 민감한 코드, 규정 준수 필요 시",
    "references": [
      {
        "title": "Docker Hub",
        "url": "https://docs.docker.com/docker-hub/"
      }
    ],
    "keywords": [
      "docker",
      "hub",
      "ecr",
      "gcr",
      "acr",
      "공식",
      "퍼블릭",
      "레지스트리",
      "이미지",
      "커뮤니티",
      "제공",
      "무료",
      "플랜",
      "무제한",
      "프라이빗"
    ]
  },
  {
    "id": "DOCKER-009",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "OCI(Open Container Initiative)란 무엇이며, Docker와의 관계를 설명해 주세요.",
    "answer": "OCI(Open Container Initiative):\nLinux Foundation 산하의 프로젝트로, 컨테이너 포맷과 런타임에 대한 개방형 표준을 정의합니다.\n\n주요 표준:\nRuntime Specification: 컨테이너 런타임 표준 (runc가 참조 구현)\nImage Specification: 이미지 포맷 표준\nDistribution Specification: 이미지 배포 표준\n\nDocker와의 관계:\nDocker가 OCI 설립에 참여하고 초기 기술 기여\nDocker의 컨테이너 런타임(runc)을 OCI에 기증\nDocker 이미지는 OCI 이미지 스펙과 호환\n이로 인해 Docker 이미지를 다른 OCI 호환 런타임(containerd, CRI-O 등)에서 실행 가능",
    "references": [
      {
        "title": "Open Container Initiative",
        "url": "https://opencontainers.org/"
      }
    ],
    "keywords": [
      "oci",
      "open",
      "container",
      "initiative",
      "linux",
      "foundation",
      "runtime",
      "specification",
      "image",
      "distribution",
      "docker",
      "cri-o",
      "산하의",
      "프로젝트로",
      "컨테이너"
    ]
  },
  {
    "id": "DOCKER-010",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "containerd와 runc의 역할과 Docker 아키텍처에서의 위치를 설명해 주세요.",
    "answer": "아키텍처 흐름:\n\ncontainerd:\n고수준 컨테이너 런타임\n이미지 전송 및 저장 관리\n컨테이너 실행 및 감독\n네트워크, 스토리지 관리\nCNCF 졸업 프로젝트\n\nrunc:\n저수준 컨테이너 런타임 (OCI 참조 구현)\n실제로 컨테이너 프로세스 생성 및 실행\nnamespace, cgroups 설정\n컨테이너 시작 후 종료됨\n\nDocker는 이 계층 구조를 통해 모듈화되어 있으며, Kubernetes도 containerd를 직접 사용할 수 있습니다.",
    "references": [
      {
        "title": "containerd",
        "url": "https://containerd.io/"
      }
    ],
    "keywords": [
      "cncf",
      "oci",
      "docker",
      "kubernetes",
      "아키텍처",
      "흐름",
      "고수준",
      "컨테이너",
      "런타임",
      "이미지",
      "전송",
      "저장",
      "관리",
      "실행",
      "감독"
    ]
  },
  {
    "id": "DOCKER-011",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Dockerfile의 주요 명령어(FROM, RUN, CMD, ENTRYPOINT, COPY, ADD)의 역할과 차이점을 설명해 주세요.",
    "answer": "명령어   역할   특징\n\nFROM   베이스 이미지 지정   Dockerfile 시작점, 멀티스테이지 가능\nRUN   빌드 시 명령 실행   새 레이어 생성, 패키지 설치 등\nCMD   컨테이너 실행 시 기본 명령   docker run 인자로 덮어쓰기 가능\nENTRYPOINT   컨테이너 실행 시 고정 명령   CMD와 조합 가능, 덮어쓰기 어려움\nCOPY   파일/디렉토리 복사   로컬 파일만, 단순하고 명확\nADD   파일 복사 + 추가 기능   URL 다운로드, tar 자동 추출\n\n권장 사항:\n단순 복사는 COPY 사용 (명확성)\nADD는 tar 추출 필요 시에만 사용",
    "references": [
      {
        "title": "Dockerfile reference",
        "url": "https://docs.docker.com/reference/dockerfile/"
      }
    ],
    "keywords": [
      "dockerfile",
      "run",
      "cmd",
      "entrypoint",
      "copy",
      "add",
      "url",
      "명령어",
      "역할",
      "특징",
      "베이스",
      "이미지",
      "지정",
      "시작점",
      "멀티스테이지"
    ]
  },
  {
    "id": "DOCKER-012",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "CMD와 ENTRYPOINT의 차이점을 설명하고, 언제 어떤 것을 사용해야 하는지 예시를 들어 설명해 주세요.",
    "answer": "차이점:\n\n구분   CMD   ENTRYPOINT\n\n덮어쓰기   docker run 인자로 쉽게 덮어씀   --entrypoint 옵션 필요\n역할   기본 인자 제공   고정 실행 명령\n조합   ENTRYPOINT의 기본 인자로 사용 가능   CMD와 함께 사용 가능\n\n사용 예시:",
    "references": [
      {
        "title": "ENTRYPOINT",
        "url": "https://docs.docker.com/reference/dockerfile/#entrypoint"
      }
    ],
    "keywords": [
      "cmd",
      "entrypoint",
      "차이점",
      "구분",
      "덮어쓰기",
      "인자로",
      "쉽게",
      "덮어씀",
      "옵션",
      "필요",
      "역할",
      "기본",
      "인자",
      "제공",
      "고정"
    ]
  },
  {
    "id": "DOCKER-013",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "COPY와 ADD 명령어의 차이점은 무엇이며, 어떤 상황에서 각각을 사용해야 하나요?",
    "answer": "COPY:\n로컬 파일/디렉토리를 이미지로 복사\n단순하고 명확한 동작\n권장: 대부분의 경우 COPY 사용\n\nADD:\nCOPY의 모든 기능 포함\nURL에서 파일 다운로드 가능\ntar 아카이브 자동 추출\n\n사용 지침:\n\nADD 주의점:\nURL 다운로드보다 RUN curl 또는 RUN wget 권장 (레이어 최적화)\n예상치 못한 tar 추출 발생 가능",
    "references": [
      {
        "title": "COPY vs ADD",
        "url": "https://docs.docker.com/reference/dockerfile/#copy"
      }
    ],
    "keywords": [
      "copy",
      "add",
      "url",
      "run",
      "로컬",
      "파일",
      "디렉토리를",
      "이미지로",
      "복사",
      "단순하고",
      "명확한",
      "동작",
      "권장",
      "대부분의",
      "사용"
    ]
  },
  {
    "id": "DOCKER-014",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "멀티스테이지 빌드(Multi-stage Build)란 무엇이며, 어떤 장점이 있나요?",
    "answer": "멀티스테이지 빌드:\n하나의 Dockerfile에서 여러 FROM 문을 사용하여 빌드 단계를 분리하고, 최종 이미지에는 필요한 결과물만 포함시키는 기법입니다.\n\n장점:\n이미지 크기 감소: 빌드 도구, 소스코드 제외\n보안 향상: 불필요한 파일 미포함\nDockerfile 단순화: 하나의 파일로 빌드/실행 환경 관리\n빌드 캐시 활용: 각 스테이지별 캐시",
    "references": [
      {
        "title": "Multi-stage builds",
        "url": "https://docs.docker.com/build/building/multi-stage/"
      }
    ],
    "keywords": [
      "dockerfile",
      "멀티스테이지",
      "빌드",
      "하나의",
      "에서",
      "여러",
      "문을",
      "사용하여",
      "단계를",
      "분리하고",
      "최종",
      "이미지에는",
      "필요한",
      "결과물만",
      "포함시키는"
    ]
  },
  {
    "id": "DOCKER-015",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "멀티스테이지 빌드를 사용하여 Go 또는 Java 애플리케이션의 이미지 크기를 줄이는 방법을 설명해 주세요.",
    "answer": "Go 예시:\n\nJava 예시:\n\n핵심 포인트:\nGo: scratch 또는 distroless 사용 가능 (정적 빌드)\nJava: JDK 대신 JRE 사용, Alpine 기반 선택",
    "references": [
      {
        "title": "Multi-stage builds",
        "url": "https://docs.docker.com/build/building/multi-stage/"
      }
    ],
    "keywords": [
      "java",
      "jdk",
      "jre",
      "alpine",
      "예시",
      "핵심",
      "포인트",
      "사용",
      "가능",
      "정적",
      "빌드",
      "대신",
      "기반",
      "선택"
    ]
  },
  {
    "id": "DOCKER-016",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": ".dockerignore 파일의 역할과 사용법을 설명해 주세요.",
    "answer": ".dockerignore 역할:\nDocker 빌드 시 빌드 컨텍스트에서 제외할 파일/디렉토리를 지정합니다.\n\n장점:\n빌드 컨텍스트 크기 감소 → 빌드 속도 향상\n불필요한 파일이 이미지에 포함되는 것 방지\n민감한 정보(credentials, .env) 제외\n\n예시:",
    "references": [
      {
        "title": ".dockerignore file",
        "url": "https://docs.docker.com/build/building/context/#dockerignore-files"
      }
    ],
    "keywords": [
      "docker",
      "역할",
      "빌드",
      "컨텍스트에서",
      "제외할",
      "파일",
      "디렉토리를",
      "지정합니다",
      "장점",
      "컨텍스트",
      "크기",
      "감소",
      "속도",
      "향상",
      "불필요한"
    ]
  },
  {
    "id": "DOCKER-017",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Dockerfile에서 ENV와 ARG의 차이점을 설명해 주세요.",
    "answer": "구분   ARG   ENV\n\n사용 시점   빌드 시에만   빌드 + 런타임\n설정 방법   --build-arg   -e 또는 docker run\n레이어   이미지에 포함 안 됨   이미지에 포함\n기본값   Dockerfile에서 지정 가능   Dockerfile에서 지정 가능\n\n예시:\n\n빌드 명령:\n\n주의: ARG로 민감한 정보(비밀번호 등)를 전달하면 이미지 히스토리에 노출될 수 있습니다.",
    "references": [
      {
        "title": "ARG",
        "url": "https://docs.docker.com/reference/dockerfile/#arg"
      }
    ],
    "keywords": [
      "arg",
      "env",
      "build-arg",
      "dockerfile",
      "구분",
      "사용",
      "시점",
      "빌드",
      "시에만",
      "런타임",
      "설정",
      "방법",
      "레이어",
      "이미지에",
      "포함"
    ]
  },
  {
    "id": "DOCKER-018",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Dockerfile의 WORKDIR 명령어의 역할과 사용 시 주의점을 설명해 주세요.",
    "answer": "WORKDIR 역할:\n이후 명령어(RUN, CMD, ENTRYPOINT, COPY, ADD)의 작업 디렉토리 설정\n디렉토리가 없으면 자동 생성\n절대/상대 경로 모두 사용 가능\n\n예시:\n\n주의점:\nRUN cd /path보다 WORKDIR 사용 권장 (명확성, 유지보수)\n절대 경로 사용 권장 (예측 가능한 동작)\n여러 번 사용 가능, 상대 경로는 이전 WORKDIR 기준\n\nBad Practice:",
    "references": [
      {
        "title": "WORKDIR",
        "url": "https://docs.docker.com/reference/dockerfile/#workdir"
      }
    ],
    "keywords": [
      "workdir",
      "run",
      "cmd",
      "entrypoint",
      "copy",
      "add",
      "bad",
      "practice",
      "역할",
      "이후",
      "명령어",
      "작업",
      "디렉토리",
      "설정",
      "디렉토리가"
    ]
  },
  {
    "id": "DOCKER-019",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Dockerfile에서 USER 명령어를 사용하는 이유와 보안상의 이점을 설명해 주세요.",
    "answer": "USER 명령어:\n이후 명령어(RUN, CMD, ENTRYPOINT)를 실행할 사용자/그룹을 지정합니다.\n\n예시:\n\n보안상 이점:\n최소 권한 원칙: 컨테이너 탈출 시 피해 최소화\n호스트 보호: root 권한으로 호스트 파일 시스템 접근 방지\n취약점 완화: 권한 상승 공격 어려움\n규정 준수: 많은 보안 정책에서 non-root 실행 요구\n\n주의: 일부 작업(포트 1024 이하 바인딩 등)은 root 필요하므로 적절한 capabilities 설정 고려",
    "references": [
      {
        "title": "USER",
        "url": "https://docs.docker.com/reference/dockerfile/#user"
      }
    ],
    "keywords": [
      "user",
      "run",
      "cmd",
      "entrypoint",
      "non-root",
      "명령어",
      "이후",
      "실행할",
      "사용자",
      "그룹을",
      "지정합니다",
      "예시",
      "보안상",
      "이점",
      "최소"
    ]
  },
  {
    "id": "DOCKER-020",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "HEALTHCHECK 명령어의 역할과 설정 옵션에 대해 설명해 주세요.",
    "answer": "HEALTHCHECK 역할:\n컨테이너 내 애플리케이션의 상태를 주기적으로 확인합니다.\n\n문법:\n\n옵션:\n옵션   기본값   설명\n\n--interval   30s   헬스체크 간격\n--timeout   30s   타임아웃\n--start-period   0s   시작 후 대기 시간\n--retries   3   실패 허용 횟수\n\n상태:\nstarting: 시작 중 (start-period 내)\nhealthy: 정상 (exit 0)\nunhealthy: 비정상 (retries 초과)\n\n활용: Docker Swarm, Compose에서 서비스 상태 관리 및 재시작 정책에 활용됩니다.",
    "references": [
      {
        "title": "HEALTHCHECK",
        "url": "https://docs.docker.com/reference/dockerfile/#healthcheck"
      }
    ],
    "keywords": [
      "healthcheck",
      "start-period",
      "docker",
      "swarm",
      "compose",
      "역할",
      "컨테이너",
      "애플리케이션의",
      "상태를",
      "주기적으로",
      "확인합니다",
      "문법",
      "옵션",
      "기본값",
      "설명"
    ]
  },
  {
    "id": "DOCKER-021",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Dockerfile 작성 시 레이어 수를 줄이고 이미지 크기를 최적화하는 방법을 설명해 주세요.",
    "answer": "레이어 수 줄이기:\n\n이미지 크기 최적화:\n경량 베이스 이미지 사용\nalpine, slim, distroless 선택\n불필요한 파일 정리\n패키지 캐시 삭제\n빌드 의존성 제거\n멀티스테이지 빌드 활용\n.dockerignore 사용\n레이어 순서 최적화\n자주 변경되는 파일은 마지막에 COPY",
    "references": [
      {
        "title": "Best practices for Dockerfile",
        "url": "https://docs.docker.com/develop/develop-images/dockerfile_best-practices/"
      }
    ],
    "keywords": [
      "copy",
      "레이어",
      "줄이기",
      "이미지",
      "크기",
      "최적화",
      "경량",
      "베이스",
      "사용",
      "선택",
      "불필요한",
      "파일",
      "정리",
      "패키지",
      "캐시"
    ]
  },
  {
    "id": "DOCKER-022",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Dockerfile의 빌드 캐시가 무효화되는 조건과 캐시를 효율적으로 활용하는 방법을 설명해 주세요.",
    "answer": "캐시 무효화 조건:\nDockerfile 명령어 변경\nCOPY/ADD 대상 파일 내용 변경 (체크섬 비교)\n이전 레이어의 캐시가 무효화됨\n--no-cache 옵션 사용\nARG 값 변경 (해당 ARG 사용하는 명령어부터)\n\n캐시 효율적 활용:\n변경 빈도 순서로 명령어 배치\n의존성 파일 분리\nRUN 명령어 통합 여부 고려\n자주 변경되는 명령은 분리\n관련 명령은 통합",
    "references": [
      {
        "title": "Leverage build cache",
        "url": "https://docs.docker.com/build/cache/"
      }
    ],
    "keywords": [
      "dockerfile",
      "copy",
      "add",
      "no-cache",
      "arg",
      "run",
      "캐시",
      "무효화",
      "조건",
      "명령어",
      "변경",
      "대상",
      "파일",
      "내용",
      "체크섬"
    ]
  },
  {
    "id": "DOCKER-023",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 이미지를 빌드하는 과정과 주요 옵션들을 설명해 주세요.",
    "answer": "빌드 과정:\n빌드 컨텍스트(현재 디렉토리) 전송\nDockerfile 파싱\n각 명령어 순차 실행, 레이어 생성\n캐시 활용 (가능한 경우)\n최종 이미지 생성\n\n기본 명령:\n\n주요 옵션:\n옵션   설명\n\n-t, --tag   이미지 이름:태그 지정\n-f, --file   Dockerfile 경로 지정\n--build-arg   ARG 값 전달\n--no-cache   캐시 미사용\n--target   멀티스테이지 특정 단계까지만 빌드\n--platform   대상 플랫폼 (linux/amd64 등)\n--progress   출력 형식 (plain, tty, auto)",
    "references": [
      {
        "title": "docker build",
        "url": "https://docs.docker.com/reference/cli/docker/image/build/"
      }
    ],
    "keywords": [
      "dockerfile",
      "build-arg",
      "arg",
      "no-cache",
      "빌드",
      "과정",
      "컨텍스트",
      "현재",
      "디렉토리",
      "전송",
      "파싱",
      "명령어",
      "순차",
      "실행",
      "레이어"
    ]
  },
  {
    "id": "DOCKER-024",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 이미지 태깅 전략과 버전 관리 방법에 대해 설명해 주세요.",
    "answer": "태깅 전략:\nSemantic Versioning\nGit 기반\n환경/날짜 기반\n\n권장 사항:\nlatest 태그는 프로덕션에서 피하기 (불명확)\n불변 태그 사용 (commit hash, 버전)\n다중 태그 적용\n\n이미지 다이제스트:",
    "references": [
      {
        "title": "Tagging best practices",
        "url": "https://docs.docker.com/develop/develop-images/guidelines/"
      }
    ],
    "keywords": [
      "semantic",
      "versioning",
      "git",
      "태깅",
      "전략",
      "기반",
      "환경",
      "날짜",
      "권장",
      "사항",
      "태그는",
      "프로덕션에서",
      "피하기",
      "불명확",
      "불변"
    ]
  },
  {
    "id": "DOCKER-025",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 이미지를 프라이빗 레지스트리에 푸시하고 풀하는 과정을 설명해 주세요.",
    "answer": "레지스트리 로그인:\n이미지 태깅:\n이미지 푸시:\n이미지 풀:\n\n클라우드 레지스트리 예시:",
    "references": [
      {
        "title": "docker push",
        "url": "https://docs.docker.com/reference/cli/docker/image/push/"
      }
    ],
    "keywords": [
      "레지스트리",
      "로그인",
      "이미지",
      "태깅",
      "푸시",
      "클라우드",
      "예시"
    ]
  },
  {
    "id": "DOCKER-026",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "dangling 이미지란 무엇이며, 이를 정리하는 방법을 설명해 주세요.",
    "answer": "Dangling 이미지란:\n태그가 없는 이미지로, <none>:<none>으로 표시됩니다. 주로 새 이미지 빌드 시 기존 태그가 새 이미지로 이동하면서 발생합니다.\n\n확인 방법:\n\n정리 방법:\n\n전체 정리:",
    "references": [
      {
        "title": "docker image prune",
        "url": "https://docs.docker.com/reference/cli/docker/image/prune/"
      }
    ],
    "keywords": [
      "dangling",
      "이미지란",
      "태그가",
      "없는",
      "이미지로",
      "으로",
      "표시됩니다",
      "주로",
      "이미지",
      "빌드",
      "기존",
      "이동하면서",
      "발생합니다",
      "확인",
      "방법"
    ]
  },
  {
    "id": "DOCKER-027",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 이미지의 히스토리를 확인하고 각 레이어의 크기를 분석하는 방법을 설명해 주세요.",
    "answer": "이미지 히스토리 확인:\n\n출력 예시:\n\n상세 분석 도구:\n\n최적화 포인트:\n큰 레이어 식별 후 최적화\n불필요한 파일 제거 확인\n캐시 정리 여부 확인",
    "references": [
      {
        "title": "docker history",
        "url": "https://docs.docker.com/reference/cli/docker/image/history/"
      }
    ],
    "keywords": [
      "이미지",
      "히스토리",
      "확인",
      "출력",
      "예시",
      "상세",
      "분석",
      "도구",
      "최적화",
      "포인트",
      "레이어",
      "식별",
      "불필요한",
      "파일",
      "제거"
    ]
  },
  {
    "id": "DOCKER-028",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "base 이미지를 선택할 때 고려해야 할 요소들을 설명해 주세요. (alpine, slim, scratch 등)",
    "answer": "이미지   크기   특징   사용 사례\n\nscratch   0B   완전히 비어있음   정적 바이너리 (Go)\nalpine   ~5MB   musl libc, busybox   경량 컨테이너\nslim   ~80MB   Debian 최소 설치   glibc 필요 시\n기본   ~100MB+   전체 OS   디버깅, 호환성\n\n고려 요소:\n이미지 크기: 전송, 저장, 시작 시간 영향\n보안: 작은 이미지 = 적은 공격 표면\n호환성:\nAlpine의 musl libc는 일부 라이브러리와 비호환\n네이티브 의존성 있으면 glibc 기반 권장\n디버깅 도구: scratch는 shell 없음\n패키지 관리자:\nAlpine: apk\nDebian계열: apt\n\n권장:\nGo/Rust 정적 바이너리: scratch 또는 distroless\nNode.js/Python: alpine 또는 slim\n복잡한 의존성: slim",
    "references": [
      {
        "title": "Best practices for Dockerfile",
        "url": "https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#from"
      }
    ],
    "keywords": [
      "debian",
      "alpine",
      "rust",
      "node",
      "python",
      "이미지",
      "크기",
      "특징",
      "사용",
      "사례",
      "완전히",
      "비어있음",
      "정적",
      "바이너리",
      "경량"
    ]
  },
  {
    "id": "DOCKER-029",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 이미지를 파일로 저장(save)하고 로드(load)하는 방법과 사용 시나리오를 설명해 주세요.",
    "answer": "이미지 저장 (save):\n\n이미지 로드 (load):\n\n사용 시나리오:\n에어갭 환경: 인터넷 없는 폐쇄망에 이미지 전달\n백업: 중요 이미지 아카이브\n오프라인 배포: USB 등으로 물리적 전달\nCI/CD 아티팩트: 빌드 결과물 저장\n\nexport/import와 차이:\nsave/load: 이미지 전체 (레이어, 메타데이터 포함)\nexport/import: 컨테이너 파일시스템 (단일 레이어)",
    "references": [
      {
        "title": "docker save",
        "url": "https://docs.docker.com/reference/cli/docker/image/save/"
      }
    ],
    "keywords": [
      "usb",
      "이미지",
      "저장",
      "로드",
      "사용",
      "시나리오",
      "에어갭",
      "환경",
      "인터넷",
      "없는",
      "폐쇄망에",
      "전달",
      "백업",
      "중요",
      "아카이브"
    ]
  },
  {
    "id": "DOCKER-030",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker Content Trust란 무엇이며, 이미지 서명의 중요성을 설명해 주세요.",
    "answer": "Docker Content Trust (DCT):\n이미지 게시자의 신원을 검증하고, 이미지 무결성을 보장하는 보안 기능입니다. Notary 프로젝트 기반으로 구현되었습니다.\n\n활성화:\n\n이미지 서명:\n\n이미지 서명의 중요성:\n무결성: 이미지가 변조되지 않았음을 보장\n신뢰성: 이미지 게시자 신원 확인\n공급망 보안: 중간자 공격 방지\n규정 준수: 보안 정책 요구사항 충족\n\n동작 원리:\n오프라인 키: root key (안전하게 보관)\n온라인 키: 이미지 서명용",
    "references": [
      {
        "title": "Content trust in Docker",
        "url": "https://docs.docker.com/engine/security/trust/"
      }
    ],
    "keywords": [
      "docker",
      "content",
      "trust",
      "dct",
      "notary",
      "이미지",
      "게시자의",
      "신원을",
      "검증하고",
      "무결성을",
      "보장하는",
      "보안",
      "기능입니다",
      "프로젝트",
      "기반으로"
    ]
  },
  {
    "id": "DOCKER-031",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker의 기본 네트워크 드라이버 종류(bridge, host, none, overlay)와 각각의 특징을 설명해 주세요.",
    "answer": "드라이버   특징   사용 사례\n\nbridge   기본값, 가상 브릿지 네트워크   단일 호스트, 독립 컨테이너\nhost   호스트 네트워크 스택 직접 사용   네트워크 성능 중요 시\nnone   네트워크 비활성화   완전한 네트워크 격리\noverlay   다중 호스트 간 네트워크   Docker Swarm, 클러스터\nmacvlan   컨테이너에 MAC 주소 할당   물리 네트워크 직접 연결\n\n예시:",
    "references": [
      {
        "title": "Network drivers",
        "url": "https://docs.docker.com/network/drivers/"
      }
    ],
    "keywords": [
      "docker",
      "swarm",
      "mac",
      "드라이버",
      "특징",
      "사용",
      "사례",
      "기본값",
      "가상",
      "브릿지",
      "네트워크",
      "단일",
      "호스트",
      "독립",
      "컨테이너"
    ]
  },
  {
    "id": "DOCKER-032",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker bridge 네트워크의 동작 원리와 컨테이너 간 통신 방식을 설명해 주세요.",
    "answer": "동작 원리:\nDocker가 호스트에 가상 브릿지(docker0) 생성\n각 컨테이너에 veth(가상 이더넷) 페어 생성\n한쪽은 컨테이너 내 eth0, 다른 쪽은 브릿지에 연결\n컨테이너는 브릿지를 통해 통신\n\n네트워크 구조:\n\n컨테이너 간 통신:\n\n외부 통신:\nNAT(MASQUERADE)를 통해 호스트 IP로 외부 통신",
    "references": [
      {
        "title": "Bridge network driver",
        "url": "https://docs.docker.com/network/drivers/bridge/"
      }
    ],
    "keywords": [
      "docker",
      "nat",
      "masquerade",
      "동작",
      "원리",
      "호스트에",
      "가상",
      "브릿지",
      "생성",
      "컨테이너에",
      "이더넷",
      "페어",
      "한쪽은",
      "컨테이너",
      "다른"
    ]
  },
  {
    "id": "DOCKER-033",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker host 네트워크 모드의 특징과 사용 시 주의점을 설명해 주세요.",
    "answer": "특징:\n컨테이너가 호스트의 네트워크 스택을 직접 사용\n네트워크 격리 없음 (network namespace 공유)\n포트 매핑 불필요 (컨테이너 포트 = 호스트 포트)\nNAT 오버헤드 없음 → 성능 향상\n\n사용 예시:\n\n장점:\n네트워크 성능 최적화 (지연 시간 감소)\n포트 매핑 복잡성 제거\n많은 포트 사용 시 편리\n\n주의점:\n포트 충돌: 호스트와 같은 포트 사용 불가\n보안 위험: 네트워크 격리 없음\n이식성 감소: 호스트 네트워크 환경에 종속\nLinux 전용: macOS/Windows는 VM 내에서만 동작\n\n사용 사례:\n네트워크 모니터링 도구\n고성능 네트워크 애플리케이션",
    "references": [
      {
        "title": "Host network driver",
        "url": "https://docs.docker.com/network/drivers/host/"
      }
    ],
    "keywords": [
      "nat",
      "linux",
      "windows",
      "특징",
      "컨테이너가",
      "호스트의",
      "네트워크",
      "스택을",
      "직접",
      "사용",
      "격리",
      "없음",
      "공유",
      "포트",
      "매핑"
    ]
  },
  {
    "id": "DOCKER-034",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker overlay 네트워크란 무엇이며, 어떤 상황에서 사용하나요?",
    "answer": "Overlay 네트워크:\n여러 Docker 호스트에 걸쳐 있는 분산 네트워크로, 서로 다른 호스트의 컨테이너가 같은 네트워크에 있는 것처럼 통신할 수 있게 합니다.\n\n동작 원리:\nVXLAN(Virtual Extensible LAN) 기술 사용\nL2 over L3 터널링\n각 호스트의 Docker 데몬이 협력\n\n생성 및 사용:\n\n사용 상황:\nDocker Swarm: 멀티 노드 클러스터\n마이크로서비스: 여러 호스트에 분산된 서비스 간 통신\n서비스 디스커버리: 내장 DNS로 서비스 이름 해석\n\n특징:\n자동 암호화 옵션 (--opt encrypted)\n내장 로드 밸런싱\n서비스 메시 라우팅",
    "references": [
      {
        "title": "Overlay network driver",
        "url": "https://docs.docker.com/network/drivers/overlay/"
      }
    ],
    "keywords": [
      "overlay",
      "docker",
      "vxlan",
      "virtual",
      "extensible",
      "lan",
      "swarm",
      "dns",
      "네트워크",
      "여러",
      "호스트에",
      "걸쳐",
      "있는",
      "분산",
      "네트워크로"
    ]
  },
  {
    "id": "DOCKER-035",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker의 내장 DNS 서비스는 어떻게 동작하며, 컨테이너 이름으로 통신하는 원리를 설명해 주세요.",
    "answer": "Docker 내장 DNS:\n사용자 정의 네트워크에서 컨테이너 이름, 서비스 이름, 네트워크 별칭을 IP 주소로 해석해주는 DNS 서버입니다.\n\n동작 원리:\n컨테이너의 /etc/resolv.conf에 내장 DNS 서버(127.0.0.11) 설정\n컨테이너 이름으로 DNS 쿼리 시 Docker DNS가 응답\n외부 도메인은 호스트 DNS로 포워딩\n\n예시:\n\n네트워크 별칭:\n\n주의:\n기본 bridge 네트워크는 DNS 미지원\n반드시 사용자 정의 네트워크 사용",
    "references": [
      {
        "title": "Networking with standalone containers",
        "url": "https://docs.docker.com/network/network-tutorial-standalone/"
      }
    ],
    "keywords": [
      "docker",
      "dns",
      "내장",
      "사용자",
      "정의",
      "네트워크에서",
      "컨테이너",
      "이름",
      "서비스",
      "네트워크",
      "별칭을",
      "주소로",
      "해석해주는",
      "서버입니다",
      "동작"
    ]
  },
  {
    "id": "DOCKER-036",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너의 포트 매핑(-p 옵션)과 포트 노출(EXPOSE)의 차이점을 설명해 주세요.",
    "answer": "EXPOSE (Dockerfile):\n문서화 목적 (컨테이너가 사용하는 포트 명시)\n실제로 포트를 열지 않음\n이미지 메타데이터에 기록\n\n-p 옵션 (docker run):\n실제 포트 매핑 수행\n호스트 포트 ↔ 컨테이너 포트 연결\n외부에서 접근 가능하게 함\n\n비교:\n구분   EXPOSE   -p\n\n위치   Dockerfile   docker run\n효과   문서화   실제 매핑\n외부 접근   불가   가능",
    "references": [
      {
        "title": "EXPOSE",
        "url": "https://docs.docker.com/reference/dockerfile/#expose"
      }
    ],
    "keywords": [
      "expose",
      "dockerfile",
      "문서화",
      "목적",
      "컨테이너가",
      "사용하는",
      "포트",
      "명시",
      "실제로",
      "포트를",
      "열지",
      "않음",
      "이미지",
      "메타데이터에",
      "기록"
    ]
  },
  {
    "id": "DOCKER-037",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "사용자 정의 네트워크(user-defined network)를 생성하고 사용하는 이유와 장점을 설명해 주세요.",
    "answer": "생성 방법:\n\n사용:\n\n장점 (기본 bridge 대비):\n자동 DNS 해석\n컨테이너 이름으로 통신 가능\n기본 bridge는 IP만 사용 가능\n더 나은 격리\n네트워크별 컨테이너 격리\n명시적으로 연결된 컨테이너만 통신\n동적 연결/해제\n설정 유연성\n서브넷, 게이트웨이 직접 설정\nIP 범위 지정 가능\n환경 변수 공유\n--link 없이도 서비스 디스커버리",
    "references": [
      {
        "title": "docker network create",
        "url": "https://docs.docker.com/reference/cli/docker/network/create/"
      }
    ],
    "keywords": [
      "dns",
      "생성",
      "방법",
      "사용",
      "장점",
      "기본",
      "대비",
      "자동",
      "해석",
      "컨테이너",
      "이름으로",
      "통신",
      "가능",
      "나은",
      "격리"
    ]
  },
  {
    "id": "DOCKER-038",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 네트워크에서 컨테이너 간 통신을 제한하는 방법을 설명해 주세요.",
    "answer": "ICC(Inter-Container Communication) 비활성화:\n별도 네트워크 분리:\nnone 네트워크:\n방화벽 규칙 (iptables):\nDocker Compose에서:",
    "references": [
      {
        "title": "Networking overview",
        "url": "https://docs.docker.com/network/"
      }
    ],
    "keywords": [
      "icc",
      "inter-container",
      "communication",
      "docker",
      "compose",
      "비활성화",
      "별도",
      "네트워크",
      "분리",
      "방화벽",
      "규칙",
      "에서",
      "inter-container communication",
      "iptables"
    ]
  },
  {
    "id": "DOCKER-039",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker에서 데이터를 영속화하는 세 가지 방법(volumes, bind mounts, tmpfs)의 차이점을 설명해 주세요.",
    "answer": "구분   Volumes   Bind Mounts   tmpfs\n\n저장 위치   Docker 관리 영역   호스트 파일 시스템   메모리\n관리   Docker CLI   직접 관리   -\n영속성   컨테이너 독립적   컨테이너 독립적   휘발성\n성능   좋음   좋음   매우 빠름\n이식성   높음   낮음 (경로 의존)   -\n\n사용 예시:\n\n선택 기준:\nVolumes: 프로덕션 데이터, DB 저장소\nBind Mounts: 개발 환경, 설정 파일 공유\ntmpfs: 민감한 임시 데이터, 캐시",
    "references": [
      {
        "title": "Manage data in Docker",
        "url": "https://docs.docker.com/storage/"
      }
    ],
    "keywords": [
      "volumes",
      "bind",
      "mounts",
      "docker",
      "cli",
      "구분",
      "저장",
      "위치",
      "관리",
      "영역",
      "호스트",
      "파일",
      "시스템",
      "메모리",
      "직접"
    ]
  },
  {
    "id": "DOCKER-040",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 볼륨(named volume)의 장점과 바인드 마운트 대비 선호되는 이유를 설명해 주세요.",
    "answer": "Named Volume 장점:\nDocker가 관리\n생성, 삭제, 목록 조회 가능\n이식성\n호스트 경로에 의존하지 않음\n다른 환경에서 동일하게 동작\n볼륨 드라이버 지원\n클라우드 스토리지, NFS 등 연동 가능\n백업 및 마이그레이션 용이\n초기 데이터 복사\n이미지의 데이터를 볼륨으로 자동 복사\nLinux/Mac/Windows 호환\n플랫폼 독립적\n\n바인드 마운트 사용 시:\n개발 환경에서 소스 코드 실시간 반영\n특정 호스트 파일/디렉토리 접근 필요 시",
    "references": [
      {
        "title": "Volumes",
        "url": "https://docs.docker.com/storage/volumes/"
      }
    ],
    "keywords": [
      "named",
      "volume",
      "docker",
      "nfs",
      "linux",
      "mac",
      "windows",
      "장점",
      "관리",
      "생성",
      "삭제",
      "목록",
      "조회",
      "가능",
      "이식성"
    ]
  },
  {
    "id": "DOCKER-041",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "바인드 마운트(bind mount)의 특징과 개발 환경에서의 활용 방법을 설명해 주세요.",
    "answer": "특징:\n호스트의 특정 경로를 컨테이너에 마운트\n양방향 동기화 (호스트 변경 ↔ 컨테이너 반영)\nDocker 외부에서 관리\n절대 경로 필요\n\n개발 환경 활용:\n소스 코드 실시간 반영:\n핫 리로드 개발:\n설정 파일 주입:\n로그 접근:\n\n주의점:\nWindows/Mac은 파일 시스템 성능 이슈 가능\n:ro 플래그로 읽기 전용 설정 권장\n호스트 경로 의존으로 이식성 낮음",
    "references": [
      {
        "title": "Bind mounts",
        "url": "https://docs.docker.com/storage/bind-mounts/"
      }
    ],
    "keywords": [
      "docker",
      "windows",
      "mac",
      "특징",
      "호스트의",
      "특정",
      "경로를",
      "컨테이너에",
      "마운트",
      "양방향",
      "동기화",
      "호스트",
      "변경",
      "컨테이너",
      "반영"
    ]
  },
  {
    "id": "DOCKER-042",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "tmpfs 마운트란 무엇이며, 어떤 상황에서 사용하나요?",
    "answer": "tmpfs 마운트란:\n호스트의 메모리(RAM)에 데이터를 저장하는 마운트 방식입니다. 컨테이너 종료 시 데이터가 삭제됩니다.\n\n사용 방법:\n\n옵션:\ntmpfs-size: 최대 크기 (바이트)\ntmpfs-mode: 파일 모드 (권한)\n\n사용 상황:\n민감한 임시 데이터\n비밀번호, 토큰 등 디스크에 남기면 안 되는 정보\n고성능 캐시\n빠른 읽기/쓰기가 필요한 임시 캐시\n빌드 아티팩트\n빌드 중 생성되는 임시 파일\n세션 데이터\n영속화 불필요한 세션 정보\n\n특징:\n매우 빠른 I/O\nLinux 호스트에서만 사용 가능\nSwarm 서비스에서 사용 가능",
    "references": [
      {
        "title": "tmpfs mounts",
        "url": "https://docs.docker.com/storage/tmpfs/"
      }
    ],
    "keywords": [
      "ram",
      "tmpfs-size",
      "tmpfs-mode",
      "linux",
      "swarm",
      "마운트란",
      "호스트의",
      "메모리",
      "데이터를",
      "저장하는",
      "마운트",
      "방식입니다",
      "컨테이너",
      "종료",
      "데이터가"
    ]
  },
  {
    "id": "DOCKER-043",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 볼륨의 생명주기와 컨테이너 삭제 시 볼륨 처리 방법을 설명해 주세요.",
    "answer": "볼륨 생명주기:\n볼륨은 컨테이너와 독립적\n컨테이너 삭제 후에도 볼륨 유지\n명시적으로 삭제해야 제거됨\n\n볼륨 생성/삭제:\n\n컨테이너 삭제 시 볼륨 처리:\n\n익명 볼륨 vs Named 볼륨:",
    "references": [
      {
        "title": "Volumes",
        "url": "https://docs.docker.com/storage/volumes/"
      }
    ],
    "keywords": [
      "named",
      "볼륨",
      "생명주기",
      "볼륨은",
      "컨테이너와",
      "독립적",
      "컨테이너",
      "삭제",
      "후에도",
      "유지",
      "명시적으로",
      "삭제해야",
      "제거됨",
      "생성",
      "처리"
    ]
  },
  {
    "id": "DOCKER-044",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 볼륨 드라이버란 무엇이며, 외부 스토리지와 연동하는 방법을 설명해 주세요.",
    "answer": "볼륨 드라이버:\nDocker 볼륨을 다양한 스토리지 백엔드와 연동할 수 있게 해주는 플러그인입니다.\n\n기본 드라이버:\nlocal: 로컬 파일 시스템 (기본값)\n\n주요 서드파티 드라이버:\nnfs: NFS 스토리지\nazure-file: Azure File Storage\ncloudstor: AWS EBS, EFS\nconvoy: 분산 스토리지\n\nNFS 볼륨 예시:\n\n플러그인 설치 및 사용:\n\nDocker Compose:",
    "references": [
      {
        "title": "Volume plugins",
        "url": "https://docs.docker.com/engine/extend/plugins_volume/"
      }
    ],
    "keywords": [
      "docker",
      "nfs",
      "azure-file",
      "azure",
      "file",
      "storage",
      "aws",
      "ebs",
      "efs",
      "compose",
      "볼륨",
      "드라이버",
      "볼륨을",
      "다양한",
      "스토리지"
    ]
  },
  {
    "id": "DOCKER-045",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "읽기 전용 볼륨 마운트의 사용 시나리오와 설정 방법을 설명해 주세요.",
    "answer": "설정 방법:\n\nDocker Compose:\n\n사용 시나리오:\n설정 파일 주입\n인증서/키 파일\n공유 데이터 보호\n여러 컨테이너가 같은 데이터 참조 시 변경 방지\n보안 강화\n컨테이너 탈취 시 데이터 변조 방지\n불변 인프라\n컨테이너가 외부 데이터를 수정하지 못하게 보장",
    "references": [
      {
        "title": "Use volumes",
        "url": "https://docs.docker.com/storage/volumes/#use-a-read-only-volume"
      }
    ],
    "keywords": [
      "docker",
      "compose",
      "설정",
      "방법",
      "사용",
      "시나리오",
      "파일",
      "주입",
      "인증서",
      "공유",
      "데이터",
      "보호",
      "여러",
      "컨테이너가",
      "같은"
    ]
  },
  {
    "id": "DOCKER-046",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker Compose란 무엇이며, 단일 docker run 명령어 대비 장점을 설명해 주세요.",
    "answer": "Docker Compose:\nYAML 파일로 멀티 컨테이너 Docker 애플리케이션을 정의하고 실행하는 도구입니다.\n\n장점:\n선언적 설정\n인프라를 코드로 관리 (IaC)\n버전 관리 가능\n일관된 환경\n개발, 테스트, 운영 환경 동일\n간편한 명령어\n서비스 간 의존성 관리\n네트워크 자동 구성\n기본 네트워크 생성\n서비스명으로 DNS 해석\n환경 변수 관리\n.env 파일 지원\n\ndocker run vs compose:",
    "references": [
      {
        "title": "Docker Compose overview",
        "url": "https://docs.docker.com/compose/"
      }
    ],
    "keywords": [
      "docker",
      "compose",
      "yaml",
      "iac",
      "dns",
      "파일로",
      "멀티",
      "컨테이너",
      "애플리케이션을",
      "정의하고",
      "실행하는",
      "도구입니다",
      "장점",
      "선언적",
      "설정"
    ]
  },
  {
    "id": "DOCKER-047",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "docker-compose.yml 파일의 주요 구성 요소(version, services, networks, volumes)를 설명해 주세요.",
    "answer": "주요 구성 요소:\nservices: 애플리케이션을 구성하는 컨테이너들\nnetworks: 서비스 간 통신을 위한 네트워크\nvolumes: 데이터 영속화를 위한 볼륨\nconfigs/secrets: 설정 및 민감 정보 (Swarm)",
    "references": [
      {
        "title": "Compose file reference",
        "url": "https://docs.docker.com/compose/compose-file/"
      }
    ],
    "keywords": [
      "swarm",
      "주요",
      "구성",
      "요소",
      "애플리케이션을",
      "구성하는",
      "컨테이너들",
      "서비스",
      "통신을",
      "위한",
      "네트워크",
      "데이터",
      "영속화를",
      "볼륨",
      "설정"
    ]
  },
  {
    "id": "DOCKER-048",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker Compose에서 서비스 간 의존성(depends_on)을 설정하는 방법과 한계점을 설명해 주세요.",
    "answer": "기본 설정:\n\n조건부 의존성 (v2.1+):\n\n조건 옵션:\nservicestarted: 컨테이너 시작됨 (기본)\nservicehealthy: healthcheck 통과\nservicecompleted_successfully: 성공적으로 종료\n\n한계점:\n시작 순서만 보장\n애플리케이션이 \"준비\" 상태인지는 모름\nDB 컨테이너 시작 ≠ DB 연결 가능\n해결 방법:\nhealthcheck 사용 (권장)\n애플리케이션에서 재시도 로직 구현\nwait-for-it.sh 같은 스크립트 사용",
    "references": [
      {
        "title": "depends_on",
        "url": "https://docs.docker.com/compose/compose-file/05-services/#depends_on"
      }
    ],
    "keywords": [
      "servicecompleted_successfully",
      "wait-for",
      "기본",
      "설정",
      "조건부",
      "의존성",
      "조건",
      "옵션",
      "컨테이너",
      "시작됨",
      "통과",
      "성공적으로",
      "종료",
      "한계점",
      "시작"
    ]
  },
  {
    "id": "DOCKER-049",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker Compose에서 환경 변수를 관리하는 방법(.env 파일, environment, env_file)을 설명해 주세요.",
    "answer": "environment (인라인):\nenvfile (외부 파일):\n.env (Compose 변수 치환):\n\n우선순위 (높음 → 낮음):\ndocker-compose run -e로 전달\n셸 환경 변수\n.env 파일\nenv_file 지정 파일\nDockerfile의 ENV\n\n보안 팁:\n.env는 .gitignore에 추가\n민감 정보는 Docker secrets 사용 고려",
    "references": [
      {
        "title": "Environment variables",
        "url": "https://docs.docker.com/compose/environment-variables/"
      }
    ],
    "keywords": [
      "compose",
      "docker-compose",
      "env_file",
      "dockerfile",
      "env",
      "docker",
      "인라인",
      "외부",
      "파일",
      "변수",
      "치환",
      "우선순위",
      "높음",
      "낮음",
      "전달"
    ]
  },
  {
    "id": "DOCKER-050",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker Compose에서 서비스를 스케일링하는 방법과 주의점을 설명해 주세요.",
    "answer": "스케일링 방법:\n\nCompose 파일에서 정의:\n\n주의점:\n포트 충돌\n컨테이너 이름 중복\n자동으로 1, 2 등 접미사 추가\n볼륨 공유\n모든 인스턴스가 같은 볼륨 사용 시 충돌 가능\n로드 밸런싱\nCompose 자체는 로드 밸런서 미제공\n별도 nginx, traefik 등 필요\n\n로드 밸런서 예시:",
    "references": [
      {
        "title": "docker-compose up",
        "url": "https://docs.docker.com/reference/cli/docker/compose/up/"
      }
    ],
    "keywords": [
      "compose",
      "스케일링",
      "방법",
      "파일에서",
      "정의",
      "주의점",
      "포트",
      "충돌",
      "컨테이너",
      "이름",
      "중복",
      "자동으로",
      "접미사",
      "추가",
      "볼륨"
    ]
  },
  {
    "id": "DOCKER-051",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker Compose의 네트워크 구성과 서비스 간 통신 방식을 설명해 주세요.",
    "answer": "기본 동작:\nCompose가 프로젝트별 기본 네트워크 자동 생성\n네트워크 이름: {프로젝트명}_default\n모든 서비스가 이 네트워크에 연결\n\n서비스 간 통신:\n\n사용자 정의 네트워크:\n\n네트워크 별칭:\n\n외부 네트워크 사용:",
    "references": [
      {
        "title": "Networking in Compose",
        "url": "https://docs.docker.com/compose/networking/"
      }
    ],
    "keywords": [
      "compose",
      "기본",
      "동작",
      "프로젝트별",
      "네트워크",
      "자동",
      "생성",
      "이름",
      "프로젝트명",
      "모든",
      "서비스가",
      "네트워크에",
      "연결",
      "서비스",
      "통신"
    ]
  },
  {
    "id": "DOCKER-052",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker Compose에서 여러 compose 파일을 오버라이드하여 사용하는 방법을 설명해 주세요.",
    "answer": "기본 오버라이드:\n\n파일 구조 예시:\n\n병합 규칙:\n단일 값: 후순위 파일이 덮어씀\n리스트: 병합됨\n맵: 재귀적으로 병합\n\n환경별 사용:",
    "references": [
      {
        "title": "Share Compose configurations",
        "url": "https://docs.docker.com/compose/multiple-compose-files/"
      }
    ],
    "keywords": [
      "기본",
      "오버라이드",
      "파일",
      "구조",
      "예시",
      "병합",
      "규칙",
      "단일",
      "후순위",
      "파일이",
      "덮어씀",
      "리스트",
      "병합됨",
      "재귀적으로",
      "환경별"
    ]
  },
  {
    "id": "DOCKER-053",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker Compose의 healthcheck 설정과 서비스 시작 순서 제어 방법을 설명해 주세요.",
    "answer": "healthcheck 설정:\n\n서비스 시작 순서 제어:\n\n일반적인 healthcheck 예시:",
    "references": [
      {
        "title": "healthcheck",
        "url": "https://docs.docker.com/compose/compose-file/05-services/#healthcheck"
      }
    ],
    "keywords": [
      "설정",
      "서비스",
      "시작",
      "순서",
      "제어",
      "일반적인",
      "예시"
    ]
  },
  {
    "id": "DOCKER-054",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker Compose에서 볼륨을 공유하는 방법과 volumes_from의 대안을 설명해 주세요.",
    "answer": "Named 볼륨 공유 (권장):\n\n바인드 마운트 공유:\n\nvolumesfrom 대안:\n\nvolumesfrom은 v3에서 제거되었습니다. 대안:\n\n볼륨 드라이버 옵션:",
    "references": [
      {
        "title": "Volumes in Compose",
        "url": "https://docs.docker.com/compose/compose-file/07-volumes/"
      }
    ],
    "keywords": [
      "named",
      "볼륨",
      "공유",
      "권장",
      "바인드",
      "마운트",
      "대안",
      "에서",
      "제거되었습니다",
      "드라이버",
      "옵션"
    ]
  },
  {
    "id": "DOCKER-055",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너의 보안 위험 요소와 이를 완화하는 방법을 설명해 주세요.",
    "answer": "주요 보안 위험:\n\n위험   완화 방법\n\nroot 권한 실행   non-root 사용자 사용\n취약한 이미지   이미지 스캐닝, 신뢰할 수 있는 베이스 이미지\n과도한 권한   capabilities 제한\n민감 정보 노출   secrets 관리, 환경 변수 주의\n컨테이너 탈출   커널 업데이트, seccomp/AppArmor\n\n완화 방법:\nnon-root 실행:\n읽기 전용 파일시스템:\ncapabilities 제한:\n리소스 제한:\n이미지 스캐닝:\n네트워크 분리:",
    "references": [
      {
        "title": "Docker security",
        "url": "https://docs.docker.com/engine/security/"
      }
    ],
    "keywords": [
      "non-root",
      "apparmor",
      "주요",
      "보안",
      "위험",
      "완화",
      "방법",
      "권한",
      "실행",
      "사용자",
      "사용",
      "취약한",
      "이미지",
      "스캐닝",
      "신뢰할"
    ]
  },
  {
    "id": "DOCKER-056",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker에서 루트리스(rootless) 모드란 무엇이며, 어떤 보안상의 이점이 있나요?",
    "answer": "Rootless 모드:\nDocker 데몬과 컨테이너를 root 권한 없이 일반 사용자로 실행하는 모드입니다.\n\n설치 및 실행:\n\n보안 이점:\n데몬 탈취 방지\n데몬 취약점 악용 시에도 root 권한 획득 불가\n컨테이너 탈출 완화\n호스트에서도 일반 사용자 권한만 가짐\nUser Namespace 활용\n컨테이너 내 root = 호스트 일반 사용자\n다중 사용자 환경\n각 사용자가 독립된 Docker 인스턴스 운영\n\n제한사항:\ncgroups v2 필요\n일부 네트워크 기능 제한\n1024 미만 포트 바인딩 제한\noverlay 스토리지 드라이버 제한 (일부 환경)\n\nvs 일반 모드:\n구분   일반 모드   Rootless\n\n데몬 권한   root   사용자\n보안   낮음   높음\n기능   완전   일부 제한",
    "references": [
      {
        "title": "Rootless mode",
        "url": "https://docs.docker.com/engine/security/rootless/"
      }
    ],
    "keywords": [
      "rootless",
      "docker",
      "user",
      "namespace",
      "모드",
      "데몬과",
      "컨테이너를",
      "권한",
      "없이",
      "일반",
      "사용자로",
      "실행하는",
      "모드입니다",
      "설치",
      "실행"
    ]
  },
  {
    "id": "DOCKER-057",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너를 non-root 사용자로 실행해야 하는 이유를 설명해 주세요.",
    "answer": "이유:\n최소 권한 원칙\n필요한 최소한의 권한만 부여\n공격 표면 감소\n컨테이너 탈출 시 피해 최소화\n취약점으로 탈출해도 일반 사용자 권한만 가짐\n호스트 시스템 보호\n파일 권한 보호\n마운트된 볼륨의 파일 변조 방지\n호스트 파일 시스템 보호\n규정 준수\nPCI-DSS, SOC2 등 보안 정책 요구사항\n\n구현 방법:\n\n실행 시 지정:\n\n주의점:\n일부 작업은 root 필요 (패키지 설치 등)\n빌드 시 root로 작업, 런타임에 non-root\n포트 1024 미만 바인딩 시 capabilities 설정 필요",
    "references": [
      {
        "title": "USER instruction",
        "url": "https://docs.docker.com/reference/dockerfile/#user"
      }
    ],
    "keywords": [
      "pci-dss",
      "soc2",
      "non-root",
      "이유",
      "최소",
      "권한",
      "원칙",
      "필요한",
      "최소한의",
      "권한만",
      "부여",
      "공격",
      "표면",
      "감소",
      "컨테이너"
    ]
  },
  {
    "id": "DOCKER-058",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker secrets를 사용하여 민감한 정보를 관리하는 방법을 설명해 주세요.",
    "answer": "Docker Secrets (Swarm):\n\n컨테이너 내 접근:\n\nDocker Compose (개발용):\n\n환경 변수 vs Secrets:\n구분   환경 변수   Secrets\n\n저장   메모리   tmpfs 파일\n암호화   X   O (전송/저장 시)\n노출 위험   docker inspect로 노출   미노출\n용도   일반 설정   민감 정보\n\nBest Practice:\nFILE 접미사 패턴 사용\n환경 변수에 직접 비밀번호 넣지 않기",
    "references": [
      {
        "title": "Manage sensitive data",
        "url": "https://docs.docker.com/engine/swarm/secrets/"
      }
    ],
    "keywords": [
      "docker",
      "secrets",
      "swarm",
      "compose",
      "best",
      "practice",
      "file",
      "컨테이너",
      "접근",
      "개발용",
      "환경",
      "변수",
      "구분",
      "저장",
      "메모리"
    ]
  },
  {
    "id": "DOCKER-059",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 이미지 취약점 스캐닝의 중요성과 사용 가능한 도구들을 설명해 주세요.",
    "answer": "중요성:\n알려진 CVE 취약점 조기 발견\n공급망 보안 강화\n규정 준수 (PCI-DSS, HIPAA 등)\n프로덕션 배포 전 보안 검증\n\n주요 스캐닝 도구:\n\n도구   특징\n\nDocker Scout   Docker 공식, Docker Hub 통합\nTrivy   오픈소스, 빠름, 포괄적\nSnyk   개발자 친화적, CI/CD 통합\nClair   오픈소스, 레지스트리 통합\nAnchore   정책 기반 스캐닝\n\n사용 예시:\n\nCI/CD 통합 (GitHub Actions):",
    "references": [
      {
        "title": "Docker Scout",
        "url": "https://docs.docker.com/scout/"
      }
    ],
    "keywords": [
      "cve",
      "pci-dss",
      "hipaa",
      "docker",
      "scout",
      "hub",
      "trivy",
      "snyk",
      "clair",
      "anchore",
      "github",
      "actions",
      "중요성",
      "알려진",
      "취약점"
    ]
  },
  {
    "id": "DOCKER-060",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker의 seccomp, AppArmor, SELinux 프로필의 역할과 설정 방법을 설명해 주세요.",
    "answer": "seccomp (Secure Computing Mode):\n시스템 콜 필터링\n컨테이너가 사용할 수 있는 syscall 제한\n\nAppArmor:\nMAC (Mandatory Access Control)\n파일, 네트워크, 프로세스 접근 제어\nUbuntu/Debian 기본\n\nSELinux:\nMAC 시스템\nRHEL/CentOS/Fedora 기본\n\n비교:\n구분   seccomp   AppArmor   SELinux\n\n대상   syscall   파일/네트워크   전체\n복잡도   중간   낮음   높음\n배포판   전체   Debian계열   RHEL계열",
    "references": [
      {
        "title": "Seccomp security profiles",
        "url": "https://docs.docker.com/engine/security/seccomp/"
      }
    ],
    "keywords": [
      "secure",
      "computing",
      "mode",
      "apparmor",
      "mac",
      "mandatory",
      "access",
      "control",
      "ubuntu",
      "debian",
      "selinux",
      "rhel",
      "centos",
      "fedora",
      "시스템"
    ]
  },
  {
    "id": "DOCKER-061",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너에서 capabilities를 제한하는 방법과 이유를 설명해 주세요.",
    "answer": "Linux Capabilities:\nroot 권한을 세분화한 권한 단위입니다. 전체 root 권한 대신 필요한 capability만 부여할 수 있습니다.\n\n제한하는 이유:\n최소 권한 원칙 적용\n컨테이너 탈출 시 피해 최소화\n불필요한 시스템 접근 차단\n\n기본 capabilities (Docker):\nCHOWN, DACOVERRIDE, FSETID, FOWNER, MKNOD, NETRAW, SETGID, SETUID, SETFCAP, SETPCAP, NETBINDSERVICE, SYSCHROOT, KILL, AUDITWRITE\n\n설정 방법:\n\n주요 capabilities:\nCapability   설명\n\nNETBINDSERVICE   1024 미만 포트 바인딩\nSYSADMIN   다양한 관리 작업 (위험)\nNETADMIN   네트워크 설정 변경\nSYSPTRACE   프로세스 디버깅\n\n권장 설정:",
    "references": [
      {
        "title": "Runtime privilege and capabilities",
        "url": "https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities"
      }
    ],
    "keywords": [
      "linux",
      "capabilities",
      "docker",
      "chown",
      "dacoverride",
      "fsetid",
      "fowner",
      "mknod",
      "netraw",
      "setgid",
      "setuid",
      "setfcap",
      "setpcap",
      "netbindservice",
      "syschroot"
    ]
  },
  {
    "id": "DOCKER-062",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "신뢰할 수 있는 base 이미지를 선택하고 관리하는 방법을 설명해 주세요.",
    "answer": "신뢰할 수 있는 이미지 선택:\n공식 이미지 사용\nVerified Publisher 확인\nDocker Hub에서 인증 마크 확인\n이미지 다이제스트로 고정\n\n이미지 관리 방법:\n정기적인 업데이트\n취약점 스캐닝\n베이스 이미지 추적\n내부 레지스트리 미러링\n외부 이미지를 내부 레지스트리로 복제\n버전 관리 및 스캔 후 사용\nGolden Image 정책\n승인된 베이스 이미지 목록 관리\nCI에서 허용 이미지만 빌드 가능",
    "references": [
      {
        "title": "Docker Official Images",
        "url": "https://docs.docker.com/trusted-content/official-images/"
      }
    ],
    "keywords": [
      "verified",
      "publisher",
      "docker",
      "hub",
      "golden",
      "image",
      "신뢰할",
      "있는",
      "이미지",
      "선택",
      "공식",
      "사용",
      "확인",
      "에서",
      "인증"
    ]
  },
  {
    "id": "DOCKER-063",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너의 CPU 사용량을 제한하는 방법과 옵션들을 설명해 주세요.",
    "answer": "CPU 제한 옵션:\n\n옵션   설명   예시\n\n--cpus   사용할 CPU 개수   --cpus=1.5\n--cpu-shares   상대적 가중치 (1024 기준)   --cpu-shares=512\n--cpu-period   CFS 주기 (마이크로초)   --cpu-period=100000\n--cpu-quota   CFS 할당량 (마이크로초)   --cpu-quota=50000\n--cpuset-cpus   특정 CPU 코어 지정   --cpuset-cpus=0,1\n\n사용 예시:\n\nDocker Compose:\n\n--cpus vs --cpu-shares:\n--cpus: 절대적 제한 (항상 적용)\n--cpu-shares: 상대적 (CPU 경쟁 시에만)",
    "references": [
      {
        "title": "Runtime options with Memory, CPUs",
        "url": "https://docs.docker.com/config/containers/resource_constraints/"
      }
    ],
    "keywords": [
      "cpu",
      "cpu-shares",
      "cpu-period",
      "cfs",
      "cpu-quota",
      "cpuset-cpus",
      "docker",
      "compose",
      "제한",
      "옵션",
      "설명",
      "예시",
      "사용할",
      "개수",
      "상대적"
    ]
  },
  {
    "id": "DOCKER-064",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너의 메모리 사용량을 제한하는 방법과 OOM(Out of Memory) 처리 방식을 설명해 주세요.",
    "answer": "메모리 제한 옵션:\n\n옵션   설명\n\n--memory (-m)   메모리 제한\n--memory-swap   메모리 + 스왑 합계\n--memory-reservation   소프트 제한 (보장 메모리)\n--oom-kill-disable   OOM Killer 비활성화\n--oom-score-adj   OOM 우선순위 조정\n\n사용 예시:\n\nOOM 처리:\n\nDocker Compose:\n\nOOM 발생 시:\n기본: 컨테이너 프로세스 종료\n--oom-kill-disable: 시스템이 멈출 수 있음 (위험)",
    "references": [
      {
        "title": "Memory constraints",
        "url": "https://docs.docker.com/config/containers/resource_constraints/#memory"
      }
    ],
    "keywords": [
      "memory-swap",
      "memory-reservation",
      "oom-kill",
      "oom",
      "killer",
      "oom-score",
      "docker",
      "compose",
      "메모리",
      "제한",
      "옵션",
      "설명",
      "스왑",
      "합계",
      "소프트"
    ]
  },
  {
    "id": "DOCKER-065",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "cgroups란 무엇이며, Docker에서 리소스 제한에 어떻게 활용되나요?",
    "answer": "cgroups (Control Groups):\nLinux 커널 기능으로, 프로세스 그룹에 대한 리소스(CPU, 메모리, I/O 등) 사용량을 제한, 계정, 격리합니다.\n\ncgroups 기능:\n리소스 제한 (Resource Limiting)\n그룹이 사용할 수 있는 리소스 상한 설정\n우선순위 (Prioritization)\n리소스 경쟁 시 우선순위 설정\n계정 (Accounting)\n리소스 사용량 측정 및 보고\n제어 (Control)\n그룹 프로세스 동결, 재개, 체크포인트\n\nDocker에서의 활용:\n\ncgroups v1 vs v2:\n구분   v1   v2\n\n구조   계층별 분리   통합 계층\n관리   복잡   단순\n지원   레거시   현재 권장\n\nDocker 리소스 매핑:\n--memory → memory.max\n--cpus → cpu.max\n--pids-limit → pids.max",
    "references": [
      {
        "title": "Configure cgroups",
        "url": "https://docs.docker.com/config/containers/resource_constraints/"
      }
    ],
    "keywords": [
      "control",
      "groups",
      "linux",
      "cpu",
      "resource",
      "limiting",
      "prioritization",
      "accounting",
      "docker",
      "pids-limit",
      "커널",
      "기능으로",
      "프로세스",
      "그룹에",
      "대한"
    ]
  },
  {
    "id": "DOCKER-066",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너의 I/O 성능을 제한하는 방법을 설명해 주세요.",
    "answer": "I/O 제한 옵션:\n\n옵션   설명\n\n--blkio-weight   상대적 I/O 가중치 (10-1000)\n--device-read-bps   디바이스 읽기 속도 제한\n--device-write-bps   디바이스 쓰기 속도 제한\n--device-read-iops   초당 읽기 작업 수 제한\n--device-write-iops   초당 쓰기 작업 수 제한\n\n사용 예시:\n\nDocker Compose (제한적 지원):\n\n주의사항:\n블록 디바이스 경로 필요\nDirect I/O에만 적용 (버퍼링된 I/O는 제외)\ncgroups v1/v2 지원 차이\n\n확인:",
    "references": [
      {
        "title": "Block IO constraints",
        "url": "https://docs.docker.com/config/containers/resource_constraints/#block-io-bandwidth-blkio-constraint"
      }
    ],
    "keywords": [
      "blkio-weight",
      "device-read",
      "device-write",
      "docker",
      "compose",
      "direct",
      "제한",
      "옵션",
      "설명",
      "상대적",
      "가중치",
      "디바이스",
      "읽기",
      "속도",
      "쓰기"
    ]
  },
  {
    "id": "DOCKER-067",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너의 PID 제한과 fork bomb 방지 방법을 설명해 주세요.",
    "answer": "Fork Bomb이란:\n무한히 프로세스를 생성하여 시스템 리소스를 고갈시키는 공격입니다.\n\nPID 제한 설정:\n\nDocker Compose:\n\n데몬 수준 기본값 설정:\n\n확인:\n\n권장사항:\n프로덕션 환경에서 항상 설정\n애플리케이션 특성에 맞게 값 조정\n너무 낮으면 정상 동작 방해\n\n다른 보호 수단:\nulimit 설정: docker run --ulimit nproc=100\nseccomp 프로필로 fork 제한",
    "references": [
      {
        "title": "Runtime options",
        "url": "https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources"
      }
    ],
    "keywords": [
      "fork",
      "bomb",
      "pid",
      "docker",
      "compose",
      "이란",
      "무한히",
      "프로세스를",
      "생성하여",
      "시스템",
      "리소스를",
      "고갈시키는",
      "공격입니다",
      "제한",
      "설정"
    ]
  },
  {
    "id": "DOCKER-068",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 리소스 사용량을 실시간으로 모니터링하는 방법(docker stats)을 설명해 주세요.",
    "answer": "docker stats 기본 사용:\n\n출력 정보:\n항목   설명\n\nCPU %   CPU 사용률\nMEM USAGE/LIMIT   메모리 사용량/제한\nMEM %   메모리 사용률\nNET I/O   네트워크 입출력\nBLOCK I/O   디스크 입출력\nPIDS   프로세스 수\n\n포맷 지정:\n\n주요 포맷 키:\n.Container, .Name, .ID\n.CPUPerc, .MemUsage, .MemPerc\n.NetIO, .BlockIO, .PIDs\n\n활용 예시:",
    "references": [
      {
        "title": "docker stats",
        "url": "https://docs.docker.com/reference/cli/docker/container/stats/"
      }
    ],
    "keywords": [
      "cpu",
      "mem",
      "usage",
      "limit",
      "net",
      "block",
      "pids",
      "container",
      "name",
      "cpuperc",
      "memusage",
      "memperc",
      "netio",
      "blockio",
      "기본"
    ]
  },
  {
    "id": "DOCKER-069",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker의 로깅 드라이버 종류와 각각의 특징을 설명해 주세요.",
    "answer": "주요 로깅 드라이버:\n\n드라이버   설명   특징\n\njson-file   JSON 파일 저장 (기본값)   docker logs 지원\nlocal   최적화된 로컬 저장   압축, 로테이션 지원\nsyslog   Syslog 서버 전송   중앙집중식 로깅\njournald   systemd journal   systemd 통합\nfluentd   Fluentd 전송   유연한 로그 라우팅\nawslogs   AWS CloudWatch   AWS 통합\ngcplogs   Google Cloud Logging   GCP 통합\nsplunk   Splunk 전송   엔터프라이즈 로깅\nnone   로깅 비활성화   성능 최적화\n\n설정 방법:\n\nDocker Compose:",
    "references": [
      {
        "title": "Configure logging drivers",
        "url": "https://docs.docker.com/config/containers/logging/configure/"
      }
    ],
    "keywords": [
      "json-file",
      "json",
      "syslog",
      "fluentd",
      "aws",
      "cloudwatch",
      "google",
      "cloud",
      "logging",
      "gcp",
      "splunk",
      "docker",
      "compose",
      "주요",
      "로깅"
    ]
  },
  {
    "id": "DOCKER-070",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너 로그를 확인하고 관리하는 방법(docker logs)을 설명해 주세요.",
    "answer": "기본 사용:\n\n옵션 조합:\n\nDocker Compose:\n\n로그 위치 (json-file 드라이버):\n\n주의사항:\n일부 로깅 드라이버(fluentd, awslogs 등)는 docker logs 미지원\n로그 크기 관리 필요 (로테이션 설정)",
    "references": [
      {
        "title": "docker logs",
        "url": "https://docs.docker.com/reference/cli/docker/container/logs/"
      }
    ],
    "keywords": [
      "docker",
      "compose",
      "json-file",
      "기본",
      "사용",
      "옵션",
      "조합",
      "로그",
      "위치",
      "드라이버",
      "주의사항",
      "일부",
      "로깅",
      "미지원",
      "크기"
    ]
  },
  {
    "id": "DOCKER-071",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 로그 로테이션을 설정하는 방법과 중요성을 설명해 주세요.",
    "answer": "중요성:\n디스크 공간 고갈 방지\n로그 파일 관리 용이\n시스템 안정성 유지\n성능 저하 방지 (대용량 로그 파일)\n\n설정 방법:\n컨테이너별 설정:\n데몬 기본값 설정:\nDocker Compose:\n\n옵션 설명:\n옵션   설명   예시\n\nmax-size   로그 파일 최대 크기   10m, 1g\nmax-file   보관할 로그 파일 수   3, 5\ncompress   gzip 압축   true\n\nlocal 드라이버 (권장):",
    "references": [
      {
        "title": "JSON File logging driver",
        "url": "https://docs.docker.com/config/containers/logging/json-file/"
      }
    ],
    "keywords": [
      "docker",
      "compose",
      "max-size",
      "max-file",
      "중요성",
      "디스크",
      "공간",
      "고갈",
      "방지",
      "로그",
      "파일",
      "관리",
      "용이",
      "시스템",
      "안정성"
    ]
  },
  {
    "id": "DOCKER-072",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너의 메트릭을 수집하고 모니터링하는 방법을 설명해 주세요.",
    "answer": "내장 도구:\n\nDocker API:\n\ncAdvisor:\n\nPrometheus + Grafana 스택:\n\n수집 가능한 메트릭:\nCPU 사용량, 메모리 사용량\n네트워크 I/O, 디스크 I/O\n컨테이너 수, 프로세스 수",
    "references": [
      {
        "title": "Collect Docker metrics with Prometheus",
        "url": "https://docs.docker.com/config/daemon/prometheus/"
      }
    ],
    "keywords": [
      "docker",
      "api",
      "prometheus",
      "grafana",
      "cpu",
      "내장",
      "도구",
      "스택",
      "수집",
      "가능한",
      "메트릭",
      "사용량",
      "메모리",
      "네트워크",
      "디스크"
    ]
  },
  {
    "id": "DOCKER-073",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 이벤트를 모니터링하는 방법(docker events)과 활용 사례를 설명해 주세요.",
    "answer": "기본 사용:\n\n필터링:\n\n포맷:\n\n주요 이벤트:\ncontainer: create, start, stop, die, kill, pause, unpause\nimage: pull, push, delete, tag\nnetwork: create, connect, disconnect, destroy\n\n활용 사례:\n자동 복구: die 이벤트 감지 후 알림/재시작\n감사 로그: 컨테이너 생성/삭제 기록\n모니터링 연동: 이벤트 기반 알림\nCI/CD: 배포 상태 추적",
    "references": [
      {
        "title": "docker events",
        "url": "https://docs.docker.com/reference/cli/docker/system/events/"
      }
    ],
    "keywords": [
      "기본",
      "사용",
      "필터링",
      "포맷",
      "주요",
      "이벤트",
      "활용",
      "사례",
      "자동",
      "복구",
      "감지",
      "알림",
      "재시작",
      "감사",
      "로그"
    ]
  },
  {
    "id": "DOCKER-074",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Prometheus와 Grafana를 사용하여 Docker 컨테이너를 모니터링하는 방법을 설명해 주세요.",
    "answer": "아키텍처:\nDocker 데몬 메트릭 활성화:\ndocker-compose.yml:\nprometheus.yml:\nGrafana 설정:\nData Source: Prometheus 추가\nDashboard: Docker 대시보드 임포트 (ID: 893, 11600)\n\n주요 메트릭:\ncontainercpuusagesecondstotal\ncontainermemoryusagebytes\ncontainernetworkreceivebytestotal",
    "references": [
      {
        "title": "Docker metrics with Prometheus",
        "url": "https://docs.docker.com/config/daemon/prometheus/"
      }
    ],
    "keywords": [
      "docker",
      "docker-compose",
      "grafana",
      "data",
      "source",
      "prometheus",
      "dashboard",
      "아키텍처",
      "데몬",
      "메트릭",
      "활성화",
      "설정",
      "추가",
      "대시보드",
      "임포트"
    ]
  },
  {
    "id": "DOCKER-075",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너가 시작되지 않을 때 디버깅하는 방법을 설명해 주세요.",
    "answer": "로그 확인:\n컨테이너 상태 확인:\n종료 코드 분석:\n코드   의미\n\n0   정상 종료\n1   애플리케이션 오류\n137   OOM Killer (128+9)\n139   세그멘테이션 폴트\n143   SIGTERM으로 종료\n인터랙티브 모드로 디버깅:\n이미지 검사:\n리소스 확인:\n이벤트 확인:\n\n일반적인 원인:\n잘못된 CMD/ENTRYPOINT\n필요한 파일/환경 변수 누락\n포트 충돌\n리소스 부족\n권한 문제",
    "references": [
      {
        "title": "Docker troubleshoot",
        "url": "https://docs.docker.com/config/daemon/troubleshoot/"
      }
    ],
    "keywords": [
      "oom",
      "killer",
      "sigterm",
      "cmd",
      "entrypoint",
      "로그",
      "확인",
      "컨테이너",
      "상태",
      "종료",
      "코드",
      "분석",
      "의미",
      "정상",
      "애플리케이션"
    ]
  },
  {
    "id": "DOCKER-076",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "실행 중인 Docker 컨테이너에 접속하여 디버깅하는 방법(docker exec)을 설명해 주세요.",
    "answer": "기본 사용:\n\n주요 옵션:\n옵션   설명\n\n-i   표준 입력 유지\n-t   TTY 할당\n-u   사용자 지정\n-w   작업 디렉토리\n-e   환경 변수\n\n디버깅 명령어 예시:\n\nroot로 접속:\n\n디버깅 도구 설치 (임시):\n\n주의: 프로덕션 컨테이너는 최소한의 도구만 포함하므로 디버깅 도구가 없을 수 있음",
    "references": [
      {
        "title": "docker exec",
        "url": "https://docs.docker.com/reference/cli/docker/container/exec/"
      }
    ],
    "keywords": [
      "tty",
      "기본",
      "사용",
      "주요",
      "옵션",
      "설명",
      "표준",
      "입력",
      "유지",
      "할당",
      "사용자",
      "지정",
      "작업",
      "디렉토리",
      "환경"
    ]
  },
  {
    "id": "DOCKER-077",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너의 파일 시스템 변경 사항을 확인하는 방법(docker diff)을 설명해 주세요.",
    "answer": "docker diff:\n컨테이너 시작 이후 파일 시스템에서 변경된 파일과 디렉토리를 표시합니다.\n\n사용법:\n\n출력 표시:\n기호   의미\n\nA   추가됨 (Added)\nC   변경됨 (Changed)\nD   삭제됨 (Deleted)\n\n출력 예시:\n\n활용 사례:\n디버깅:\n애플리케이션이 예상치 못한 파일 생성/수정 확인\n보안 감사:\n컨테이너 내 파일 변조 감지\n이미지 최적화:\n불필요한 파일 생성 확인 후 Dockerfile 개선\n커밋 전 확인:\n\n주의사항:\n실행 중이거나 정지된 컨테이너에서 사용 가능\n볼륨 마운트된 경로는 표시되지 않음",
    "references": [
      {
        "title": "docker diff",
        "url": "https://docs.docker.com/reference/cli/docker/container/diff/"
      }
    ],
    "keywords": [
      "added",
      "changed",
      "deleted",
      "dockerfile",
      "컨테이너",
      "시작",
      "이후",
      "파일",
      "시스템에서",
      "변경된",
      "파일과",
      "디렉토리를",
      "표시합니다",
      "사용법",
      "출력"
    ]
  },
  {
    "id": "DOCKER-078",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너와 호스트 간 파일을 복사하는 방법(docker cp)을 설명해 주세요.",
    "answer": "기본 문법:\n\n사용 예시:\n\n옵션:\n옵션   설명\n\n-a, --archive   모든 uid/gid 정보 보존\n-L, --follow-link   심볼릭 링크 따라가기\n\n활용 사례:\n설정 파일 주입: 실행 중 컨테이너에 설정 업데이트\n로그 추출: 디버깅을 위한 로그 파일 추출\n백업: 컨테이너 데이터 백업\n디버깅: 문제 분석을 위한 파일 추출\n\n주의사항:\n실행 중/정지된 컨테이너 모두 가능\n볼륨에 쓰는 것보다 비효율적 (임시 용도)\n심볼릭 링크 처리 주의",
    "references": [
      {
        "title": "docker cp",
        "url": "https://docs.docker.com/reference/cli/docker/container/cp/"
      }
    ],
    "keywords": [
      "follow-link",
      "기본",
      "문법",
      "사용",
      "예시",
      "옵션",
      "설명",
      "모든",
      "정보",
      "보존",
      "심볼릭",
      "링크",
      "따라가기",
      "활용",
      "사례"
    ]
  },
  {
    "id": "DOCKER-079",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 이미지와 컨테이너를 정리하여 디스크 공간을 확보하는 방법(docker system prune)을 설명해 주세요.",
    "answer": "디스크 사용량 확인:\n\n정리 명령어:\n\n개별 정리:\n\n필터링:\n\n주의사항:\nprune -a는 현재 사용 중이지 않은 모든 이미지 삭제\n볼륨 삭제는 데이터 손실 주의\nCI/CD에서 정기적 실행 권장",
    "references": [
      {
        "title": "docker system prune",
        "url": "https://docs.docker.com/reference/cli/docker/system/prune/"
      }
    ],
    "keywords": [
      "디스크",
      "사용량",
      "확인",
      "정리",
      "명령어",
      "개별",
      "필터링",
      "주의사항",
      "현재",
      "사용",
      "중이지",
      "않은",
      "모든",
      "이미지",
      "삭제"
    ]
  },
  {
    "id": "DOCKER-080",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 네트워크 문제를 진단하고 해결하는 방법을 설명해 주세요.",
    "answer": "진단 도구:\n네트워크 상태 확인:\n컨테이너 네트워크 설정 확인:\n컨테이너 내부에서 진단:\n\n일반적인 문제와 해결:\n\n문제   원인   해결\n\n컨테이너 간 통신 불가   다른 네트워크   같은 네트워크에 연결\nDNS 해석 실패   기본 bridge 사용   사용자 정의 네트워크 사용\n외부 접근 불가   포트 미노출   -p 옵션으로 포트 매핑\n호스트 접근 불가   네트워크 격리   host.docker.internal 사용\n\n디버깅 컨테이너:",
    "references": [
      {
        "title": "Networking overview",
        "url": "https://docs.docker.com/network/"
      }
    ],
    "keywords": [
      "dns",
      "진단",
      "도구",
      "네트워크",
      "상태",
      "확인",
      "컨테이너",
      "설정",
      "내부에서",
      "일반적인",
      "문제와",
      "해결",
      "문제",
      "원인",
      "통신"
    ]
  },
  {
    "id": "DOCKER-081",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너의 재시작 정책(restart policy)과 각 옵션의 차이점을 설명해 주세요.",
    "answer": "재시작 정책 옵션:\n\n정책   설명\n\nno   재시작 안 함 (기본값)\non-failure[:max-retries]   비정상 종료 시 재시작\nalways   항상 재시작 (수동 중지 포함)\nunless-stopped   수동 중지 전까지 재시작\n\n사용법:\n\nDocker Compose:\n\nalways vs unless-stopped:\n\n상황   always   unless-stopped\n\n컨테이너 비정상 종료   재시작   재시작\nDocker 데몬 재시작   재시작   재시작\ndocker stop 후 데몬 재시작   재시작   시작 안 함\n\n실행 중인 컨테이너 정책 변경:",
    "references": [
      {
        "title": "Start containers automatically",
        "url": "https://docs.docker.com/config/containers/start-containers-automatically/"
      }
    ],
    "keywords": [
      "on-failure",
      "max-retries",
      "unless-stopped",
      "docker",
      "compose",
      "재시작",
      "정책",
      "옵션",
      "설명",
      "기본값",
      "비정상",
      "종료",
      "항상",
      "수동",
      "중지"
    ]
  },
  {
    "id": "DOCKER-082",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너가 예기치 않게 종료되었을 때 원인을 분석하는 방법을 설명해 주세요.",
    "answer": "종료 코드 확인:\n\n주요 종료 코드:\n코드   의미\n\n0   정상 종료\n1   애플리케이션 오류\n137   SIGKILL (128+9), OOM 가능성\n139   세그멘테이션 폴트 (128+11)\n143   SIGTERM (128+15)\n로그 확인:\nOOM 확인:\n이벤트 확인:\n상세 상태:\n분석 체크리스트:\n메모리 제한 확인 (--memory)\n리소스 사용량 (docker stats)\n애플리케이션 로그\nhealthcheck 상태\n의존 서비스 상태\n\n자동 재시작 정책 확인:",
    "references": [
      {
        "title": "Troubleshoot containers",
        "url": "https://docs.docker.com/config/containers/runmetrics/"
      }
    ],
    "keywords": [
      "sigkill",
      "oom",
      "sigterm",
      "종료",
      "코드",
      "확인",
      "주요",
      "의미",
      "정상",
      "애플리케이션",
      "오류",
      "가능성",
      "세그멘테이션",
      "폴트",
      "로그"
    ]
  },
  {
    "id": "DOCKER-083",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 이미지 크기를 최소화하기 위한 베스트 프랙티스를 설명해 주세요.",
    "answer": "경량 베이스 이미지 사용:\n멀티스테이지 빌드:\nRUN 명령 최적화:\n.dockerignore 활용:\n불필요한 파일 제거:\n패키지 캐시 삭제\n문서, 맨페이지 제외\n개발 의존성 제외\n특수 빌드 옵션:",
    "references": [
      {
        "title": "Best practices for Dockerfile",
        "url": "https://docs.docker.com/develop/develop-images/dockerfile_best-practices/"
      }
    ],
    "keywords": [
      "run",
      "경량",
      "베이스",
      "이미지",
      "사용",
      "멀티스테이지",
      "빌드",
      "명령",
      "최적화",
      "활용",
      "불필요한",
      "파일",
      "제거",
      "패키지",
      "캐시"
    ]
  },
  {
    "id": "DOCKER-084",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 빌드 시간을 단축하기 위한 캐시 활용 전략을 설명해 주세요.",
    "answer": "캐시 원리:\n각 명령어가 레이어 생성\n명령어와 파일 체크섬이 같으면 캐시 사용\n한 레이어가 변경되면 이후 모든 레이어 재빌드\n의존성 파일 먼저 복사:\n자주 변경되는 것은 마지막에:\nBuildKit 캐시 마운트:\n외부 캐시 (CI/CD):\n멀티스테이지에서 특정 단계만:",
    "references": [
      {
        "title": "Build cache",
        "url": "https://docs.docker.com/build/cache/"
      }
    ],
    "keywords": [
      "buildkit",
      "캐시",
      "원리",
      "명령어가",
      "레이어",
      "생성",
      "명령어와",
      "파일",
      "체크섬이",
      "같으면",
      "사용",
      "레이어가",
      "변경되면",
      "이후",
      "모든"
    ]
  },
  {
    "id": "DOCKER-085",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker의 BuildKit이란 무엇이며, 기존 빌더 대비 어떤 장점이 있나요?",
    "answer": "BuildKit:\nDocker의 차세대 빌드 엔진으로, Docker 23.0+에서 기본값입니다.\n\n활성화:\n\n장점:\n병렬 빌드:\n독립적인 스테이지 동시 빌드\n빌드 시간 단축\n캐시 마운트:\n시크릿 마운트:\nSSH 마운트:\n출력 최적화:\n진행률 표시 개선\n불필요한 레이어 전송 최소화\n외부 캐시:\n\nDockerfile 문법:",
    "references": [
      {
        "title": "Build with BuildKit",
        "url": "https://docs.docker.com/build/buildkit/"
      }
    ],
    "keywords": [
      "buildkit",
      "docker",
      "ssh",
      "dockerfile",
      "차세대",
      "빌드",
      "엔진으로",
      "에서",
      "기본값입니다",
      "활성화",
      "장점",
      "병렬",
      "독립적인",
      "스테이지",
      "동시"
    ]
  },
  {
    "id": "DOCKER-086",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 컨테이너의 시작 시간을 최적화하는 방법을 설명해 주세요.",
    "answer": "이미지 크기 최소화:\n작은 이미지 = 빠른 pull/load\nAlpine, distroless 사용\n멀티스테이지 빌드\n이미지 사전 배포:\n애플리케이션 최적화:\n느린 초기화 피하기:\n무거운 DB 마이그레이션 분리\nLazy loading 활용\n사전 컴파일/빌드\n헬스체크 최적화:\n리소스 할당:\n스토리지 드라이버:\noverlay2 사용 (권장)\n로컬 레지스트리:\n네트워크 지연 감소\n\n측정:",
    "references": [
      {
        "title": "Optimize container startup",
        "url": "https://docs.docker.com/develop/develop-images/dockerfile_best-practices/"
      }
    ],
    "keywords": [
      "alpine",
      "lazy",
      "이미지",
      "크기",
      "최소화",
      "작은",
      "빠른",
      "사용",
      "멀티스테이지",
      "빌드",
      "사전",
      "배포",
      "애플리케이션",
      "최적화",
      "느린"
    ]
  },
  {
    "id": "DOCKER-087",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 레이어 최적화를 통해 이미지 풀/푸시 시간을 단축하는 방법을 설명해 주세요.",
    "answer": "레이어 공유 원리:\n동일한 레이어는 한 번만 전송\n베이스 이미지 공유 시 효율적\n일관된 베이스 이미지:\n변경 빈도별 레이어 분리:\n불필요한 레이어 방지:\n레이어 크기 균형:\n너무 큰 레이어: 부분 변경에도 전체 재전송\n너무 작은 레이어: 오버헤드 증가\n캐시 활용:",
    "references": [
      {
        "title": "Optimize layers",
        "url": "https://docs.docker.com/build/cache/"
      }
    ],
    "keywords": [
      "레이어",
      "공유",
      "원리",
      "동일한",
      "레이어는",
      "번만",
      "전송",
      "베이스",
      "이미지",
      "효율적",
      "일관된",
      "변경",
      "빈도별",
      "분리",
      "불필요한"
    ]
  },
  {
    "id": "DOCKER-088",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "distroless 이미지란 무엇이며, 보안과 성능 관점에서의 장점을 설명해 주세요.",
    "answer": "Distroless 이미지란:\nGoogle에서 제공하는 최소한의 런타임만 포함된 이미지입니다. 패키지 관리자, 셸, 기타 프로그램이 없습니다.\n\n사용 가능한 이미지:\ngcr.io/distroless/static - 정적 바이너리용\ngcr.io/distroless/base - libc 필요 시\ngcr.io/distroless/java - Java 애플리케이션\ngcr.io/distroless/nodejs - Node.js 애플리케이션\ngcr.io/distroless/python3 - Python 애플리케이션\n\n사용 예시:\n\n보안 장점:\n셸 없음 → RCE 공격 어려움\n패키지 관리자 없음 → 악성 패키지 설치 불가\n최소 공격 표면\nCVE 취약점 감소\n\n성능 장점:\n이미지 크기 최소화 (2-20MB)\n빠른 pull/push\n빠른 컨테이너 시작\n\n제한사항:\n디버깅 어려움 (셸 없음)\ndebug 태그 버전으로 busybox 포함 가능",
    "references": [
      {
        "title": "GoogleContainerTools/distroless",
        "url": "https://github.com/GoogleContainerTools/distroless"
      }
    ],
    "keywords": [
      "distroless",
      "google",
      "java",
      "node",
      "python",
      "rce",
      "cve",
      "이미지란",
      "에서",
      "제공하는",
      "최소한의",
      "런타임만",
      "포함된",
      "이미지입니다",
      "패키지"
    ]
  },
  {
    "id": "DOCKER-089",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "CI/CD 파이프라인에서 Docker 이미지를 빌드하고 배포하는 일반적인 워크플로우를 설명해 주세요.",
    "answer": "일반적인 워크플로우:\n\n상세 단계:\n코드 변경 감지:\nGit push, PR 이벤트\n빌드 및 테스트:\nDocker 이미지 빌드:\n보안 스캔:\n레지스트리 푸시:\n배포:\n\n예시 (GitHub Actions):",
    "references": [
      {
        "title": "CI/CD with Docker",
        "url": "https://docs.docker.com/build/ci/"
      }
    ],
    "keywords": [
      "git",
      "docker",
      "github",
      "actions",
      "일반적인",
      "워크플로우",
      "상세",
      "단계",
      "코드",
      "변경",
      "감지",
      "이벤트",
      "빌드",
      "테스트",
      "이미지"
    ]
  },
  {
    "id": "DOCKER-090",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "GitHub Actions에서 Docker 이미지를 빌드하고 레지스트리에 푸시하는 방법을 설명해 주세요.",
    "answer": "GitHub Container Registry (ghcr.io) 사용:\n\nDocker Hub 사용 시:",
    "references": [
      {
        "title": "Build and push Docker images",
        "url": "https://github.com/docker/build-push-action"
      }
    ],
    "keywords": [
      "github",
      "container",
      "registry",
      "docker",
      "hub",
      "사용"
    ]
  },
  {
    "id": "DOCKER-091",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 이미지 태깅 전략(semantic versioning, git commit hash)과 CI/CD에서의 적용 방법을 설명해 주세요.",
    "answer": "주요 태깅 전략:\n\n전략   형식   특징\n\nSemantic Version   v1.2.3   명확한 버전 관리\nGit SHA   abc1234   불변, 추적 가능\nBranch   main, develop   환경별 배포\nBuild Number   build-123   CI/CD 추적\n\nCI/CD에서 적용:\n\n스크립트 예시:\n\n권장 사항:\n프로덕션: Semantic Version + SHA\nlatest는 개발 환경에서만\n이미지 다이제스트로 완전한 불변성",
    "references": [
      {
        "title": "docker/metadata-action",
        "url": "https://github.com/docker/metadata-action"
      }
    ],
    "keywords": [
      "semantic",
      "version",
      "git",
      "sha",
      "branch",
      "build",
      "number",
      "주요",
      "태깅",
      "전략",
      "형식",
      "특징",
      "명확한",
      "버전",
      "관리"
    ]
  },
  {
    "id": "DOCKER-092",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker를 사용한 테스트 환경 구성과 테스트 컨테이너(Testcontainers) 활용 방법을 설명해 주세요.",
    "answer": "Docker Compose로 테스트 환경:\n\nTestcontainers:\n테스트 코드에서 Docker 컨테이너를 프로그래밍 방식으로 관리하는 라이브러리입니다.\n\nJava 예시:\n\nNode.js 예시:\n\n장점:\n실제 서비스로 통합 테스트\n테스트 격리 보장\nCI/CD 환경 동일성",
    "references": [
      {
        "title": "Testcontainers",
        "url": "https://testcontainers.com/"
      }
    ],
    "keywords": [
      "docker",
      "compose",
      "testcontainers",
      "java",
      "node",
      "테스트",
      "환경",
      "코드에서",
      "컨테이너를",
      "프로그래밍",
      "방식으로",
      "관리하는",
      "라이브러리입니다",
      "예시",
      "장점"
    ]
  },
  {
    "id": "DOCKER-093",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker 이미지의 보안 스캔을 CI/CD 파이프라인에 통합하는 방법을 설명해 주세요.",
    "answer": "GitHub Actions - Trivy:\n\nDocker Scout:\n\nSnyk:\n\n통합 워크플로우:",
    "references": [
      {
        "title": "Docker Scout in CI",
        "url": "https://docs.docker.com/scout/integrations/ci/"
      }
    ],
    "keywords": [
      "github",
      "actions",
      "trivy",
      "docker",
      "scout",
      "snyk",
      "통합",
      "워크플로우"
    ]
  },
  {
    "id": "DOCKER-094",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker layer caching을 CI/CD 환경에서 활용하여 빌드 시간을 단축하는 방법을 설명해 주세요.",
    "answer": "문제:\nCI/CD 환경은 매번 새로운 러너에서 실행되어 로컬 캐시가 없습니다.\n\n해결 방법:\nGitHub Actions Cache:\n레지스트리 캐시:\n인라인 캐시:\n로컬 캐시 (self-hosted runner):\n\n캐시 모드:\nmin: 최종 이미지 레이어만\nmax: 모든 중간 레이어 포함 (권장)",
    "references": [
      {
        "title": "Cache backends",
        "url": "https://docs.docker.com/build/cache/backends/"
      }
    ],
    "keywords": [
      "github",
      "actions",
      "cache",
      "self-hosted",
      "문제",
      "환경은",
      "매번",
      "새로운",
      "러너에서",
      "실행되어",
      "로컬",
      "캐시가",
      "없습니다",
      "해결",
      "방법"
    ]
  },
  {
    "id": "DOCKER-095",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Blue-Green 또는 Rolling 배포 전략에서 Docker의 역할을 설명해 주세요.",
    "answer": "Blue-Green 배포:\n두 개의 동일한 환경을 유지하고 트래픽을 전환합니다.\n\nRolling 배포:\n인스턴스를 순차적으로 업데이트합니다.\n\nDocker의 역할:\n이미지 불변성: 버전별 독립적 이미지\n빠른 롤백: 이전 이미지로 즉시 전환\n환경 일관성: 테스트된 이미지 그대로 배포\n컨테이너 오케스트레이션: Swarm/K8s와 연동\n헬스체크: 배포 성공 여부 확인\n\n롤백:",
    "references": [
      {
        "title": "Deploy services",
        "url": "https://docs.docker.com/engine/swarm/services/"
      }
    ],
    "keywords": [
      "blue-green",
      "rolling",
      "docker",
      "swarm",
      "k8s",
      "배포",
      "개의",
      "동일한",
      "환경을",
      "유지하고",
      "트래픽을",
      "전환합니다",
      "인스턴스를",
      "순차적으로",
      "업데이트합니다"
    ]
  },
  {
    "id": "DOCKER-096",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker와 Kubernetes의 관계와 각각의 역할을 설명해 주세요.",
    "answer": "Docker의 역할:\n컨테이너 이미지 빌드\n단일 호스트에서 컨테이너 실행\n컨테이너 런타임 제공\n이미지 레지스트리 (Docker Hub)\n\nKubernetes의 역할:\n컨테이너 오케스트레이션\n멀티 노드 클러스터 관리\n자동 스케일링, 로드 밸런싱\n서비스 디스커버리\n롤링 업데이트, 롤백\n셀프 힐링\n\n관계:\n\n구분   Docker   Kubernetes\n\n범위   단일 호스트   클러스터\n초점   컨테이너 생성   컨테이너 관리\n스케일   수동   자동\n고가용성   제한적   내장\n\n현재 상태:\nKubernetes는 containerd, CRI-O 등 다양한 런타임 지원\nKubernetes 1.24부터 Docker 직접 지원 제거 (dockershim 제거)\n그러나 Docker로 빌드한 이미지는 여전히 K8s에서 실행 가능 (OCI 표준)\n\n요약:\nDocker = 컨테이너 빌드/실행 도구\nKubernetes = 컨테이너 오케스트레이션 플랫폼",
    "references": [
      {
        "title": "Kubernetes Overview",
        "url": "https://kubernetes.io/docs/concepts/overview/"
      }
    ],
    "keywords": [
      "docker",
      "hub",
      "kubernetes",
      "cri-o",
      "k8s",
      "oci",
      "역할",
      "컨테이너",
      "이미지",
      "빌드",
      "단일",
      "호스트에서",
      "실행",
      "런타임",
      "제공"
    ]
  },
  {
    "id": "DOCKER-097",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker Swarm과 Kubernetes의 차이점과 각각의 사용 시나리오를 설명해 주세요.",
    "answer": "비교:\n\n구분   Docker Swarm   Kubernetes\n\n복잡도   낮음   높음\n학습 곡선   완만   가파름\n설치   Docker 내장   별도 설치 필요\n확장성   중소 규모   대규모\n기능   기본적   풍부함\n생태계   제한적   매우 활발\n자동 스케일링   제한적   강력 (HPA, VPA)\n로드 밸런싱   내장   내장 + Ingress\n\nDocker Swarm 사용 시나리오:\n소규모 클러스터 (5-10 노드)\n빠른 구축 필요\nDocker 생태계에 익숙한 팀\n복잡한 기능 불필요\n리소스 제한 환경\n\nKubernetes 사용 시나리오:\n대규모 클러스터\n복잡한 마이크로서비스\n자동 스케일링 필수\n멀티 클라우드/하이브리드\n풍부한 에코시스템 활용\n\n예시:\n\n결론:\n단순함과 빠른 시작: Swarm\n확장성과 기능: Kubernetes",
    "references": [
      {
        "title": "Docker Swarm overview",
        "url": "https://docs.docker.com/engine/swarm/"
      }
    ],
    "keywords": [
      "docker",
      "swarm",
      "kubernetes",
      "hpa",
      "vpa",
      "ingress",
      "비교",
      "구분",
      "복잡도",
      "낮음",
      "높음",
      "학습",
      "곡선",
      "완만",
      "가파름"
    ]
  },
  {
    "id": "DOCKER-098",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker in Docker(DinD)란 무엇이며, 사용 시 고려사항을 설명해 주세요.",
    "answer": "Docker in Docker (DinD):\nDocker 컨테이너 내부에서 Docker 데몬을 실행하여 컨테이너 안에서 컨테이너를 빌드/실행하는 방식입니다.\n\n사용 방법:\n\nDinD vs DooD:\n구분   DinD   DooD (Docker outside of Docker)\n\n방식   컨테이너 내 Docker 데몬   호스트 Docker 소켓 마운트\n격리   완전 격리   호스트와 공유\n성능   오버헤드 있음   네이티브\n보안   --privileged 필요   소켓 접근 권한만\n\n사용 시나리오:\nCI/CD 파이프라인에서 Docker 이미지 빌드\n개발/테스트 환경\n\n고려사항:\n보안 위험:\n--privileged 플래그는 호스트 전체 접근 권한 부여\n프로덕션에서는 피해야 함\n스토리지 드라이버:\nDinD 내부 overlay와 외부 overlay 충돌 가능\nvfs 드라이버 사용 권장 (느림)\n캐시 공유:\nDinD는 매번 새로운 캐시\n볼륨으로 캐시 공유 필요\n\n권장:\n가능하면 DooD 또는 Kaniko 사용\nCI/CD: Kaniko, Buildah 등 대안 고려",
    "references": [
      {
        "title": "Docker in Docker",
        "url": "https://hub.docker.com/_/docker"
      }
    ],
    "keywords": [
      "docker",
      "dind",
      "dood",
      "kaniko",
      "buildah",
      "컨테이너",
      "내부에서",
      "데몬을",
      "실행하여",
      "안에서",
      "컨테이너를",
      "빌드",
      "실행하는",
      "방식입니다",
      "사용"
    ]
  },
  {
    "id": "DOCKER-099",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "Docker의 storage driver 종류(overlay2, aufs, btrfs 등)와 선택 기준을 설명해 주세요.",
    "answer": "주요 Storage Driver:\n\n드라이버   특징   권장 환경\n\noverlay2   현재 기본값, 안정적   대부분의 Linux\nfuse-overlayfs   Rootless 모드용   Rootless Docker\nbtrfs   CoW 파일 시스템   btrfs 파티션\nzfs   스냅샷, 압축 지원   zfs 파티션\nvfs   간단, 비효율적   테스트, 다른 드라이버 불가 시\naufs   레거시   Ubuntu 이전 버전\ndevicemapper   레거시   CentOS/RHEL 이전 버전\n\noverlay2 (권장):\n\n선택 기준:\n커널 버전: overlay2는 4.0+ 필요\n파일 시스템: backing filesystem 호환성\n워크로드: 쓰기 집약적 → 직접 마운트 볼륨 권장\nRootless: fuse-overlayfs 필요\n\n확인 및 변경:",
    "references": [
      {
        "title": "Docker storage drivers",
        "url": "https://docs.docker.com/storage/storagedriver/select-storage-driver/"
      }
    ],
    "keywords": [
      "storage",
      "driver",
      "linux",
      "fuse-overlayfs",
      "rootless",
      "docker",
      "cow",
      "ubuntu",
      "centos",
      "rhel",
      "주요",
      "드라이버",
      "특징",
      "권장",
      "환경"
    ]
  },
  {
    "id": "DOCKER-100",
    "category": "docker",
    "categoryName": "Docker",
    "priority": "P2",
    "question": "마이크로서비스 아키텍처에서 Docker를 활용할 때의 장점과 주의점을 설명해 주세요.",
    "answer": "장점:\n서비스 독립성:\n각 서비스를 독립적인 컨테이너로 패키징\n서로 다른 기술 스택 사용 가능\n일관된 환경:\n개발, 테스트, 운영 환경 동일\n\"내 컴퓨터에서는 되는데\" 문제 해결\n빠른 배포:\n서비스별 독립 배포\n롤백 용이\n확장성:\n서비스별 수평 확장\n리소스 효율적 사용\n격리:\n서비스 간 영향 최소화\n장애 전파 방지\n\n주의점:\n네트워크 복잡성:\n서비스 간 통신 관리\n서비스 디스커버리 필요\n데이터 관리:\n볼륨 전략 수립\n데이터 일관성\n모니터링:\n분산 로깅 필요\n트레이싱 구현\n보안:\n컨테이너 간 통신 암호화\n이미지 취약점 관리\n오케스트레이션:\n많은 컨테이너 관리를 위해 K8s/Swarm 고려\n\n구조 예시:",
    "references": [
      {
        "title": "Docker and Microservices",
        "url": "https://docs.docker.com/get-started/overview/"
      }
    ],
    "keywords": [
      "k8s",
      "swarm",
      "장점",
      "서비스",
      "독립성",
      "서비스를",
      "독립적인",
      "컨테이너로",
      "패키징",
      "서로",
      "다른",
      "기술",
      "스택",
      "사용",
      "가능"
    ]
  },
  {
    "id": "K8S-001",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Kubernetes의 전체 아키텍처를 설명하고, Control Plane과 Worker Node의 역할 차이를 설명해주세요.",
    "answer": "Control Plane: 클러스터 상태 관리 및 의사결정 담당 (kube-apiserver, etcd, scheduler, controller-manager)\n\nWorker Node: 실제 Pod 실행 담당 (kubelet, kube-proxy, Container Runtime)\n\n핵심 차이: Control Plane은 \"결정\", Worker Node는 \"실행\"",
    "references": [
      {
        "title": "Kubernetes Components",
        "url": "https://kubernetes.io/docs/concepts/overview/components/"
      }
    ],
    "keywords": [
      "control",
      "plane",
      "kube-apiserver",
      "controller-manager",
      "worker",
      "node",
      "pod",
      "kube-proxy",
      "container",
      "runtime",
      "클러스터",
      "상태",
      "관리",
      "의사결정",
      "담당"
    ]
  },
  {
    "id": "K8S-002",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "kube-apiserver의 역할과 동작 방식에 대해 설명해주세요. 다른 컴포넌트들과 어떻게 통신하나요?",
    "answer": "역할: Kubernetes API를 노출하는 Control Plane의 프론트엔드. 모든 컴포넌트 간 통신의 중심점.\n\n동작 방식:\nRESTful API 제공 (kubectl, 다른 컴포넌트 요청 처리)\n인증, 인가, Admission Control 수행\netcd와 직접 통신하는 유일한 컴포넌트\n\n통신 방식: 다른 컴포넌트들은 API Server를 통해서만 상호작용 (Hub-and-Spoke 패턴)",
    "references": [
      {
        "title": "kube-apiserver",
        "url": "https://kubernetes.io/docs/concepts/overview/components/#kube-apiserver"
      }
    ],
    "keywords": [
      "kubernetes",
      "api",
      "control",
      "plane",
      "restful",
      "admission",
      "server",
      "hub-and-spoke",
      "역할",
      "노출하는",
      "프론트엔드",
      "모든",
      "컴포넌트",
      "통신의",
      "중심점"
    ]
  },
  {
    "id": "K8S-003",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "etcd의 역할과 중요성에 대해 설명해주세요. 왜 etcd의 백업이 중요한가요?",
    "answer": "역할: 클러스터의 모든 상태 데이터를 저장하는 분산 키-값 저장소\n\n중요성:\n모든 클러스터 설정, Pod/Service 정보, Secret 등 저장\n고가용성을 위해 Raft 합의 알고리즘 사용\n\n백업이 중요한 이유: etcd 손실 = 클러스터 전체 상태 손실. 재해 복구를 위해 정기적 백업 필수",
    "references": [
      {
        "title": "etcd",
        "url": "https://kubernetes.io/docs/concepts/overview/components/#etcd"
      }
    ],
    "keywords": [
      "pod",
      "service",
      "secret",
      "raft",
      "역할",
      "클러스터의",
      "모든",
      "상태",
      "데이터를",
      "저장하는",
      "분산",
      "저장소",
      "중요성",
      "클러스터",
      "설정"
    ]
  },
  {
    "id": "K8S-004",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "kube-scheduler의 스케줄링 과정을 단계별로 설명해주세요. Filtering과 Scoring 단계는 무엇인가요?",
    "answer": "스케줄링 과정:\nFiltering: Pod 실행 가능한 노드 필터링 (리소스, nodeSelector, taint/toleration 등 확인)\nScoring: 필터링된 노드들에 점수 부여 (리소스 균형, affinity 등 고려)\n최고 점수 노드에 Pod 배정\n\nFiltering: \"실행 가능한가?\" - 불가능한 노드 제외\nScoring: \"어디가 최적인가?\" - 적합도 점수 계산",
    "references": [
      {
        "title": "Kubernetes Scheduler",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/"
      }
    ],
    "keywords": [
      "filtering",
      "pod",
      "scoring",
      "스케줄링",
      "과정",
      "실행",
      "가능한",
      "노드",
      "필터링",
      "리소스",
      "확인",
      "필터링된",
      "노드들에",
      "점수",
      "부여"
    ]
  },
  {
    "id": "K8S-005",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "kube-controller-manager에 포함된 주요 컨트롤러들과 각각의 역할에 대해 설명해주세요.",
    "answer": "주요 컨트롤러:\nNode Controller: 노드 상태 모니터링, 장애 감지\nReplication Controller: ReplicaSet의 Pod 수 유지\nEndpoints Controller: Service와 Pod 연결 관리\nServiceAccount Controller: 네임스페이스별 기본 ServiceAccount 생성\nDeployment Controller: Deployment 상태 관리\n\n모든 컨트롤러는 현재 상태를 원하는 상태로 수렴시키는 제어 루프 실행",
    "references": [
      {
        "title": "kube-controller-manager",
        "url": "https://kubernetes.io/docs/concepts/overview/components/#kube-controller-manager"
      }
    ],
    "keywords": [
      "node",
      "controller",
      "replication",
      "replicaset",
      "pod",
      "endpoints",
      "service",
      "serviceaccount",
      "deployment",
      "주요",
      "컨트롤러",
      "노드",
      "상태",
      "모니터링",
      "장애"
    ]
  },
  {
    "id": "K8S-006",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "cloud-controller-manager의 역할과 클라우드 프로바이더와의 통합 방식에 대해 설명해주세요.",
    "answer": "역할: 클라우드 공급자 전용 로직을 Kubernetes 코어에서 분리하여 관리\n\n주요 컨트롤러:\nNode Controller: 클라우드에서 노드 삭제 시 감지\nRoute Controller: 클라우드 인프라 라우트 설정\nService Controller: LoadBalancer 타입 Service 생성 시 클라우드 로드밸런서 프로비저닝\n\n통합 방식: 각 클라우드 벤더(AWS, GCP, Azure)가 자체 cloud-controller-manager 구현 제공",
    "references": [
      {
        "title": "Cloud Controller Manager",
        "url": "https://kubernetes.io/docs/concepts/overview/components/#cloud-controller-manager"
      }
    ],
    "keywords": [
      "kubernetes",
      "node",
      "controller",
      "route",
      "service",
      "loadbalancer",
      "aws",
      "gcp",
      "azure",
      "cloud-controller",
      "역할",
      "클라우드",
      "공급자",
      "전용",
      "로직을"
    ]
  },
  {
    "id": "K8S-007",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "kubelet의 역할과 동작 방식에 대해 설명해주세요. Pod의 상태를 어떻게 관리하나요?",
    "answer": "역할: 각 노드에서 실행되며 Pod와 컨테이너 실행을 담당하는 에이전트\n\n동작 방식:\nAPI Server로부터 PodSpec 수신\nContainer Runtime을 통해 컨테이너 생성/관리\nPod 상태를 주기적으로 API Server에 보고\n\nPod 상태 관리:\nLiveness/Readiness Probe 실행\n컨테이너 재시작 정책 적용\n리소스 사용량 모니터링",
    "references": [
      {
        "title": "kubelet",
        "url": "https://kubernetes.io/docs/concepts/overview/components/#kubelet"
      }
    ],
    "keywords": [
      "pod",
      "api",
      "server",
      "podspec",
      "container",
      "runtime",
      "liveness",
      "readiness",
      "probe",
      "역할",
      "노드에서",
      "실행되며",
      "컨테이너",
      "실행을",
      "담당하는"
    ]
  },
  {
    "id": "K8S-008",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "kube-proxy의 역할과 iptables/IPVS 모드의 차이점에 대해 설명해주세요.",
    "answer": "역할: 노드의 네트워크 규칙 관리, Service의 가상 IP를 통한 Pod 접근 구현\n\niptables 모드:\n리눅스 iptables 규칙으로 트래픽 라우팅\n랜덤 방식 로드밸런싱\n규칙이 많아지면 성능 저하\n\nIPVS 모드:\n커널 레벨 로드밸런서 사용\n다양한 로드밸런싱 알고리즘 지원 (rr, lc, sh 등)\n대규모 클러스터에서 더 나은 성능",
    "references": [
      {
        "title": "kube-proxy",
        "url": "https://kubernetes.io/docs/concepts/overview/components/#kube-proxy"
      }
    ],
    "keywords": [
      "service",
      "pod",
      "ipvs",
      "역할",
      "노드의",
      "네트워크",
      "규칙",
      "관리",
      "가상",
      "통한",
      "접근",
      "구현",
      "모드",
      "리눅스",
      "규칙으로"
    ]
  },
  {
    "id": "K8S-009",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Container Runtime Interface(CRI)란 무엇이며, containerd와 CRI-O의 차이점은 무엇인가요?",
    "answer": "CRI: kubelet과 컨테이너 런타임 간의 표준 인터페이스. 다양한 런타임을 플러그인 방식으로 사용 가능\n\ncontainerd:\nDocker에서 분리된 런타임\n범용적, 다양한 기능 제공\nDocker 이미지 호환\n\nCRI-O:\nKubernetes 전용으로 설계\n경량화, 최소 기능만 제공\nOCI 표준 준수에 집중\n\n공통점: 둘 다 OCI 표준 준수, Kubernetes와 호환",
    "references": [
      {
        "title": "Container Runtime",
        "url": "https://kubernetes.io/docs/setup/production-environment/container-runtimes/"
      }
    ],
    "keywords": [
      "cri",
      "docker",
      "cri-o",
      "kubernetes",
      "oci",
      "컨테이너",
      "런타임",
      "간의",
      "표준",
      "인터페이스",
      "다양한",
      "런타임을",
      "플러그인",
      "방식으로",
      "사용"
    ]
  },
  {
    "id": "K8S-010",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Kubernetes에서 사용되는 CNI(Container Network Interface)란 무엇이며, 주요 CNI 플러그인들을 비교해주세요.",
    "answer": "CNI: 컨테이너 네트워크 설정을 위한 표준 인터페이스\n\n주요 플러그인 비교:\nCalico: NetworkPolicy 지원, BGP 기반, 대규모 클러스터에 적합\nFlannel: 간단한 설정, 오버레이 네트워크, 소규모 클러스터에 적합\nCilium: eBPF 기반, 고성능, 고급 보안 기능\nWeave: 암호화 지원, 설정 간편, 멀티클라우드 환경에 적합\n\n선택 기준: 클러스터 규모, NetworkPolicy 필요 여부, 성능 요구사항",
    "references": [
      {
        "title": "Cluster Networking",
        "url": "https://kubernetes.io/docs/concepts/cluster-administration/networking/"
      }
    ],
    "keywords": [
      "cni",
      "calico",
      "networkpolicy",
      "bgp",
      "flannel",
      "cilium",
      "weave",
      "컨테이너",
      "네트워크",
      "설정을",
      "위한",
      "표준",
      "인터페이스",
      "주요",
      "플러그인"
    ]
  },
  {
    "id": "K8S-011",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Pod란 무엇이며, 왜 컨테이너 대신 Pod 단위로 관리하나요?",
    "answer": "Pod: Kubernetes에서 배포 가능한 가장 작은 단위. 하나 이상의 컨테이너 그룹\n\nPod 단위 관리 이유:\n공유 리소스: 같은 Pod 내 컨테이너는 네트워크(localhost), 스토리지 공유\n공동 스케줄링: 밀접하게 연관된 컨테이너를 같은 노드에 배치\n생명주기 관리: 함께 시작/종료되어야 하는 컨테이너 그룹화\nSidecar 패턴: 메인 앱 + 보조 컨테이너 조합 가능",
    "references": [
      {
        "title": "Pods",
        "url": "https://kubernetes.io/docs/concepts/workloads/pods/"
      }
    ],
    "keywords": [
      "pod",
      "kubernetes",
      "sidecar",
      "에서",
      "배포",
      "가능한",
      "가장",
      "작은",
      "단위",
      "하나",
      "이상의",
      "컨테이너",
      "그룹",
      "관리",
      "이유"
    ]
  },
  {
    "id": "K8S-012",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Pod의 생명주기(Lifecycle) 단계(Pending, Running, Succeeded, Failed, Unknown)에 대해 각각 설명해주세요.",
    "answer": "Pod Phase:\nPending: Pod 생성됨, 컨테이너 아직 실행 안됨 (이미지 다운로드, 스케줄링 대기)\nRunning: 최소 하나의 컨테이너 실행 중\nSucceeded: 모든 컨테이너 성공적 종료 (exit 0), 재시작 안됨\nFailed: 모든 컨테이너 종료, 하나 이상 실패 (exit non-zero)\nUnknown: Pod 상태 확인 불가 (노드 통신 문제)",
    "references": [
      {
        "title": "Pod Lifecycle",
        "url": "https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/"
      }
    ],
    "keywords": [
      "pod",
      "phase",
      "pending",
      "running",
      "succeeded",
      "failed",
      "non-zero",
      "unknown",
      "생성됨",
      "컨테이너",
      "아직",
      "실행",
      "안됨",
      "이미지",
      "다운로드"
    ]
  },
  {
    "id": "K8S-013",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Pod의 재시작 정책(restartPolicy)인 Always, OnFailure, Never의 차이점과 사용 시나리오를 설명해주세요.",
    "answer": "restartPolicy:\nAlways (기본값): 항상 재시작. Deployment, ReplicaSet용\nOnFailure: 실패(exit code != 0) 시만 재시작. Job용\nNever: 재시작 안함. 일회성 작업용\n\n사용 시나리오:\nAlways: 웹 서버, API 서버 등 상시 운영 앱\nOnFailure: 배치 작업, 실패 시 재시도 필요한 Job\nNever: 디버깅, 로그 분석 등 일회성 작업",
    "references": [
      {
        "title": "Pod Lifecycle - Restart Policy",
        "url": "https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy"
      }
    ],
    "keywords": [
      "always",
      "deployment",
      "replicaset",
      "onfailure",
      "job",
      "never",
      "api",
      "기본값",
      "항상",
      "재시작",
      "실패",
      "시만",
      "안함",
      "일회성",
      "작업용"
    ]
  },
  {
    "id": "K8S-014",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Pod가 Pending 상태에 머무는 원인들과 해결 방법을 설명해주세요.",
    "answer": "주요 원인과 해결 방법:\n리소스 부족: 노드 추가 또는 리소스 요청량 조정\nnodeSelector/affinity 불일치: 레이블 확인 및 수정\nTaint 미허용: Toleration 추가\nPVC 바인딩 실패: PV 확인, StorageClass 점검\n이미지 다운로드 지연: 이미지 경로/권한 확인\n\n디버깅: kubectl describe pod <pod-name>으로 Events 확인",
    "references": [
      {
        "title": "Debugging Pods",
        "url": "https://kubernetes.io/docs/tasks/debug/debug-application/debug-pods/"
      }
    ],
    "keywords": [
      "taint",
      "toleration",
      "pvc",
      "storageclass",
      "pod-name",
      "events",
      "주요",
      "원인과",
      "해결",
      "방법",
      "리소스",
      "부족",
      "노드",
      "추가",
      "요청량"
    ]
  },
  {
    "id": "K8S-015",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Pod Phase와 Container State의 차이점은 무엇인가요?",
    "answer": "Pod Phase: Pod 전체의 상태 (Pending, Running, Succeeded, Failed, Unknown)\n\nContainer State: 개별 컨테이너의 상태\nWaiting: 시작 대기 (이미지 pull, 볼륨 마운트 등)\nRunning: 실행 중\nTerminated: 종료됨 (성공/실패)\n\n차이점:\nPod Phase는 상위 레벨 요약\nContainer State는 각 컨테이너의 세부 상태\nPod Running이어도 일부 컨테이너는 Waiting/Terminated일 수 있음",
    "references": [
      {
        "title": "Container States",
        "url": "https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-states"
      }
    ],
    "keywords": [
      "pod",
      "phase",
      "pending",
      "running",
      "succeeded",
      "failed",
      "unknown",
      "container",
      "state",
      "waiting",
      "terminated",
      "전체의",
      "상태",
      "개별",
      "컨테이너의"
    ]
  },
  {
    "id": "K8S-016",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Sidecar 패턴이란 무엇이며, 어떤 상황에서 사용하나요? 구체적인 예시를 들어주세요.",
    "answer": "Sidecar 패턴: 메인 컨테이너와 함께 보조 기능을 수행하는 컨테이너를 같은 Pod에 배치\n\n사용 상황:\n로깅: 로그 수집/전송 (Fluentd sidecar)\n모니터링: 메트릭 수집 (Prometheus exporter)\n프록시: 서비스 메시 (Envoy sidecar)\n설정 동기화: ConfigMap 변경 감지\n\n예시: 웹 서버 + 로그 수집기\n메인: nginx 컨테이너\nSidecar: fluentd 컨테이너 (로그 파일 읽어서 전송)\n공유 볼륨으로 로그 파일 공유",
    "references": [
      {
        "title": "Sidecar Containers",
        "url": "https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/"
      }
    ],
    "keywords": [
      "sidecar",
      "pod",
      "fluentd",
      "prometheus",
      "envoy",
      "configmap",
      "패턴",
      "메인",
      "컨테이너와",
      "함께",
      "보조",
      "기능을",
      "수행하는",
      "컨테이너를",
      "같은"
    ]
  },
  {
    "id": "K8S-017",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Ambassador 패턴이란 무엇이며, 프록시 역할을 하는 컨테이너의 활용 사례를 설명해주세요.",
    "answer": "Ambassador 패턴: 외부 서비스 접근을 대리하는 프록시 컨테이너 패턴\n\n역할: 메인 컨테이너가 localhost로 통신하면, Ambassador가 외부 서비스로 연결\n\n활용 사례:\nDB 연결 프록시: 메인앱 -> localhost:5432 -> Ambassador -> 실제 DB 클러스터\nAPI Gateway: 인증, 속도 제한 처리\n서비스 디스커버리: 복잡한 라우팅 로직 캡슐화\n레거시 시스템 연동: 프로토콜 변환\n\n장점: 메인 앱 코드 변경 없이 외부 연결 로직 분리",
    "references": [
      {
        "title": "Multi-container Pods",
        "url": "https://kubernetes.io/docs/concepts/workloads/pods/#how-pods-manage-multiple-containers"
      }
    ],
    "keywords": [
      "ambassador",
      "api",
      "gateway",
      "패턴",
      "외부",
      "서비스",
      "접근을",
      "대리하는",
      "프록시",
      "컨테이너",
      "역할",
      "메인",
      "컨테이너가",
      "통신하면",
      "서비스로"
    ]
  },
  {
    "id": "K8S-018",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Adapter 패턴이란 무엇이며, 로그 포맷 변환 등의 활용 사례를 설명해주세요.",
    "answer": "Adapter 패턴: 메인 컨테이너의 출력을 표준 형식으로 변환하는 컨테이너 패턴\n\n역할: 다양한 형식의 데이터를 통일된 인터페이스로 변환\n\n활용 사례:\n로그 포맷 변환: 앱별 로그 형식 -> 표준 JSON 형식\n메트릭 변환: 앱 메트릭 -> Prometheus 형식\n데이터 정규화: 레거시 시스템 출력 변환\n프로토콜 변환: XML -> JSON\n\n예시: 로그 어댑터\n메인: 자체 로그 형식 출력\nAdapter: 로그 파일 읽어서 표준 JSON으로 변환 후 출력",
    "references": [
      {
        "title": "Multi-container Pods",
        "url": "https://kubernetes.io/docs/concepts/workloads/pods/#how-pods-manage-multiple-containers"
      }
    ],
    "keywords": [
      "adapter",
      "json",
      "prometheus",
      "xml",
      "패턴",
      "메인",
      "컨테이너의",
      "출력을",
      "표준",
      "형식으로",
      "변환하는",
      "컨테이너",
      "역할",
      "다양한",
      "형식의"
    ]
  },
  {
    "id": "K8S-019",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Init Container의 역할과 일반 컨테이너와의 차이점을 설명해주세요.",
    "answer": "역할: Pod 내 메인 컨테이너 시작 전에 초기화 작업 수행\n\n일반 컨테이너와의 차이점:\n구분   Init Container   일반 컨테이너\n\n실행 시점   메인 컨테이너 전   Init 완료 후\n실행 방식   순차적 (하나씩)   동시 (병렬)\n완료 조건   반드시 완료되어야 함   계속 실행\nProbe   지원 안함   지원\n\n사용 예시:\nDB 연결 대기\n설정 파일 다운로드\n권한/스키마 초기화",
    "references": [
      {
        "title": "Init Containers",
        "url": "https://kubernetes.io/docs/concepts/workloads/pods/init-containers/"
      }
    ],
    "keywords": [
      "pod",
      "init",
      "container",
      "probe",
      "역할",
      "메인",
      "컨테이너",
      "시작",
      "전에",
      "초기화",
      "작업",
      "수행",
      "일반",
      "컨테이너와의",
      "차이점"
    ]
  },
  {
    "id": "K8S-020",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Init Container의 실행 순서와 실패 시 동작에 대해 설명해주세요.",
    "answer": "실행 순서:\nInit Container들이 정의된 순서대로 순차 실행\n각 Init Container는 이전 것이 성공해야 시작\n모든 Init Container 성공 후 메인 컨테이너 시작\n\n실패 시 동작:\nInit Container 실패 -> Pod 재시작 (restartPolicy에 따라)\nrestartPolicy: Always/OnFailure -> Init Container부터 재실행\nrestartPolicy: Never -> Pod Failed 상태\n\n주의사항:\nInit Container 실패 시 Pod는 Pending 상태 유지\n무한 재시도로 CrashLoopBackOff 발생 가능",
    "references": [
      {
        "title": "Init Containers",
        "url": "https://kubernetes.io/docs/concepts/workloads/pods/init-containers/#detailed-behavior"
      }
    ],
    "keywords": [
      "init",
      "container",
      "pod",
      "always",
      "onfailure",
      "never",
      "failed",
      "pending",
      "crashloopbackoff",
      "실행",
      "순서",
      "들이",
      "정의된",
      "순서대로",
      "순차"
    ]
  },
  {
    "id": "K8S-021",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Deployment의 역할과 ReplicaSet과의 관계에 대해 설명해주세요.",
    "answer": "Deployment 역할:\n선언적 Pod 업데이트 관리\n롤링 업데이트, 롤백 지원\n배포 이력 관리\n\nReplicaSet과의 관계:\nDeployment는 ReplicaSet을 생성하고 관리\nReplicaSet은 Pod 복제본 수 유지\n업데이트 시 새 ReplicaSet 생성, 기존 것은 스케일 다운\n\n구조: Deployment -> ReplicaSet -> Pod\n\n직접 ReplicaSet 사용하지 않는 이유: Deployment가 버전 관리, 롤백 등 추가 기능 제공",
    "references": [
      {
        "title": "Deployments",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/"
      }
    ],
    "keywords": [
      "deployment",
      "pod",
      "replicaset",
      "역할",
      "선언적",
      "업데이트",
      "관리",
      "롤링",
      "롤백",
      "지원",
      "배포",
      "이력",
      "과의",
      "관계",
      "생성하고"
    ]
  },
  {
    "id": "K8S-022",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Deployment의 배포 전략(RollingUpdate, Recreate)을 비교하고, 각각의 사용 시나리오를 설명해주세요.",
    "answer": "RollingUpdate (기본값):\n점진적으로 새 버전 배포\n다운타임 없음\n두 버전이 동시에 존재하는 시간 있음\n\nRecreate:\n기존 Pod 모두 종료 후 새 Pod 생성\n다운타임 발생\n버전 혼재 없음\n\n사용 시나리오:\nRollingUpdate: 일반적인 웹 서비스, API 서버\nRecreate:\n볼륨을 단일 Pod만 사용해야 할 때\n버전 호환성 문제가 있을 때\n개발/테스트 환경",
    "references": [
      {
        "title": "Deployment Strategy",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy"
      }
    ],
    "keywords": [
      "rollingupdate",
      "recreate",
      "pod",
      "api",
      "기본값",
      "점진적으로",
      "버전",
      "배포",
      "다운타임",
      "없음",
      "버전이",
      "동시에",
      "존재하는",
      "시간",
      "있음"
    ]
  },
  {
    "id": "K8S-023",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "RollingUpdate 전략에서 maxSurge와 maxUnavailable 설정의 의미와 적절한 값 설정 방법을 설명해주세요.",
    "answer": "maxSurge: 원하는 Pod 수 대비 최대 초과 생성 가능 수\n예: replicas=10, maxSurge=25% -> 최대 12개까지 존재 가능\n\nmaxUnavailable: 업데이트 중 최대 사용 불가 Pod 수\n예: replicas=10, maxUnavailable=25% -> 최소 7개는 항상 가용\n\n적절한 설정:\n빠른 배포: maxSurge 높게, maxUnavailable 높게\n안정적 배포: maxSurge 낮게, maxUnavailable=0\n리소스 제한: maxSurge=0, maxUnavailable 활용\n\n기본값: 둘 다 25%",
    "references": [
      {
        "title": "Rolling Update Deployment",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#rolling-update-deployment"
      }
    ],
    "keywords": [
      "pod",
      "원하는",
      "대비",
      "최대",
      "초과",
      "생성",
      "가능",
      "개까지",
      "존재",
      "업데이트",
      "사용",
      "불가",
      "최소",
      "개는",
      "항상"
    ]
  },
  {
    "id": "K8S-024",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Deployment의 롤백(rollback) 방법과 revision history 관리에 대해 설명해주세요.",
    "answer": "롤백 방법:\n\nRevision History 관리:\nrevisionHistoryLimit: 보관할 ReplicaSet 수 (기본값 10)\n각 업데이트마다 새 ReplicaSet 생성, 기존 것은 보관\n이력에서 롤백 가능",
    "references": [
      {
        "title": "Rolling Back a Deployment",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#rolling-back-a-deployment"
      }
    ],
    "keywords": [
      "revision",
      "history",
      "replicaset",
      "롤백",
      "방법",
      "관리",
      "보관할",
      "기본값",
      "업데이트마다",
      "생성",
      "기존",
      "것은",
      "보관",
      "이력에서",
      "가능"
    ]
  },
  {
    "id": "K8S-025",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Blue-Green 배포와 Canary 배포를 Kubernetes에서 구현하는 방법을 설명해주세요.",
    "answer": "Blue-Green 배포:\n두 개의 Deployment 생성 (blue, green)\nService selector로 하나만 활성화\n전환 시 Service selector 변경\n\nCanary 배포:\n기존 Deployment + 새 버전 Deployment (적은 replicas)\n동일한 label로 Service가 둘 다 선택\n점진적으로 새 버전 replicas 증가\n\n고급 방법: Istio VirtualService로 트래픽 비율 제어",
    "references": [
      {
        "title": "Deployments",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/"
      }
    ],
    "keywords": [
      "blue-green",
      "deployment",
      "service",
      "canary",
      "istio",
      "virtualservice",
      "배포",
      "개의",
      "생성",
      "하나만",
      "활성화",
      "전환",
      "변경",
      "기존",
      "버전"
    ]
  },
  {
    "id": "K8S-026",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "StatefulSet이란 무엇이며, Deployment와의 차이점을 설명해주세요.",
    "answer": "StatefulSet: 상태를 가진 애플리케이션을 위한 워크로드 리소스\n\nDeployment와의 차이점:\n구분   StatefulSet   Deployment\n\nPod 이름   고정 (app-0, app-1)   랜덤\n네트워크 ID   고정 (Headless Service)   변경 가능\n스토리지   Pod별 PVC 유지   공유 또는 없음\n배포 순서   순차적   병렬\n삭제 순서   역순   무관\n\n사용 사례: 데이터베이스, 분산 시스템 (Kafka, ZooKeeper, Elasticsearch)",
    "references": [
      {
        "title": "StatefulSets",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/"
      }
    ],
    "keywords": [
      "statefulset",
      "deployment",
      "pod",
      "headless",
      "service",
      "pvc",
      "kafka",
      "zookeeper",
      "elasticsearch",
      "상태를",
      "가진",
      "애플리케이션을",
      "위한",
      "워크로드",
      "리소스"
    ]
  },
  {
    "id": "K8S-027",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "StatefulSet에서 Pod 이름과 네트워크 ID의 안정성(stable identity)은 어떻게 보장되나요?",
    "answer": "Pod 이름 안정성:\n형식: <statefulset-name>-<ordinal> (예: mysql-0, mysql-1)\nPod 재생성 시에도 동일한 이름 유지\nordinal은 0부터 순차 증가\n\n네트워크 ID 안정성:\nHeadless Service와 함께 사용\nDNS: <pod-name>.<service-name>.<namespace>.svc.cluster.local\n예: mysql-0.mysql.default.svc.cluster.local\n\n보장 방법:\nStatefulSet Controller가 ordinal 기반 관리\nPod 삭제/재생성 시 동일 이름과 PVC 재연결",
    "references": [
      {
        "title": "Stable Network ID",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#stable-network-id"
      }
    ],
    "keywords": [
      "pod",
      "statefulset-name",
      "headless",
      "service",
      "dns",
      "pod-name",
      "service-name",
      "statefulset",
      "controller",
      "pvc",
      "이름",
      "안정성",
      "형식",
      "재생성",
      "시에도"
    ]
  },
  {
    "id": "K8S-028",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "StatefulSet의 순차적 배포(ordered deployment)와 병렬 배포(parallel deployment) 방식의 차이를 설명해주세요.",
    "answer": "podManagementPolicy 설정:\n\nOrderedReady (기본값):\nPod를 순서대로 생성 (0 -> 1 -> 2)\n이전 Pod가 Ready 상태여야 다음 생성\n삭제는 역순 (2 -> 1 -> 0)\n사용: 마스터-슬레이브 DB, 리더 선출 시스템\n\nParallel:\n모든 Pod 동시 생성/삭제\n순서 보장 불필요 시 사용\n더 빠른 스케일링",
    "references": [
      {
        "title": "Pod Management Policies",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies"
      }
    ],
    "keywords": [
      "orderedready",
      "pod",
      "ready",
      "parallel",
      "설정",
      "기본값",
      "순서대로",
      "생성",
      "이전",
      "상태여야",
      "다음",
      "삭제는",
      "역순",
      "사용",
      "마스터"
    ]
  },
  {
    "id": "K8S-029",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "StatefulSet에서 PersistentVolumeClaim 템플릿의 역할과 동작 방식을 설명해주세요.",
    "answer": "역할: 각 Pod에 대해 개별 PVC 자동 생성\n\n동작 방식:\nPod 생성 시 volumeClaimTemplates 기반으로 PVC 생성\nPVC 이름: <template-name>-<statefulset-name>-<ordinal>\nPod와 PVC 영구 연결\n\n특징:\nPod 삭제 시 PVC는 유지됨\nPod 재생성 시 기존 PVC 재연결\nStatefulSet 삭제 시에도 PVC 수동 삭제 필요",
    "references": [
      {
        "title": "Stable Storage",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#stable-storage"
      }
    ],
    "keywords": [
      "pod",
      "pvc",
      "template-name",
      "statefulset-name",
      "statefulset",
      "역할",
      "개별",
      "자동",
      "생성",
      "동작",
      "방식",
      "기반으로",
      "이름",
      "영구",
      "연결"
    ]
  },
  {
    "id": "K8S-030",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "StatefulSet 사용 시 Headless Service가 필요한 이유를 설명해주세요.",
    "answer": "Headless Service: ClusterIP가 None인 Service\n\n필요한 이유:\n개별 Pod 접근: 각 Pod에 고유 DNS 이름 부여\n일반 Service: 로드밸런싱으로 임의 Pod 접근\nHeadless: 특정 Pod 직접 접근 가능\nDNS 레코드 생성:\npod-name.service-name.namespace.svc.cluster.local\n클라이언트가 특정 인스턴스에 연결 필요 시 사용\n상태 저장 앱 요구사항:\nDB 복제 시 마스터/슬레이브 구분 필요\n클러스터 멤버 간 직접 통신",
    "references": [
      {
        "title": "Headless Services",
        "url": "https://kubernetes.io/docs/concepts/services-networking/service/#headless-services"
      }
    ],
    "keywords": [
      "headless",
      "service",
      "clusterip",
      "none",
      "pod",
      "dns",
      "pod-name",
      "service-name",
      "필요한",
      "이유",
      "개별",
      "접근",
      "고유",
      "이름",
      "부여"
    ]
  },
  {
    "id": "K8S-031",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "DaemonSet의 역할과 사용 사례(로그 수집, 모니터링 에이전트 등)를 설명해주세요.",
    "answer": "역할: 모든(또는 특정) 노드에서 Pod를 하나씩 실행하도록 보장\n\n동작:\n노드 추가 시 자동으로 Pod 생성\n노드 삭제 시 자동으로 Pod 제거\n\n사용 사례:\n로그 수집: Fluentd, Filebeat (각 노드 로그 수집)\n모니터링: Node Exporter, Datadog Agent\n네트워킹: CNI 플러그인 (Calico, Weave)\n스토리지: CSI 드라이버\n보안: 보안 에이전트, 안티바이러스",
    "references": [
      {
        "title": "DaemonSet",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/"
      }
    ],
    "keywords": [
      "pod",
      "fluentd",
      "filebeat",
      "node",
      "exporter",
      "datadog",
      "agent",
      "cni",
      "calico",
      "weave",
      "csi",
      "역할",
      "모든",
      "특정",
      "노드에서"
    ]
  },
  {
    "id": "K8S-032",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "DaemonSet에서 특정 노드에만 Pod를 배포하는 방법을 설명해주세요.",
    "answer": "방법 1: nodeSelector\n\n방법 2: Node Affinity\n\n방법 3: Toleration (Taint된 노드에 배포)",
    "references": [
      {
        "title": "DaemonSet on specific Nodes",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/#running-pods-on-select-nodes"
      }
    ],
    "keywords": [
      "node",
      "affinity",
      "toleration",
      "taint",
      "방법",
      "노드에",
      "배포"
    ]
  },
  {
    "id": "K8S-033",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Job의 역할과 completions, parallelism 설정의 의미를 설명해주세요.",
    "answer": "역할: 하나 이상의 Pod를 생성하고 지정된 수만큼 성공적으로 완료되도록 보장\n\n설정값:\ncompletions: 성공해야 하는 Pod 수 (기본값: 1)\nparallelism: 동시에 실행할 Pod 수 (기본값: 1)\n\n예시:\n\n동작 패턴:\ncompletions=1, parallelism=1: 단일 작업\ncompletions=N, parallelism=1: 순차 실행\ncompletions=N, parallelism=M: 병렬 배치",
    "references": [
      {
        "title": "Jobs",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/job/"
      }
    ],
    "keywords": [
      "pod",
      "역할",
      "하나",
      "이상의",
      "생성하고",
      "지정된",
      "수만큼",
      "성공적으로",
      "완료되도록",
      "보장",
      "설정값",
      "성공해야",
      "하는",
      "기본값",
      "동시에"
    ]
  },
  {
    "id": "K8S-034",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Job의 backoffLimit와 activeDeadlineSeconds 설정의 역할을 설명해주세요.",
    "answer": "backoffLimit:\nJob 실패 시 재시도 횟수 (기본값: 6)\n재시도 간격: 지수 백오프 (10s, 20s, 40s... 최대 6분)\n초과 시 Job Failed 상태\n\nactiveDeadlineSeconds:\nJob의 최대 실행 시간 (초)\n시간 초과 시 모든 Pod 종료, Job Failed\nbackoffLimit보다 우선\n\n사용 시나리오:\n무한 루프 방지\nSLA 준수를 위한 타임아웃 설정",
    "references": [
      {
        "title": "Job Termination",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/job/#job-termination-and-cleanup"
      }
    ],
    "keywords": [
      "job",
      "failed",
      "pod",
      "sla",
      "실패",
      "재시도",
      "횟수",
      "기본값",
      "간격",
      "지수",
      "백오프",
      "최대",
      "초과",
      "상태",
      "실행"
    ]
  },
  {
    "id": "K8S-035",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "CronJob의 역할과 스케줄 표현식, concurrencyPolicy 설정에 대해 설명해주세요.",
    "answer": "역할: 지정된 스케줄에 따라 Job을 반복 생성\n\n스케줄 표현식 (Cron 형식):\n\nconcurrencyPolicy:\nAllow (기본값): 동시 실행 허용\nForbid: 이전 Job 실행 중이면 새 Job 건너뜀\nReplace: 이전 Job 취소하고 새 Job 시작",
    "references": [
      {
        "title": "CronJob",
        "url": "https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/"
      }
    ],
    "keywords": [
      "job",
      "cron",
      "allow",
      "forbid",
      "replace",
      "역할",
      "지정된",
      "스케줄에",
      "따라",
      "반복",
      "생성",
      "스케줄",
      "표현식",
      "형식",
      "기본값"
    ]
  },
  {
    "id": "K8S-036",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Kubernetes Service의 역할과 필요성에 대해 설명해주세요.",
    "answer": "역할: Pod 집합에 대한 단일 접근점 제공 및 로드밸런싱\n\n필요성:\nPod IP 변동성: Pod 재생성 시 IP 변경됨\n서비스 디스커버리: 안정적인 DNS 이름 제공\n로드밸런싱: 여러 Pod에 트래픽 분산\n추상화: 백엔드 Pod 변경에도 클라이언트 영향 없음\n\n동작 방식:\nLabel Selector로 대상 Pod 그룹 지정\nClusterIP (가상 IP) 할당\nkube-proxy가 트래픽 라우팅 규칙 관리",
    "references": [
      {
        "title": "Service",
        "url": "https://kubernetes.io/docs/concepts/services-networking/service/"
      }
    ],
    "keywords": [
      "pod",
      "dns",
      "label",
      "selector",
      "clusterip",
      "kube-proxy",
      "역할",
      "집합에",
      "대한",
      "단일",
      "접근점",
      "제공",
      "로드밸런싱",
      "필요성",
      "변동성"
    ]
  },
  {
    "id": "K8S-037",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "ClusterIP 타입 Service의 동작 방식과 사용 시나리오를 설명해주세요.",
    "answer": "동작 방식:\n클러스터 내부에서만 접근 가능한 가상 IP 할당\nkube-proxy가 ClusterIP로 오는 트래픽을 Pod로 라우팅\nDNS: <service-name>.<namespace>.svc.cluster.local\n\n특징:\n기본 Service 타입\n외부에서 직접 접근 불가\n클러스터 내 Pod 간 통신용\n\n사용 시나리오:\n내부 마이크로서비스 간 통신\n백엔드 DB 접근\n캐시 서버 (Redis) 접근\n내부 API 서비스",
    "references": [
      {
        "title": "ClusterIP",
        "url": "https://kubernetes.io/docs/concepts/services-networking/service/#type-clusterip"
      }
    ],
    "keywords": [
      "kube-proxy",
      "clusterip",
      "pod",
      "dns",
      "service-name",
      "service",
      "redis",
      "api",
      "동작",
      "방식",
      "클러스터",
      "내부에서만",
      "접근",
      "가능한",
      "가상"
    ]
  },
  {
    "id": "K8S-038",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "NodePort 타입 Service의 동작 방식과 포트 범위 제한에 대해 설명해주세요.",
    "answer": "동작 방식:\nClusterIP 기능 포함\n모든 노드의 특정 포트에서 Service 노출\n<NodeIP>:<NodePort>로 외부 접근 가능\n트래픽: NodePort -> ClusterIP -> Pod\n\n포트 범위:\n기본: 30000-32767\nkube-apiserver --service-node-port-range 플래그로 변경 가능\n\n사용 시나리오:\n개발/테스트 환경\n로드밸런서 없는 온프레미스 환경\n외부 로드밸런서와 연동\n\n단점: 노드 IP 노출, 포트 관리 필요",
    "references": [
      {
        "title": "NodePort",
        "url": "https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport"
      }
    ],
    "keywords": [
      "clusterip",
      "service",
      "nodeip",
      "nodeport",
      "pod",
      "kube-apiserver",
      "service-node",
      "port-range",
      "동작",
      "방식",
      "기능",
      "포함",
      "모든",
      "노드의",
      "특정"
    ]
  },
  {
    "id": "K8S-039",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "LoadBalancer 타입 Service의 동작 방식과 클라우드 환경에서의 프로비저닝 과정을 설명해주세요.",
    "answer": "동작 방식:\nNodePort 기능 포함\n클라우드 로드밸런서 자동 프로비저닝\n외부 IP 할당\n트래픽: External LB -> NodePort -> ClusterIP -> Pod\n\n프로비저닝 과정:\nService 생성 시 cloud-controller-manager가 감지\n클라우드 API 호출하여 LB 생성 (AWS ELB, GCP LB 등)\nLB가 NodePort로 트래픽 전달하도록 설정\nExternal IP가 Service에 할당\n\n주의사항:\n클라우드 환경에서만 동작\nLB당 비용 발생\n온프레미스는 MetalLB 등 별도 솔루션 필요",
    "references": [
      {
        "title": "LoadBalancer",
        "url": "https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer"
      }
    ],
    "keywords": [
      "nodeport",
      "external",
      "clusterip",
      "pod",
      "service",
      "cloud-controller",
      "api",
      "aws",
      "elb",
      "gcp",
      "metallb",
      "동작",
      "방식",
      "기능",
      "포함"
    ]
  },
  {
    "id": "K8S-040",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "ExternalName 타입 Service의 역할과 사용 사례를 설명해주세요.",
    "answer": "역할: 외부 DNS 이름을 클러스터 내부 Service 이름으로 매핑 (CNAME 레코드)\n\n동작 방식:\nClusterIP 할당 없음\nDNS 쿼리 시 외부 도메인으로 CNAME 반환\n프록시나 포워딩 없이 DNS 레벨 리디렉션\n\n사용 사례:\n외부 데이터베이스 연결 (RDS, Cloud SQL)\n외부 API 서비스 추상화\n마이그레이션 중 외부 서비스 참조\n환경별 외부 서비스 전환",
    "references": [
      {
        "title": "ExternalName",
        "url": "https://kubernetes.io/docs/concepts/services-networking/service/#externalname"
      }
    ],
    "keywords": [
      "dns",
      "service",
      "cname",
      "clusterip",
      "rds",
      "cloud",
      "sql",
      "api",
      "역할",
      "외부",
      "이름을",
      "클러스터",
      "내부",
      "이름으로",
      "매핑"
    ]
  },
  {
    "id": "K8S-041",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Headless Service란 무엇이며, StatefulSet과 함께 사용되는 이유를 설명해주세요.",
    "answer": "Headless Service: clusterIP: None으로 설정된 Service\n\n특징:\nClusterIP 할당 없음\nDNS 쿼리 시 Pod IP들 직접 반환\n로드밸런싱 없이 개별 Pod 접근\n\nStatefulSet과 함께 사용하는 이유:\n개별 Pod DNS: pod-name.service.namespace.svc.cluster.local\n안정적 네트워크 ID: Pod 이름 기반 DNS로 재시작 후에도 동일\n직접 통신: 클러스터 멤버 간 피어 통신 필요 (DB 복제)\n클라이언트 제어: 클라이언트가 특정 인스턴스 선택 가능\n\n예: Kafka 브로커, MySQL 마스터/슬레이브 구분",
    "references": [
      {
        "title": "Headless Services",
        "url": "https://kubernetes.io/docs/concepts/services-networking/service/#headless-services"
      }
    ],
    "keywords": [
      "headless",
      "service",
      "none",
      "clusterip",
      "dns",
      "pod",
      "statefulset",
      "pod-name",
      "kafka",
      "mysql",
      "으로",
      "설정된",
      "특징",
      "할당",
      "없음"
    ]
  },
  {
    "id": "K8S-042",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Ingress의 역할과 Service와의 차이점을 설명해주세요.",
    "answer": "Ingress 역할: HTTP/HTTPS 트래픽을 클러스터 내부 Service로 라우팅하는 API 객체\n\nService와의 차이점:\n구분   Ingress   Service (LB)\n\n프로토콜   HTTP/HTTPS   L4 (TCP/UDP)\n라우팅   호스트/경로 기반   포트 기반\nSSL 종료   지원   별도 설정 필요\n단일 진입점   여러 Service 통합   Service당 하나\n비용   LB 하나로 여러 서비스   Service마다 LB\n\nIngress 기능:\n경로 기반 라우팅 (/api, /web)\n호스트 기반 라우팅 (api.example.com)\nTLS/SSL 종료",
    "references": [
      {
        "title": "Ingress",
        "url": "https://kubernetes.io/docs/concepts/services-networking/ingress/"
      }
    ],
    "keywords": [
      "ingress",
      "http",
      "https",
      "service",
      "api",
      "tcp",
      "udp",
      "ssl",
      "tls",
      "역할",
      "트래픽을",
      "클러스터",
      "내부",
      "라우팅하는",
      "객체"
    ]
  },
  {
    "id": "K8S-043",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Ingress Controller의 역할과 주요 구현체(NGINX, Traefik, HAProxy 등)를 비교해주세요.",
    "answer": "역할: Ingress 리소스를 감시하고 실제 라우팅 규칙을 구현하는 컨트롤러\n\n주요 구현체 비교:\n구현체   특징\n\nNGINX   가장 널리 사용, 안정적, 풍부한 기능\nTraefik   자동 설정, Let's Encrypt 통합, 경량\nHAProxy   고성능, 엔터프라이즈급 로드밸런싱\nContour   Envoy 기반, 멀티테넌트 지원\nAWS ALB   AWS 통합, 네이티브 ALB 사용\n\n선택 기준:\n성능 요구사항\n필요한 기능 (mTLS, 속도 제한)\n클라우드 환경\n운영 복잡도",
    "references": [
      {
        "title": "Ingress Controllers",
        "url": "https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/"
      }
    ],
    "keywords": [
      "ingress",
      "nginx",
      "traefik",
      "let",
      "encrypt",
      "haproxy",
      "contour",
      "envoy",
      "aws",
      "alb",
      "역할",
      "리소스를",
      "감시하고",
      "실제",
      "라우팅"
    ]
  },
  {
    "id": "K8S-044",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Ingress에서 호스트 기반 라우팅과 경로 기반 라우팅을 설정하는 방법을 설명해주세요.",
    "answer": "호스트 기반 라우팅:\n\n경로 기반 라우팅:\n\npathType: Exact, Prefix, ImplementationSpecific",
    "references": [
      {
        "title": "Ingress Rules",
        "url": "https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-rules"
      }
    ],
    "keywords": [
      "exact",
      "prefix",
      "implementationspecific",
      "호스트",
      "기반",
      "라우팅",
      "경로"
    ]
  },
  {
    "id": "K8S-045",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Ingress에서 TLS/SSL 인증서를 설정하는 방법과 cert-manager와의 연동에 대해 설명해주세요.",
    "answer": "수동 TLS 설정:\n\ncert-manager 연동:\n\ncert-manager가 Let's Encrypt 인증서 자동 발급/갱신",
    "references": [
      {
        "title": "Ingress TLS",
        "url": "https://kubernetes.io/docs/concepts/services-networking/ingress/#tls"
      }
    ],
    "keywords": [
      "tls",
      "cert-manager",
      "let",
      "encrypt",
      "수동",
      "설정",
      "연동",
      "인증서",
      "자동",
      "발급",
      "갱신"
    ]
  },
  {
    "id": "K8S-046",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Ingress의 annotations을 활용한 설정(rate limiting, rewrites 등) 방법을 설명해주세요.",
    "answer": "annotations: Ingress Controller별 추가 설정 (NGINX Ingress 예시)\n\nRate Limiting:\n\nURL Rewrite:\n\n기타 유용한 annotations:\nssl-redirect: HTTP -> HTTPS 리디렉션\nproxy-body-size: 요청 바디 크기 제한\nproxy-read-timeout: 타임아웃 설정\nwhitelist-source-range: IP 화이트리스트",
    "references": [
      {
        "title": "NGINX Ingress Annotations",
        "url": "https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/"
      }
    ],
    "keywords": [
      "ingress",
      "controller",
      "nginx",
      "rate",
      "limiting",
      "url",
      "rewrite",
      "ssl-redirect",
      "http",
      "https",
      "proxy-body",
      "proxy-read",
      "whitelist-source",
      "추가",
      "설정"
    ]
  },
  {
    "id": "K8S-047",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "PersistentVolume(PV)과 PersistentVolumeClaim(PVC)의 개념과 관계를 설명해주세요.",
    "answer": "PersistentVolume (PV):\n클러스터 레벨의 스토리지 리소스\n관리자가 프로비저닝 (또는 동적 생성)\n실제 스토리지 (NFS, EBS, PD 등)를 추상화\n\nPersistentVolumeClaim (PVC):\n사용자의 스토리지 요청\n필요한 크기, 접근 모드 명시\nPod에서 볼륨으로 마운트\n\n관계:\nPVC는 조건 맞는 PV에 바인딩\n1:1 관계 (하나의 PVC = 하나의 PV)\nPVC 삭제 시 PV는 reclaimPolicy에 따라 처리",
    "references": [
      {
        "title": "Persistent Volumes",
        "url": "https://kubernetes.io/docs/concepts/storage/persistent-volumes/"
      }
    ],
    "keywords": [
      "persistentvolume",
      "nfs",
      "ebs",
      "persistentvolumeclaim",
      "pvc",
      "pod",
      "클러스터",
      "레벨의",
      "스토리지",
      "리소스",
      "관리자가",
      "프로비저닝",
      "동적",
      "생성",
      "실제"
    ]
  },
  {
    "id": "K8S-048",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "PV의 접근 모드(ReadWriteOnce, ReadOnlyMany, ReadWriteMany)의 차이점을 설명해주세요.",
    "answer": "접근 모드:\n모드   약어   설명\n\nReadWriteOnce   RWO   단일 노드에서 읽기/쓰기\nReadOnlyMany   ROX   여러 노드에서 읽기 전용\nReadWriteMany   RWX   여러 노드에서 읽기/쓰기\nReadWriteOncePod   RWOP   단일 Pod에서만 읽기/쓰기\n\n스토리지 타입별 지원:\nAWS EBS: RWO만 지원\nNFS: RWO, ROX, RWX 모두 지원\nGCP PD: RWO, ROX 지원\n\n사용 시나리오:\nRWO: 일반 DB, 단일 인스턴스 앱\nROX: 공유 설정 파일, 정적 콘텐츠\nRWX: 여러 Pod가 공유하는 업로드 디렉토리",
    "references": [
      {
        "title": "Access Modes",
        "url": "https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes"
      }
    ],
    "keywords": [
      "readwriteonce",
      "rwo",
      "readonlymany",
      "rox",
      "readwritemany",
      "rwx",
      "readwriteoncepod",
      "rwop",
      "pod",
      "aws",
      "ebs",
      "nfs",
      "gcp",
      "접근",
      "모드"
    ]
  },
  {
    "id": "K8S-049",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "PV의 Reclaim Policy(Retain, Delete, Recycle)의 차이점과 사용 시나리오를 설명해주세요.",
    "answer": "Reclaim Policy: PVC 삭제 후 PV 처리 방법\n\n정책   동작   사용 시나리오\n\nRetain   PV와 데이터 유지, 수동 정리 필요   중요 데이터, 프로덕션 DB\nDelete   PV와 외부 스토리지 함께 삭제   임시 데이터, 동적 프로비저닝\nRecycle   데이터 삭제 후 PV 재사용 (deprecated)   사용 권장 안함\n\nRetain 후 재사용 절차:\nPVC 삭제\nPV에서 claimRef 제거\n필요시 데이터 정리\n새 PVC로 바인딩\n\n기본값: StorageClass에 따라 다름 (동적 프로비저닝은 보통 Delete)",
    "references": [
      {
        "title": "Reclaim Policy",
        "url": "https://kubernetes.io/docs/concepts/storage/persistent-volumes/#reclaiming"
      }
    ],
    "keywords": [
      "reclaim",
      "policy",
      "pvc",
      "retain",
      "delete",
      "recycle",
      "storageclass",
      "삭제",
      "처리",
      "방법",
      "정책",
      "동작",
      "사용",
      "시나리오",
      "데이터"
    ]
  },
  {
    "id": "K8S-050",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "StorageClass의 역할과 동적 프로비저닝(Dynamic Provisioning)의 동작 방식을 설명해주세요.",
    "answer": "StorageClass 역할: 스토리지 \"클래스\" 정의 - 프로비저너, 파라미터, 정책 지정\n\n동적 프로비저닝 동작:\nPVC 생성 시 storageClassName 지정\nProvisioner가 PVC 감지\n자동으로 PV 생성 및 외부 스토리지 프로비저닝\nPVC와 PV 자동 바인딩\n\nvolumeBindingMode:\nImmediate: PVC 생성 즉시 바인딩\nWaitForFirstConsumer: Pod 스케줄링 후 바인딩",
    "references": [
      {
        "title": "Storage Classes",
        "url": "https://kubernetes.io/docs/concepts/storage/storage-classes/"
      }
    ],
    "keywords": [
      "storageclass",
      "pvc",
      "provisioner",
      "immediate",
      "waitforfirstconsumer",
      "pod",
      "역할",
      "스토리지",
      "클래스",
      "정의",
      "프로비저너",
      "파라미터",
      "정책",
      "지정",
      "동적"
    ]
  },
  {
    "id": "K8S-051",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "CSI(Container Storage Interface)의 역할과 주요 CSI 드라이버들에 대해 설명해주세요.",
    "answer": "CSI 역할: 스토리지 시스템과 Kubernetes 간 표준 인터페이스\n\n장점:\n스토리지 벤더 독립적\nKubernetes 코어와 분리된 개발/배포\n플러그인 방식으로 새 스토리지 추가\n\n주요 CSI 드라이버:\n드라이버   스토리지\n\naws-ebs-csi-driver   AWS EBS\ngcp-pd-csi-driver   GCP Persistent Disk\nazuredisk-csi-driver   Azure Disk\ncsi-driver-nfs   NFS\nsecrets-store-csi-driver   Secret 관리\nceph-csi   Ceph RBD/CephFS\n\n구성 요소: Controller Plugin, Node Plugin",
    "references": [
      {
        "title": "CSI",
        "url": "https://kubernetes.io/docs/concepts/storage/volumes/#csi"
      }
    ],
    "keywords": [
      "csi",
      "kubernetes",
      "aws-ebs",
      "csi-driver",
      "aws",
      "ebs",
      "gcp-pd",
      "gcp",
      "persistent",
      "disk",
      "azuredisk-csi",
      "azure",
      "nfs",
      "secrets-store",
      "secret"
    ]
  },
  {
    "id": "K8S-052",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "emptyDir, hostPath, configMap, secret 볼륨 타입의 차이점과 사용 사례를 설명해주세요.",
    "answer": "볼륨 타입   생명주기   사용 사례\n\nemptyDir   Pod와 함께 (임시)   컨테이너 간 데이터 공유, 캐시\nhostPath   노드에 영구 저장   로그 수집, 시스템 파일 접근\nconfigMap   ConfigMap 수명   설정 파일, 환경변수\nsecret   Secret 수명   민감 정보 (패스워드, 키)\n\nemptyDir: Pod 삭제 시 데이터 손실\n\nhostPath: 노드 종속적, 보안 주의\n\nconfigMap/secret: 읽기 전용, 자동 업데이트 가능",
    "references": [
      {
        "title": "Volumes",
        "url": "https://kubernetes.io/docs/concepts/storage/volumes/"
      }
    ],
    "keywords": [
      "pod",
      "configmap",
      "secret",
      "볼륨",
      "타입",
      "생명주기",
      "사용",
      "사례",
      "함께",
      "임시",
      "컨테이너",
      "데이터",
      "공유",
      "캐시",
      "노드에"
    ]
  },
  {
    "id": "K8S-053",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "ConfigMap의 역할과 생성 방법(literal, file, directory)에 대해 설명해주세요.",
    "answer": "역할: 설정 데이터를 키-값 쌍으로 저장, 컨테이너와 설정 분리\n\n생성 방법:\n\nLiteral (키-값):\n\nFile (파일 내용):\n\nDirectory (디렉토리 전체):\n\nYAML로 직접 생성:",
    "references": [
      {
        "title": "ConfigMaps",
        "url": "https://kubernetes.io/docs/concepts/configuration/configmap/"
      }
    ],
    "keywords": [
      "literal",
      "file",
      "directory",
      "yaml",
      "역할",
      "설정",
      "데이터를",
      "쌍으로",
      "저장",
      "컨테이너와",
      "분리",
      "생성",
      "방법",
      "파일",
      "내용"
    ]
  },
  {
    "id": "K8S-054",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "ConfigMap을 Pod에 주입하는 방법(환경변수, 볼륨 마운트)의 차이점을 설명해주세요.",
    "answer": "환경변수 방식:\nPod 시작 시 값 고정\nConfigMap 변경 시 Pod 재시작 필요\n단순 키-값에 적합\n\n볼륨 마운트 방식:\n파일로 마운트\nConfigMap 변경 시 자동 업데이트 (지연 있음)\n설정 파일 형태에 적합\n\n차이점 요약:\n방식   업데이트   형태\n\n환경변수   재시작 필요   키-값\n볼륨   자동 (수초~분)   파일",
    "references": [
      {
        "title": "Configure Pod ConfigMap",
        "url": "https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/"
      }
    ],
    "keywords": [
      "pod",
      "configmap",
      "환경변수",
      "방식",
      "시작",
      "고정",
      "변경",
      "재시작",
      "필요",
      "단순",
      "값에",
      "적합",
      "볼륨",
      "마운트",
      "파일로"
    ]
  },
  {
    "id": "K8S-055",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Secret의 역할과 ConfigMap과의 차이점을 설명해주세요. Secret은 정말 안전한가요?",
    "answer": "역할: 민감한 데이터 (패스워드, 토큰, 키) 저장\n\nConfigMap과의 차이:\n구분   Secret   ConfigMap\n\n용도   민감 데이터   일반 설정\n저장   Base64 인코딩   평문\n메모리   tmpfs에 저장   일반 저장\n크기 제한   1MB   1MB\n\nSecret은 정말 안전한가?\n기본적으로 안전하지 않음: Base64는 암호화가 아님\netcd에 평문 저장 (기본 설정)\n\n보안 강화 방법:\netcd 암호화 활성화\nRBAC로 접근 제한\n외부 시크릿 관리자 사용 (Vault, AWS Secrets Manager)\nSealed Secrets 사용",
    "references": [
      {
        "title": "Secrets",
        "url": "https://kubernetes.io/docs/concepts/configuration/secret/"
      }
    ],
    "keywords": [
      "configmap",
      "secret",
      "base64",
      "rbac",
      "vault",
      "aws",
      "secrets",
      "manager",
      "sealed",
      "역할",
      "민감한",
      "데이터",
      "패스워드",
      "토큰",
      "저장"
    ]
  },
  {
    "id": "K8S-056",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Secret의 타입(Opaque, kubernetes.io/dockerconfigjson, kubernetes.io/tls 등)에 대해 설명해주세요.",
    "answer": "주요 Secret 타입:\n\n타입   용도\n\nOpaque   기본 타입, 임의의 사용자 데이터\nkubernetes.io/dockerconfigjson   Docker 레지스트리 인증\nkubernetes.io/tls   TLS 인증서 (tls.crt, tls.key)\nkubernetes.io/basic-auth   기본 인증 (username, password)\nkubernetes.io/ssh-auth   SSH 인증 (ssh-privatekey)\nkubernetes.io/service-account-token   ServiceAccount 토큰\n\n생성 예시:",
    "references": [
      {
        "title": "Secret Types",
        "url": "https://kubernetes.io/docs/concepts/configuration/secret/#secret-types"
      }
    ],
    "keywords": [
      "secret",
      "opaque",
      "docker",
      "tls",
      "basic-auth",
      "ssh-auth",
      "ssh",
      "ssh-privatekey",
      "service-account",
      "serviceaccount",
      "주요",
      "타입",
      "용도",
      "기본",
      "임의의"
    ]
  },
  {
    "id": "K8S-057",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "외부 시크릿 관리 도구(Vault, AWS Secrets Manager)와 Kubernetes Secret의 연동 방법을 설명해주세요.",
    "answer": "연동 방법:\nExternal Secrets Operator:\n외부 시크릿을 Kubernetes Secret으로 동기화\nAWS Secrets Manager, Vault, GCP Secret Manager 지원\nSecrets Store CSI Driver:\nCSI 볼륨으로 시크릿 마운트\nPod에서 파일로 접근\nVault Agent Injector:\nSidecar로 Vault 시크릿 주입\n자동 갱신 지원\n\n장점: 중앙 집중 관리, 감사 로그, 자동 회전",
    "references": [
      {
        "title": "External Secrets Operator",
        "url": "https://external-secrets.io/"
      }
    ],
    "keywords": [
      "external",
      "secrets",
      "operator",
      "kubernetes",
      "secret",
      "aws",
      "manager",
      "vault",
      "gcp",
      "store",
      "csi",
      "driver",
      "pod",
      "agent",
      "injector"
    ]
  },
  {
    "id": "K8S-058",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "ConfigMap/Secret 변경 시 Pod에 자동으로 반영되지 않는 이유와 해결 방법을 설명해주세요.",
    "answer": "자동 반영되지 않는 이유:\n환경변수: Pod 시작 시 값이 고정됨\n볼륨 마운트: 자동 업데이트되나 앱이 파일 변경 감지 필요\n앱 재시작 없이 설정 리로드 로직 필요\n\n해결 방법:\nPod 재시작 (롤아웃):\nReloader 사용 (stakater/Reloader):\nConfigMap/Secret 변경 감지 후 자동 롤아웃\n해시 기반 업데이트:\nConfigMap 해시를 annotation에 포함\n변경 시 Deployment 스펙 변경 -> 자동 롤아웃\n앱 레벨 핫 리로드 구현",
    "references": [
      {
        "title": "ConfigMap",
        "url": "https://kubernetes.io/docs/concepts/configuration/configmap/"
      }
    ],
    "keywords": [
      "pod",
      "reloader",
      "configmap",
      "secret",
      "deployment",
      "자동",
      "반영되지",
      "않는",
      "이유",
      "환경변수",
      "시작",
      "값이",
      "고정됨",
      "볼륨",
      "마운트"
    ]
  },
  {
    "id": "K8S-059",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "nodeSelector를 사용한 Pod 스케줄링 방법과 한계점을 설명해주세요.",
    "answer": "nodeSelector 사용법:\n\n노드에 해당 레이블이 있어야 스케줄링됨\n\n노드 레이블 추가:\n\n한계점:\n단순 일치만 가능: OR, NOT 조건 불가\nHard 제약만: 조건 불일치 시 스케줄링 실패\nSoft 선호 불가: \"가능하면\" 조건 표현 못함\n복잡한 표현식 불가: In, NotIn, Exists 등 미지원\n\n대안: Node Affinity 사용\n더 풍부한 표현식\nSoft/Hard 제약 모두 지원",
    "references": [
      {
        "title": "Assigning Pods to Nodes",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/"
      }
    ],
    "keywords": [
      "hard",
      "soft",
      "notin",
      "exists",
      "node",
      "affinity",
      "사용법",
      "노드에",
      "해당",
      "레이블이",
      "있어야",
      "스케줄링됨",
      "노드",
      "레이블",
      "추가"
    ]
  },
  {
    "id": "K8S-060",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Node Affinity와 nodeSelector의 차이점, requiredDuringSchedulingIgnoredDuringExecution와 preferredDuringSchedulingIgnoredDuringExecution의 차이를 설명해주세요.",
    "answer": "nodeSelector vs Node Affinity:\n구분   nodeSelector   Node Affinity\n\n표현력   단순 일치   In, NotIn, Exists 등\n제약 타입   Hard만   Hard + Soft\n가중치   불가   지원\n\nrequiredDuringSchedulingIgnoredDuringExecution (Hard):\n반드시 충족해야 스케줄링\n조건 불일치 시 Pending 상태\n\npreferredDuringSchedulingIgnoredDuringExecution (Soft):\n가능하면 충족, 불가시 다른 노드 선택\nweight로 우선순위 지정 (1-100)",
    "references": [
      {
        "title": "Node Affinity",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity"
      }
    ],
    "keywords": [
      "node",
      "affinity",
      "notin",
      "exists",
      "hard",
      "soft",
      "pending",
      "구분",
      "표현력",
      "단순",
      "일치",
      "제약",
      "타입",
      "가중치",
      "불가"
    ]
  },
  {
    "id": "K8S-061",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Pod Affinity와 Pod Anti-Affinity의 개념과 사용 사례를 설명해주세요.",
    "answer": "Pod Affinity: 특정 Pod와 같은 위치에 스케줄링\nPod Anti-Affinity: 특정 Pod와 다른 위치에 스케줄링\n\n사용 사례:\n\nPod Affinity:\n웹 서버와 캐시 서버를 같은 노드에 배치 (지연 감소)\n관련 서비스 Co-location\n\nPod Anti-Affinity:\n동일 앱 Pod를 다른 노드에 분산 (고가용성)\n리소스 경합 방지\n\n-> 같은 app=web Pod가 있는 노드 피함",
    "references": [
      {
        "title": "Inter-pod Affinity",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity"
      }
    ],
    "keywords": [
      "pod",
      "affinity",
      "anti-affinity",
      "co-location",
      "특정",
      "같은",
      "위치에",
      "스케줄링",
      "다른",
      "사용",
      "사례",
      "서버와",
      "캐시",
      "서버를",
      "노드에"
    ]
  },
  {
    "id": "K8S-062",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "topologyKey의 역할과 topology spread constraints의 활용 방법을 설명해주세요.",
    "answer": "topologyKey: Pod Affinity/Anti-Affinity의 범위 정의\nkubernetes.io/hostname: 노드 단위\ntopology.kubernetes.io/zone: 가용영역 단위\ntopology.kubernetes.io/region: 리전 단위\n\nTopology Spread Constraints: Pod를 토폴로지 도메인에 균등 분산\n\n설정값:\nmaxSkew: 최대 불균형 허용치\ntopologyKey: 분산 기준 도메인\nwhenUnsatisfiable: DoNotSchedule / ScheduleAnyway\n\n활용: 가용영역 간 균등 분산으로 고가용성 확보",
    "references": [
      {
        "title": "Topology Spread Constraints",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/"
      }
    ],
    "keywords": [
      "pod",
      "affinity",
      "anti-affinity",
      "topology",
      "spread",
      "constraints",
      "donotschedule",
      "scheduleanyway",
      "범위",
      "정의",
      "노드",
      "단위",
      "가용영역",
      "리전",
      "토폴로지"
    ]
  },
  {
    "id": "K8S-063",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Taint와 Toleration의 개념과 동작 방식을 설명해주세요.",
    "answer": "Taint: 노드에 적용, Pod 배치 제한 (노드가 Pod를 밀어냄)\nToleration: Pod에 적용, 특정 Taint 허용 (Pod가 Taint 용인)\n\n동작 방식:\n노드에 Taint 설정\n해당 Taint를 Toleration하는 Pod만 스케줄링 가능\n\nTaint 적용:\n\nToleration 설정:\n\noperator:\nEqual: key와 value 모두 일치\nExists: key만 일치 (value 무시)\n\n사용 사례: 전용 노드 (GPU, 특정 팀용)",
    "references": [
      {
        "title": "Taints and Tolerations",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/"
      }
    ],
    "keywords": [
      "taint",
      "pod",
      "toleration",
      "equal",
      "exists",
      "gpu",
      "노드에",
      "적용",
      "배치",
      "제한",
      "노드가",
      "밀어냄",
      "특정",
      "허용",
      "용인"
    ]
  },
  {
    "id": "K8S-064",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Taint의 effect(NoSchedule, PreferNoSchedule, NoExecute)의 차이점을 설명해주세요.",
    "answer": "Taint Effect 종류:\n\nEffect   새 Pod 스케줄링   기존 Pod\n\nNoSchedule   차단   영향 없음\nPreferNoSchedule   가능하면 피함   영향 없음\nNoExecute   차단   제거됨\n\n상세 설명:\nNoSchedule: Toleration 없으면 절대 스케줄링 안됨\nPreferNoSchedule: Soft 제약, 다른 노드 없으면 스케줄링됨\nNoExecute: 기존 실행 중인 Pod도 제거 (tolerationSeconds로 유예 가능)\n\n사용 시나리오:\nNoSchedule: 전용 노드 분리\nPreferNoSchedule: 가능하면 분리\nNoExecute: 노드 유지보수, 장애 처리",
    "references": [
      {
        "title": "Taint Effects",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/#concepts"
      }
    ],
    "keywords": [
      "taint",
      "effect",
      "pod",
      "noschedule",
      "prefernoschedule",
      "noexecute",
      "toleration",
      "soft",
      "종류",
      "스케줄링",
      "기존",
      "차단",
      "영향",
      "없음",
      "가능하면"
    ]
  },
  {
    "id": "K8S-065",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Master/Control Plane 노드에 Pod가 스케줄되지 않는 이유와 이를 허용하는 방법을 설명해주세요.",
    "answer": "스케줄되지 않는 이유:\nControl Plane 노드에 기본 Taint 적용됨:\n\n허용 방법 1: Toleration 추가\n\n허용 방법 2: Taint 제거 (권장하지 않음)\n\n주의사항:\n프로덕션에서는 Control Plane 분리 권장\n단일 노드 클러스터 (개발용)에서만 허용 고려\nControl Plane 리소스 경합 위험",
    "references": [
      {
        "title": "Taints and Tolerations",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/"
      }
    ],
    "keywords": [
      "control",
      "plane",
      "taint",
      "toleration",
      "스케줄되지",
      "않는",
      "이유",
      "노드에",
      "기본",
      "적용됨",
      "허용",
      "방법",
      "추가",
      "제거",
      "권장하지"
    ]
  },
  {
    "id": "K8S-066",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Node에 문제가 생겼을 때 자동으로 적용되는 Taint(node.kubernetes.io/not-ready 등)에 대해 설명해주세요.",
    "answer": "자동 적용 Taint (Node Controller가 관리):\n\nTaint   상황\n\nnode.kubernetes.io/not-ready   노드 Ready 조건 False\nnode.kubernetes.io/unreachable   노드 통신 불가\nnode.kubernetes.io/memory-pressure   메모리 부족\nnode.kubernetes.io/disk-pressure   디스크 부족\nnode.kubernetes.io/pid-pressure   PID 부족\nnode.kubernetes.io/network-unavailable   네트워크 미설정\nnode.kubernetes.io/unschedulable   cordon 적용됨\n\n기본 Toleration:\nDaemonSet Pod는 기본적으로 이러한 Taint를 Toleration함\n\ntolerationSeconds:\nnot-ready, unreachable: 기본 300초 유예 후 제거\n설정으로 조정 가능",
    "references": [
      {
        "title": "Taint based Evictions",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/#taint-based-evictions"
      }
    ],
    "keywords": [
      "taint",
      "node",
      "controller",
      "not-ready",
      "ready",
      "false",
      "memory-pressure",
      "disk-pressure",
      "pid-pressure",
      "pid",
      "network-unavailable",
      "toleration",
      "daemonset",
      "pod",
      "자동"
    ]
  },
  {
    "id": "K8S-067",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "컨테이너의 resource requests와 limits의 차이점과 역할을 설명해주세요.",
    "answer": "Requests:\n스케줄링에 사용되는 최소 보장 리소스\n노드 선택 시 이 값 기준으로 용량 확인\n컨테이너에 보장되는 리소스\n\nLimits:\n컨테이너가 사용할 수 있는 최대 리소스\n이 값 초과 시 제한됨 (CPU: throttle, Memory: OOM Kill)\n\n차이점 요약:\n구분   Requests   Limits\n\n용도   스케줄링   제한\n보장   항상 보장   최대값\n초과 시   -   제한/종료",
    "references": [
      {
        "title": "Resource Management",
        "url": "https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"
      }
    ],
    "keywords": [
      "requests",
      "limits",
      "cpu",
      "memory",
      "oom",
      "kill",
      "스케줄링에",
      "사용되는",
      "최소",
      "보장",
      "리소스",
      "노드",
      "선택",
      "기준으로",
      "용량"
    ]
  },
  {
    "id": "K8S-068",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "CPU와 Memory 리소스 단위(millicore, Mi, Gi)에 대해 설명해주세요.",
    "answer": "CPU 단위:\n1: 1 CPU 코어 (1000m)\n500m: 0.5 CPU (millicore)\n100m: 0.1 CPU\n클라우드 1 vCPU = 1 코어\n\nMemory 단위:\n단위   의미   값\n\nKi   Kibibyte   1024 bytes\nMi   Mebibyte   1024 Ki\nGi   Gibibyte   1024 Mi\nK   Kilobyte   1000 bytes\nM   Megabyte   1000 K\nG   Gigabyte   1000 M\n\n예시:",
    "references": [
      {
        "title": "Resource Units",
        "url": "https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#resource-units-in-kubernetes"
      }
    ],
    "keywords": [
      "cpu",
      "memory",
      "kibibyte",
      "mebibyte",
      "gibibyte",
      "kilobyte",
      "megabyte",
      "gigabyte",
      "단위",
      "코어",
      "클라우드",
      "의미",
      "예시",
      "millicore"
    ]
  },
  {
    "id": "K8S-069",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "requests만 설정했을 때와 limits만 설정했을 때의 동작 차이를 설명해주세요.",
    "answer": "requests만 설정:\nlimits: 무제한 (노드 전체 리소스 사용 가능)\nQoS: Burstable\n스케줄링 시 requests 기준으로 노드 선택\n\nlimits만 설정:\nrequests: limits와 동일 값으로 자동 설정\nQoS: Guaranteed\n스케줄링 시 limits 값 기준\n\n권장 사항:\n항상 requests와 limits 둘 다 설정\nrequests <= limits\n프로덕션에서는 적절한 값 측정 후 설정",
    "references": [
      {
        "title": "Resource Management",
        "url": "https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"
      }
    ],
    "keywords": [
      "qos",
      "burstable",
      "guaranteed",
      "설정",
      "무제한",
      "노드",
      "전체",
      "리소스",
      "사용",
      "가능",
      "스케줄링",
      "기준으로",
      "선택",
      "동일",
      "값으로"
    ]
  },
  {
    "id": "K8S-070",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Memory limits을 초과했을 때와 CPU limits을 초과했을 때의 동작 차이를 설명해주세요.",
    "answer": "Memory Limits 초과:\nOOM (Out of Memory) Kill 발생\n컨테이너 종료, restartPolicy에 따라 재시작\n압축 불가능한 리소스 (반환 불가)\n\nCPU Limits 초과:\nCPU Throttling 발생\n컨테이너는 계속 실행\n처리 속도만 제한됨\n압축 가능한 리소스 (일시적 제한)\n\n비교:\n리소스   초과 시 동작   특성\n\nMemory   OOM Kill   압축 불가\nCPU   Throttle   압축 가능\n\n모니터링:\nMemory: containermemoryworkingsetbytes\nCPU Throttle: containercpucfsthrottledseconds_total",
    "references": [
      {
        "title": "Resource Management",
        "url": "https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"
      }
    ],
    "keywords": [
      "memory",
      "limits",
      "oom",
      "out",
      "kill",
      "cpu",
      "throttling",
      "throttle",
      "containercpucfsthrottledseconds_total",
      "초과",
      "발생",
      "컨테이너",
      "종료",
      "따라",
      "재시작"
    ]
  },
  {
    "id": "K8S-071",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Pod의 QoS(Quality of Service) 클래스(Guaranteed, Burstable, BestEffort)의 결정 기준과 의미를 설명해주세요.",
    "answer": "QoS 클래스 결정 기준:\n\nQoS   조건   Eviction 우선순위\n\nGuaranteed   모든 컨테이너: requests = limits (CPU, Memory)   최후\nBurstable   최소 하나의 requests/limits 설정   중간\nBestEffort   requests/limits 없음   최우선\n\n의미:\n노드 리소스 부족 시 Eviction 순서 결정\nBestEffort -> Burstable -> Guaranteed 순으로 제거\n\n확인 방법:\n\n권장 사항:\n중요 워크로드: Guaranteed\n일반 워크로드: Burstable (적절한 requests/limits)\n개발/테스트: BestEffort 허용 가능",
    "references": [
      {
        "title": "Pod QoS Classes",
        "url": "https://kubernetes.io/docs/concepts/workloads/pods/pod-qos/"
      }
    ],
    "keywords": [
      "qos",
      "eviction",
      "guaranteed",
      "cpu",
      "memory",
      "burstable",
      "besteffort",
      "클래스",
      "결정",
      "기준",
      "조건",
      "우선순위",
      "모든",
      "컨테이너",
      "최후"
    ]
  },
  {
    "id": "K8S-072",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "LimitRange의 역할과 설정 방법(default, defaultRequest, min, max)을 설명해주세요.",
    "answer": "역할: 네임스페이스 내 개별 컨테이너/Pod의 리소스 제약 정의\n\n설정 항목:\n항목   설명\n\ndefault   limits 미지정 시 기본값\ndefaultRequest   requests 미지정 시 기본값\nmin   최소 리소스\nmax   최대 리소스\nmaxLimitRequestRatio   limits/requests 최대 비율\n\n적용 대상: Container, Pod, PersistentVolumeClaim",
    "references": [
      {
        "title": "LimitRange",
        "url": "https://kubernetes.io/docs/concepts/policy/limit-range/"
      }
    ],
    "keywords": [
      "pod",
      "container",
      "persistentvolumeclaim",
      "역할",
      "네임스페이스",
      "개별",
      "컨테이너",
      "리소스",
      "제약",
      "정의",
      "설정",
      "항목",
      "설명",
      "미지정",
      "기본값"
    ]
  },
  {
    "id": "K8S-073",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "ResourceQuota의 역할과 네임스페이스 단위 리소스 제한 방법을 설명해주세요.",
    "answer": "역할: 네임스페이스 전체의 리소스 총량 제한\n\n제한 가능 항목:\n컴퓨팅: requests.cpu, limits.memory 등\n스토리지: requests.storage, persistentvolumeclaims\n오브젝트 수: pods, services, configmaps 등\n\n확인:\n\n주의: ResourceQuota 적용 시 Pod에 반드시 requests/limits 필요 (LimitRange와 함께 사용)",
    "references": [
      {
        "title": "ResourceQuota",
        "url": "https://kubernetes.io/docs/concepts/policy/resource-quotas/"
      }
    ],
    "keywords": [
      "resourcequota",
      "pod",
      "limitrange",
      "역할",
      "네임스페이스",
      "전체의",
      "리소스",
      "총량",
      "제한",
      "가능",
      "항목",
      "컴퓨팅",
      "스토리지",
      "오브젝트",
      "확인"
    ]
  },
  {
    "id": "K8S-074",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "PriorityClass의 역할과 Pod 우선순위 기반 스케줄링/프리엠션에 대해 설명해주세요.",
    "answer": "역할: Pod 간 우선순위 정의, 스케줄링 순서와 프리엠션 결정\n\nPriorityClass 정의:\n\nPod에 적용:\n\n프리엠션(Preemption):\n고우선순위 Pod 스케줄 불가 시 저우선순위 Pod 제거\npreemptionPolicy: PreemptLowerPriority / Never\n\n스케줄링:\n우선순위 높은 Pod 먼저 스케줄링\n\n기본 PriorityClass:\nsystem-cluster-critical (2000000000)\nsystem-node-critical (2000001000)",
    "references": [
      {
        "title": "Pod Priority and Preemption",
        "url": "https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/"
      }
    ],
    "keywords": [
      "pod",
      "priorityclass",
      "preemption",
      "preemptlowerpriority",
      "never",
      "system-cluster",
      "system-node",
      "역할",
      "우선순위",
      "정의",
      "스케줄링",
      "순서와",
      "프리엠션",
      "결정",
      "적용"
    ]
  },
  {
    "id": "K8S-075",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "HPA(Horizontal Pod Autoscaler)의 동작 원리와 설정 방법을 설명해주세요.",
    "answer": "동작 원리:\nmetrics-server에서 Pod 메트릭 수집\nHPA Controller가 주기적으로 (15초) 메트릭 확인\n목표값과 현재값 비교하여 replicas 조정\n\n설정 방법:\n\n스케일링 공식: replicas = ceil(현재 메트릭 / 목표 메트릭 * 현재 replicas)",
    "references": [
      {
        "title": "Horizontal Pod Autoscaler",
        "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
      }
    ],
    "keywords": [
      "metrics-server",
      "pod",
      "hpa",
      "controller",
      "동작",
      "원리",
      "에서",
      "메트릭",
      "수집",
      "주기적으로",
      "확인",
      "목표값과",
      "현재값",
      "비교하여",
      "조정"
    ]
  },
  {
    "id": "K8S-076",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "HPA에서 CPU/Memory 기반 스케일링과 Custom Metrics 기반 스케일링의 차이를 설명해주세요.",
    "answer": "CPU/Memory 기반 (Resource Metrics):\nmetrics-server에서 제공\n기본 제공, 설정 간단\n제한: CPU/Memory만 가능\n\nCustom Metrics 기반:\nPrometheus Adapter 등 필요\n비즈니스 메트릭 사용 가능 (RPS, Queue 길이 등)\n\nExternal Metrics: 외부 시스템 메트릭 (AWS SQS 등)\n\n선택 기준:\nCPU 바운드 앱: CPU 메트릭\nI/O 바운드 앱: Custom Metrics 권장",
    "references": [
      {
        "title": "HPA Custom Metrics",
        "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-multiple-metrics-and-custom-metrics"
      }
    ],
    "keywords": [
      "cpu",
      "memory",
      "resource",
      "metrics",
      "metrics-server",
      "custom",
      "prometheus",
      "adapter",
      "rps",
      "queue",
      "external",
      "aws",
      "sqs",
      "기반",
      "에서"
    ]
  },
  {
    "id": "K8S-077",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "HPA의 스케일링 알고리즘과 stabilizationWindowSeconds 설정의 역할을 설명해주세요.",
    "answer": "스케일링 알고리즘:\n여러 메트릭 사용 시 가장 큰 값 선택\ntolerance (기본 10%): 0.9 ~ 1.1 범위는 스케일링 안함\n\nstabilizationWindowSeconds:\n급격한 스케일링 방지를 위한 안정화 기간\n\n역할:\nscaleDown 기본값: 300초 (급격한 축소 방지)\nscaleUp 기본값: 0초 (빠른 확장)\n윈도우 내 최대/최소값 기준 스케일링",
    "references": [
      {
        "title": "HPA Algorithm",
        "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details"
      }
    ],
    "keywords": [
      "스케일링",
      "알고리즘",
      "여러",
      "메트릭",
      "사용",
      "가장",
      "선택",
      "기본",
      "범위는",
      "안함",
      "급격한",
      "방지를",
      "위한",
      "안정화",
      "기간"
    ]
  },
  {
    "id": "K8S-078",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "HPA 사용 시 주의사항과 Best Practice를 설명해주세요.",
    "answer": "주의사항:\nrequests 필수: HPA는 requests 기준으로 사용률 계산\nmetrics-server 필요: 설치되어 있어야 메트릭 수집\nDeployment 권장: ReplicaSet 직접 사용 비권장\nminReplicas: 최소 2개 이상 (고가용성)\n\nBest Practice:\n적절한 target 설정: CPU 50-80% 권장\n충분한 minReplicas: 트래픽 급증 대비\nscaleDown 안정화: 기본 300초 유지\n여러 메트릭 조합: CPU + 커스텀 메트릭\nReadiness Probe 설정: 준비된 Pod만 트래픽 수신\n\n모니터링: HPA 상태 주기적 확인",
    "references": [
      {
        "title": "HPA",
        "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
      }
    ],
    "keywords": [
      "hpa",
      "metrics-server",
      "deployment",
      "replicaset",
      "best",
      "practice",
      "cpu",
      "readiness",
      "probe",
      "pod",
      "주의사항",
      "필수",
      "기준으로",
      "사용률",
      "계산"
    ]
  },
  {
    "id": "K8S-079",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "VPA(Vertical Pod Autoscaler)의 동작 원리와 HPA와의 차이점을 설명해주세요.",
    "answer": "VPA 동작 원리:\nRecommender: 리소스 사용량 분석, 권장값 계산\nUpdater: 권장값과 현재값 차이 확인, Pod 재시작 트리거\nAdmission Controller: 새 Pod 생성 시 권장 리소스 적용\n\nHPA와의 차이:\n구분   HPA   VPA\n\n스케일링 방향   수평 (Pod 수)   수직 (리소스)\n적용 방식   즉시   Pod 재시작 필요\n사용 사례   Stateless 앱   Stateful, 단일 Pod\n함께 사용   가능 (권장 안함)   메모리만 조절 시\n\n제한사항:\nHPA와 동일 리소스(CPU/Memory) 동시 사용 불가\nPod 재시작 발생 가능",
    "references": [
      {
        "title": "Vertical Pod Autoscaler",
        "url": "https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler"
      }
    ],
    "keywords": [
      "vpa",
      "recommender",
      "updater",
      "pod",
      "admission",
      "controller",
      "hpa",
      "stateless",
      "stateful",
      "cpu",
      "memory",
      "동작",
      "원리",
      "리소스",
      "사용량"
    ]
  },
  {
    "id": "K8S-080",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "VPA의 updateMode(Off, Initial, Auto)의 차이점을 설명해주세요.",
    "answer": "updateMode 종류:\n\n모드   동작\n\nOff   권장값만 계산, 적용 안함 (관찰 모드)\nInitial   새 Pod 생성 시만 적용, 기존 Pod 변경 안함\nAuto   권장값 자동 적용, 필요시 Pod 재시작\nRecreate   Auto와 동일 (deprecated)\n\n사용 시나리오:\nOff: 권장값 확인 후 수동 적용\nInitial: 재시작 최소화, 새 Pod에만 적용\nAuto: 완전 자동화 (다운타임 허용 시)",
    "references": [
      {
        "title": "VPA Update Modes",
        "url": "https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler#quick-start"
      }
    ],
    "keywords": [
      "off",
      "initial",
      "pod",
      "auto",
      "recreate",
      "종류",
      "모드",
      "동작",
      "권장값만",
      "계산",
      "적용",
      "안함",
      "관찰",
      "생성",
      "시만"
    ]
  },
  {
    "id": "K8S-081",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Cluster Autoscaler의 동작 원리와 노드 추가/삭제 조건을 설명해주세요.",
    "answer": "동작 원리:\n클라우드 API와 연동하여 노드 그룹(ASG, MIG 등) 조정\n주기적으로 스케줄 불가 Pod 확인\n\n노드 추가 조건 (Scale Up):\nPending 상태 Pod 존재\n리소스(CPU/Memory) 부족으로 스케줄링 불가\nnodeSelector/affinity 조건 만족하는 노드 부재\n\n노드 삭제 조건 (Scale Down):\n노드 활용률 < 50% (기본, 설정 가능)\n해당 노드의 모든 Pod가 다른 노드로 이동 가능\n10분간 (기본) 유휴 상태 유지\nPDB 위반 없음\n\n삭제 제외 조건:\ncluster-autoscaler.kubernetes.io/safe-to-evict: \"false\"\n로컬 스토리지 사용\nPDB로 보호된 Pod",
    "references": [
      {
        "title": "Cluster Autoscaler",
        "url": "https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler"
      }
    ],
    "keywords": [
      "api",
      "asg",
      "mig",
      "pod",
      "scale",
      "pending",
      "cpu",
      "memory",
      "down",
      "pdb",
      "cluster-autoscaler",
      "safe-to",
      "동작",
      "원리",
      "클라우드"
    ]
  },
  {
    "id": "K8S-082",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "HPA, VPA, Cluster Autoscaler를 함께 사용할 때의 고려사항을 설명해주세요.",
    "answer": "조합 사용 시 고려사항:\n\nHPA + Cluster Autoscaler (권장):\nHPA가 Pod 수 증가 -> Pending Pod 발생 -> CA가 노드 추가\n잘 동작하는 조합\n\nVPA + Cluster Autoscaler:\nVPA가 리소스 증가 -> 노드 리소스 부족 -> CA가 노드 추가\nPod 재시작 주의\n\nHPA + VPA (주의 필요):\n동일 리소스(CPU) 동시 사용 불가 -> 충돌\n해결: VPA는 Memory만, HPA는 CPU만 (또는 커스텀 메트릭)\n\nBest Practice:\n\n권장 구성:\nStateless 앱: HPA + CA\nStateful 앱: VPA + CA\n리소스 최적화: VPA(Off) + HPA + CA",
    "references": [
      {
        "title": "Autoscaling in Kubernetes",
        "url": "https://kubernetes.io/docs/concepts/cluster-administration/cluster-autoscaling/"
      }
    ],
    "keywords": [
      "hpa",
      "cluster",
      "autoscaler",
      "pod",
      "pending",
      "vpa",
      "cpu",
      "memory",
      "best",
      "practice",
      "stateless",
      "stateful",
      "off",
      "조합",
      "사용"
    ]
  },
  {
    "id": "K8S-083",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "RBAC(Role-Based Access Control)의 개념과 구성 요소(Role, ClusterRole, RoleBinding, ClusterRoleBinding)를 설명해주세요.",
    "answer": "RBAC 개념: 역할 기반으로 Kubernetes API 접근 권한 관리\n\n구성 요소:\n\n구성 요소   범위   설명\n\nRole   네임스페이스   특정 네임스페이스 내 권한 정의\nClusterRole   클러스터   클러스터 전체 권한 정의\nRoleBinding   네임스페이스   Role을 주체에 연결\nClusterRoleBinding   클러스터   ClusterRole을 주체에 연결\n\n예시:",
    "references": [
      {
        "title": "RBAC",
        "url": "https://kubernetes.io/docs/reference/access-authn-authz/rbac/"
      }
    ],
    "keywords": [
      "rbac",
      "kubernetes",
      "api",
      "role",
      "clusterrole",
      "rolebinding",
      "clusterrolebinding",
      "개념",
      "역할",
      "기반으로",
      "접근",
      "권한",
      "관리",
      "구성",
      "요소"
    ]
  },
  {
    "id": "K8S-084",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Role과 ClusterRole의 차이점, RoleBinding과 ClusterRoleBinding의 차이점을 설명해주세요.",
    "answer": "Role vs ClusterRole:\n구분   Role   ClusterRole\n\n범위   특정 네임스페이스   클러스터 전체\n비네임스페이스 리소스   불가   가능 (nodes, PV 등)\n여러 NS 재사용   불가   가능 (RoleBinding으로)\n\nRoleBinding vs ClusterRoleBinding:\n구분   RoleBinding   ClusterRoleBinding\n\n범위   특정 네임스페이스   클러스터 전체\nRole 참조   같은 NS의 Role   ClusterRole만\nClusterRole 참조   해당 NS에만 적용   전체 NS에 적용\n\n활용 패턴:\nClusterRole + RoleBinding: 재사용 가능한 권한을 특정 NS에만 적용\nClusterRole + ClusterRoleBinding: 클러스터 전체 권한",
    "references": [
      {
        "title": "RBAC",
        "url": "https://kubernetes.io/docs/reference/access-authn-authz/rbac/"
      }
    ],
    "keywords": [
      "role",
      "clusterrole",
      "rolebinding",
      "clusterrolebinding",
      "구분",
      "범위",
      "특정",
      "네임스페이스",
      "클러스터",
      "전체",
      "비네임스페이스",
      "리소스",
      "불가",
      "가능",
      "여러"
    ]
  },
  {
    "id": "K8S-085",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "RBAC에서 verbs(get, list, watch, create, update, patch, delete)의 의미를 설명해주세요.",
    "answer": "verbs 의미:\n\nVerb   HTTP 메서드   설명\n\nget   GET   단일 리소스 조회\nlist   GET   리소스 목록 조회\nwatch   GET (watch)   리소스 변경 감시\ncreate   POST   리소스 생성\nupdate   PUT   리소스 전체 수정\npatch   PATCH   리소스 부분 수정\ndelete   DELETE   단일 리소스 삭제\ndeletecollection   DELETE   여러 리소스 삭제\n\n특수 verbs:\n*: 모든 동작 허용\nuse: PodSecurityPolicy 사용\nbind: RoleBinding 생성\nescalate: Role 권한 상승\n\n예시:",
    "references": [
      {
        "title": "RBAC verbs",
        "url": "https://kubernetes.io/docs/reference/access-authn-authz/authorization/#determine-the-request-verb"
      }
    ],
    "keywords": [
      "verb",
      "http",
      "get",
      "post",
      "put",
      "patch",
      "delete",
      "podsecuritypolicy",
      "rolebinding",
      "role",
      "의미",
      "메서드",
      "설명",
      "단일",
      "리소스"
    ]
  },
  {
    "id": "K8S-086",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "최소 권한 원칙(Principle of Least Privilege)을 Kubernetes RBAC에서 적용하는 방법을 설명해주세요.",
    "answer": "최소 권한 원칙 적용 방법:\n필요한 리소스만 지정:\n필요한 verbs만 부여:\nresourceNames로 특정 리소스 제한:\nRole 대신 ClusterRole 지양: 필요한 NS에만 권한 부여\n기본 ServiceAccount 사용 지양: 앱별 전용 ServiceAccount 생성\n정기적 감사:\n와일드카드() 사용 금지**",
    "references": [
      {
        "title": "RBAC Good Practices",
        "url": "https://kubernetes.io/docs/concepts/security/rbac-good-practices/"
      }
    ],
    "keywords": [
      "role",
      "clusterrole",
      "serviceaccount",
      "최소",
      "권한",
      "원칙",
      "적용",
      "방법",
      "필요한",
      "리소스만",
      "지정",
      "부여",
      "특정",
      "리소스",
      "제한"
    ]
  },
  {
    "id": "K8S-087",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "ServiceAccount의 역할과 Pod에서의 사용 방법을 설명해주세요.",
    "answer": "역할: Pod 내 프로세스가 Kubernetes API에 인증하기 위한 ID\n\n기본 동작:\n각 네임스페이스에 default ServiceAccount 자동 생성\nPod 생성 시 자동으로 ServiceAccount 연결\n토큰이 Pod에 자동 마운트\n\nPod에서 사용:\n\nServiceAccount 생성:\n\n토큰 위치 (Pod 내):\n\nRBAC 연동: RoleBinding으로 ServiceAccount에 권한 부여",
    "references": [
      {
        "title": "Service Accounts",
        "url": "https://kubernetes.io/docs/concepts/security/service-accounts/"
      }
    ],
    "keywords": [
      "pod",
      "kubernetes",
      "api",
      "serviceaccount",
      "rbac",
      "rolebinding",
      "역할",
      "프로세스가",
      "인증하기",
      "위한",
      "기본",
      "동작",
      "네임스페이스에",
      "자동",
      "생성"
    ]
  },
  {
    "id": "K8S-088",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "ServiceAccount 토큰의 자동 마운트와 이를 비활성화하는 방법을 설명해주세요.",
    "answer": "자동 마운트:\n기본적으로 ServiceAccount 토큰이 Pod에 자동 마운트\n경로: /var/run/secrets/kubernetes.io/serviceaccount/\n파일: token, ca.crt, namespace\n\n비활성화 방법:\nPod 레벨:\nServiceAccount 레벨:\n\n비활성화 권장 상황:\nAPI 서버 접근 불필요한 Pod\n보안 강화 필요 시\n외부에서 자격증명 주입 시\n\n우선순위: Pod 설정 > ServiceAccount 설정",
    "references": [
      {
        "title": "Configure Service Accounts",
        "url": "https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/"
      }
    ],
    "keywords": [
      "serviceaccount",
      "pod",
      "api",
      "자동",
      "마운트",
      "기본적으로",
      "토큰이",
      "경로",
      "파일",
      "비활성화",
      "방법",
      "레벨",
      "권장",
      "상황",
      "서버"
    ]
  },
  {
    "id": "K8S-089",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Kubernetes API 서버의 인증(Authentication) 방식들(X.509, Bearer Token, OIDC 등)을 설명해주세요.",
    "answer": "주요 인증 방식:\n\n방식   설명   사용 사례\n\nX.509 Client Cert   클라이언트 인증서   kubeconfig, 관리자\nBearer Token   정적 토큰 파일   서비스 계정\nServiceAccount Token   JWT 토큰   Pod 내 앱\nOIDC   OpenID Connect   SSO, 기업 인증\nWebhook   외부 인증 서비스   커스텀 인증\n\nX.509 인증서:\nCN(Common Name): 사용자 이름\nO(Organization): 그룹\n\nOIDC 장점:\n기존 IdP(Okta, Azure AD) 연동\n짧은 수명 토큰\n그룹 기반 권한 관리\n\n여러 인증 방식 조합 가능: 하나만 성공하면 인증 통과",
    "references": [
      {
        "title": "Authentication",
        "url": "https://kubernetes.io/docs/reference/access-authn-authz/authentication/"
      }
    ],
    "keywords": [
      "client",
      "cert",
      "bearer",
      "token",
      "serviceaccount",
      "jwt",
      "pod",
      "oidc",
      "openid",
      "connect",
      "sso",
      "webhook",
      "common",
      "name",
      "organization"
    ]
  },
  {
    "id": "K8S-090",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "kubeconfig 파일의 구조와 contexts, clusters, users 설정에 대해 설명해주세요.",
    "answer": "kubeconfig 구조:\n\n구성 요소:\nclusters: API 서버 주소, CA 인증서\nusers: 인증 정보 (인증서, 토큰 등)\ncontexts: cluster + user + namespace 조합\ncurrent-context: 현재 사용 중인 context\n\n명령어:",
    "references": [
      {
        "title": "Organizing Cluster Access",
        "url": "https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/"
      }
    ],
    "keywords": [
      "api",
      "current-context",
      "구조",
      "구성",
      "요소",
      "서버",
      "주소",
      "인증서",
      "인증",
      "정보",
      "토큰",
      "조합",
      "현재",
      "사용",
      "중인"
    ]
  },
  {
    "id": "K8S-091",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "NetworkPolicy의 역할과 Ingress/Egress 규칙 설정 방법을 설명해주세요.",
    "answer": "역할: Pod 간 네트워크 트래픽 제어 (방화벽 규칙)\n\n기본 동작: NetworkPolicy 없으면 모든 트래픽 허용\n\n예시:\n\n규칙 조합:\npodSelector: 같은 NS의 특정 Pod\nnamespaceSelector: 특정 NS의 Pod\nipBlock: CIDR 범위",
    "references": [
      {
        "title": "Network Policies",
        "url": "https://kubernetes.io/docs/concepts/services-networking/network-policies/"
      }
    ],
    "keywords": [
      "pod",
      "networkpolicy",
      "cidr",
      "역할",
      "네트워크",
      "트래픽",
      "제어",
      "방화벽",
      "규칙",
      "기본",
      "동작",
      "없으면",
      "모든",
      "허용",
      "예시"
    ]
  },
  {
    "id": "K8S-092",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "NetworkPolicy가 적용되지 않는 경우(CNI 미지원 등)와 기본 정책에 대해 설명해주세요.",
    "answer": "NetworkPolicy 미적용 상황:\nCNI 미지원:\nFlannel (기본): 지원 안함\n지원 CNI: Calico, Cilium, Weave Net\nNetworkPolicy 생성해도 무시됨\nHostNetwork Pod: hostNetwork: true Pod는 영향 안받음\n시스템 네임스페이스: kube-system의 Pod는 보통 제외\n\n기본 정책:\nNetworkPolicy 없음: 모든 트래픽 허용 (default allow)\nNetworkPolicy 적용 시: 해당 Pod는 명시적 허용만 가능 (default deny)\n\n전체 거부 정책:",
    "references": [
      {
        "title": "Network Policies",
        "url": "https://kubernetes.io/docs/concepts/services-networking/network-policies/"
      }
    ],
    "keywords": [
      "networkpolicy",
      "cni",
      "flannel",
      "calico",
      "cilium",
      "weave",
      "net",
      "hostnetwork",
      "pod",
      "kube-system",
      "미적용",
      "상황",
      "미지원",
      "기본",
      "지원"
    ]
  },
  {
    "id": "K8S-093",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Pod Security Standards(Privileged, Baseline, Restricted)의 차이점을 설명해주세요.",
    "answer": "Pod Security Standards (PSS):\n\n레벨   설명   사용 사례\n\nPrivileged   제한 없음, 모든 권한 허용   시스템 컴포넌트, 신뢰된 워크로드\nBaseline   최소 제한, 알려진 위험 차단   일반 워크로드\nRestricted   최대 제한, 보안 Best Practice   보안 중요 워크로드\n\n주요 제한 항목:\n항목   Baseline   Restricted\n\nhostNetwork   차단   차단\nhostPID/IPC   차단   차단\nprivileged   차단   차단\nrunAsNonRoot   -   필수\nreadOnlyRootFilesystem   -   권장\ncapabilities   일부 허용   거의 없음",
    "references": [
      {
        "title": "Pod Security Standards",
        "url": "https://kubernetes.io/docs/concepts/security/pod-security-standards/"
      }
    ],
    "keywords": [
      "pod",
      "security",
      "standards",
      "pss",
      "privileged",
      "baseline",
      "restricted",
      "best",
      "practice",
      "ipc",
      "레벨",
      "설명",
      "사용",
      "사례",
      "제한"
    ]
  },
  {
    "id": "K8S-094",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Pod Security Admission Controller의 역할과 enforce, audit, warn 모드의 차이를 설명해주세요.",
    "answer": "역할: 네임스페이스 레벨에서 Pod Security Standards 적용\n\n모드 차이:\n모드   동작   사용 목적\n\nenforce   위반 시 Pod 생성 거부   프로덕션\naudit   위반 감사 로그 기록, 허용   모니터링\nwarn   위반 경고 메시지, 허용   전환 준비\n\n네임스페이스 레이블 설정:\n\n권장 전략:\nwarn/audit로 시작하여 영향 파악\n점진적으로 enforce 적용",
    "references": [
      {
        "title": "Pod Security Admission",
        "url": "https://kubernetes.io/docs/concepts/security/pod-security-admission/"
      }
    ],
    "keywords": [
      "pod",
      "security",
      "standards",
      "역할",
      "네임스페이스",
      "레벨에서",
      "적용",
      "모드",
      "차이",
      "동작",
      "사용",
      "목적",
      "위반",
      "생성",
      "거부"
    ]
  },
  {
    "id": "K8S-095",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "컨테이너의 securityContext 설정(runAsUser, runAsNonRoot, readOnlyRootFilesystem 등)에 대해 설명해주세요.",
    "answer": "주요 securityContext 설정:\n\n설정 범위:\nPod 레벨: spec.securityContext\nContainer 레벨: spec.containers[].securityContext\nContainer 설정이 Pod 설정보다 우선\n\n권장 설정:\nrunAsNonRoot: true\nreadOnlyRootFilesystem: true\nallowPrivilegeEscalation: false\ncapabilities.drop: ALL",
    "references": [
      {
        "title": "Security Context",
        "url": "https://kubernetes.io/docs/tasks/configure-pod-container/security-context/"
      }
    ],
    "keywords": [
      "pod",
      "container",
      "all",
      "주요",
      "설정",
      "범위",
      "레벨",
      "설정이",
      "설정보다",
      "우선",
      "권장"
    ]
  },
  {
    "id": "K8S-096",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Liveness Probe의 역할과 설정 방법(httpGet, tcpSocket, exec)을 설명해주세요.",
    "answer": "역할: 컨테이너가 살아있는지 확인, 실패 시 컨테이너 재시작\n\n설정 방법:\n\nhttpGet:\n\ntcpSocket:\n\nexec:\n\n성공 조건:\nhttpGet: 200-399 응답\ntcpSocket: 연결 성공\nexec: exit code 0",
    "references": [
      {
        "title": "Configure Liveness Probes",
        "url": "https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/"
      }
    ],
    "keywords": [
      "역할",
      "컨테이너가",
      "살아있는지",
      "확인",
      "실패",
      "컨테이너",
      "재시작",
      "설정",
      "방법",
      "성공",
      "조건",
      "응답",
      "연결"
    ]
  },
  {
    "id": "K8S-097",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Readiness Probe의 역할과 Liveness Probe와의 차이점을 설명해주세요.",
    "answer": "Readiness Probe 역할: 컨테이너가 트래픽 수신 준비 되었는지 확인\n\nLiveness vs Readiness:\n구분   Liveness   Readiness\n\n목적   살아있는지 확인   준비됐는지 확인\n실패 시   컨테이너 재시작   Service에서 제외\n사용 시점   데드락 감지   시작 준비, 일시적 불가\n\nReadiness 실패 시:\nService Endpoints에서 제거\n트래픽 수신 안함\n컨테이너는 계속 실행\n\n사용 예시:\n\nBest Practice:\n둘 다 설정 권장\n다른 엔드포인트 사용 (/healthz vs /ready)",
    "references": [
      {
        "title": "Readiness Probes",
        "url": "https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-readiness-probes"
      }
    ],
    "keywords": [
      "readiness",
      "probe",
      "liveness",
      "service",
      "endpoints",
      "best",
      "practice",
      "역할",
      "컨테이너가",
      "트래픽",
      "수신",
      "준비",
      "되었는지",
      "확인",
      "구분"
    ]
  },
  {
    "id": "K8S-098",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Startup Probe의 역할과 느린 시작 애플리케이션에서의 활용 방법을 설명해주세요.",
    "answer": "역할: 애플리케이션 시작 완료 확인, 성공할 때까지 Liveness/Readiness 비활성화\n\n필요성:\n시작 시간이 긴 앱 (레거시, JVM 앱)\nLiveness의 initialDelaySeconds를 과도하게 늘리지 않아도 됨\n\n활용 방법:\n\n동작:\nStartup Probe 성공할 때까지 Liveness/Readiness 실행 안함\nStartup 성공 후 Liveness/Readiness 시작\nStartup 실패 (failureThreshold 초과) 시 컨테이너 재시작",
    "references": [
      {
        "title": "Startup Probes",
        "url": "https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-startup-probes"
      }
    ],
    "keywords": [
      "liveness",
      "readiness",
      "jvm",
      "startup",
      "probe",
      "역할",
      "애플리케이션",
      "시작",
      "완료",
      "확인",
      "성공할",
      "때까지",
      "비활성화",
      "필요성",
      "시간이"
    ]
  },
  {
    "id": "K8S-099",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Probe 설정값(initialDelaySeconds, periodSeconds, timeoutSeconds, failureThreshold)의 의미와 적절한 설정 방법을 설명해주세요.",
    "answer": "설정값 의미:\n설정   의미   기본값\n\ninitialDelaySeconds   첫 Probe 전 대기   0\nperiodSeconds   Probe 간격   10\ntimeoutSeconds   응답 대기 시간   1\nfailureThreshold   연속 실패 허용 횟수   3\nsuccessThreshold   연속 성공 필요 횟수   1\n\n적절한 설정:\n\n설정 팁:\n실패 감지 시간 = periodSeconds * failureThreshold\ntimeoutSeconds < periodSeconds\nStartup Probe 활용으로 initialDelaySeconds 최소화",
    "references": [
      {
        "title": "Configure Probes",
        "url": "https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes"
      }
    ],
    "keywords": [
      "probe",
      "startup",
      "설정값",
      "의미",
      "설정",
      "기본값",
      "대기",
      "간격",
      "응답",
      "시간",
      "연속",
      "실패",
      "허용",
      "횟수",
      "성공"
    ]
  },
  {
    "id": "K8S-100",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "잘못된 Probe 설정으로 인한 문제(CrashLoopBackOff, 서비스 불가 등)와 해결 방법을 설명해주세요.",
    "answer": "일반적인 문제와 해결:\nCrashLoopBackOff:\n원인: Liveness 실패로 계속 재시작\n해결: initialDelaySeconds 증가, Startup Probe 사용\n서비스 불가 (트래픽 수신 안함):\n원인: Readiness 계속 실패\n해결: 엔드포인트/포트 확인, threshold 조정\n느린 응답으로 인한 재시작:\n원인: timeoutSeconds 너무 짧음\n해결: timeoutSeconds 증가 (기본 1초)\n잦은 재시작:\n원인: failureThreshold 너무 낮음\n해결: 일시적 오류 고려하여 증가\n\n디버깅:\n\nBest Practice:\nLiveness/Readiness 다른 엔드포인트 사용\nLiveness는 보수적으로 (재시작 최소화)\nReadiness는 엄격하게 (준비된 Pod만)",
    "references": [
      {
        "title": "Probes",
        "url": "https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/"
      }
    ],
    "keywords": [
      "crashloopbackoff",
      "liveness",
      "startup",
      "probe",
      "readiness",
      "best",
      "practice",
      "pod",
      "일반적인",
      "문제와",
      "해결",
      "원인",
      "실패로",
      "계속",
      "재시작"
    ]
  },
  {
    "id": "K8S-101",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "kubectl logs 명령어의 다양한 옵션(-f, --previous, -c, --since)을 설명해주세요.",
    "answer": "주요 옵션:\n\n옵션   설명\n\n-f, --follow   실시간 로그 스트리밍\n--previous   이전 컨테이너 로그 (재시작 전)\n-c <container>   특정 컨테이너 지정 (멀티컨테이너)\n--since=1h   지난 1시간 로그\n--since-time   특정 시간 이후\n--tail=100   마지막 100줄\n--timestamps   타임스탬프 포함\n\n사용 예시:",
    "references": [
      {
        "title": "kubectl logs",
        "url": "https://kubernetes.io/docs/reference/kubectl/generated/kubectl_logs/"
      }
    ],
    "keywords": [
      "since-time",
      "주요",
      "옵션",
      "설명",
      "실시간",
      "로그",
      "스트리밍",
      "이전",
      "컨테이너",
      "재시작",
      "특정",
      "지정",
      "멀티컨테이너",
      "지난",
      "시간"
    ]
  },
  {
    "id": "K8S-102",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Kubernetes에서의 로깅 아키텍처와 노드 레벨/클러스터 레벨 로깅의 차이를 설명해주세요.",
    "answer": "로깅 아키텍처:\n컨테이너 stdout/stderr -> 컨테이너 런타임 -> 노드 파일시스템\n경로: /var/log/containers/, /var/log/pods/\n\n노드 레벨 로깅:\n각 노드에서 로그 로테이션\nkubelet이 관리 (logrotate)\n제한: Pod 삭제 시 로그 손실\n\n클러스터 레벨 로깅:\n중앙 집중식 로그 수집/저장\nPod 삭제 후에도 로그 보존\n\n클러스터 레벨 구현 방법:\n방법   설명\n\nNode-level agent   DaemonSet으로 Fluentd/Filebeat\nSidecar   앱과 함께 로그 수집기\nDirect push   앱에서 직접 로그 서비스로 전송\n\n일반적 스택: Fluentd + Elasticsearch + Kibana (EFK)",
    "references": [
      {
        "title": "Logging Architecture",
        "url": "https://kubernetes.io/docs/concepts/cluster-administration/logging/"
      }
    ],
    "keywords": [
      "pod",
      "node-level",
      "daemonset",
      "fluentd",
      "filebeat",
      "sidecar",
      "direct",
      "elasticsearch",
      "kibana",
      "efk",
      "로깅",
      "아키텍처",
      "컨테이너",
      "런타임",
      "노드"
    ]
  },
  {
    "id": "K8S-103",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "metrics-server의 역할과 kubectl top 명령어 사용 방법을 설명해주세요.",
    "answer": "metrics-server 역할:\n클러스터 내 리소스 메트릭 수집 (CPU, Memory)\nkubelet에서 메트릭 수집\nHPA, VPA, kubectl top에 메트릭 제공\nMetrics API 노출 (metrics.k8s.io)\n\n설치:\n\nkubectl top 사용:\n\n주의: 실시간 메트릭이 아닌 짧은 기간 평균값",
    "references": [
      {
        "title": "metrics-server",
        "url": "https://github.com/kubernetes-sigs/metrics-server"
      }
    ],
    "keywords": [
      "metrics-server",
      "cpu",
      "memory",
      "hpa",
      "vpa",
      "metrics",
      "api",
      "역할",
      "클러스터",
      "리소스",
      "메트릭",
      "수집",
      "에서",
      "제공",
      "노출"
    ]
  },
  {
    "id": "K8S-104",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Prometheus를 활용한 Kubernetes 모니터링 구성 방법을 설명해주세요.",
    "answer": "구성 요소:\nPrometheus Server: 메트릭 수집/저장\nNode Exporter: 노드 메트릭\nkube-state-metrics: K8s 오브젝트 상태\nAlertmanager: 알림 관리\nGrafana: 시각화\n\n설치 방법 (kube-prometheus-stack):\n\n서비스 디스커버리:\nPrometheus가 K8s API로 타겟 자동 발견\nPod annotation으로 스크래핑 설정\n\n주요 메트릭 소스:\nkubelet /metrics: 컨테이너 메트릭\nAPI server /metrics: API 메트릭\nNode exporter: 노드 OS 메트릭",
    "references": [
      {
        "title": "Prometheus Operator",
        "url": "https://prometheus-operator.dev/"
      }
    ],
    "keywords": [
      "prometheus",
      "server",
      "node",
      "exporter",
      "kube-state",
      "k8s",
      "alertmanager",
      "grafana",
      "kube-prometheus",
      "api",
      "pod",
      "구성",
      "요소",
      "메트릭",
      "수집"
    ]
  },
  {
    "id": "K8S-105",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Kubernetes에서 수집해야 하는 주요 메트릭(Node, Pod, Container 레벨)을 설명해주세요.",
    "answer": "Node 레벨:\nCPU 사용률: nodecpusecondstotal\n메모리: nodememoryMemAvailablebytes\n디스크: nodefilesystemavailbytes\n네트워크: nodenetworkreceivebytestotal\n\nPod/Container 레벨:\nCPU: containercpuusagesecondstotal\n메모리: containermemoryworkingsetbytes\n재시작 횟수: kubepodcontainerstatusrestartstotal\n상태: kubepodstatusphase\n\nKubernetes 오브젝트:\nDeployment replicas: kubedeploymentstatusreplicasavailable\nPVC 상태: kubepersistentvolumeclaimstatusphase\nJob 상태: kubejobstatus_succeeded\n\n알림 권장 메트릭:\nPod CrashLoopBackOff\nNode NotReady\nPVC Pending\nCPU/Memory 임계치 초과\nHPA 최대 replicas 도달",
    "references": [
      {
        "title": "kube-state-metrics",
        "url": "https://github.com/kubernetes/kube-state-metrics"
      }
    ],
    "keywords": [
      "node",
      "cpu",
      "pod",
      "container",
      "kubernetes",
      "deployment",
      "pvc",
      "job",
      "kubejobstatus_succeeded",
      "crashloopbackoff",
      "notready",
      "pending",
      "memory",
      "hpa",
      "레벨"
    ]
  },
  {
    "id": "K8S-106",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Helm의 역할과 Chart, Release, Repository의 개념을 설명해주세요.",
    "answer": "Helm 역할: Kubernetes 패키지 관리자, 앱 배포/관리 간소화\n\n핵심 개념:\n\n개념   설명\n\nChart   Kubernetes 리소스 패키지 (템플릿 + 설정)\nRelease   Chart의 설치 인스턴스\nRepository   Chart 저장소\n\n예시:\n\n특징:\n버전 관리: Chart와 Release 모두 버전화\n롤백 지원: helm rollback\n값 오버라이드: --set, -f values.yaml",
    "references": [
      {
        "title": "Helm Documentation",
        "url": "https://helm.sh/docs/"
      }
    ],
    "keywords": [
      "helm",
      "kubernetes",
      "chart",
      "release",
      "repository",
      "역할",
      "패키지",
      "관리자",
      "배포",
      "관리",
      "간소화",
      "핵심",
      "개념",
      "설명",
      "리소스"
    ]
  },
  {
    "id": "K8S-107",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Helm Chart의 구조(Chart.yaml, values.yaml, templates/)를 설명해주세요.",
    "answer": "Chart 디렉토리 구조:\n\nChart.yaml:\n\nvalues.yaml:\n\ntemplates/deployment.yaml:",
    "references": [
      {
        "title": "Chart Template Guide",
        "url": "https://helm.sh/docs/chart_template_guide/"
      }
    ],
    "keywords": [
      "chart",
      "디렉토리",
      "구조"
    ]
  },
  {
    "id": "K8S-108",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Helm의 템플릿 함수와 values.yaml을 통한 설정 오버라이드 방법을 설명해주세요.",
    "answer": "주요 템플릿 함수:\n\n설정 오버라이드 방법:\n--set 플래그:\nvalues 파일:\n여러 파일 조합 (뒤가 우선):\n\n우선순위: --set > -f (마지막) > 기본 values.yaml",
    "references": [
      {
        "title": "Helm Values",
        "url": "https://helm.sh/docs/chart_template_guide/values_files/"
      }
    ],
    "keywords": [
      "주요",
      "템플릿",
      "함수",
      "설정",
      "오버라이드",
      "방법",
      "플래그",
      "파일",
      "여러",
      "조합",
      "뒤가",
      "우선",
      "우선순위",
      "마지막",
      "기본"
    ]
  },
  {
    "id": "K8S-109",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Helm의 Release 관리(install, upgrade, rollback, uninstall)와 Revision에 대해 설명해주세요.",
    "answer": "Release 관리 명령어:\n\nRevision 개념:\n각 install/upgrade마다 Revision 번호 증가\n이전 Revision 상태 저장 (롤백용)\nSecret으로 저장 (release.* 레이블)\n\n유용한 옵션:",
    "references": [
      {
        "title": "Helm Release Management",
        "url": "https://helm.sh/docs/intro/using_helm/"
      }
    ],
    "keywords": [
      "release",
      "revision",
      "secret",
      "관리",
      "명령어",
      "개념",
      "마다",
      "번호",
      "증가",
      "이전",
      "상태",
      "저장",
      "롤백용",
      "으로",
      "레이블"
    ]
  },
  {
    "id": "K8S-110",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Helm Hooks의 역할과 pre-install, post-install 등의 사용 사례를 설명해주세요.",
    "answer": "Hook 역할: 릴리스 라이프사이클 특정 시점에 작업 실행\n\nHook 종류:\nHook   실행 시점\n\npre-install   템플릿 렌더링 후, 리소스 생성 전\npost-install   모든 리소스 생성 후\npre-upgrade   업그레이드 전\npost-upgrade   업그레이드 후\npre-delete   삭제 요청 후, 리소스 삭제 전\npost-delete   모든 리소스 삭제 후\npre-rollback   롤백 전\npost-rollback   롤백 후\n\n설정 예시:\n\n사용 사례:\npre-install: DB 스키마 마이그레이션\npost-install: 초기 데이터 로드\npre-upgrade: 백업 생성\npost-delete: 정리 작업",
    "references": [
      {
        "title": "Helm Hooks",
        "url": "https://helm.sh/docs/topics/charts_hooks/"
      }
    ],
    "keywords": [
      "hook",
      "pre-install",
      "post-install",
      "pre-upgrade",
      "post-upgrade",
      "pre-delete",
      "post-delete",
      "pre-rollback",
      "post-rollback",
      "역할",
      "릴리스",
      "라이프사이클",
      "특정",
      "시점에",
      "작업"
    ]
  },
  {
    "id": "K8S-111",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Kubernetes 클러스터 버전 업그레이드 절차와 주의사항을 설명해주세요.",
    "answer": "업그레이드 절차:\n릴리스 노트 확인 (deprecation, breaking changes)\netcd 백업\nControl Plane 업그레이드 (순차적)\nWorker Node 업그레이드 (하나씩)\n검증\n\n주의사항:\n버전 스킵 금지: 한 번에 한 마이너 버전만 (1.25 -> 1.26)\n버전 차이 제한: kubelet은 API server보다 2버전 낮을 수 있음\nAPI 변경 확인: deprecated API 미리 대응\n애드온 호환성: CNI, CSI 등 버전 확인\n\nkubeadm 업그레이드 (예시):",
    "references": [
      {
        "title": "Upgrading kubeadm clusters",
        "url": "https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/"
      }
    ],
    "keywords": [
      "control",
      "plane",
      "worker",
      "node",
      "api",
      "cni",
      "csi",
      "업그레이드",
      "절차",
      "릴리스",
      "노트",
      "확인",
      "백업",
      "순차적",
      "하나씩"
    ]
  },
  {
    "id": "K8S-112",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Control Plane 업그레이드와 Worker Node 업그레이드의 순서와 방법을 설명해주세요.",
    "answer": "순서: Control Plane 먼저 -> Worker Node\n\nControl Plane 업그레이드:\n\nWorker Node 업그레이드:\n\nHA 고려: Control Plane 하나씩 순차적으로",
    "references": [
      {
        "title": "Upgrade worker nodes",
        "url": "https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/upgrading-linux-nodes/"
      }
    ],
    "keywords": [
      "control",
      "plane",
      "worker",
      "node",
      "순서",
      "먼저",
      "업그레이드",
      "고려",
      "하나씩",
      "순차적으로"
    ]
  },
  {
    "id": "K8S-113",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "etcd 백업과 복구 방법을 설명해주세요.",
    "answer": "etcd 백업:\n\netcd 복구:\n\n백업 권장 사항:\n정기적 자동 백업 (cronjob)\n오프사이트 저장 (S3, GCS)\n복구 테스트 정기 수행",
    "references": [
      {
        "title": "Operating etcd",
        "url": "https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/"
      }
    ],
    "keywords": [
      "gcs",
      "백업",
      "복구",
      "권장",
      "사항",
      "정기적",
      "자동",
      "오프사이트",
      "저장",
      "테스트",
      "정기",
      "수행",
      "cronjob"
    ]
  },
  {
    "id": "K8S-114",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "kubectl drain과 cordon 명령어의 역할과 차이점을 설명해주세요.",
    "answer": "cordon:\n노드를 스케줄 불가(Unschedulable)로 표시\n기존 Pod는 계속 실행\n새 Pod만 스케줄링 안됨\n\ndrain:\ncordon + 기존 Pod 제거 (eviction)\nPod를 다른 노드로 이동\nDaemonSet Pod는 기본적으로 무시\n\n차이점:\n명령어   새 Pod 스케줄   기존 Pod\n\ncordon   차단   유지\ndrain   차단   제거/이동\n\ndrain 옵션:\n--ignore-daemonsets: DaemonSet Pod 무시\n--delete-emptydir-data: emptyDir 볼륨 Pod 삭제\n--force: RC 없는 Pod 강제 삭제",
    "references": [
      {
        "title": "Safely Drain a Node",
        "url": "https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/"
      }
    ],
    "keywords": [
      "unschedulable",
      "pod",
      "daemonset",
      "ignore-daemonsets",
      "delete-emptydir",
      "노드를",
      "스케줄",
      "불가",
      "표시",
      "기존",
      "계속",
      "실행",
      "스케줄링",
      "안됨",
      "제거"
    ]
  },
  {
    "id": "K8S-115",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "노드 유지보수 시 Pod 안전하게 이동시키는 방법과 PodDisruptionBudget의 역할을 설명해주세요.",
    "answer": "안전한 Pod 이동 절차:\nPDB 설정 확인/생성\nkubectl drain 실행\n유지보수 작업\nkubectl uncordon 실행\n\nPodDisruptionBudget (PDB):\n자발적 중단 시 최소 가용 Pod 수 보장\n\nPDB 동작:\ndrain 시 PDB 조건 만족해야 eviction 진행\n조건 불만족 시 eviction 대기\n강제 삭제(--force)는 PDB 무시\n\nBest Practice:\n프로덕션 워크로드에 PDB 필수\nminAvailable 또는 maxUnavailable 중 하나만 설정\nreplicas 수 고려하여 설정",
    "references": [
      {
        "title": "PodDisruptionBudget",
        "url": "https://kubernetes.io/docs/concepts/workloads/pods/disruptions/"
      }
    ],
    "keywords": [
      "pod",
      "pdb",
      "poddisruptionbudget",
      "best",
      "practice",
      "안전한",
      "이동",
      "절차",
      "설정",
      "확인",
      "생성",
      "실행",
      "유지보수",
      "작업",
      "자발적"
    ]
  },
  {
    "id": "K8S-116",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Pod가 CrashLoopBackOff 상태일 때의 원인 분석과 해결 방법을 설명해주세요.",
    "answer": "CrashLoopBackOff: 컨테이너가 반복적으로 시작 실패, 재시작 대기\n\n주요 원인:\n애플리케이션 오류 (코드 버그, 설정 오류)\n리소스 부족 (OOM Kill)\n잘못된 command/args\n의존성 문제 (DB 연결 실패)\nLiveness Probe 실패\n권한 문제\n\n분석 방법:\n\n해결 방법:\n로그 분석으로 원인 파악\nOOM: 메모리 limits 증가\n의존성: Init Container로 대기\nLiveness: Probe 설정 조정\n임시 디버깅: command: [\"sleep\", \"3600\"]",
    "references": [
      {
        "title": "Debug Pods",
        "url": "https://kubernetes.io/docs/tasks/debug/debug-application/debug-pods/"
      }
    ],
    "keywords": [
      "crashloopbackoff",
      "oom",
      "kill",
      "liveness",
      "probe",
      "init",
      "container",
      "컨테이너가",
      "반복적으로",
      "시작",
      "실패",
      "재시작",
      "대기",
      "주요",
      "원인"
    ]
  },
  {
    "id": "K8S-117",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Pod가 ImagePullBackOff 상태일 때의 원인과 해결 방법을 설명해주세요.",
    "answer": "ImagePullBackOff: 이미지 다운로드 반복 실패\n\n주요 원인:\n이미지 이름/태그 오타\n이미지 존재하지 않음\nPrivate registry 인증 실패\n네트워크 문제\nRegistry 접근 불가\n\n분석 방법:\n\n해결 방법:\n\n이미지 확인:\n\nPrivate registry 인증:\n\n이미지 정책 확인:\nimagePullPolicy: Always -> 항상 pull\nimagePullPolicy: IfNotPresent -> 없을 때만",
    "references": [
      {
        "title": "Images",
        "url": "https://kubernetes.io/docs/concepts/containers/images/"
      }
    ],
    "keywords": [
      "imagepullbackoff",
      "private",
      "registry",
      "always",
      "ifnotpresent",
      "이미지",
      "다운로드",
      "반복",
      "실패",
      "주요",
      "원인",
      "이름",
      "태그",
      "오타",
      "존재하지"
    ]
  },
  {
    "id": "K8S-118",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "kubectl describe, kubectl logs, kubectl exec를 활용한 디버깅 방법을 설명해주세요.",
    "answer": "kubectl describe:\n리소스 상세 정보와 이벤트 확인\n\nkubectl logs:\n컨테이너 로그 확인\n\nkubectl exec:\n컨테이너 내부 명령 실행\n\n디버깅 순서:\ndescribe로 이벤트 확인\nlogs로 애플리케이션 로그 확인\nexec로 내부 상태 확인",
    "references": [
      {
        "title": "Debug Running Pods",
        "url": "https://kubernetes.io/docs/tasks/debug/debug-application/debug-running-pod/"
      }
    ],
    "keywords": [
      "리소스",
      "상세",
      "정보와",
      "이벤트",
      "확인",
      "컨테이너",
      "로그",
      "내부",
      "명령",
      "실행",
      "디버깅",
      "순서",
      "애플리케이션",
      "상태"
    ]
  },
  {
    "id": "K8S-119",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "kubectl debug 명령어를 활용한 ephemeral container 디버깅 방법을 설명해주세요.",
    "answer": "kubectl debug: 실행 중인 Pod에 디버깅 컨테이너 추가\n\nEphemeral Container 사용:\n\nPod 복사본으로 디버깅:\n\n노드 디버깅:\n\n장점:\nDistroless 이미지 디버깅 가능\n실행 중인 Pod 변경 없이 디버깅\n네트워크/프로세스 네임스페이스 공유",
    "references": [
      {
        "title": "Debug with Ephemeral Containers",
        "url": "https://kubernetes.io/docs/tasks/debug/debug-application/debug-running-pod/#ephemeral-container"
      }
    ],
    "keywords": [
      "pod",
      "ephemeral",
      "container",
      "distroless",
      "실행",
      "중인",
      "디버깅",
      "컨테이너",
      "추가",
      "사용",
      "복사본으로",
      "노드",
      "장점",
      "이미지",
      "가능"
    ]
  },
  {
    "id": "K8S-120",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Service에 연결되지 않는 Pod 문제 해결 방법(selector, endpoints 확인 등)을 설명해주세요.",
    "answer": "문제 분석 단계:\nService selector 확인:\nPod 레이블 확인:\nEndpoints 확인:\nPod 상태 확인:\n포트 확인:\n\n일반적인 원인:\nselector 오타\n레이블 불일치\nReadiness Probe 실패\nPod가 Running이 아님\n포트 번호 불일치\n\n테스트:",
    "references": [
      {
        "title": "Debug Services",
        "url": "https://kubernetes.io/docs/tasks/debug/debug-application/debug-service/"
      }
    ],
    "keywords": [
      "service",
      "pod",
      "endpoints",
      "readiness",
      "probe",
      "running",
      "문제",
      "분석",
      "단계",
      "확인",
      "레이블",
      "상태",
      "포트",
      "일반적인",
      "원인"
    ]
  },
  {
    "id": "K8S-121",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "DNS 관련 문제 해결 방법(CoreDNS 확인, nslookup 테스트 등)을 설명해주세요.",
    "answer": "DNS 문제 진단:\nCoreDNS 상태 확인:\nPod 내부에서 DNS 테스트:\nresolv.conf 확인:\nCoreDNS ConfigMap 확인:\n\n일반적인 원인:\nCoreDNS Pod 장애\nNetworkPolicy로 DNS 차단\n잘못된 Service/Namespace 이름\n노드 DNS 설정 문제\n\nDNS 형식:\nService: <svc>.<ns>.svc.cluster.local\nPod: <pod-ip>.<ns>.pod.cluster.local",
    "references": [
      {
        "title": "Debugging DNS Resolution",
        "url": "https://kubernetes.io/docs/tasks/administer-cluster/dns-debugging-resolution/"
      }
    ],
    "keywords": [
      "dns",
      "coredns",
      "pod",
      "configmap",
      "networkpolicy",
      "service",
      "namespace",
      "pod-ip",
      "문제",
      "진단",
      "상태",
      "확인",
      "내부에서",
      "테스트",
      "일반적인"
    ]
  },
  {
    "id": "K8S-122",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "서비스 메시(Service Mesh)의 개념과 필요성에 대해 설명해주세요.",
    "answer": "서비스 메시 개념: 마이크로서비스 간 통신을 관리하는 인프라 계층\n\n구성:\nData Plane: Sidecar 프록시 (Envoy)로 트래픽 처리\nControl Plane: 정책 관리, 설정 배포\n\n필요성:\n\n기능   설명\n\n트래픽 관리   로드밸런싱, 라우팅, A/B 테스트, Canary\n보안   mTLS 암호화, 인증/인가\n관찰성   분산 추적, 메트릭, 로그\n복원력   재시도, 타임아웃, 서킷브레이커\n\n없을 때 문제점:\n각 서비스에서 직접 구현 필요\n언어/프레임워크별 다른 구현\n일관성 없는 보안/모니터링\n\n적합한 상황:\n많은 마이크로서비스\n복잡한 서비스 간 통신\n강화된 보안 요구사항",
    "references": [
      {
        "title": "Service Mesh",
        "url": "https://istio.io/latest/about/service-mesh/"
      }
    ],
    "keywords": [
      "data",
      "plane",
      "sidecar",
      "envoy",
      "control",
      "canary",
      "서비스",
      "메시",
      "개념",
      "마이크로서비스",
      "통신을",
      "관리하는",
      "인프라",
      "계층",
      "구성"
    ]
  },
  {
    "id": "K8S-123",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Sidecar Proxy 패턴과 서비스 메시에서의 트래픽 제어 방식을 설명해주세요.",
    "answer": "Sidecar Proxy 패턴:\n각 Pod에 프록시 컨테이너 (Envoy) 주입\n모든 인바운드/아웃바운드 트래픽이 프록시 경유\n애플리케이션 코드 수정 없이 기능 추가\n\n트래픽 흐름:\n\n트래픽 제어 방식:\n로드밸런싱:\nRound Robin, Least Connection, Random\n가중치 기반 분배\n트래픽 분할:\n재시도/타임아웃:\n서킷브레이커:\n연속 실패 시 요청 차단\n서비스 장애 전파 방지",
    "references": [
      {
        "title": "Istio Traffic Management",
        "url": "https://istio.io/latest/docs/concepts/traffic-management/"
      }
    ],
    "keywords": [
      "sidecar",
      "proxy",
      "pod",
      "envoy",
      "round",
      "robin",
      "least",
      "connection",
      "random",
      "패턴",
      "프록시",
      "컨테이너",
      "주입",
      "모든",
      "인바운드"
    ]
  },
  {
    "id": "K8S-124",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Istio의 아키텍처와 주요 컴포넌트(Envoy, Istiod)에 대해 설명해주세요.",
    "answer": "Istio 아키텍처:\n\nData Plane:\nEnvoy Proxy: 각 Pod의 Sidecar로 배포\nL4/L7 프록시\n트래픽 라우팅, 로드밸런싱\nTLS 종료, 인증\n메트릭 수집\n\nControl Plane:\nIstiod: 통합 컨트롤 플레인 (Pilot + Citadel + Galley 통합)\nPilot: 서비스 디스커버리, 트래픽 정책\nCitadel: 인증서 관리, mTLS\nGalley: 설정 검증, 배포\n\n설치:\n\nCRD:\nVirtualService: 트래픽 라우팅 규칙\nDestinationRule: 로드밸런싱, 서킷브레이커\nGateway: Ingress/Egress 설정\nAuthorizationPolicy: 접근 제어",
    "references": [
      {
        "title": "Istio Architecture",
        "url": "https://istio.io/latest/docs/ops/deployment/architecture/"
      }
    ],
    "keywords": [
      "istio",
      "data",
      "plane",
      "envoy",
      "proxy",
      "pod",
      "sidecar",
      "tls",
      "control",
      "istiod",
      "pilot",
      "citadel",
      "galley",
      "crd",
      "virtualservice"
    ]
  },
  {
    "id": "K8S-125",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Istio의 트래픽 관리 기능(VirtualService, DestinationRule)에 대해 설명해주세요.",
    "answer": "VirtualService: 요청 라우팅 규칙 정의\n\nDestinationRule: 목적지 정책 정의\n\n주요 기능:\n트래픽 분할 (Canary, A/B)\n헤더 기반 라우팅\n재시도, 타임아웃\n서킷브레이커",
    "references": [
      {
        "title": "Istio Traffic Management",
        "url": "https://istio.io/latest/docs/concepts/traffic-management/"
      }
    ],
    "keywords": [
      "virtualservice",
      "destinationrule",
      "canary",
      "요청",
      "라우팅",
      "규칙",
      "정의",
      "목적지",
      "정책",
      "주요",
      "기능",
      "트래픽",
      "분할",
      "헤더",
      "기반"
    ]
  },
  {
    "id": "K8S-126",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Istio의 보안 기능(mTLS, Authorization Policy)에 대해 설명해주세요.",
    "answer": "mTLS (Mutual TLS):\n서비스 간 양방향 TLS 인증/암호화\n\n모드:\nSTRICT: mTLS만 허용\nPERMISSIVE: mTLS와 평문 모두 허용 (마이그레이션용)\nDISABLE: mTLS 비활성화\n\nAuthorization Policy:\n서비스 간 접근 제어\n\n기능: ServiceAccount 기반 인증, HTTP 메서드/경로 기반 인가",
    "references": [
      {
        "title": "Istio Security",
        "url": "https://istio.io/latest/docs/concepts/security/"
      }
    ],
    "keywords": [
      "mutual",
      "tls",
      "strict",
      "permissive",
      "disable",
      "authorization",
      "policy",
      "serviceaccount",
      "http",
      "서비스",
      "양방향",
      "인증",
      "암호화",
      "모드",
      "허용"
    ]
  },
  {
    "id": "K8S-127",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Linkerd의 특징과 Istio와의 비교를 설명해주세요.",
    "answer": "Linkerd 특징:\n경량화, 단순성 중시\nRust로 작성된 프록시 (linkerd2-proxy)\n빠른 설치, 낮은 리소스 사용\nCNCF graduated 프로젝트\n\nIstio vs Linkerd 비교:\n\n항목   Istio   Linkerd\n\n프록시   Envoy (C++)   linkerd2-proxy (Rust)\n복잡도   높음   낮음\n리소스   더 많이 사용   경량\n기능   풍부   핵심 기능 집중\n학습 곡선   가파름   완만\n커뮤니티   더 큼   성장 중\n\n선택 기준:\nIstio: 복잡한 트래픽 관리, 풍부한 기능 필요\nLinkerd: 단순함, 낮은 오버헤드 우선\n\nLinkerd 설치:",
    "references": [
      {
        "title": "Linkerd",
        "url": "https://linkerd.io/"
      }
    ],
    "keywords": [
      "linkerd",
      "rust",
      "cncf",
      "istio",
      "envoy",
      "특징",
      "경량화",
      "단순성",
      "중시",
      "작성된",
      "프록시",
      "빠른",
      "설치",
      "낮은",
      "리소스"
    ]
  },
  {
    "id": "K8S-128",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "CRD(Custom Resource Definition)의 개념과 Kubernetes 확장 방법을 설명해주세요.",
    "answer": "CRD 개념: Kubernetes API를 확장하여 사용자 정의 리소스 타입 생성\n\nCRD 정의 예시:\n\nCustom Resource 사용:\n\n확장 방법:\nCRD로 리소스 타입 정의\nCustom Controller로 리소스 관리 로직 구현\nOperator 패턴으로 운영 자동화",
    "references": [
      {
        "title": "Custom Resources",
        "url": "https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"
      }
    ],
    "keywords": [
      "crd",
      "kubernetes",
      "api",
      "custom",
      "resource",
      "controller",
      "operator",
      "개념",
      "확장하여",
      "사용자",
      "정의",
      "리소스",
      "타입",
      "생성",
      "예시"
    ]
  },
  {
    "id": "K8S-129",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Custom Resource와 Custom Controller의 관계를 설명해주세요.",
    "answer": "관계: Custom Resource는 \"원하는 상태\", Controller는 \"실제 구현\"\n\nCustom Resource (CR):\n사용자가 정의한 Kubernetes 오브젝트\n원하는 상태(spec)를 선언\netcd에 저장됨\n\nCustom Controller:\nCR을 감시(watch)\n현재 상태와 원하는 상태 비교\n차이를 해소하는 동작 수행 (Reconciliation Loop)\n\n동작 흐름:\n\n예시:",
    "references": [
      {
        "title": "Controller Pattern",
        "url": "https://kubernetes.io/docs/concepts/architecture/controller/"
      }
    ],
    "keywords": [
      "custom",
      "resource",
      "controller",
      "kubernetes",
      "reconciliation",
      "loop",
      "관계",
      "원하는",
      "상태",
      "실제",
      "구현",
      "사용자가",
      "정의한",
      "오브젝트",
      "선언"
    ]
  },
  {
    "id": "K8S-130",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Operator 패턴이란 무엇이며, 어떤 상황에서 사용하나요?",
    "answer": "Operator 패턴: CRD + Custom Controller로 복잡한 애플리케이션 운영 자동화\n\n핵심 개념:\n운영자(Operator)의 지식을 코드화\n도메인 전문 지식을 Kubernetes 리소스로 표현\n자동 복구, 스케일링, 업그레이드 등 자동화\n\n사용 상황:\nStateful 애플리케이션: 데이터베이스, 메시지 큐\n복잡한 설정: 클러스터링, 복제 설정\n운영 자동화: 백업, 복구, 업그레이드\n도메인 지식 필요: 특정 애플리케이션의 운영 노하우\n\n예시:\n\nOperator vs Helm:\nHelm: 설치/업그레이드 시점만\nOperator: 전체 라이프사이클 관리",
    "references": [
      {
        "title": "Operator Pattern",
        "url": "https://kubernetes.io/docs/concepts/extend-kubernetes/operator/"
      }
    ],
    "keywords": [
      "operator",
      "crd",
      "custom",
      "controller",
      "kubernetes",
      "stateful",
      "helm",
      "패턴",
      "복잡한",
      "애플리케이션",
      "운영",
      "자동화",
      "핵심",
      "개념",
      "운영자"
    ]
  },
  {
    "id": "K8S-131",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Operator Framework(Operator SDK, Kubebuilder)를 활용한 Operator 개발 방법을 설명해주세요.",
    "answer": "주요 프레임워크:\n\n프레임워크   특징\n\nKubebuilder   Go 기반, CNCF 프로젝트\nOperator SDK   Go/Ansible/Helm 지원, Red Hat\n\nKubebuilder 개발 흐름:\n\nReconcile 함수 예시:",
    "references": [
      {
        "title": "Kubebuilder Book",
        "url": "https://book.kubebuilder.io/"
      }
    ],
    "keywords": [
      "kubebuilder",
      "cncf",
      "operator",
      "sdk",
      "ansible",
      "helm",
      "red",
      "hat",
      "reconcile",
      "주요",
      "프레임워크",
      "특징",
      "기반",
      "프로젝트",
      "지원"
    ]
  },
  {
    "id": "K8S-132",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "유명한 Operator 사례(Prometheus Operator, MySQL Operator 등)와 그 장점을 설명해주세요.",
    "answer": "주요 Operator 사례:\n\nOperator   용도   장점\n\nPrometheus Operator   모니터링   ServiceMonitor CRD로 자동 타겟 설정\nCert-Manager   인증서 관리   Let's Encrypt 자동 발급/갱신\nStrimzi   Kafka   클러스터 자동 관리, 업그레이드\nZalando PostgreSQL   PostgreSQL   HA, 자동 페일오버\nElastic Operator   Elasticsearch   클러스터 관리, 스케일링\nArgoCD   GitOps   자동 배포, 동기화\n\nPrometheus Operator 예시:\n\nOperator 장점:\n복잡한 운영 작업 자동화\n일관된 배포/업그레이드\n도메인 전문 지식 캡슐화\n자가 치유 (self-healing)",
    "references": [
      {
        "title": "OperatorHub.io",
        "url": "https://operatorhub.io/"
      }
    ],
    "keywords": [
      "operator",
      "prometheus",
      "servicemonitor",
      "crd",
      "cert-manager",
      "let",
      "encrypt",
      "strimzi",
      "kafka",
      "zalando",
      "postgresql",
      "elastic",
      "elasticsearch",
      "argocd",
      "gitops"
    ]
  },
  {
    "id": "K8S-133",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Kubernetes 클러스터 내 Pod 간 통신 원리를 설명해주세요.",
    "answer": "Kubernetes 네트워크 모델 요구사항:\n모든 Pod는 NAT 없이 다른 Pod와 통신 가능\n모든 노드는 NAT 없이 모든 Pod와 통신 가능\nPod가 보는 자신의 IP = 다른 Pod가 보는 IP\n\nPod 간 통신 방식:\n\n같은 노드 내:\n가상 이더넷 쌍 (veth)\n리눅스 브릿지로 연결\n\n다른 노드 간:\n\nCNI 구현 방식:\n오버레이: VXLAN 터널 (Flannel, Weave)\n라우팅: BGP 기반 (Calico)\neBPF: 커널 레벨 라우팅 (Cilium)\n\nPod IP 할당:\n노드별 Pod CIDR 범위 할당\nCNI가 Pod에 IP 할당",
    "references": [
      {
        "title": "Cluster Networking",
        "url": "https://kubernetes.io/docs/concepts/cluster-administration/networking/"
      }
    ],
    "keywords": [
      "kubernetes",
      "pod",
      "nat",
      "cni",
      "vxlan",
      "flannel",
      "weave",
      "bgp",
      "calico",
      "cilium",
      "cidr",
      "네트워크",
      "모델",
      "요구사항",
      "모든"
    ]
  },
  {
    "id": "K8S-134",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Service의 ClusterIP가 동작하는 원리(kube-proxy, iptables/IPVS)를 설명해주세요.",
    "answer": "ClusterIP 동작 원리:\nClusterIP는 가상 IP로, 실제 인터페이스에 바인딩되지 않음\n\nkube-proxy 역할:\nAPI Server에서 Service/Endpoints 변경 감지\n노드에 트래픽 라우팅 규칙 설정\n\niptables 모드:\nService당 iptables 규칙 생성\n랜덤 Pod 선택 (확률 기반)\n규칙 많아지면 성능 저하\n\nIPVS 모드:\n커널 레벨 로드밸런서\n해시 테이블 기반 (O(1) 조회)\n다양한 알고리즘 (rr, lc, sh, dh)\n대규모 클러스터에 적합\n\n확인:",
    "references": [
      {
        "title": "Virtual IPs and Service Proxies",
        "url": "https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"
      }
    ],
    "keywords": [
      "clusterip",
      "kube-proxy",
      "api",
      "server",
      "service",
      "endpoints",
      "pod",
      "ipvs",
      "동작",
      "원리",
      "가상",
      "실제",
      "인터페이스에",
      "바인딩되지",
      "않음"
    ]
  },
  {
    "id": "K8S-135",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Pod에서 외부 서비스로 통신할 때의 네트워크 흐름을 설명해주세요.",
    "answer": "네트워크 흐름:\n\n상세 단계:\nPod에서 요청 발생\n소스: Pod IP, 목적지: 외부 IP\nCNI 네트워크 통과\nPod -> veth -> bridge -> 노드 eth0\nSNAT (Source NAT)\n소스 IP: Pod IP -> 노드 IP로 변환\n외부에서 응답 가능하도록\n외부로 전송\n노드의 기본 라우팅 테이블 사용\n응답 수신\n역SNAT: 노드 IP -> Pod IP\nPod로 전달\n\nEgress 제어:\nNetworkPolicy: 아웃바운드 트래픽 제한\nNAT Gateway: 클라우드 환경에서 고정 IP 사용\n\nExternalName Service:",
    "references": [
      {
        "title": "Cluster Networking",
        "url": "https://kubernetes.io/docs/concepts/cluster-administration/networking/"
      }
    ],
    "keywords": [
      "pod",
      "cni",
      "snat",
      "source",
      "nat",
      "egress",
      "networkpolicy",
      "gateway",
      "externalname",
      "service",
      "네트워크",
      "흐름",
      "상세",
      "단계",
      "에서"
    ]
  },
  {
    "id": "K8S-136",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Gateway API의 개념과 Ingress와의 차이점을 설명해주세요.",
    "answer": "Gateway API: 차세대 Ingress API, Kubernetes SIG-Network에서 개발\n\n주요 리소스:\nGatewayClass: 인프라 공급자 정의 (클러스터 관리자)\nGateway: 로드밸런서 인스턴스 (인프라 관리자)\nHTTPRoute: 라우팅 규칙 (앱 개발자)\n\nIngress와의 차이:\n\n항목   Ingress   Gateway API\n\n프로토콜   HTTP/HTTPS   HTTP, TCP, UDP, gRPC\n역할 분리   없음   GatewayClass/Gateway/Route\n확장성   annotations   명시적 CRD\n표준화   느슨함   엄격한 스펙\n트래픽 분할   미지원   기본 지원\n\n예시:",
    "references": [
      {
        "title": "Gateway API",
        "url": "https://gateway-api.sigs.k8s.io/"
      }
    ],
    "keywords": [
      "gateway",
      "api",
      "ingress",
      "kubernetes",
      "sig-network",
      "gatewayclass",
      "httproute",
      "http",
      "https",
      "tcp",
      "udp",
      "route",
      "crd",
      "차세대",
      "에서"
    ]
  },
  {
    "id": "K8S-137",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "멀티 클러스터 관리의 필요성과 주요 고려사항을 설명해주세요.",
    "answer": "필요성:\n고가용성: 리전/가용영역 장애 대비\n지연 최소화: 사용자 가까운 리전에 배포\n규정 준수: 데이터 지역성 요구사항\n격리: 환경별, 팀별 분리\n스케일: 단일 클러스터 한계 극복\n\n주요 고려사항:\n\n영역   고려사항\n\n네트워킹   클러스터 간 통신, Service mesh\n데이터   상태 동기화, 데이터 복제\n배포   일관된 배포 전략, GitOps\n보안   통합 인증/인가, Secret 관리\n모니터링   중앙 집중식 관찰성\n관리   클러스터 프로비저닝 자동화\n\n도구:\nRancher, OpenShift\nCluster API\nLiqo, Submariner (네트워킹)\nIstio (서비스 메시)",
    "references": [
      {
        "title": "Multi-cluster",
        "url": "https://kubernetes.io/docs/concepts/cluster-administration/"
      }
    ],
    "keywords": [
      "service",
      "gitops",
      "secret",
      "rancher",
      "openshift",
      "cluster",
      "api",
      "liqo",
      "submariner",
      "istio",
      "필요성",
      "고가용성",
      "리전",
      "가용영역",
      "장애"
    ]
  },
  {
    "id": "K8S-138",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Federation의 개념과 멀티 클러스터 배포 전략을 설명해주세요.",
    "answer": "Federation 개념: 여러 클러스터를 단일 논리적 단위로 관리\n\nKubeFed (Kubernetes Federation v2):\n중앙 제어 플레인에서 여러 클러스터 관리\nFederatedDeployment 등 Federated 리소스\n클러스터별 오버라이드 지원\n\n멀티 클러스터 배포 전략:\n\n전략   설명\n\nActive-Active   모든 클러스터에서 트래픽 처리\nActive-Passive   장애 시 대기 클러스터 활성화\nFollow-the-Sun   시간대별 활성 클러스터 변경\nSharding   데이터/사용자별 클러스터 분리\n\n도구: KubeFed, Cluster API, ArgoCD ApplicationSet",
    "references": [
      {
        "title": "KubeFed",
        "url": "https://github.com/kubernetes-sigs/kubefed"
      }
    ],
    "keywords": [
      "federation",
      "kubefed",
      "kubernetes",
      "federateddeployment",
      "federated",
      "active-active",
      "active-passive",
      "follow-the-sun",
      "sharding",
      "cluster",
      "api",
      "argocd",
      "applicationset",
      "개념",
      "여러"
    ]
  },
  {
    "id": "K8S-139",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "GitOps의 개념과 ArgoCD를 활용한 Kubernetes 배포 방법을 설명해주세요.",
    "answer": "GitOps 개념:\nGit을 Single Source of Truth로 사용\n선언적 인프라/앱 정의\n자동화된 동기화 (Git -> 클러스터)\n\nGitOps 원칙:\n선언적 시스템\nGit에 버전 관리\n자동 적용\n지속적 검증 및 동기화\n\nArgoCD 설치:\n\nApplication 정의:\n\n워크플로우:\nGit Push -> ArgoCD 감지 -> Sync -> 클러스터 배포",
    "references": [
      {
        "title": "ArgoCD",
        "url": "https://argo-cd.readthedocs.io/"
      }
    ],
    "keywords": [
      "gitops",
      "git",
      "single",
      "source",
      "truth",
      "argocd",
      "application",
      "push",
      "sync",
      "개념",
      "사용",
      "선언적",
      "인프라",
      "정의",
      "자동화된"
    ]
  },
  {
    "id": "K8S-140",
    "category": "kubernetes",
    "categoryName": "Kubernetes",
    "priority": "P2",
    "question": "Flux와 ArgoCD의 비교 및 선택 기준을 설명해주세요.",
    "answer": "ArgoCD vs Flux 비교:\n\n항목   ArgoCD   Flux\n\nUI   웹 UI 기본 제공   별도 설치 필요\n아키텍처   중앙 집중식   분산형 (에이전트)\n리소스 사용   더 많음   경량\n멀티테넌시   Project로 지원   네임스페이스 기반\nHelm 지원   네이티브   Helm Controller\n학습 곡선   완만   조금 가파름\nCNCF   Incubating   Graduated\n\nArgoCD 선택 시:\n웹 UI 필요\n팀 단위 접근 제어 필요\n시각적 상태 확인 중요\n\nFlux 선택 시:\n경량 솔루션 선호\nCLI 중심 워크플로우\n엣지/소규모 클러스터\nKustomize 활용 많음\n\n공통점:\nGit 기반 배포\n자동 동기화\nKubernetes 네이티브",
    "references": [
      {
        "title": "Flux",
        "url": "https://fluxcd.io/"
      },
      {
        "title": "ArgoCD",
        "url": "https://argo-cd.readthedocs.io/"
      }
    ],
    "keywords": [
      "argocd",
      "flux",
      "project",
      "helm",
      "controller",
      "cncf",
      "incubating",
      "graduated",
      "cli",
      "kustomize",
      "git",
      "kubernetes",
      "비교",
      "항목",
      "기본"
    ]
  },
  {
    "id": "KAFKA-001",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka의 기본 아키텍처와 주요 컴포넌트(Producer, Broker, Consumer, Topic 등)에 대해 설명해주세요.",
    "answer": "Kafka는 분산 스트리밍 플랫폼으로, 다음과 같은 주요 컴포넌트로 구성됩니다:\nProducer: 메시지를 생성하여 Topic에 발행하는 클라이언트\nBroker: 메시지를 저장하고 관리하는 Kafka 서버. 클러스터는 여러 Broker로 구성됨\nConsumer: Topic에서 메시지를 읽어 처리하는 클라이언트\nTopic: 메시지가 저장되는 논리적 채널. 카테고리 또는 피드 이름과 유사\nPartition: Topic을 물리적으로 분할한 단위. 병렬 처리와 확장성을 제공\nZooKeeper/KRaft: 클러스터 메타데이터 관리 및 리더 선출 담당\n\n메시지 흐름: Producer → Broker(Topic/Partition) → Consumer",
    "references": [
      {
        "title": "Apache Kafka Documentation",
        "url": "https://kafka.apache.org/documentation/#gettingStarted"
      }
    ],
    "keywords": [
      "kafka",
      "producer",
      "topic",
      "broker",
      "consumer",
      "partition",
      "zookeeper",
      "kraft",
      "분산",
      "스트리밍",
      "플랫폼으로",
      "다음과",
      "같은",
      "주요",
      "컴포넌트로"
    ]
  },
  {
    "id": "KAFKA-002",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka Broker의 역할과 주요 기능은 무엇인가요?",
    "answer": "Kafka Broker는 Kafka 클러스터의 핵심 서버로, 다음과 같은 역할을 수행합니다:\n메시지 저장: Producer로부터 받은 메시지를 디스크에 영구 저장\n메시지 전달: Consumer 요청 시 저장된 메시지를 전달\n파티션 관리: 각 파티션의 리더 또는 팔로워 역할 수행\n복제 관리: 데이터 복제를 통한 내결함성 보장\n클라이언트 요청 처리: Producer/Consumer의 메타데이터 요청 처리\n\nBroker는 Controller로 선출되어 파티션 리더 선출, 브로커 장애 감지 등 클러스터 관리 작업을 수행할 수 있습니다.",
    "references": [
      {
        "title": "Apache Kafka Documentation - Design",
        "url": "https://kafka.apache.org/documentation/#design"
      }
    ],
    "keywords": [
      "kafka",
      "broker",
      "producer",
      "consumer",
      "controller",
      "클러스터의",
      "핵심",
      "서버로",
      "다음과",
      "같은",
      "역할을",
      "수행합니다",
      "메시지",
      "저장",
      "로부터"
    ]
  },
  {
    "id": "KAFKA-003",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Producer와 Consumer의 차이점 및 역할에 대해 설명해 주세요.",
    "answer": "Producer (생산자)\n메시지를 생성하여 Kafka Topic에 발행\n파티션 선택 전략 결정 (라운드 로빈, 키 기반 해싱 등)\n배치 전송, 압축, 재시도 등 설정 가능\nACK 설정으로 전송 신뢰성 조절\n\nConsumer (소비자)\nTopic에서 메시지를 구독하고 처리\nOffset을 관리하여 처리 위치 추적\nConsumer Group에 속하여 병렬 처리 가능\nPull 방식으로 메시지를 가져옴 (Consumer가 능동적으로 요청)\n\n핵심 차이점: Producer는 데이터를 밀어넣고(push), Consumer는 데이터를 당겨옴(pull)",
    "references": [
      {
        "title": "Apache Kafka Documentation - Producers",
        "url": "https://kafka.apache.org/documentation/#theproducer"
      }
    ],
    "keywords": [
      "producer",
      "kafka",
      "topic",
      "ack",
      "consumer",
      "offset",
      "group",
      "pull",
      "생산자",
      "메시지를",
      "생성하여",
      "발행",
      "파티션",
      "선택",
      "전략"
    ]
  },
  {
    "id": "KAFKA-004",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka에서 Partition과 Offset의 개념 및 활용 방법은 무엇인가요?",
    "answer": "Partition (파티션)\nTopic을 물리적으로 분할한 단위\n각 파티션은 순서가 보장된 불변의 메시지 시퀀스\n병렬 처리의 기본 단위 (파티션 수 = 최대 Consumer 병렬성)\n파티션 키를 통해 관련 메시지를 같은 파티션에 저장 가능\n\nOffset (오프셋)\n파티션 내 각 메시지의 고유 식별자 (순차 증가하는 정수)\nConsumer가 어디까지 읽었는지 추적하는 위치 표시\n자동/수동 커밋을 통해 관리\n_consumeroffsets 토픽에 저장됨\n\n활용: 파티션 수를 늘려 처리량 확장, Offset을 조절하여 메시지 재처리 가능",
    "references": [
      {
        "title": "Apache Kafka Documentation - Topics and Logs",
        "url": "https://kafka.apache.org/documentation/#intro_topics"
      }
    ],
    "keywords": [
      "partition",
      "topic",
      "consumer",
      "offset",
      "파티션",
      "물리적으로",
      "분할한",
      "단위",
      "파티션은",
      "순서가",
      "보장된",
      "불변의",
      "메시지",
      "시퀀스",
      "병렬"
    ]
  },
  {
    "id": "KAFKA-005",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka의 메시지 보존 정책(retention policy)은 어떻게 작동하나요?",
    "answer": "Kafka는 두 가지 메시지 보존 정책을 제공합니다:\n\n시간 기반 보존 (Time-based)\nlog.retention.hours/minutes/ms: 메시지 보존 기간 설정\n기본값: 7일 (168시간)\n설정된 시간이 지나면 자동 삭제\n\n크기 기반 보존 (Size-based)\nlog.retention.bytes: 파티션당 최대 로그 크기\n크기 초과 시 오래된 세그먼트부터 삭제\n\n세그먼트 관리\nlog.segment.bytes: 세그먼트 파일 크기 (기본 1GB)\nlog.segment.ms: 세그먼트 롤링 주기\n삭제는 세그먼트 단위로 수행됨\n\n두 정책 모두 설정 시, 먼저 도달하는 조건에 따라 삭제됩니다.",
    "references": [
      {
        "title": "Apache Kafka Documentation - Log Retention",
        "url": "https://kafka.apache.org/documentation/#brokerconfigs_log.retention.hours"
      }
    ],
    "keywords": [
      "kafka",
      "time-based",
      "size-based",
      "가지",
      "메시지",
      "보존",
      "정책을",
      "제공합니다",
      "시간",
      "기반",
      "기간",
      "설정",
      "기본값",
      "설정된",
      "시간이"
    ]
  },
  {
    "id": "KAFKA-006",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Consumer Group의 개념과 이를 통해 메시지 병렬 처리를 어떻게 구현하는지 설명해주세요.",
    "answer": "Consumer Group 개념\n동일한 group.id를 공유하는 Consumer들의 논리적 그룹\n그룹 내 각 Consumer는 서로 다른 파티션을 담당\n하나의 파티션은 그룹 내 하나의 Consumer만 소비 가능\n\n병렬 처리 구현\nTopic의 파티션 수 설정 (예: 6개)\nConsumer Group 생성 후 여러 Consumer 추가\nKafka가 자동으로 파티션을 Consumer에 분배 (Rebalancing)\n각 Consumer가 할당된 파티션을 독립적으로 처리\n\n주의사항\nConsumer 수 > 파티션 수일 경우, 유휴 Consumer 발생\n최적 병렬성: Consumer 수 = 파티션 수\n서로 다른 Consumer Group은 같은 메시지를 독립적으로 소비 가능",
    "references": [
      {
        "title": "Apache Kafka Documentation - Consumer Groups",
        "url": "https://kafka.apache.org/documentation/#intro_consumers"
      }
    ],
    "keywords": [
      "consumer",
      "group",
      "topic",
      "kafka",
      "rebalancing",
      "개념",
      "동일한",
      "공유하는",
      "들의",
      "논리적",
      "그룹",
      "서로",
      "다른",
      "파티션을",
      "담당"
    ]
  },
  {
    "id": "KAFKA-007",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka에서 리플리케이션(replication)의 필요성과 설정 방법은 무엇인가요?",
    "answer": "리플리케이션의 필요성\n브로커 장애 시 데이터 손실 방지\n고가용성(High Availability) 보장\n무중단 서비스 운영 가능\n\n설정 방법\nreplication.factor: 토픽 생성 시 복제본 수 지정 (권장: 3)\ndefault.replication.factor: 기본 복제 계수 설정\nmin.insync.replicas: 최소 동기화 복제본 수 (권장: 2)\n\n동작 방식\n각 파티션에는 1개의 Leader와 N-1개의 Follower\nProducer/Consumer는 Leader와만 통신\nFollower는 Leader로부터 데이터를 복제\nLeader 장애 시 ISR 중 하나가 새 Leader로 선출",
    "references": [
      {
        "title": "Apache Kafka Documentation - Replication",
        "url": "https://kafka.apache.org/documentation/#replication"
      }
    ],
    "keywords": [
      "high",
      "availability",
      "leader",
      "n-1",
      "follower",
      "producer",
      "consumer",
      "isr",
      "리플리케이션의",
      "필요성",
      "브로커",
      "장애",
      "데이터",
      "손실",
      "방지"
    ]
  },
  {
    "id": "KAFKA-008",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 클러스터의 장애 복구(failover) 메커니즘에 대해 설명해주세요.",
    "answer": "Leader 선출 과정\nController가 브로커 장애 감지 (ZooKeeper/KRaft 통해)\n장애 브로커가 담당하던 파티션의 ISR 목록 확인\nISR 중 하나를 새로운 Leader로 선출\n메타데이터 업데이트 및 클라이언트에 전파\n\nFailover 설정\nunclean.leader.election.enable: ISR 외 복제본의 리더 승격 허용 여부 (기본: false)\nleader.imbalance.check.interval.seconds: 리더 재분배 주기\ncontrolled.shutdown.enable: 정상 종료 시 리더 이전 여부\n\n클라이언트 복구\nProducer: 재시도 로직으로 새 Leader에 재전송\nConsumer: 새 Leader로부터 이어서 소비\n\n주의: unclean.leader.election.enable=true는 데이터 손실 가능성이 있으므로 신중히 설정",
    "references": [
      {
        "title": "Apache Kafka Documentation - Leader Election",
        "url": "https://kafka.apache.org/documentation/#design_replicatedlog"
      }
    ],
    "keywords": [
      "leader",
      "controller",
      "zookeeper",
      "kraft",
      "isr",
      "failover",
      "producer",
      "consumer",
      "선출",
      "과정",
      "브로커",
      "장애",
      "감지",
      "브로커가",
      "담당하던"
    ]
  },
  {
    "id": "KAFKA-009",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka Connect의 역할과 이를 활용한 데이터 파이프라인 구축 방법은 무엇인가요?",
    "answer": "Kafka Connect 역할\n외부 시스템과 Kafka 간 데이터 스트리밍을 위한 프레임워크\n코드 작성 없이 설정만으로 데이터 파이프라인 구축\nSource Connector: 외부 → Kafka로 데이터 수집\nSink Connector: Kafka → 외부로 데이터 전송\n\n데이터 파이프라인 구축 방법\nConnect 클러스터 설정 (standalone/distributed 모드)\nConnector 플러그인 설치 (JDBC, S3, Elasticsearch 등)\nConnector 설정 JSON 작성\nREST API로 Connector 배포",
    "references": [
      {
        "title": "Apache Kafka Documentation - Connect",
        "url": "https://kafka.apache.org/documentation/#connect"
      }
    ],
    "keywords": [
      "kafka",
      "connect",
      "source",
      "connector",
      "sink",
      "jdbc",
      "elasticsearch",
      "json",
      "rest",
      "api",
      "역할",
      "외부",
      "시스템과",
      "데이터",
      "스트리밍을"
    ]
  },
  {
    "id": "KAFKA-010",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka Streams와 KSQL의 차이점 및 각각의 사용 사례에 대해 설명해주세요.",
    "answer": "Kafka Streams\nJava/Scala 라이브러리 (별도 클러스터 불필요)\n복잡한 스트림 처리 로직 구현 가능\n마이크로서비스에 내장하여 사용\n사용 사례: 실시간 데이터 변환, 집계, 조인\n\nKSQL (ksqlDB)\nSQL 기반 스트리밍 쿼리 엔진\n별도의 KSQL 서버 클러스터 필요\n코드 없이 SQL만으로 스트림 처리\n사용 사례: 빠른 프로토타이핑, 데이터 분석, 간단한 ETL\n\n주요 차이점\n구분   Kafka Streams   KSQL\n\n언어   Java/Scala   SQL\n배포   애플리케이션 내장   별도 클러스터\n복잡도   높은 유연성   낮은 진입 장벽\n적합 대상   개발자   데이터 분석가",
    "references": [
      {
        "title": "Apache Kafka Documentation - Streams",
        "url": "https://kafka.apache.org/documentation/streams/"
      }
    ],
    "keywords": [
      "kafka",
      "streams",
      "java",
      "scala",
      "ksql",
      "sql",
      "etl",
      "라이브러리",
      "별도",
      "클러스터",
      "불필요",
      "복잡한",
      "스트림",
      "처리",
      "로직"
    ]
  },
  {
    "id": "KAFKA-011",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka에서 Exactly-Once Semantics를 구현하는 방법에 대해 설명해주세요.",
    "answer": "Exactly-Once Semantics (EOS) 구현 방법\nIdempotent Producer\nenable.idempotence=true 설정\nProducer ID와 시퀀스 번호로 중복 메시지 방지\n단일 파티션 내에서 exactly-once 보장\nTransactional API\n여러 파티션에 걸친 원자적 쓰기\ntransactional.id 설정 필요\nConsumer 설정\nisolation.level=readcommitted: 커밋된 트랜잭션만 읽기\n수동 오프셋 커밋으로 처리 완료 후 커밋\n\nKafka Streams\nprocessing.guarantee=exactlyonce_v2 설정으로 자동 EOS 지원",
    "references": [
      {
        "title": "Apache Kafka Documentation - Transactions",
        "url": "https://kafka.apache.org/documentation/#semantics"
      }
    ],
    "keywords": [
      "exactly-once",
      "semantics",
      "eos",
      "idempotent",
      "producer",
      "transactional",
      "api",
      "consumer",
      "kafka",
      "streams",
      "구현",
      "방법",
      "설정",
      "시퀀스",
      "번호로"
    ]
  },
  {
    "id": "KAFKA-012",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Producer 측에서 발생할 수 있는 메시지 중복 문제를 어떻게 해결할 수 있나요?",
    "answer": "중복 발생 원인\n네트워크 오류로 ACK 미수신 후 재전송\nProducer 재시작 후 동일 메시지 재전송\n브로커 장애 복구 과정에서의 중복\n\n해결 방법\nIdempotent Producer 활성화\nPID(Producer ID) + Sequence Number로 중복 감지 및 무시\nTransactional Producer 사용\n트랜잭션 단위로 원자적 전송 보장\n장애 복구 시에도 중복 방지\nConsumer 측 멱등성 처리\n메시지에 고유 ID 포함\n처리 전 중복 체크 (DB unique constraint, Redis 등)\n멱등한 처리 로직 설계",
    "references": [
      {
        "title": "Apache Kafka Documentation - Idempotent Producer",
        "url": "https://kafka.apache.org/documentation/#producerconfigs_enable.idempotence"
      }
    ],
    "keywords": [
      "ack",
      "producer",
      "idempotent",
      "pid",
      "sequence",
      "number",
      "transactional",
      "consumer",
      "redis",
      "중복",
      "발생",
      "원인",
      "네트워크",
      "오류로",
      "미수신"
    ]
  },
  {
    "id": "KAFKA-013",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka Consumer가 재시작될 때 오프셋(offset) 관리를 어떻게 수행하나요?",
    "answer": "Offset 저장 위치\n내부 토픽 _consumeroffsets에 저장\nConsumer Group ID와 Topic-Partition 별로 관리\n\n재시작 시 동작\nConsumer가 Group에 조인\n마지막 커밋된 Offset 조회\n해당 Offset부터 메시지 소비 재개\n\nOffset Reset 정책 (auto.offset.reset)\nearliest: 가장 처음 Offset부터 시작\nlatest: 가장 최근 Offset부터 시작 (기본값)\nnone: Offset 없으면 예외 발생\n\n커밋 전략\n\n수동 커밋 방식\ncommitSync(): 동기 커밋 (블로킹)\ncommitAsync(): 비동기 커밋 (논블로킹)",
    "references": [
      {
        "title": "Apache Kafka Documentation - Consumer Configs",
        "url": "https://kafka.apache.org/documentation/#consumerconfigs"
      }
    ],
    "keywords": [
      "offset",
      "consumer",
      "group",
      "topic-partition",
      "reset",
      "저장",
      "위치",
      "내부",
      "토픽",
      "별로",
      "관리",
      "재시작",
      "동작",
      "조인",
      "마지막"
    ]
  },
  {
    "id": "KAFKA-014",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 로그 컴팩션(log compaction)이란 무엇이며, 어떤 상황에서 사용되나요?",
    "answer": "Log Compaction 개념\n동일한 키를 가진 메시지 중 최신 값만 유지하는 보존 정책\n키-값 저장소처럼 각 키의 최종 상태만 보관\n삭제가 아닌 압축을 통해 로그 크기 감소\n\n설정 방법\n\n사용 사례\nCDC (Change Data Capture): DB 변경 이벤트 저장\n상태 저장소: 사용자 설정, 세션 정보\nKafka Streams State Store: 내부 상태 복원\nConsumer Offset 토픽: _consumeroffsets\n\nTombstone 레코드\n키에 null 값을 전송하면 해당 키 삭제 표시\ndelete.retention.ms 후 완전 삭제",
    "references": [
      {
        "title": "Apache Kafka Documentation - Log Compaction",
        "url": "https://kafka.apache.org/documentation/#compaction"
      }
    ],
    "keywords": [
      "log",
      "compaction",
      "cdc",
      "change",
      "data",
      "capture",
      "kafka",
      "streams",
      "state",
      "store",
      "consumer",
      "offset",
      "tombstone",
      "개념",
      "동일한"
    ]
  },
  {
    "id": "KAFKA-015",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 성능 튜닝을 위한 주요 고려 사항에는 어떤 것들이 있나요?",
    "answer": "Producer 튜닝\nbatch.size: 배치 크기 증가 (기본 16KB → 64KB 이상)\nlinger.ms: 배치 대기 시간 (0 → 5-100ms)\ncompression.type: 압축 활성화 (lz4, snappy)\nbuffer.memory: 버퍼 메모리 확대\n\nConsumer 튜닝\nfetch.min.bytes: 최소 fetch 크기 증가\nfetch.max.wait.ms: 대기 시간 조정\nmax.poll.records: 폴링당 레코드 수 조정\n\nBroker 튜닝\nnum.io.threads: I/O 스레드 수 (디스크 수에 맞게)\nnum.network.threads: 네트워크 스레드 수\nsocket.send.buffer.bytes/socket.receive.buffer.bytes: 소켓 버퍼 크기\nlog.flush.interval.messages: 디스크 플러시 간격\n\n일반 고려사항\n파티션 수 적정 설계\nJVM 힙 설정 (6-8GB 권장)\n페이지 캐시를 위한 OS 메모리 확보",
    "references": [
      {
        "title": "Apache Kafka Documentation - Configuration",
        "url": "https://kafka.apache.org/documentation/#configuration"
      }
    ],
    "keywords": [
      "producer",
      "consumer",
      "broker",
      "jvm",
      "튜닝",
      "배치",
      "크기",
      "증가",
      "기본",
      "이상",
      "대기",
      "시간",
      "압축",
      "활성화",
      "버퍼"
    ]
  },
  {
    "id": "KAFKA-016",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 클러스터 구성 시 네트워크 및 하드웨어 설정에서 고려해야 할 점은 무엇인가요?",
    "answer": "네트워크 설정\n브로커 간 전용 네트워크 대역폭 확보 (10Gbps 권장)\n클라이언트-브로커 간 낮은 레이턴시 네트워크\nsocket.send.buffer.bytes, socket.receive.buffer.bytes 튜닝\nTCP 설정 최적화 (net.core.rmem_max 등)\n\n스토리지\nSSD 권장 (처리량 향상)\nRAID 10 또는 JBOD 구성\n여러 디스크에 로그 디렉토리 분산 (log.dirs)\nXFS 파일시스템 권장\n\n메모리\nJVM 힙: 6-8GB (과도한 GC 방지)\n나머지는 OS 페이지 캐시용으로 확보\n총 메모리: 32-64GB 권장\n\nCPU\n압축 사용 시 CPU 코어 중요\n최소 8코어 이상 권장\n\n파티션/브로커 비율\n브로커당 파티션 수 제한 (4,000개 이하 권장)\n리더 파티션 균등 분배",
    "references": [
      {
        "title": "Apache Kafka Documentation - Hardware and OS",
        "url": "https://kafka.apache.org/documentation/#hwandos"
      }
    ],
    "keywords": [
      "tcp",
      "rmem_max",
      "ssd",
      "raid",
      "jbod",
      "xfs",
      "jvm",
      "cpu",
      "네트워크",
      "설정",
      "브로커",
      "전용",
      "대역폭",
      "확보",
      "권장"
    ]
  },
  {
    "id": "KAFKA-017",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka에서 데이터 손실을 방지하기 위한 전략은 무엇인가요?",
    "answer": "Producer 설정\nacks=all: 모든 ISR 복제 완료 후 ACK\nretries: 충분한 재시도 횟수 설정\nenable.idempotence=true: 멱등성 활성화\n\nBroker 설정\nreplication.factor=3: 3개 이상 복제본\nmin.insync.replicas=2: 최소 2개 동기화 필수\nunclean.leader.election.enable=false: 비동기 복제본의 리더 승격 방지\ndefault.replication.factor=3: 기본 복제 계수\n\nConsumer 설정\nenable.auto.commit=false: 수동 오프셋 커밋\n처리 완료 후 커밋 (at-least-once 보장)\n\n운영 전략\n다중 데이터센터 복제 (MirrorMaker 2)\n정기적인 백업 및 복구 테스트\n모니터링: Under-replicated partitions 감시\n\n조합 예시\n\n→ 최소 2개 브로커 장애까지 데이터 안전",
    "references": [
      {
        "title": "Apache Kafka Documentation - Durability",
        "url": "https://kafka.apache.org/documentation/#design_ha"
      }
    ],
    "keywords": [
      "producer",
      "isr",
      "ack",
      "broker",
      "consumer",
      "at-least",
      "mirrormaker",
      "under-replicated",
      "설정",
      "모든",
      "복제",
      "완료",
      "충분한",
      "재시도",
      "횟수"
    ]
  },
  {
    "id": "KAFKA-018",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka의 ACL(Access Control List) 및 보안 설정 방법에 대해 설명해주세요.",
    "answer": "ACL 개념\n리소스(Topic, Consumer Group 등)에 대한 접근 권한 제어\nPrincipal(사용자/서비스)별로 허용/거부 규칙 정의\n\nACL 구성 요소\nPrincipal: 접근 주체 (User:alice)\nResource: 대상 리소스 (Topic:orders)\nOperation: 허용 작업 (Read, Write, Create 등)\nPermission: Allow 또는 Deny\n\n설정 방법\nBroker 설정\nACL 추가\nACL 조회",
    "references": [
      {
        "title": "Apache Kafka Documentation - Authorization",
        "url": "https://kafka.apache.org/documentation/#security_authz"
      }
    ],
    "keywords": [
      "acl",
      "topic",
      "consumer",
      "group",
      "principal",
      "user",
      "resource",
      "operation",
      "read",
      "write",
      "create",
      "permission",
      "allow",
      "deny",
      "broker"
    ]
  },
  {
    "id": "KAFKA-019",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "SSL/TLS 및 SASL을 사용한 Kafka 보안 구성 방법에 대해 설명해주세요.",
    "answer": "SSL/TLS (전송 암호화)\n인증서 생성 (keytool 사용)\nBroker 설정\n\nSASL (인증)\nSASL/PLAIN (간단한 사용자/비밀번호)\nSASL/SCRAM (안전한 비밀번호 저장)\nSASL/GSSAPI (Kerberos)\n엔터프라이즈 환경에서 주로 사용\nKerberos KDC 연동 필요\n\n권장 조합: SASLSSL (인증 + 암호화)",
    "references": [
      {
        "title": "Apache Kafka Documentation - Security",
        "url": "https://kafka.apache.org/documentation/#security"
      }
    ],
    "keywords": [
      "ssl",
      "tls",
      "broker",
      "sasl",
      "plain",
      "scram",
      "gssapi",
      "kerberos",
      "kdc",
      "saslssl",
      "전송",
      "암호화",
      "인증서",
      "생성",
      "사용"
    ]
  },
  {
    "id": "KAFKA-020",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka Broker 재시작 시 클러스터 안정성을 유지하는 방법은 무엇인가요?",
    "answer": "Rolling Restart 절차\n브로커의 controlled.shutdown.enable=true 확인\n한 번에 하나의 브로커만 재시작\nISR이 복구될 때까지 대기 후 다음 브로커 진행\n\n안정성 유지 설정\n\n재시작 전 확인 사항\n\n모범 사례\n피크 시간 외 재시작 수행\n리더 재분배 자동화 (auto.leader.rebalance.enable=true)\n모니터링 알림 설정\n충분한 복제본 수 유지 (3개 이상)",
    "references": [
      {
        "title": "Apache Kafka Documentation - Broker Configs",
        "url": "https://kafka.apache.org/documentation/#brokerconfigs"
      }
    ],
    "keywords": [
      "rolling",
      "restart",
      "isr",
      "절차",
      "브로커의",
      "확인",
      "번에",
      "하나의",
      "브로커만",
      "재시작",
      "복구될",
      "때까지",
      "대기",
      "다음",
      "브로커"
    ]
  },
  {
    "id": "KAFKA-021",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "In-Sync Replica(ISR)의 역할과 중요성은 무엇인가요?",
    "answer": "ISR (In-Sync Replica) 개념\nLeader와 동기화된 Replica들의 집합\nLeader를 포함한 \"충분히 최신 상태\"인 복제본들\nreplica.lag.time.max.ms 내에 복제된 복제본만 ISR에 포함\n\nISR의 역할\n리더 선출 후보: Leader 장애 시 ISR 중에서 새 Leader 선출\nACK 대상: acks=all 시 ISR 모두에 복제 완료 후 응답\n데이터 일관성: 동기화된 복제본만 서비스 참여\n\n중요성\nISR 크기가 min.insync.replicas 미만이면 Producer 쓰기 실패\nISR 축소는 데이터 손실 위험 신호\nUnder-replicated 파티션 모니터링 필수\n\n관련 설정\n\n모니터링 지표\nkafka.server:type=ReplicaManager,name=UnderReplicatedPartitions\n0이 아니면 즉시 조사 필요",
    "references": [
      {
        "title": "Apache Kafka Documentation - ISR",
        "url": "https://kafka.apache.org/documentation/#design_replicatedlog"
      }
    ],
    "keywords": [
      "isr",
      "in-sync",
      "replica",
      "leader",
      "ack",
      "producer",
      "under-replicated",
      "replicamanager",
      "underreplicatedpartitions",
      "개념",
      "동기화된",
      "들의",
      "집합",
      "포함한",
      "충분히"
    ]
  },
  {
    "id": "KAFKA-022",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka에서 메시지의 순서를 보장하는 방법은 무엇인가요?",
    "answer": "파티션 내 순서 보장\nKafka는 단일 파티션 내에서만 메시지 순서 보장\n파티션 간에는 순서 보장 없음\n\n순서 보장 방법\n파티션 키 사용\n단일 파티션 토픽 (처리량 제한됨)\nProducer 설정\n\n주의사항\nmax.in.flight.requests.per.connection > 1이고 멱등성 비활성화 시, 재시도로 인해 순서 역전 가능\nConsumer는 단일 스레드로 파티션 처리 권장",
    "references": [
      {
        "title": "Apache Kafka Documentation - Message Ordering",
        "url": "https://kafka.apache.org/documentation/#design_quotasandguarantees"
      }
    ],
    "keywords": [
      "kafka",
      "producer",
      "consumer",
      "파티션",
      "순서",
      "보장",
      "단일",
      "내에서만",
      "메시지",
      "간에는",
      "없음",
      "방법",
      "사용",
      "토픽",
      "처리량"
    ]
  },
  {
    "id": "KAFKA-023",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Producer의 ACK 설정 옵션(0, 1, all)의 차이점과 의미에 대해 설명해주세요.",
    "answer": "ACK 설정 옵션\n\nacks=0\nProducer는 브로커 응답을 기다리지 않음\n가장 빠른 전송 속도\n메시지 손실 가능성 높음\n사용 사례: 로그, 메트릭 등 손실 허용 데이터\n\nacks=1\nLeader가 로컬 로그에 기록 후 응답\nLeader 장애 시 데이터 손실 가능 (Follower 복제 전)\n적절한 성능과 신뢰성 균형\n사용 사례: 일반적인 애플리케이션\n\nacks=all (또는 -1)\n모든 ISR이 복제 완료 후 응답\n가장 높은 내구성 보장\n가장 느린 전송 속도\nmin.insync.replicas와 함께 사용 권장\n사용 사례: 금융 데이터, 주문 등 중요 데이터\n\n비교 요약\nACK   속도   내구성   손실 위험\n\n0   최고   없음   높음\n1   중간   Leader만   중간\nall   낮음   ISR 전체   낮음",
    "references": [
      {
        "title": "Apache Kafka Documentation - Producer Configs",
        "url": "https://kafka.apache.org/documentation/#producerconfigs_acks"
      }
    ],
    "keywords": [
      "ack",
      "producer",
      "leader",
      "follower",
      "isr",
      "설정",
      "옵션",
      "브로커",
      "응답을",
      "기다리지",
      "않음",
      "가장",
      "빠른",
      "전송",
      "속도"
    ]
  },
  {
    "id": "KAFKA-024",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka와 RabbitMQ 같은 다른 메시징 시스템의 주요 차이점은 무엇인가요?",
    "answer": "아키텍처 차이\n\n구분   Kafka   RabbitMQ\n\n모델   로그 기반   메시지 브로커\n메시지 저장   영구 저장 (retention)   소비 후 삭제\n소비 방식   Pull (Consumer가 가져감)   Push (Broker가 전달)\n프로토콜   자체 프로토콜   AMQP\n\n주요 차이점\n메시지 재처리\nKafka: Offset 조정으로 재처리 가능\nRabbitMQ: 기본적으로 소비 후 삭제\n처리량\nKafka: 높은 처리량에 최적화 (초당 수백만 건)\nRabbitMQ: 중간 처리량, 낮은 지연시간\nConsumer 확장\nKafka: 파티션 기반 병렬 처리\nRabbitMQ: 큐 경쟁 방식\n사용 사례\nKafka: 로그 수집, 이벤트 스트리밍, 데이터 파이프라인\nRabbitMQ: 작업 큐, RPC, 복잡한 라우팅\n\n선택 기준\n대용량 스트리밍 → Kafka\n복잡한 라우팅, 유연한 메시징 패턴 → RabbitMQ",
    "references": [
      {
        "title": "Apache Kafka Documentation - Introduction",
        "url": "https://kafka.apache.org/documentation/#introduction"
      }
    ],
    "keywords": [
      "kafka",
      "rabbitmq",
      "pull",
      "consumer",
      "push",
      "broker",
      "amqp",
      "offset",
      "rpc",
      "아키텍처",
      "차이",
      "구분",
      "모델",
      "로그",
      "기반"
    ]
  },
  {
    "id": "KAFKA-025",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 클러스터의 Zero Downtime 배포 전략에 대해 설명해주세요.",
    "answer": "Rolling Upgrade 전략\n사전 준비\n복제 계수 3 이상 확인\nmin.insync.replicas=2 설정\nUnder-replicated 파티션 없음 확인\n브로커 업그레이드 절차\n클라이언트 호환성\ninter.broker.protocol.version 점진적 업그레이드\nlog.message.format.version 설정 유지 후 변경\n\n설정 예시\n\n모니터링\nISR 상태 지속 확인\nConsumer lag 모니터링\n클라이언트 에러 확인",
    "references": [
      {
        "title": "Apache Kafka Documentation - Upgrading",
        "url": "https://kafka.apache.org/documentation/#upgrade"
      }
    ],
    "keywords": [
      "rolling",
      "upgrade",
      "under-replicated",
      "isr",
      "consumer",
      "전략",
      "사전",
      "준비",
      "복제",
      "계수",
      "이상",
      "확인",
      "설정",
      "파티션",
      "없음"
    ]
  },
  {
    "id": "KAFKA-026",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "스트림 처리와 배치 처리의 차이점을 Kafka 관점에서 설명해주세요.",
    "answer": "배치 처리 (Batch Processing)\n일정 기간 데이터를 모아서 한 번에 처리\n높은 처리량, 높은 지연시간\nKafka 활용: Consumer가 주기적으로 대량 데이터 소비\n\n스트림 처리 (Stream Processing)\n데이터 도착 즉시 실시간 처리\n낮은 지연시간, 연속적인 처리\nKafka 활용: Kafka Streams, KSQL\n\nKafka에서의 차이\n\n구분   배치 처리   스트림 처리\n\n도구   Consumer + Spark/Flink   Kafka Streams, KSQL\n지연   분~시간   밀리초~초\n윈도우   고정 시간 범위   텀블링/슬라이딩/세션\n상태   외부 저장소   State Store (RocksDB)\n\nKafka Streams의 스트림 처리 특징\n\nLambda 아키텍처\nKafka를 중심으로 배치 + 스트림 동시 처리\n배치 레이어: 정확한 결과\n스피드 레이어: 실시간 근사 결과",
    "references": [
      {
        "title": "Apache Kafka Documentation - Streams Concepts",
        "url": "https://kafka.apache.org/documentation/streams/core-concepts"
      }
    ],
    "keywords": [
      "batch",
      "processing",
      "kafka",
      "consumer",
      "stream",
      "streams",
      "ksql",
      "spark",
      "flink",
      "state",
      "store",
      "rocksdb",
      "lambda",
      "배치",
      "처리"
    ]
  },
  {
    "id": "KAFKA-027",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka에서 멀티 테넌시(Multi-Tenancy)를 어떻게 지원하나요?",
    "answer": "멀티 테넌시 구현 방법\n토픽 네이밍 컨벤션\nACL 기반 접근 제어\nQuota 설정\n\nQuota 종류\nproducerbyterate: 초당 Producer 전송량 제한\nconsumerbyterate: 초당 Consumer 수신량 제한\nrequest_percentage: CPU 사용률 제한\n\n격리 수준\n방식   격리 수준   운영 복잡도\n\n네이밍 컨벤션   낮음   낮음\nACL + Quota   중간   중간\n별도 클러스터   높음   높음\n\n모범 사례\n테넌트별 전용 Consumer Group\n모니터링 대시보드 분리\n네트워크 격리 (VLAN/VPC)",
    "references": [
      {
        "title": "Apache Kafka Documentation - Quotas",
        "url": "https://kafka.apache.org/documentation/#design_quotas"
      }
    ],
    "keywords": [
      "acl",
      "quota",
      "producer",
      "consumer",
      "request_percentage",
      "cpu",
      "group",
      "vlan",
      "vpc",
      "멀티",
      "테넌시",
      "구현",
      "방법",
      "토픽",
      "네이밍"
    ]
  },
  {
    "id": "KAFKA-028",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 클러스터 모니터링을 위한 주요 지표와 사용 도구에는 어떤 것들이 있나요?",
    "answer": "주요 모니터링 지표\n\nBroker 지표\nUnderReplicatedPartitions: 복제 지연 파티션 수 (0이어야 함)\nActiveControllerCount: 활성 컨트롤러 수 (클러스터당 1)\nOfflinePartitionsCount: 오프라인 파티션 수 (0이어야 함)\nRequestsPerSec: 초당 요청 수\nBytesInPerSec/BytesOutPerSec: 네트워크 처리량\n\nProducer 지표\nrecord-send-rate: 초당 전송 레코드 수\nrecord-error-rate: 전송 실패율\nrequest-latency-avg: 평균 요청 지연시간\n\nConsumer 지표\nrecords-lag-max: 최대 Consumer Lag\nrecords-consumed-rate: 초당 소비 레코드 수\ncommit-latency-avg: 오프셋 커밋 지연시간\n\n모니터링 도구\nJMX: Kafka 기본 메트릭 노출\nPrometheus + Grafana: 시계열 메트릭 수집 및 시각화\nKafka Manager/CMAK: 클러스터 관리 UI\nConfluent Control Center: 상용 모니터링 솔루션\nBurrow: Consumer Lag 전문 모니터링",
    "references": [
      {
        "title": "Apache Kafka Documentation - Monitoring",
        "url": "https://kafka.apache.org/documentation/#monitoring"
      }
    ],
    "keywords": [
      "broker",
      "underreplicatedpartitions",
      "activecontrollercount",
      "offlinepartitionscount",
      "requestspersec",
      "bytesinpersec",
      "bytesoutpersec",
      "producer",
      "record-send",
      "record-error",
      "request-latency",
      "consumer",
      "records-lag",
      "lag",
      "records-consumed"
    ]
  },
  {
    "id": "KAFKA-029",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Consumer Rebalance 과정과 이를 최적화하기 위한 방법은 무엇인가요?",
    "answer": "Rebalance 발생 조건\nConsumer 그룹에 새 Consumer 참여/이탈\nConsumer가 heartbeat 미전송 (세션 타임아웃)\n토픽 파티션 수 변경\n정규식 구독 토픽 변경\n\nRebalance 과정\nGroup Coordinator가 리밸런스 트리거\n모든 Consumer가 파티션 할당 해제 (Stop-the-World)\nConsumer Leader가 새 파티션 할당 계획 수립\n각 Consumer에 파티션 재할당\n소비 재개\n\n최적화 방법\nCooperative Rebalancing (증분 리밸런스)\n전체 중단 없이 점진적 재할당\nStatic Membership\nConsumer 재시작 시 즉시 파티션 복구\n세션 타임아웃 최적화\npoll() 처리 시간 단축\nmax.poll.records 조정\n처리 로직 최적화",
    "references": [
      {
        "title": "Apache Kafka Documentation - Consumer Rebalance",
        "url": "https://kafka.apache.org/documentation/#consumerconfigs_partition.assignment.strategy"
      }
    ],
    "keywords": [
      "rebalance",
      "consumer",
      "group",
      "coordinator",
      "stop-the-world",
      "leader",
      "cooperative",
      "rebalancing",
      "static",
      "membership",
      "발생",
      "조건",
      "그룹에",
      "참여",
      "이탈"
    ]
  },
  {
    "id": "KAFKA-030",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Producer 성능 병목 현상 발생 시 해결 전략은 무엇인가요?",
    "answer": "병목 진단 지표\nrecord-queue-time-avg: 배치 대기 시간\nrequest-latency-avg: 요청 응답 시간\nbuffer-available-bytes: 사용 가능 버퍼\n\n해결 전략\n배치 최적화\n압축 활성화\n병렬 처리 증가\n비동기 전송\n파티션 수 증가\n더 많은 브로커에 부하 분산\nACK 수준 조정 (내구성 트레이드오프)\n\n하드웨어 개선\n네트워크 대역폭 확장\n브로커 디스크 I/O 개선 (SSD)\n브로커 수 증가",
    "references": [
      {
        "title": "Apache Kafka Documentation - Producer Performance",
        "url": "https://kafka.apache.org/documentation/#producerconfigs"
      }
    ],
    "keywords": [
      "record-queue",
      "time-avg",
      "request-latency",
      "buffer-available",
      "ack",
      "ssd",
      "병목",
      "진단",
      "지표",
      "배치",
      "대기",
      "시간",
      "요청",
      "응답",
      "사용"
    ]
  },
  {
    "id": "KAFKA-031",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "ZooKeeper의 역할과 KRaft 모드의 차이점에 대해 설명해주세요.",
    "answer": "ZooKeeper의 역할\n클러스터 메타데이터 저장 (토픽, 파티션, 브로커 정보)\nController 선출\n브로커 상태 감지 (Ephemeral 노드)\nACL 및 설정 저장\n\nKRaft (Kafka Raft) 모드\nKafka 자체 내장 메타데이터 관리 (ZooKeeper 제거)\nRaft 합의 프로토콜 사용\nKafka 3.3부터 프로덕션 준비 완료\n\n주요 차이점\n\n구분   ZooKeeper 모드   KRaft 모드\n\n의존성   ZooKeeper 클러스터 필요   Kafka만으로 운영\n메타데이터   ZooKeeper에 저장   내부 토픽에 저장\n확장성   파티션 수 제한 (수만 개)   수백만 파티션 가능\n운영   두 시스템 관리   단일 시스템\n복구   느린 컨트롤러 페일오버   빠른 복구\n\nKRaft 설정 예시\n\n마이그레이션: ZooKeeper → KRaft 무중단 전환 도구 제공",
    "references": [
      {
        "title": "Apache Kafka Documentation - KRaft",
        "url": "https://kafka.apache.org/documentation/#kraft"
      }
    ],
    "keywords": [
      "zookeeper",
      "controller",
      "ephemeral",
      "acl",
      "kraft",
      "kafka",
      "raft",
      "역할",
      "클러스터",
      "메타데이터",
      "저장",
      "토픽",
      "파티션",
      "브로커",
      "정보"
    ]
  },
  {
    "id": "KAFKA-032",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka의 메시지 압축 옵션(gzip, snappy, lz4 등)의 장단점은 무엇인가요?",
    "answer": "압축 옵션 비교\n\n압축 방식   압축률   속도   CPU 사용량   권장 사용\n\ngzip   높음   느림   높음   네트워크 대역폭 제한\nsnappy   중간   빠름   낮음   일반적 사용\nlz4   중간   매우 빠름   낮음   고성능 권장\nzstd   높음   빠름   중간   균형 잡힌 선택\n\n설정 방법\n\n장단점 상세\n\ngzip\n장점: 최고 압축률, 범용 호환성\n단점: CPU 집약적, 지연시간 증가\n\nsnappy\n장점: 빠른 압축/해제, 낮은 CPU\n단점: 압축률 상대적으로 낮음\n\nlz4\n장점: 가장 빠른 속도, 매우 낮은 CPU\n단점: gzip보다 낮은 압축률\n권장: 대부분의 프로덕션 환경\n\nzstd\n장점: 높은 압축률 + 적절한 속도\n단점: 구버전 호환성 이슈",
    "references": [
      {
        "title": "Apache Kafka Documentation - Compression",
        "url": "https://kafka.apache.org/documentation/#producerconfigs_compression.type"
      }
    ],
    "keywords": [
      "cpu",
      "압축",
      "옵션",
      "비교",
      "방식",
      "압축률",
      "속도",
      "사용량",
      "권장",
      "사용",
      "높음",
      "느림",
      "네트워크",
      "대역폭",
      "제한"
    ]
  },
  {
    "id": "KAFKA-033",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "메시지 처리 중 오류가 발생했을 때의 처리 전략(예: DLQ 도입 등)에 대해 설명해주세요.",
    "answer": "에러 처리 전략\n재시도 (Retry)\nDead Letter Queue (DLQ)\n에러 토픽 분리\n재시도 가능 에러 → retry-topic\n영구 실패 → dlq-topic\nSkip/Ignore\n로깅 후 다음 메시지 처리\n중요도 낮은 데이터에 적용\n\nDLQ 구현 모범 사례\n원본 메시지 + 에러 정보 저장\n헤더에 원본 토픽, 파티션, 오프셋 포함\nDLQ 모니터링 및 알림 설정\n재처리 도구 준비\n\nSpring Kafka 예시",
    "references": [
      {
        "title": "Apache Kafka Documentation - Error Handling",
        "url": "https://kafka.apache.org/documentation/#consumerconfigs"
      }
    ],
    "keywords": [
      "retry",
      "dead",
      "letter",
      "queue",
      "dlq",
      "retry-topic",
      "dlq-topic",
      "skip",
      "ignore",
      "spring",
      "kafka",
      "에러",
      "처리",
      "전략",
      "재시도"
    ]
  },
  {
    "id": "KAFKA-034",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 클러스터 확장(Scale-out) 시 고려해야 할 모범 사례는 무엇인가요?",
    "answer": "브로커 추가 시 고려사항\n파티션 재분배\n점진적 확장\n한 번에 하나의 브로커 추가\n네트워크 및 디스크 I/O 모니터링\n재분배 스로틀링 적용\n스로틀 설정\n\n파티션 수 증가\n운영 중 파티션 추가 가능 (감소 불가)\n키 기반 파티셔닝 시 기존 데이터 순서 영향\n\n모범 사례\n충분한 초기 파티션 수 계획\nauto.create.topics.enable=false 권장\nRack-awareness 설정으로 장애 도메인 분리\nLeader 재분배 자동화\n\n확장 전 체크리스트\n[ ] 디스크 용량 계획\n[ ] 네트워크 대역폭 확인\n[ ] ZooKeeper/KRaft 부하 검토\n[ ] 클라이언트 연결 수 확인",
    "references": [
      {
        "title": "Apache Kafka Documentation - Adding Brokers",
        "url": "https://kafka.apache.org/documentation/#basic_ops_cluster_expansion"
      }
    ],
    "keywords": [
      "rack-awareness",
      "leader",
      "zookeeper",
      "kraft",
      "브로커",
      "추가",
      "고려사항",
      "파티션",
      "재분배",
      "점진적",
      "확장",
      "번에",
      "하나의",
      "네트워크",
      "디스크"
    ]
  },
  {
    "id": "KAFKA-035",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka에서 KRaft 모드 전환 시 고려해야 할 사항은 무엇인가요?",
    "answer": "KRaft 전환 전 확인사항\nKafka 버전 3.3 이상 (프로덕션 권장 3.6+)\n모든 클라이언트 호환성 확인\n현재 ZooKeeper 클러스터 상태 정상 확인\n\n마이그레이션 절차\n메타데이터 스냅샷 생성\nKRaft Controller 구성\n점진적 전환\n브로커를 하나씩 KRaft 모드로 재시작\nController 쿼럼 구성\n마지막으로 ZooKeeper 연결 해제\n\n고려사항\n롤백 계획: 전환 전 백업 필수\n다운타임: 무중단 전환 도구 제공되나 테스트 필요\n기능 차이: 일부 기능은 KRaft에서 다르게 동작\n모니터링: 새로운 KRaft 관련 메트릭 추가\n\nKRaft 장점\n운영 단순화 (ZooKeeper 제거)\n빠른 컨트롤러 페일오버\n향상된 확장성 (수백만 파티션)\n\n주의사항\n기존 ACL, Config 마이그레이션 확인\n클라이언트 라이브러리 버전 호환성\n프로덕션 전 충분한 테스트",
    "references": [
      {
        "title": "Apache Kafka Documentation - ZooKeeper to KRaft Migration",
        "url": "https://kafka.apache.org/documentation/#kraft_zk_migration"
      }
    ],
    "keywords": [
      "kraft",
      "kafka",
      "zookeeper",
      "controller",
      "acl",
      "config",
      "전환",
      "확인사항",
      "버전",
      "이상",
      "프로덕션",
      "권장",
      "모든",
      "클라이언트",
      "호환성"
    ]
  },
  {
    "id": "KAFKA-036",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 메시지 전송 지연(latency)을 최소화하는 방법에는 어떤 것들이 있나요?",
    "answer": "Producer 지연 최소화\n\nConsumer 지연 최소화\n\nBroker 튜닝\n\n인프라 최적화\nSSD 스토리지 사용\nProducer/Broker 네트워크 근접 배치\n낮은 레이턴시 네트워크 (10Gbps+)\n\n파티션 전략\n파티션 수 적정 유지 (과도한 파티션은 오버헤드)\n리더 균등 분배\n\n모니터링 지표\nproduce-throttle-time: Producer 스로틀링\nfetch-latency-avg: Consumer fetch 지연\nrequest-latency-avg: 전체 요청 지연\n\n주의: 지연 최소화는 처리량/내구성과 트레이드오프 관계",
    "references": [
      {
        "title": "Apache Kafka Documentation - Performance",
        "url": "https://kafka.apache.org/documentation/#configuration"
      }
    ],
    "keywords": [
      "producer",
      "consumer",
      "broker",
      "ssd",
      "produce-throttle",
      "fetch-latency",
      "request-latency",
      "지연",
      "최소화",
      "튜닝",
      "인프라",
      "최적화",
      "스토리지",
      "사용",
      "네트워크"
    ]
  },
  {
    "id": "KAFKA-037",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Sync와 Async 전송 방식의 차이점과 각각의 장단점은 무엇인가요?",
    "answer": "동기 전송 (Sync)\n\n장점\n전송 성공/실패 즉시 확인\n순서 보장 용이\n에러 처리 직관적\n\n단점\n낮은 처리량 (매 전송마다 대기)\n네트워크 지연에 민감\n\n비동기 전송 (Async)\n\n장점\n높은 처리량 (병렬 전송)\n논블로킹으로 리소스 효율적\n배치 최적화 활용 가능\n\n단점\n에러 처리 복잡\n메모리 관리 필요 (버퍼 초과 시)\n순서 보장 어려움\n\n선택 기준\n상황   권장 방식\n\n고처리량 필요   Async\n엄격한 순서 보장   Sync\n실시간 에러 처리   Sync\n대량 데이터 전송   Async + Callback",
    "references": [
      {
        "title": "Apache Kafka Documentation - Producer API",
        "url": "https://kafka.apache.org/documentation/#producerapi"
      }
    ],
    "keywords": [
      "sync",
      "async",
      "callback",
      "동기",
      "전송",
      "장점",
      "성공",
      "실패",
      "즉시",
      "확인",
      "순서",
      "보장",
      "용이",
      "에러",
      "처리"
    ]
  },
  {
    "id": "KAFKA-038",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 클러스터 운영 시 예상할 수 있는 장애와 그에 대한 대응 방안은 무엇인가요?",
    "answer": "주요 장애 유형 및 대응\n브로커 장애\n증상: UnderReplicatedPartitions 증가\n대응:\nISR에서 자동 리더 선출 확인\n브로커 복구 또는 대체 브로커 투입\nmin.insync.replicas 설정 확인\n디스크 장애\n증상: 로그 쓰기 실패, 브로커 비정상\n대응:\nJBOD 구성 시 해당 디스크만 격리\n파티션 재분배로 데이터 복구\n디스크 교체 후 브로커 재시작\n네트워크 파티션\n증상: 브로커 간 통신 실패, ISR 축소\n대응:\n네트워크 장비 점검\nunclean.leader.election.enable=false 유지\n분할 복구 후 데이터 정합성 확인\nZooKeeper/Controller 장애\n증상: 메타데이터 업데이트 불가\n대응:\nZooKeeper 앙상블 복구\nController 재선출 대기\nKRaft 전환 고려\nConsumer Lag 급증\n원인: 처리 병목, 파티션 불균형\n대응:\nConsumer 스케일 아웃\n파티션 재분배\n처리 로직 최적화\n\n장애 대비 체크리스트\n[ ] 복제 계수 3 이상\n[ ] 다중 AZ/랙 분산\n[ ] 모니터링/알림 설정\n[ ] 정기 DR 훈련",
    "references": [
      {
        "title": "Apache Kafka Documentation - Operations",
        "url": "https://kafka.apache.org/documentation/#operations"
      }
    ],
    "keywords": [
      "underreplicatedpartitions",
      "isr",
      "jbod",
      "zookeeper",
      "controller",
      "kraft",
      "consumer",
      "lag",
      "주요",
      "장애",
      "유형",
      "대응",
      "브로커",
      "증상",
      "증가"
    ]
  },
  {
    "id": "KAFKA-039",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Consumer Lag(지연) 모니터링 방법과 이를 해결하기 위한 전략은 무엇인가요?",
    "answer": "Consumer Lag 개념\n마지막 생산된 Offset과 마지막 소비된 Offset의 차이\nLag이 증가하면 Consumer가 Producer를 따라잡지 못함\n\n모니터링 방법\nkafka-consumer-groups 명령\nJMX 메트릭\nrecords-lag-max: 최대 Lag\nrecords-lag: 파티션별 Lag\n모니터링 도구\nBurrow (LinkedIn 오픈소스)\nPrometheus + kafka_exporter\nConfluent Control Center\n\nLag 해결 전략\nConsumer 확장\n처리 최적화\n병렬 처리\n파티션 증가\n병렬 처리 단위 확대\nConsumer 추가 여유 확보\n일시적 해결\nConsumer Group 리셋 (데이터 손실 주의)\nauto.offset.reset=latest로 재시작\n\n알림 설정 권장값\nWarning: Lag > 10,000\nCritical: Lag > 100,000 또는 지속 증가",
    "references": [
      {
        "title": "Apache Kafka Documentation - Consumer Lag",
        "url": "https://kafka.apache.org/documentation/#basic_ops_consumer_lag"
      }
    ],
    "keywords": [
      "consumer",
      "lag",
      "offset",
      "producer",
      "kafka-consumer",
      "jmx",
      "records-lag",
      "burrow",
      "linkedin",
      "prometheus",
      "kafka_exporter",
      "confluent",
      "control",
      "center",
      "group"
    ]
  },
  {
    "id": "KAFKA-040",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka에서 데이터 일관성을 보장하는 방법은 무엇인가요?",
    "answer": "일관성 보장 메커니즘\n복제와 ISR\n최소 ISR 수 만족 시에만 쓰기 허용\nLeader 장애 시 최신 데이터를 가진 복제본이 승격\nProducer ACK 설정\n트랜잭션\nConsumer 격리 수준\n순서 보장\n단일 파티션 내 순서 보장\n키 기반 파티셔닝으로 관련 메시지 동일 파티션\n\n일관성 vs 가용성 트레이드오프\n설정   일관성   가용성\n\nacks=all, min.insync.replicas=2   높음   중간\nacks=1   중간   높음\nunclean.leader.election=true   낮음   높음",
    "references": [
      {
        "title": "Apache Kafka Documentation - Semantics",
        "url": "https://kafka.apache.org/documentation/#semantics"
      }
    ],
    "keywords": [
      "isr",
      "leader",
      "producer",
      "ack",
      "consumer",
      "일관성",
      "보장",
      "메커니즘",
      "복제와",
      "최소",
      "만족",
      "시에만",
      "쓰기",
      "허용",
      "장애"
    ]
  },
  {
    "id": "KAFKA-041",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Producer의 배치 전송(batch sending) 설정이 성능에 미치는 영향에 대해 설명해주세요.",
    "answer": "배치 관련 설정\n\n성능 영향\n\nbatch.size 증가\n장점: 네트워크 오버헤드 감소, 높은 처리량\n단점: 메모리 사용량 증가, 첫 메시지 지연\n권장: 64KB ~ 256KB\n\nlinger.ms 증가\n장점: 배치 채움률 향상, 압축 효율 증가\n단점: 지연 시간 증가\n권장: 5ms ~ 100ms (처리량 중시)\n\n조합 예시\n\n시나리오   batch.size   linger.ms   효과\n\n저지연   16KB   0   즉시 전송\n고처리량   128KB   50ms   배치 최적화\n균형   64KB   10ms   적절한 균형\n\n압축과의 연계\n큰 배치 + 압축 = 높은 네트워크 효율\n\n모니터링 지표\nbatch-size-avg: 평균 배치 크기\nrecord-queue-time-avg: 배치 대기 시간\ncompression-rate-avg: 압축률",
    "references": [
      {
        "title": "Apache Kafka Documentation - Producer Batching",
        "url": "https://kafka.apache.org/documentation/#producerconfigs_batch.size"
      }
    ],
    "keywords": [
      "batch-size",
      "record-queue",
      "time-avg",
      "compression-rate",
      "배치",
      "관련",
      "설정",
      "성능",
      "영향",
      "증가",
      "장점",
      "네트워크",
      "오버헤드",
      "감소",
      "높은"
    ]
  },
  {
    "id": "KAFKA-042",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka Consumer의 오프셋 커밋 전략(자동 vs 수동 커밋)에 대해 설명해주세요.",
    "answer": "자동 커밋 (Auto Commit)\n\n장점\n구현 간단\n개발자 관리 부담 없음\n\n단점\n메시지 손실 위험 (처리 전 커밋)\n중복 처리 가능 (커밋 후 처리 실패)\n\n수동 커밋 (Manual Commit)\n\n동기 커밋\n\n비동기 커밋\n\n혼합 전략 (권장)\n\n커밋 전략 비교\n전략   메시지 손실   중복 처리   성능\n\n자동 커밋   가능   가능   높음\n처리 후 커밋   없음   가능   중간\n커밋 후 처리   가능   없음   중간",
    "references": [
      {
        "title": "Apache Kafka Documentation - Offset Management",
        "url": "https://kafka.apache.org/documentation/#consumerconfigs_enable.auto.commit"
      }
    ],
    "keywords": [
      "auto",
      "commit",
      "manual",
      "자동",
      "커밋",
      "장점",
      "구현",
      "간단",
      "개발자",
      "관리",
      "부담",
      "없음",
      "단점",
      "메시지",
      "손실"
    ]
  },
  {
    "id": "KAFKA-043",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Dead Letter Queue(DLQ)를 Kafka에서 구현하는 방법은 무엇인가요?",
    "answer": "DLQ 구현 패턴\n기본 DLQ 구현\n재시도 토픽 + DLQ 패턴\nSpring Kafka 활용\n\nDLQ 운영 모범 사례\nDLQ 토픽 별도 모니터링 및 알림\n메시지 원본 정보 보존 (헤더 활용)\nDLQ 메시지 재처리 도구 준비\nDLQ 보존 기간 충분히 설정",
    "references": [
      {
        "title": "Apache Kafka Documentation - Error Handling",
        "url": "https://kafka.apache.org/documentation/"
      }
    ],
    "keywords": [
      "dlq",
      "spring",
      "kafka",
      "구현",
      "패턴",
      "기본",
      "재시도",
      "토픽",
      "활용",
      "운영",
      "모범",
      "사례",
      "별도",
      "모니터링",
      "알림"
    ]
  },
  {
    "id": "KAFKA-044",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 메시지 스키마 관리(Schema Registry)의 역할과 필요성은 무엇인가요?",
    "answer": "Schema Registry 역할\n메시지 스키마(Avro, Protobuf, JSON Schema)를 중앙 저장소에서 관리\nProducer/Consumer 간 스키마 호환성 보장\n스키마 버전 관리 및 진화 지원\n\n필요성\n데이터 계약: Producer/Consumer 간 명확한 데이터 형식 정의\n호환성 검증: 스키마 변경 시 하위/상위 호환성 자동 검증\n효율적 직렬화: 스키마 ID만 전송하여 페이로드 크기 감소\n스키마 진화: 필드 추가/삭제 시 기존 Consumer 영향 최소화\n\n호환성 모드\n모드   설명\n\nBACKWARD   새 스키마로 이전 데이터 읽기 가능\nFORWARD   이전 스키마로 새 데이터 읽기 가능\nFULL   양방향 호환\nNONE   호환성 검사 없음\n\n사용 예시 (Avro)\n\n모범 사례\nBACKWARD 또는 FULL 호환성 사용\n필드 삭제 시 default 값 설정\nCI/CD에서 스키마 호환성 테스트",
    "references": [
      {
        "title": "Confluent Schema Registry Documentation",
        "url": "https://docs.confluent.io/platform/current/schema-registry/"
      }
    ],
    "keywords": [
      "schema",
      "registry",
      "avro",
      "protobuf",
      "json",
      "producer",
      "consumer",
      "backward",
      "forward",
      "full",
      "none",
      "역할",
      "메시지",
      "스키마",
      "중앙"
    ]
  },
  {
    "id": "KAFKA-045",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka와 NoSQL 데이터베이스를 연동할 때 고려해야 할 사항은 무엇인가요?",
    "answer": "연동 방식\nKafka Connect 활용\nConsumer 직접 구현\n\n고려사항\n일관성\n트랜잭션 미지원 NoSQL: 멱등성 설계 필수\n중복 메시지 처리 로직 (upsert 활용)\n성능\n배치 쓰기로 처리량 향상\n인덱스 설계 최적화\n백프레셔 처리\n스키마 관리\nSchema Registry로 데이터 형식 관리\nNoSQL 유연한 스키마와의 조화\n에러 처리\n재시도 로직 구현\nDLQ 활용\n커넥션 풀 관리\n확장성\n파티션 수와 Consumer 병렬성\nNoSQL 샤딩 전략과 조화\n\n데이터베이스별 권장 Connector\nMongoDB: MongoDB Kafka Connector\nCassandra: DataStax Connector\nElasticsearch: Confluent Elasticsearch Sink\nRedis: Redis Sink Connector",
    "references": [
      {
        "title": "Apache Kafka Documentation - Connect",
        "url": "https://kafka.apache.org/documentation/#connect"
      }
    ],
    "keywords": [
      "kafka",
      "connect",
      "consumer",
      "nosql",
      "schema",
      "registry",
      "dlq",
      "connector",
      "mongodb",
      "cassandra",
      "datastax",
      "elasticsearch",
      "confluent",
      "sink",
      "redis"
    ]
  },
  {
    "id": "KAFKA-046",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka Streams의 상태 저장소(State Store) 관리 방식에 대해 설명해주세요.",
    "answer": "State Store 개념\nKafka Streams에서 상태가 필요한 연산(집계, 조인 등)을 위한 로컬 저장소\n기본적으로 RocksDB 사용 (in-memory 옵션도 가능)\n\nState Store 유형\nKeyValueStore: 키-값 저장\nWindowStore: 시간 윈도우별 키-값 저장\nSessionStore: 세션 기반 키-값 저장\n\n내부 동작 방식\n\nChangelog Topic\nState Store 변경사항을 Kafka 토픽에 기록\n장애 복구 시 상태 재구축에 사용\n자동 생성됨 (application.id-storename-changelog)\n\n설정 예시\n\n관리 방법\n\n상태 복구\nChangelog 토픽에서 상태 재구축\nStandby 복제본이 있으면 빠른 복구\n\n모범 사례\n충분한 로컬 디스크 공간 확보\nStandby 복제본 설정으로 복구 시간 단축\nState Store 크기 모니터링",
    "references": [
      {
        "title": "Apache Kafka Documentation - Streams State",
        "url": "https://kafka.apache.org/documentation/streams/developer-guide/processor-api#state-stores"
      }
    ],
    "keywords": [
      "state",
      "store",
      "kafka",
      "streams",
      "rocksdb",
      "in-memory",
      "keyvaluestore",
      "windowstore",
      "sessionstore",
      "changelog",
      "topic",
      "id-storename",
      "standby",
      "개념",
      "에서"
    ]
  },
  {
    "id": "KAFKA-047",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka를 활용한 마이크로서비스 아키텍처 설계 사례에 대해 설명해주세요.",
    "answer": "이벤트 기반 마이크로서비스 패턴\n이벤트 소싱 (Event Sourcing)\n모든 상태 변경을 이벤트로 저장\n이벤트 재생으로 상태 복원 가능\nCQRS (Command Query Responsibility Segregation)\n쓰기와 읽기 모델 분리\n읽기 최적화된 뷰 구성\nSaga 패턴 (분산 트랜잭션)\n보상 트랜잭션으로 일관성 유지\n\n토픽 설계\n\n구현 예시\n\n모범 사례\n이벤트 스키마 버전 관리\n멱등성 처리 필수\n서비스별 Consumer Group 분리",
    "references": [
      {
        "title": "Apache Kafka Documentation - Use Cases",
        "url": "https://kafka.apache.org/documentation/#uses"
      }
    ],
    "keywords": [
      "event",
      "sourcing",
      "cqrs",
      "command",
      "query",
      "responsibility",
      "segregation",
      "saga",
      "consumer",
      "group",
      "이벤트",
      "기반",
      "마이크로서비스",
      "패턴",
      "소싱"
    ]
  },
  {
    "id": "KAFKA-048",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 클러스터에 새로운 브로커를 추가할 때 고려해야 할 주요 요소는 무엇인가요?",
    "answer": "브로커 추가 절차\n새 브로커 설정\n브로커 시작\n파티션 재분배 (선택)\n\n고려 요소\n하드웨어 일관성\n기존 브로커와 동일한 사양 권장\n디스크 용량, 네트워크 대역폭 확인\n네트워크 구성\n기존 브로커와 동일 네트워크 세그먼트\n방화벽 규칙 확인 (9092, 9093 포트)\n파티션 재분배\n자동 분배되지 않음 (수동 재분배 필요)\n스로틀링으로 성능 영향 최소화\n피크 시간 외 수행\nRack Awareness\n장애 도메인 분산\n모니터링\n새 브로커 메트릭 수집 확인\n리더 분배 균형 확인\nUnder-replicated 파티션 없음 확인",
    "references": [
      {
        "title": "Apache Kafka Documentation - Adding Servers",
        "url": "https://kafka.apache.org/documentation/#basic_ops_cluster_expansion"
      }
    ],
    "keywords": [
      "rack",
      "awareness",
      "under-replicated",
      "브로커",
      "추가",
      "절차",
      "설정",
      "시작",
      "파티션",
      "재분배",
      "선택",
      "고려",
      "요소",
      "하드웨어",
      "일관성"
    ]
  },
  {
    "id": "KAFKA-049",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 커넥터(Connector) 개발 및 커스터마이징 방법에 대해 설명해주세요.",
    "answer": "커넥터 유형\nSource Connector: 외부 시스템 → Kafka\nSink Connector: Kafka → 외부 시스템\n\nSource Connector 개발\n\nSink Connector 개발\n\n커스터마이징 포인트\n변환 (SMT - Single Message Transform)\n에러 처리\n\n배포",
    "references": [
      {
        "title": "Apache Kafka Documentation - Connect Development",
        "url": "https://kafka.apache.org/documentation/#connect_development"
      }
    ],
    "keywords": [
      "source",
      "connector",
      "kafka",
      "sink",
      "smt",
      "single",
      "message",
      "transform",
      "커넥터",
      "유형",
      "외부",
      "시스템",
      "개발",
      "커스터마이징",
      "포인트"
    ]
  },
  {
    "id": "KAFKA-050",
    "category": "kafka",
    "categoryName": "Kafka",
    "priority": "P2",
    "question": "Kafka 운영 시 모니터링과 경보 시스템 설정 시 중요한 핵심 지표는 무엇인가요?",
    "answer": "브로커 핵심 지표\n\n지표   설명   임계값\n\nUnderReplicatedPartitions   복제 지연 파티션   > 0 경고\nOfflinePartitionsCount   오프라인 파티션   > 0 위험\nActiveControllerCount   활성 컨트롤러   != 1 위험\nRequestsPerSec   요청 처리량   용량 대비\nNetworkProcessorAvgIdlePercent   네트워크 스레드 유휴율   < 30% 경고\nRequestHandlerAvgIdlePercent   요청 핸들러 유휴율   < 30% 경고\n\nProducer 지표\n지표   설명   임계값\n\nrecord-error-rate   전송 실패율   > 0 경고\nrecord-send-rate   전송 처리량   모니터링\nrequest-latency-avg   평균 지연시간   > 100ms 경고\n\nConsumer 지표\n지표   설명   임계값\n\nrecords-lag-max   최대 Consumer Lag   증가 추세 경고\nfetch-rate   소비 처리량   모니터링\ncommit-latency-avg   커밋 지연시간   > 50ms 경고\n\n시스템 지표\nCPU 사용률 (< 70%)\n메모리 사용률\n디스크 사용률 (< 80%)\n네트워크 I/O\n\n알림 설정 예시 (Prometheus)",
    "references": [
      {
        "title": "Apache Kafka Documentation - Monitoring",
        "url": "https://kafka.apache.org/documentation/#monitoring"
      }
    ],
    "keywords": [
      "underreplicatedpartitions",
      "offlinepartitionscount",
      "activecontrollercount",
      "requestspersec",
      "networkprocessoravgidlepercent",
      "requesthandleravgidlepercent",
      "producer",
      "record-error",
      "record-send",
      "request-latency",
      "consumer",
      "records-lag",
      "lag",
      "fetch-rate",
      "commit-latency"
    ]
  }
];

// 카테고리 목록
const categories = [
  {
    "id": "architecture",
    "name": "아키텍처",
    "priority": "P1",
    "count": 60
  },
  {
    "id": "database",
    "name": "Database",
    "priority": "P1",
    "count": 70
  },
  {
    "id": "ds",
    "name": "자료구조",
    "priority": "P1",
    "count": 63
  },
  {
    "id": "network",
    "name": "Network",
    "priority": "P1",
    "count": 104
  },
  {
    "id": "os",
    "name": "OS",
    "priority": "P1",
    "count": 122
  },
  {
    "id": "elasticsearch",
    "name": "Elasticsearch",
    "priority": "P3",
    "count": 50
  },
  {
    "id": "mongodb",
    "name": "MongoDB",
    "priority": "P3",
    "count": 80
  },
  {
    "id": "redis",
    "name": "Redis",
    "priority": "P2",
    "count": 30
  },
  {
    "id": "crdt",
    "name": "CRDT",
    "priority": "P3",
    "count": 30
  },
  {
    "id": "pl",
    "name": "프로그래밍 언어",
    "priority": "P3",
    "count": 160
  },
  {
    "id": "system_design",
    "name": "시스템 설계",
    "priority": "P3",
    "count": 95
  },
  {
    "id": "websocket",
    "name": "WebSocket",
    "priority": "P3",
    "count": 30
  },
  {
    "id": "ktor",
    "name": "Ktor",
    "priority": "P4",
    "count": 38
  },
  {
    "id": "spring",
    "name": "Spring",
    "priority": "P1",
    "count": 51
  },
  {
    "id": "docker",
    "name": "Docker",
    "priority": "P2",
    "count": 100
  },
  {
    "id": "kubernetes",
    "name": "Kubernetes",
    "priority": "P2",
    "count": 140
  },
  {
    "id": "kafka",
    "name": "Kafka",
    "priority": "P2",
    "count": 50
  }
];

// Node.js 환경에서는 export
if (typeof module !== 'undefined' && module.exports) {
    module.exports = { quizData, categories };
}
